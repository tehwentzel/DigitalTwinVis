{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c766fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Const.data_dir + '/models/'\n",
    "\n",
    "tuned_transition_models = [\n",
    "    'final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
    "    'final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
    "    'final_outcome_model_state1_input83_dims1000_dropout0,0.pt'\n",
    "]\n",
    "tuned_transition_models = [model_dir + f for f in tuned_transition_models]\n",
    "Const.tuned_transition_models = tuned_transition_models\n",
    "Const.tuned_decision_model = model_dir +  'final_decision_model_statedecisions_input132_dims100,100_dropout0.1,0.7.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c748333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "\n",
    "def get_tt_split(ids=None,use_default_split=True,use_bagging_split=False,resample_training=False):\n",
    "        if ids is None:\n",
    "            ids = get_dt_ids()\n",
    "        #pre-made, stratified by decision and outcome 72:28\n",
    "        if use_default_split:\n",
    "            train_ids = Const.stratified_train_ids[:]\n",
    "            test_ids = Const.stratified_test_ids[:]\n",
    "        elif use_bagging_split:\n",
    "            train_ids = np.random.choice(ids,len(ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        else:\n",
    "            test_ids = ids[0: int(len(ids)*(1-split))]\n",
    "            train_ids = [i for i in ids if i not in test_ids]\n",
    "\n",
    "        if resample_training:\n",
    "            train_ids = np.random.choice(train_ids,len(train_ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        return train_ids,test_ids\n",
    "    \n",
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "#     nloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = bce(dlt_pred[:,i].view(-1),dlt_true[:,i].view(-1))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "def outcome_loss(ytrue,ypred,weights=[1,1,1]):\n",
    "    loss = 0\n",
    "    nloss = torch.nn.BCELoss()\n",
    "    for i in range(len(weights)):\n",
    "        iloss = nloss(ypred[:,i],ytrue[i])*weights[i]\n",
    "        loss += iloss\n",
    "    return loss\n",
    "\n",
    "def mc_metrics(yt,yp,numpy=False,is_dlt=False):\n",
    "    if not numpy:\n",
    "        yt = yt .cpu().detach().numpy()\n",
    "        yp = yp.cpu().detach().numpy()\n",
    "    #dlt prediction (binary)\n",
    "    if is_dlt:\n",
    "        acc = accuracy_score(yt,yp>.5)\n",
    "        if yt.sum() > 1:\n",
    "            auc = roc_auc_score(yt,yp)\n",
    "        else:\n",
    "            auc=-1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': acc, 'mse': error, 'auc': auc}\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    elif yt.ndim > 1:\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        except:\n",
    "            roc_micro=-1\n",
    "        try:\n",
    "            roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        except:\n",
    "            roc_macro = -1\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    #outcomes (binary)\n",
    "    else:\n",
    "        if yp.ndim > 1:\n",
    "            yp = yp.argmax(axis=1)\n",
    "        try:\n",
    "            bacc = accuracy_score(yt,yp)\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc = roc_auc_score(yt,yp)\n",
    "        except:\n",
    "            roc = -1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred,numpy=False):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0],numpy=numpy)\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i].view(-1),is_dlt=True)\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'accuracy_mean': np.mean(dlt_acc),'auc': dlt_auc,'auc_mean': np.mean(dlt_auc)}}\n",
    "    \n",
    "def outcome_metrics(ytrue,ypred,numpy=False):\n",
    "    res = {}\n",
    "    for i, outcome in enumerate(Const.outcomes):\n",
    "        metrics = mc_metrics(ytrue[i],ypred[:,i])\n",
    "        res[outcome] = metrics\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95667ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd1': {'accuracy': 0.34712441314553993,\n",
       "  'roc_micro': 0.5057627557627558,\n",
       "  'roc_macro': 0.5069683908045977},\n",
       " 'nd1': {'accuracy': 0.38253241800152554,\n",
       "  'roc_micro': 0.5694120694120695,\n",
       "  'roc_macro': 0.5231884057971015},\n",
       " 'mod': {'accuracy': 0.16666666666666666,\n",
       "  'roc_micro': 0.5093167701863354,\n",
       "  'roc_macro': -1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_state_rf(model_args={}):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "\n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    #most things are multiclass, dlts are several ordinal and outcomes are multiple binary\n",
    "    xtrain1 = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest1 = dataset.get_state('baseline',ids=test_ids)\n",
    "    \n",
    "    xtrain2 = dataset.get_input_state(step=2,ids=train_ids)\n",
    "    xtest2 = dataset.get_input_state(step=2,ids=test_ids)\n",
    "    \n",
    "    xtrain3 = dataset.get_input_state(step=3,ids=train_ids)\n",
    "    xtest3 = dataset.get_input_state(step=3,ids=test_ids)\n",
    "    \n",
    "    [pd1_train,nd1_train, mod_train,dlts1_train] = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    [pd2_train,nd2_train, cc_train,dlts2_train] = dataset.get_intermediate_outcomes(step=2,ids=train_ids)\n",
    "    [pd1_test,nd1_test, mod_test,dlts1_test] = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "    [pd2_test,nd2_test, cc_test,dlts2_test] = dataset.get_intermediate_outcomes(step=2,ids=test_ids)\n",
    "    outcomes_train = dataset.get_state('outcomes',ids=train_ids)\n",
    "    outcomes_test = dataset.get_state('outcomes',ids=test_ids)\n",
    "    \n",
    "\n",
    "    def train_multiclass_rf(xtrain,xtest,ytrain,ytest):\n",
    "        model = RandomForestClassifier(class_weight='balanced',**model_args).fit(xtrain,ytrain)\n",
    "        ypred = model.predict(xtest)\n",
    "        metrics = mc_metrics(ytest.values,ypred,numpy=True)\n",
    "        return model, metrics\n",
    "    \n",
    "    all_metrics = {}\n",
    "    pd1_model, all_metrics['pd1'] = train_multiclass_rf(xtrain1,xtest1,pd1_train,pd1_test)\n",
    "    nd1_model, all_metrics['nd1']  = train_multiclass_rf(xtrain1,xtest1,nd1_train,nd1_test)\n",
    "    mod_model, all_metrics['mod']  = train_multiclass_rf(xtrain1,xtest1,mod_train,mod_test)\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "train_state_rf({'max_depth': 5,'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a513da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B2A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A2B</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B5A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A5B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contra_spread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_fraction</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ips_spread</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dose</th>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                               3      5          6          7      \\\n",
       "1A                                 0.0    0.0        0.0        0.0   \n",
       "1A1B                               0.0    0.0        0.0        0.0   \n",
       "1A6                                0.0    0.0        0.0        0.0   \n",
       "1B                                 0.0    0.0        0.0        0.0   \n",
       "1B2A                               0.0    0.0        0.0        0.0   \n",
       "1B3                                0.0    0.0        0.0        0.0   \n",
       "2A                                 1.0    0.0        1.0        1.0   \n",
       "2A2B                               1.0    0.0        1.0        1.0   \n",
       "2A3                                1.0    0.0        1.0        1.0   \n",
       "2B                                 1.0    0.0        1.0        1.0   \n",
       "2B5A                               0.0    0.0        0.0        0.0   \n",
       "3                                  1.0    1.0        1.0        1.0   \n",
       "34                                 0.0    0.0        0.0        0.0   \n",
       "35A                                0.0    0.0        0.0        0.0   \n",
       "36                                 0.0    0.0        0.0        0.0   \n",
       "4                                  0.0    0.0        0.0        0.0   \n",
       "45B                                0.0    0.0        0.0        0.0   \n",
       "46                                 0.0    0.0        0.0        0.0   \n",
       "5A                                 0.0    0.0        0.0        0.0   \n",
       "5A5B                               0.0    0.0        0.0        0.0   \n",
       "5B                                 0.0    0.0        0.0        0.0   \n",
       "6                                  0.0    0.0        0.0        0.0   \n",
       "AJCC_1                               1      0          0          0   \n",
       "AJCC_2                               0      0          0          1   \n",
       "AJCC_3                               0      0          1          0   \n",
       "AJCC_4                               0      1          0          0   \n",
       "Aspiration rate Pre-therapy          0      0          1          0   \n",
       "DLT (Y/N)                            0      0          0          0   \n",
       "DLT_Grade                            0      0          0          0   \n",
       "N-category_0                         0      0          0          0   \n",
       "N-category_1                         1      0          0          0   \n",
       "N-category_2                         0      1          1          1   \n",
       "N-category_3                         0      0          0          0   \n",
       "Pathological Grade_0                 1      0          0          1   \n",
       "Pathological Grade_1                 0      0          0          0   \n",
       "Pathological Grade_2                 0      1          1          0   \n",
       "Pathological Grade_3                 0      0          0          0   \n",
       "Pathological Grade_4                 0      0          0          0   \n",
       "RPLN                               0.0    0.0        0.0        0.0   \n",
       "T-category_1                         0      0          0          1   \n",
       "T-category_2                         1      0          0          0   \n",
       "T-category_3                         0      0          0          0   \n",
       "T-category_4                         0      1          1          0   \n",
       "age                          55.969444  20.95  69.930556  72.319444   \n",
       "bilateral                        False  False       True      False   \n",
       "contra_spread                      0.0    0.0        0.0        0.0   \n",
       "dose_fraction                      2.2    1.8   2.121212   2.121212   \n",
       "gender                               1      1          0          1   \n",
       "hpv                                  1      0          1          1   \n",
       "ips_spread                         0.8    0.0        0.8        0.4   \n",
       "ln_cluster_1                         1      1          1          1   \n",
       "ln_cluster_2                         0      0          0          0   \n",
       "ln_cluster_3                         0      0          0          0   \n",
       "ln_cluster_4                         0      0          0          0   \n",
       "packs_per_year                     0.0   38.0       35.0        0.0   \n",
       "smoking_status                     0.0    1.0        1.0        1.0   \n",
       "subsite_BOT                          1      1          1          0   \n",
       "subsite_GPS                          0      0          0          0   \n",
       "subsite_NOS                          0      0          0          1   \n",
       "subsite_Soft palate                  0      0          0          0   \n",
       "subsite_Tonsil                       0      0          0          0   \n",
       "total_dose                        66.0   72.0       70.0       70.0   \n",
       "\n",
       "id                               8          9          10         11     \\\n",
       "1A                                 0.0        0.0        0.0        0.0   \n",
       "1A1B                               0.0        0.0        0.0        0.0   \n",
       "1A6                                0.0        0.0        0.0        0.0   \n",
       "1B                                 0.0        0.0        0.0        0.0   \n",
       "1B2A                               0.0        0.0        0.0        0.0   \n",
       "1B3                                0.0        0.0        0.0        0.0   \n",
       "2A                                 1.0        1.0        0.0        1.0   \n",
       "2A2B                               1.0        1.0        0.0        1.0   \n",
       "2A3                                0.0        0.0        0.0        0.0   \n",
       "2B                                 1.0        1.0        0.0        1.0   \n",
       "2B5A                               0.0        0.0        0.0        0.0   \n",
       "3                                  0.0        0.0        1.0        0.0   \n",
       "34                                 0.0        0.0        0.0        0.0   \n",
       "35A                                0.0        0.0        0.0        0.0   \n",
       "36                                 0.0        0.0        0.0        0.0   \n",
       "4                                  0.0        0.0        0.0        0.0   \n",
       "45B                                0.0        0.0        0.0        0.0   \n",
       "46                                 0.0        0.0        0.0        0.0   \n",
       "5A                                 0.0        0.0        0.0        0.0   \n",
       "5A5B                               0.0        0.0        0.0        0.0   \n",
       "5B                                 0.0        0.0        0.0        0.0   \n",
       "6                                  0.0        0.0        0.0        0.0   \n",
       "AJCC_1                               1          1          0          1   \n",
       "AJCC_2                               0          0          0          0   \n",
       "AJCC_3                               0          0          1          0   \n",
       "AJCC_4                               0          0          0          0   \n",
       "Aspiration rate Pre-therapy          0          0          0          0   \n",
       "DLT (Y/N)                            0          0          0          0   \n",
       "DLT_Grade                            0          0          0          0   \n",
       "N-category_0                         0          0          0          0   \n",
       "N-category_1                         1          1          1          1   \n",
       "N-category_2                         0          0          0          0   \n",
       "N-category_3                         0          0          0          0   \n",
       "Pathological Grade_0                 0          0          0          0   \n",
       "Pathological Grade_1                 0          0          0          0   \n",
       "Pathological Grade_2                 0          0          1          1   \n",
       "Pathological Grade_3                 1          1          0          0   \n",
       "Pathological Grade_4                 0          0          0          0   \n",
       "RPLN                               0.0        0.0        0.0        0.0   \n",
       "T-category_1                         1          1          0          0   \n",
       "T-category_2                         0          0          0          1   \n",
       "T-category_3                         0          0          1          0   \n",
       "T-category_4                         0          0          0          0   \n",
       "age                          59.730556  60.083333  67.708333  57.858333   \n",
       "bilateral                        False      False      False      False   \n",
       "contra_spread                      0.0        0.0        0.0        0.0   \n",
       "dose_fraction                      2.2        2.2       2.12   2.121212   \n",
       "gender                               1          1          1          1   \n",
       "hpv                                  1          1         -1          1   \n",
       "ips_spread                         0.4        0.4        0.0        0.4   \n",
       "ln_cluster_1                         1          1          1          1   \n",
       "ln_cluster_2                         0          0          0          0   \n",
       "ln_cluster_3                         0          0          0          0   \n",
       "ln_cluster_4                         0          0          0          0   \n",
       "packs_per_year                     0.0        0.0       40.0       44.0   \n",
       "smoking_status                     0.0        0.0        1.0        1.0   \n",
       "subsite_BOT                          0          1          1          0   \n",
       "subsite_GPS                          0          0          0          0   \n",
       "subsite_NOS                          0          0          0          1   \n",
       "subsite_Soft palate                  0          0          0          0   \n",
       "subsite_Tonsil                       1          0          0          0   \n",
       "total_dose                        66.0       66.0      69.96       70.0   \n",
       "\n",
       "id                               13        14     ...      10196      10197  \\\n",
       "1A                                 0.0       0.0  ...        0.0        0.0   \n",
       "1A1B                               0.0       0.0  ...        0.0        0.0   \n",
       "1A6                                0.0       0.0  ...        0.0        0.0   \n",
       "1B                                 0.0       0.0  ...        0.0        0.0   \n",
       "1B2A                               0.0       1.0  ...        0.0        0.0   \n",
       "1B3                                0.0       1.0  ...        0.0        0.0   \n",
       "2A                                 1.0       2.0  ...        0.0        1.0   \n",
       "2A2B                               1.0       2.0  ...        0.0        1.0   \n",
       "2A3                                1.0       2.0  ...        0.0        0.0   \n",
       "2B                                 1.0       2.0  ...        0.0        1.0   \n",
       "2B5A                               0.0       1.0  ...        0.0        0.0   \n",
       "3                                  1.0       2.0  ...        0.0        0.0   \n",
       "34                                 0.0       2.0  ...        0.0        0.0   \n",
       "35A                                0.0       1.0  ...        0.0        0.0   \n",
       "36                                 0.0       1.0  ...        0.0        0.0   \n",
       "4                                  0.0       2.0  ...        0.0        0.0   \n",
       "45B                                0.0       2.0  ...        0.0        0.0   \n",
       "46                                 0.0       1.0  ...        0.0        0.0   \n",
       "5A                                 0.0       0.0  ...        0.0        0.0   \n",
       "5A5B                               0.0       1.0  ...        0.0        0.0   \n",
       "5B                                 0.0       2.0  ...        0.0        0.0   \n",
       "6                                  0.0       0.0  ...        0.0        0.0   \n",
       "AJCC_1                               0         0  ...          0          0   \n",
       "AJCC_2                               0         1  ...          0          0   \n",
       "AJCC_3                               0         0  ...          0          1   \n",
       "AJCC_4                               1         0  ...          1          0   \n",
       "Aspiration rate Pre-therapy          0         0  ...          0          0   \n",
       "DLT (Y/N)                            0         0  ...          0          1   \n",
       "DLT_Grade                            0         0  ...          0          2   \n",
       "N-category_0                         0         0  ...          0          0   \n",
       "N-category_1                         0         0  ...          0          0   \n",
       "N-category_2                         1         1  ...          1          0   \n",
       "N-category_3                         0         0  ...          0          1   \n",
       "Pathological Grade_0                 0         0  ...          1          0   \n",
       "Pathological Grade_1                 0         0  ...          0          0   \n",
       "Pathological Grade_2                 1         0  ...          0          1   \n",
       "Pathological Grade_3                 0         1  ...          0          0   \n",
       "Pathological Grade_4                 0         0  ...          0          0   \n",
       "RPLN                               0.0       1.0  ...        0.0        0.0   \n",
       "T-category_1                         0         0  ...          0          0   \n",
       "T-category_2                         0         1  ...          1          0   \n",
       "T-category_3                         0         0  ...          0          1   \n",
       "T-category_4                         1         0  ...          0          0   \n",
       "age                          51.758333     56.25  ...  47.619444  50.163889   \n",
       "bilateral                         True     False  ...      False      False   \n",
       "contra_spread                      0.0       4.0  ...        0.0        0.0   \n",
       "dose_fraction                      2.0  2.121212  ...   2.121212        1.8   \n",
       "gender                               1         1  ...          0          1   \n",
       "hpv                                  0         1  ...          0          1   \n",
       "ips_spread                         0.8       1.6  ...        0.0        0.4   \n",
       "ln_cluster_1                         1         0  ...          1          1   \n",
       "ln_cluster_2                         0         0  ...          0          0   \n",
       "ln_cluster_3                         0         0  ...          0          0   \n",
       "ln_cluster_4                         0         1  ...          0          0   \n",
       "packs_per_year                     0.0      40.0  ...        5.0        0.0   \n",
       "smoking_status                     0.0       1.0  ...        0.5        0.0   \n",
       "subsite_BOT                          1         1  ...          0          1   \n",
       "subsite_GPS                          0         0  ...          0          0   \n",
       "subsite_NOS                          0         0  ...          0          0   \n",
       "subsite_Soft palate                  0         0  ...          0          0   \n",
       "subsite_Tonsil                       0         0  ...          1          0   \n",
       "total_dose                        70.0      70.0  ...       70.0       72.0   \n",
       "\n",
       "id                               10198     10199      10200      10201  \\\n",
       "1A                                 0.0       0.0        0.0        0.0   \n",
       "1A1B                               0.0       0.0        0.0        0.0   \n",
       "1A6                                0.0       0.0        0.0        0.0   \n",
       "1B                                 0.0       0.0        0.0        0.0   \n",
       "1B2A                               0.0       0.0        0.0        0.0   \n",
       "1B3                                0.0       0.0        0.0        0.0   \n",
       "2A                                 1.0       1.0        1.0        0.0   \n",
       "2A2B                               1.0       1.0        1.0        0.0   \n",
       "2A3                                0.0       0.0        0.0        0.0   \n",
       "2B                                 1.0       1.0        1.0        0.0   \n",
       "2B5A                               0.0       0.0        0.0        0.0   \n",
       "3                                  0.0       0.0        0.0        0.0   \n",
       "34                                 0.0       0.0        0.0        0.0   \n",
       "35A                                0.0       0.0        0.0        0.0   \n",
       "36                                 0.0       0.0        0.0        0.0   \n",
       "4                                  0.0       0.0        0.0        0.0   \n",
       "45B                                0.0       0.0        0.0        0.0   \n",
       "46                                 0.0       0.0        0.0        0.0   \n",
       "5A                                 0.0       0.0        0.0        0.0   \n",
       "5A5B                               0.0       0.0        0.0        0.0   \n",
       "5B                                 0.0       0.0        0.0        0.0   \n",
       "6                                  0.0       0.0        0.0        0.0   \n",
       "AJCC_1                               0         0          0          0   \n",
       "AJCC_2                               0         0          1          1   \n",
       "AJCC_3                               0         0          0          0   \n",
       "AJCC_4                               1         1          0          0   \n",
       "Aspiration rate Pre-therapy          0         0          0          0   \n",
       "DLT (Y/N)                            0         0          0          0   \n",
       "DLT_Grade                            0         0          0          0   \n",
       "N-category_0                         0         0          0          0   \n",
       "N-category_1                         0         0          1          1   \n",
       "N-category_2                         1         1          0          0   \n",
       "N-category_3                         0         0          0          0   \n",
       "Pathological Grade_0                 0         1          0          0   \n",
       "Pathological Grade_1                 1         0          0          0   \n",
       "Pathological Grade_2                 0         0          1          0   \n",
       "Pathological Grade_3                 0         0          0          1   \n",
       "Pathological Grade_4                 0         0          0          0   \n",
       "RPLN                               0.0       0.0        0.0        0.0   \n",
       "T-category_1                         1         0          0          0   \n",
       "T-category_2                         0         1          0          0   \n",
       "T-category_3                         0         0          1          1   \n",
       "T-category_4                         0         0          0          0   \n",
       "age                          70.888889    67.825  56.336111  49.566667   \n",
       "bilateral                        False     False      False      False   \n",
       "contra_spread                      0.0       0.0        0.0        0.0   \n",
       "dose_fraction                      2.2  2.121212       2.12   2.121212   \n",
       "gender                               0         1          1          1   \n",
       "hpv                                 -1         0          1          1   \n",
       "ips_spread                         0.4       0.4        0.4        0.0   \n",
       "ln_cluster_1                         1         1          1          1   \n",
       "ln_cluster_2                         0         0          0          0   \n",
       "ln_cluster_3                         0         0          0          0   \n",
       "ln_cluster_4                         0         0          0          0   \n",
       "packs_per_year                    50.0       0.0        0.0       30.0   \n",
       "smoking_status                     0.5       0.0        0.0        1.0   \n",
       "subsite_BOT                          0         1          0          1   \n",
       "subsite_GPS                          0         0          0          0   \n",
       "subsite_NOS                          0         0          1          0   \n",
       "subsite_Soft palate                  0         0          0          0   \n",
       "subsite_Tonsil                       1         0          0          0   \n",
       "total_dose                        66.0      70.0      69.96       70.0   \n",
       "\n",
       "id                               10202      10203  10204      10205  \n",
       "1A                                 0.0        0.0    0.0        0.0  \n",
       "1A1B                               0.0        0.0    0.0        0.0  \n",
       "1A6                                0.0        0.0    0.0        0.0  \n",
       "1B                                 0.0        0.0    0.0        0.0  \n",
       "1B2A                               0.0        0.0    0.0        0.0  \n",
       "1B3                                0.0        0.0    0.0        0.0  \n",
       "2A                                 1.0        1.0    1.0        1.0  \n",
       "2A2B                               1.0        1.0    1.0        1.0  \n",
       "2A3                                1.0        0.0    0.0        0.0  \n",
       "2B                                 1.0        1.0    1.0        1.0  \n",
       "2B5A                               0.0        0.0    0.0        0.0  \n",
       "3                                  1.0        0.0    0.0        0.0  \n",
       "34                                 0.0        0.0    0.0        0.0  \n",
       "35A                                0.0        0.0    0.0        0.0  \n",
       "36                                 0.0        0.0    0.0        0.0  \n",
       "4                                  0.0        0.0    0.0        0.0  \n",
       "45B                                0.0        0.0    0.0        0.0  \n",
       "46                                 0.0        0.0    0.0        0.0  \n",
       "5A                                 0.0        0.0    0.0        0.0  \n",
       "5A5B                               0.0        0.0    0.0        0.0  \n",
       "5B                                 0.0        0.0    0.0        0.0  \n",
       "6                                  0.0        0.0    0.0        0.0  \n",
       "AJCC_1                               0          1      0          0  \n",
       "AJCC_2                               0          0      0          0  \n",
       "AJCC_3                               0          0      0          1  \n",
       "AJCC_4                               1          0      1          0  \n",
       "Aspiration rate Pre-therapy          0          0      0          0  \n",
       "DLT (Y/N)                            0          0      0          0  \n",
       "DLT_Grade                            0          0      0          0  \n",
       "N-category_0                         0          0      0          0  \n",
       "N-category_1                         0          1      0          1  \n",
       "N-category_2                         1          0      0          0  \n",
       "N-category_3                         0          0      1          0  \n",
       "Pathological Grade_0                 0          1      0          0  \n",
       "Pathological Grade_1                 0          0      0          0  \n",
       "Pathological Grade_2                 0          0      0          1  \n",
       "Pathological Grade_3                 1          0      1          0  \n",
       "Pathological Grade_4                 0          0      0          0  \n",
       "RPLN                               0.0        0.0    0.0        0.0  \n",
       "T-category_1                         0          1      0          0  \n",
       "T-category_2                         0          0      0          0  \n",
       "T-category_3                         0          0      1          0  \n",
       "T-category_4                         1          0      0          1  \n",
       "age                          48.705556  77.116667  45.95  49.733333  \n",
       "bilateral                        False      False   True      False  \n",
       "contra_spread                      0.0   1.333333    0.0        0.0  \n",
       "dose_fraction                 1.714286   2.333333   2.12       2.12  \n",
       "gender                               1          1      1          1  \n",
       "hpv                                  0          1      0          1  \n",
       "ips_spread                         0.8        0.0    0.4        0.4  \n",
       "ln_cluster_1                         1          1      1          1  \n",
       "ln_cluster_2                         0          0      0          0  \n",
       "ln_cluster_3                         0          0      0          0  \n",
       "ln_cluster_4                         0          0      0          0  \n",
       "packs_per_year                    30.0        0.0    5.0        0.0  \n",
       "smoking_status                     1.0        0.0    0.5        0.0  \n",
       "subsite_BOT                          0          0      0          1  \n",
       "subsite_GPS                          0          0      0          0  \n",
       "subsite_NOS                          1          0      0          0  \n",
       "subsite_Soft palate                  0          0      0          0  \n",
       "subsite_Tonsil                       0          1      1          0  \n",
       "total_dose                        72.0       70.0  69.96      69.96  \n",
       "\n",
       "[62 rows x 536 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DTDataset().get_state('baseline').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c4445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_state(model=None,\n",
    "                model_args={},\n",
    "                state=1,\n",
    "                split=.7,\n",
    "                lr=.0001,\n",
    "                epochs=1000,\n",
    "                patience=10,\n",
    "                use_attention=True,\n",
    "                weights=[1,1,1,10],\n",
    "                save_path='../data/models/',\n",
    "                use_default_split=True,\n",
    "                use_bagging_split=False,\n",
    "                resample_training=False,#use bootstraping on training data after splitting\n",
    "                n_validation_trainsteps=2,\n",
    "                verbose=True,\n",
    "                file_suffix=''):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids)\n",
    "    \n",
    "\n",
    "    if state < 3:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = OutcomeAttentionSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "            else:\n",
    "                model = OutcomeSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "        lfunc = state_loss\n",
    "    else:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = EndpointAttentionSimulator(xtrain.shape[1],**model_args)\n",
    "            else:\n",
    "                model = EndpointSimulator(xtrain.shape[1],**model_args)\n",
    "        weights = weights[:3]\n",
    "        lfunc = outcome_loss\n",
    "        \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    save_file = save_path + 'model_' + model.identifier + '_split' + str(split) + '_resample' + str(resample_training) +  '_hash' + hashcode + file_suffix + '.tar'\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    model.fit_normalizer(xtrain)\n",
    "#     normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "#     unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    last_epoch = False\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(xtrain_sample)\n",
    "        loss = lfunc(ytrain,ypred,weights=weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        if state < 3:\n",
    "            val_metrics = state_metrics(ytest,yval)\n",
    "        else:\n",
    "            val_metrics = outcome_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if verbose:\n",
    "            print('val loss',val_loss.item())\n",
    "            print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    #train one step on validation data\n",
    "    for i in range(n_validation_trainsteps):\n",
    "        model.train()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        val_loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model.state_dict(),save_file)\n",
    "    \n",
    "    model.eval()\n",
    "    return model,  best_val_loss, best_loss_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9536fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def gridsearch_transition_models(state=1):\n",
    "#     model_arglist = [\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500,500],\n",
    "#             'attention_heads': [5,5,5]\n",
    "#         }\n",
    "#     ]\n",
    "    model_arglist = [\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [200,400,800]:\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.9,.95]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.25,.35,.5]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    model,m_loss,m_metrics = train_state(model_args=args,state=state,verbose=False)\n",
    "                    print('done',k,m_loss)\n",
    "                    k+=1\n",
    "                    if m_loss < best_loss:\n",
    "                        best_loss = m_loss\n",
    "                        best_metrics  = m_metrics\n",
    "                        best_model = model\n",
    "                        best_args = args\n",
    "                        print('_++++++++++New Best++++____')\n",
    "                        print(best_loss)\n",
    "                        print(best_metrics)\n",
    "                        print(best_args)\n",
    "                        print('___________')\n",
    "                        print('++++++++')\n",
    "                        print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "# model = gridsearch_transition_models(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cdf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = gridsearch_transition_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33d908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = gridsearch_transition_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75b44897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
       " '../data/models/final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
       " '../data/models/final_outcome_model_state1_input83_dims1000_dropout0,0.pt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Const.tuned_transition_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models():\n",
    "    files = Const.tuned_transition_models\n",
    "    decision_file = Const.tuned_decision_model\n",
    "    [model1,model2,model3] = [torch.load(file) for file in files]\n",
    "    decision_model = torch.load(decision_file)\n",
    "    return decision_model, model1,model2,model3\n",
    "_, model1, model2, model3 =load_trained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8af5c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 0 _____\n",
      "train imitation 2.161153554916382 reward 1.1807951927185059\n",
      "val imitation 1.9953837394714355 reward 1.184358835220337\n",
      "val loss 3.1797425746917725 1000000000.0\n",
      "[{'decision': 0, 'accuracy': 0.6232876712328768, 'auc': 0.36875}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.43229166666666663}, {'decision': 2, 'accuracy': 0.678082191780822, 'auc': 0.5198717948717948}]\n",
      "______epoch 1 _____\n",
      "train imitation 2.119168996810913 reward 1.1801512241363525\n",
      "val imitation 1.9548444747924805 reward 1.1844807863235474\n",
      "val loss 3.1393251419067383 3.1797425746917725\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.37115384615384617}, {'decision': 1, 'accuracy': 0.7191780821917808, 'auc': 0.4413377192982456}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.5266025641025641}]\n",
      "______epoch 2 _____\n",
      "train imitation 2.083787679672241 reward 1.1801612377166748\n",
      "val imitation 1.9162837266921997 reward 1.1845741271972656\n",
      "val loss 3.100857734680176 3.1393251419067383\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.37067307692307694}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.4514802631578947}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.5333333333333333}]\n",
      "______epoch 3 _____\n",
      "train imitation 2.0217862129211426 reward 1.1817899942398071\n",
      "val imitation 1.879340410232544 reward 1.1850218772888184\n",
      "val loss 3.0643622875213623 3.100857734680176\n",
      "[{'decision': 0, 'accuracy': 0.821917808219178, 'auc': 0.37067307692307694}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.4621710526315789}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.5432692307692307}]\n",
      "______epoch 4 _____\n",
      "train imitation 2.035775661468506 reward 1.1803572177886963\n",
      "val imitation 1.8442091941833496 reward 1.1850218772888184\n",
      "val loss 3.029231071472168 3.0643622875213623\n",
      "[{'decision': 0, 'accuracy': 0.863013698630137, 'auc': 0.375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.46957236842105265}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5496794871794871}]\n",
      "______epoch 5 _____\n",
      "train imitation 2.0083608627319336 reward 1.1792173385620117\n",
      "val imitation 1.8106348514556885 reward 1.1850388050079346\n",
      "val loss 2.995673656463623 3.029231071472168\n",
      "[{'decision': 0, 'accuracy': 0.863013698630137, 'auc': 0.3778846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.4799890350877193}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.5544871794871795}]\n",
      "______epoch 6 _____\n",
      "train imitation 1.9739670753479004 reward 1.1792309284210205\n",
      "val imitation 1.778703212738037 reward 1.1851418018341064\n",
      "val loss 2.9638450145721436 2.995673656463623\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.3783653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.48711622807017546}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.5628205128205128}]\n",
      "______epoch 7 _____\n",
      "train imitation 1.8946439027786255 reward 1.179656744003296\n",
      "val imitation 1.7482939958572388 reward 1.1852755546569824\n",
      "val loss 2.9335694313049316 2.9638450145721436\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.37932692307692306}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.496984649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5689102564102564}]\n",
      "______epoch 8 _____\n",
      "train imitation 1.907537817955017 reward 1.1814990043640137\n",
      "val imitation 1.719266414642334 reward 1.1861871480941772\n",
      "val loss 2.905453681945801 2.9335694313049316\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.38317307692307695}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5076754385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5740384615384616}]\n",
      "______epoch 9 _____\n",
      "train imitation 1.8446964025497437 reward 1.1796696186065674\n",
      "val imitation 1.691850185394287 reward 1.1860215663909912\n",
      "val loss 2.8778717517852783 2.905453681945801\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3817307692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5172697368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5794871794871794}]\n",
      "______epoch 10 _____\n",
      "train imitation 1.8543148040771484 reward 1.1802830696105957\n",
      "val imitation 1.6657283306121826 reward 1.1858313083648682\n",
      "val loss 2.851559638977051 2.8778717517852783\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.38221153846153844}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5235745614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5858974358974359}]\n",
      "______epoch 11 _____\n",
      "train imitation 1.779540777206421 reward 1.1827634572982788\n",
      "val imitation 1.6410133838653564 reward 1.185046672821045\n",
      "val loss 2.8260600566864014 2.851559638977051\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3860576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5296052631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5942307692307692}]\n",
      "______epoch 12 _____\n",
      "train imitation 1.752004623413086 reward 1.179490566253662\n",
      "val imitation 1.6176304817199707 reward 1.185032606124878\n",
      "val loss 2.8026630878448486 2.8260600566864014\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.38509615384615387}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.540296052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5961538461538461}]\n",
      "______epoch 13 _____\n",
      "train imitation 1.777108907699585 reward 1.1793348789215088\n",
      "val imitation 1.5954349040985107 reward 1.1850650310516357\n",
      "val loss 2.7804999351501465 2.8026630878448486\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3850961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5452302631578948}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6038461538461539}]\n",
      "______epoch 14 _____\n",
      "train imitation 1.7632339000701904 reward 1.1799399852752686\n",
      "val imitation 1.5743035078048706 reward 1.1850650310516357\n",
      "val loss 2.759368419647217 2.7804999351501465\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.38557692307692315}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.553453947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6073717948717949}]\n",
      "______epoch 15 _____\n",
      "train imitation 1.7242176532745361 reward 1.181729793548584\n",
      "val imitation 1.5543212890625 reward 1.185041904449463\n",
      "val loss 2.739363193511963 2.759368419647217\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.38653846153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5627741228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.614423076923077}]\n",
      "______epoch 16 _____\n",
      "train imitation 1.6945807933807373 reward 1.181190013885498\n",
      "val imitation 1.5353760719299316 reward 1.18491530418396\n",
      "val loss 2.7202913761138916 2.739363193511963\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.39086538461538467}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5693530701754387}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6217948717948718}]\n",
      "______epoch 17 _____\n",
      "train imitation 1.6334896087646484 reward 1.180711030960083\n",
      "val imitation 1.5174740552902222 reward 1.184918999671936\n",
      "val loss 2.702393054962158 2.7202913761138916\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.39038461538461544}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5759320175438596}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6301282051282051}]\n",
      "______epoch 18 _____\n",
      "train imitation 1.693321704864502 reward 1.1815364360809326\n",
      "val imitation 1.5006179809570312 reward 1.1848959922790527\n",
      "val loss 2.685513973236084 2.702393054962158\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.39086538461538467}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5805921052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6368589743589743}]\n",
      "______epoch 19 _____\n",
      "train imitation 1.5704481601715088 reward 1.1800920963287354\n",
      "val imitation 1.4847663640975952 reward 1.1848618984222412\n",
      "val loss 2.669628143310547 2.685513973236084\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3918269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.589638157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6429487179487179}]\n",
      "______epoch 20 _____\n",
      "train imitation 1.5827281475067139 reward 1.1799333095550537\n",
      "val imitation 1.4698851108551025 reward 1.184873342514038\n",
      "val loss 2.6547584533691406 2.669628143310547\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3927884615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5973135964912281}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6509615384615385}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 21 _____\n",
      "train imitation 1.6016905307769775 reward 1.1839709281921387\n",
      "val imitation 1.4559180736541748 reward 1.184873342514038\n",
      "val loss 2.640791416168213 2.6547584533691406\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.39278846153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6014254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6580128205128205}]\n",
      "______epoch 22 _____\n",
      "train imitation 1.588714361190796 reward 1.1800607442855835\n",
      "val imitation 1.4429160356521606 reward 1.1848335266113281\n",
      "val loss 2.627749443054199 2.640791416168213\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.39278846153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6052631578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6673076923076924}]\n",
      "______epoch 23 _____\n",
      "train imitation 1.5808918476104736 reward 1.1814935207366943\n",
      "val imitation 1.430832862854004 reward 1.1847141981124878\n",
      "val loss 2.6155471801757812 2.627749443054199\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.3980769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6058114035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6717948717948719}]\n",
      "______epoch 24 _____\n",
      "train imitation 1.5902884006500244 reward 1.18206787109375\n",
      "val imitation 1.4196041822433472 reward 1.1846808195114136\n",
      "val loss 2.6042850017547607 2.6155471801757812\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.40048076923076925}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6096491228070177}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6759615384615385}]\n",
      "______epoch 25 _____\n",
      "train imitation 1.5750339031219482 reward 1.1827056407928467\n",
      "val imitation 1.4092580080032349 reward 1.184583306312561\n",
      "val loss 2.593841314315796 2.6042850017547607\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.40048076923076925}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6129385964912281}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.680448717948718}]\n",
      "______epoch 26 _____\n",
      "train imitation 1.5110937356948853 reward 1.1810154914855957\n",
      "val imitation 1.3996953964233398 reward 1.1856054067611694\n",
      "val loss 2.585300922393799 2.593841314315796\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.40384615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6167763157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6865384615384615}]\n",
      "______epoch 27 _____\n",
      "train imitation 1.5404784679412842 reward 1.1811413764953613\n",
      "val imitation 1.3908565044403076 reward 1.1856263875961304\n",
      "val loss 2.5764827728271484 2.585300922393799\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.40817307692307697}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6241776315789475}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6907051282051282}]\n",
      "______epoch 28 _____\n",
      "train imitation 1.509691834449768 reward 1.1827147006988525\n",
      "val imitation 1.3827515840530396 reward 1.185788869857788\n",
      "val loss 2.568540573120117 2.5764827728271484\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4091346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6263706140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6964743589743589}]\n",
      "______epoch 29 _____\n",
      "train imitation 1.528977870941162 reward 1.1835713386535645\n",
      "val imitation 1.37532639503479 reward 1.1857554912567139\n",
      "val loss 2.561081886291504 2.568540573120117\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4134615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6299342105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7009615384615384}]\n",
      "______epoch 30 _____\n",
      "train imitation 1.511077880859375 reward 1.1816058158874512\n",
      "val imitation 1.3686517477035522 reward 1.1858086585998535\n",
      "val loss 2.5544605255126953 2.561081886291504\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4173076923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6351425438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7070512820512821}]\n",
      "______epoch 31 _____\n",
      "train imitation 1.505190134048462 reward 1.182053565979004\n",
      "val imitation 1.3626238107681274 reward 1.1861624717712402\n",
      "val loss 2.548786163330078 2.5544605255126953\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.41442307692307695}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6370614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7092948717948718}]\n",
      "______epoch 32 _____\n",
      "train imitation 1.492368459701538 reward 1.181687831878662\n",
      "val imitation 1.3572094440460205 reward 1.1863553524017334\n",
      "val loss 2.543564796447754 2.548786163330078\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.41923076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6398026315789475}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7147435897435896}]\n",
      "______epoch 33 _____\n",
      "train imitation 1.4481127262115479 reward 1.1821820735931396\n",
      "val imitation 1.352407693862915 reward 1.186476469039917\n",
      "val loss 2.538884162902832 2.543564796447754\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4221153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6436403508771931}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.717948717948718}]\n",
      "______epoch 34 _____\n",
      "train imitation 1.4766621589660645 reward 1.18104887008667\n",
      "val imitation 1.3481519222259521 reward 1.1864980459213257\n",
      "val loss 2.5346498489379883 2.538884162902832\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.42163461538461533}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6477521929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7237179487179488}]\n",
      "______epoch 35 _____\n",
      "train imitation 1.4556732177734375 reward 1.1811081171035767\n",
      "val imitation 1.3444105386734009 reward 1.1864980459213257\n",
      "val loss 2.5309085845947266 2.5346498489379883\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4206730769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6507675438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7288461538461539}]\n",
      "______epoch 36 _____\n",
      "train imitation 1.4649569988250732 reward 1.1817750930786133\n",
      "val imitation 1.341017484664917 reward 1.1864980459213257\n",
      "val loss 2.527515411376953 2.5309085845947266\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.42403846153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6529605263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7323717948717948}]\n",
      "______epoch 37 _____\n",
      "train imitation 1.4860997200012207 reward 1.1820307970046997\n",
      "val imitation 1.337972640991211 reward 1.1865215301513672\n",
      "val loss 2.524494171142578 2.527515411376953\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.42644230769230773}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6565241228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7342948717948719}]\n",
      "______epoch 38 _____\n",
      "train imitation 1.4326152801513672 reward 1.1808277368545532\n",
      "val imitation 1.3352477550506592 reward 1.1865215301513672\n",
      "val loss 2.5217692852020264 2.524494171142578\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.43173076923076925}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6576206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7397435897435898}]\n",
      "______epoch 39 _____\n",
      "train imitation 1.4573575258255005 reward 1.1829414367675781\n",
      "val imitation 1.3328723907470703 reward 1.1866042613983154\n",
      "val loss 2.5194766521453857 2.5217692852020264\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.43365384615384617}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6609100877192982}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7432692307692308}]\n",
      "______epoch 40 _____\n",
      "train imitation 1.4752012491226196 reward 1.1814250946044922\n",
      "val imitation 1.3306803703308105 reward 1.1866953372955322\n",
      "val loss 2.5173757076263428 2.5194766521453857\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.43990384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6633771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7480769230769231}]\n",
      "______epoch 41 _____\n",
      "train imitation 1.452061414718628 reward 1.1810423135757446\n",
      "val imitation 1.328678846359253 reward 1.1866953372955322\n",
      "val loss 2.515374183654785 2.5173757076263428\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.44375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.665296052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7496794871794872}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 42 _____\n",
      "train imitation 1.4334405660629272 reward 1.1813918352127075\n",
      "val imitation 1.3269062042236328 reward 1.1866122484207153\n",
      "val loss 2.5135183334350586 2.515374183654785\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.44759615384615387}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6674890350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7528846153846154}]\n",
      "______epoch 43 _____\n",
      "train imitation 1.4425970315933228 reward 1.182062029838562\n",
      "val imitation 1.325310468673706 reward 1.1866122484207153\n",
      "val loss 2.511922836303711 2.5135183334350586\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.451923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6702302631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.757051282051282}]\n",
      "______epoch 44 _____\n",
      "train imitation 1.4762611389160156 reward 1.1827021837234497\n",
      "val imitation 1.3238191604614258 reward 1.1866122484207153\n",
      "val loss 2.5104312896728516 2.511922836303711\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4557692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6746162280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7602564102564102}]\n",
      "______epoch 45 _____\n",
      "train imitation 1.437719464302063 reward 1.1840726137161255\n",
      "val imitation 1.3225083351135254 reward 1.1873109340667725\n",
      "val loss 2.509819269180298 2.5104312896728516\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.45961538461538465}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6757127192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7615384615384615}]\n",
      "______epoch 46 _____\n",
      "train imitation 1.4201865196228027 reward 1.181626319885254\n",
      "val imitation 1.3212251663208008 reward 1.1873109340667725\n",
      "val loss 2.5085361003875732 2.509819269180298\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.46105769230769234}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6770833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.760576923076923}]\n",
      "______epoch 47 _____\n",
      "train imitation 1.4257889986038208 reward 1.1844804286956787\n",
      "val imitation 1.3200223445892334 reward 1.1872673034667969\n",
      "val loss 2.5072896480560303 2.5085361003875732\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.46826923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7631410256410256}]\n",
      "______epoch 48 _____\n",
      "train imitation 1.448049783706665 reward 1.1814213991165161\n",
      "val imitation 1.3188538551330566 reward 1.1873365640640259\n",
      "val loss 2.506190299987793 2.5072896480560303\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4740384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6817434210526315}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.764423076923077}]\n",
      "______epoch 49 _____\n",
      "train imitation 1.4443166255950928 reward 1.182563066482544\n",
      "val imitation 1.3177058696746826 reward 1.1873365640640259\n",
      "val loss 2.505042552947998 2.506190299987793\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.47451923076923075}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6811951754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7666666666666666}]\n",
      "______epoch 50 _____\n",
      "train imitation 1.4628643989562988 reward 1.1819121837615967\n",
      "val imitation 1.316550374031067 reward 1.1873984336853027\n",
      "val loss 2.50394868850708 2.505042552947998\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4802884615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.684484649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7689102564102565}]\n",
      "______epoch 51 _____\n",
      "train imitation 1.429408311843872 reward 1.1828351020812988\n",
      "val imitation 1.315372109413147 reward 1.187660574913025\n",
      "val loss 2.503032684326172 2.50394868850708\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.48461538461538467}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333333}]\n",
      "______epoch 52 _____\n",
      "train imitation 1.4253005981445312 reward 1.1816799640655518\n",
      "val imitation 1.3142170906066895 reward 1.188073992729187\n",
      "val loss 2.502291202545166 2.503032684326172\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4884615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6902412280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153846}]\n",
      "______epoch 53 _____\n",
      "train imitation 1.4140625 reward 1.182896614074707\n",
      "val imitation 1.313104271888733 reward 1.188073992729187\n",
      "val loss 2.50117826461792 2.502291202545166\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4918269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6929824561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564103}]\n",
      "______epoch 54 _____\n",
      "train imitation 1.3829790353775024 reward 1.1824007034301758\n",
      "val imitation 1.3120291233062744 reward 1.188073992729187\n",
      "val loss 2.500102996826172 2.50117826461792\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.49375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6938048245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 55 _____\n",
      "train imitation 1.4201520681381226 reward 1.1805775165557861\n",
      "val imitation 1.3109338283538818 reward 1.188073992729187\n",
      "val loss 2.4990077018737793 2.500102996826172\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.49855769230769237}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6949013157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410258}]\n",
      "______epoch 56 _____\n",
      "train imitation 1.4122774600982666 reward 1.18131685256958\n",
      "val imitation 1.3098385334014893 reward 1.1881567239761353\n",
      "val loss 2.497995376586914 2.4990077018737793\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7785256410256409}]\n",
      "______epoch 57 _____\n",
      "train imitation 1.4385900497436523 reward 1.1843173503875732\n",
      "val imitation 1.3087314367294312 reward 1.1882569789886475\n",
      "val loss 2.496988296508789 2.497995376586914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6995614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 58 _____\n",
      "train imitation 1.3850961923599243 reward 1.1836304664611816\n",
      "val imitation 1.3075942993164062 reward 1.1884164810180664\n",
      "val loss 2.4960107803344727 2.496988296508789\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5120192307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7006578947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.780448717948718}]\n",
      "______epoch 59 _____\n",
      "train imitation 1.4255955219268799 reward 1.1811597347259521\n",
      "val imitation 1.3065311908721924 reward 1.1888127326965332\n",
      "val loss 2.4953439235687256 2.4960107803344727\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5163461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7023026315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897436}]\n",
      "______epoch 60 _____\n",
      "train imitation 1.3943248987197876 reward 1.1795183420181274\n",
      "val imitation 1.305450201034546 reward 1.1888272762298584\n",
      "val loss 2.4942774772644043 2.4953439235687256\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5197115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7017543859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 61 _____\n",
      "train imitation 1.4201490879058838 reward 1.1834022998809814\n",
      "val imitation 1.3043124675750732 reward 1.1888272762298584\n",
      "val loss 2.4931397438049316 2.4942774772644043\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5201923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7039473684210527}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897435}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 62 _____\n",
      "train imitation 1.3845112323760986 reward 1.180848479270935\n",
      "val imitation 1.3032461404800415 reward 1.1889135837554932\n",
      "val loss 2.492159843444824 2.4931397438049316\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5278846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7064144736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923078}]\n",
      "______epoch 63 _____\n",
      "train imitation 1.4348039627075195 reward 1.1819158792495728\n",
      "val imitation 1.3021972179412842 reward 1.1884677410125732\n",
      "val loss 2.4906649589538574 2.492159843444824\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7077850877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7817307692307692}]\n",
      "______epoch 64 _____\n",
      "train imitation 1.381913185119629 reward 1.1810784339904785\n",
      "val imitation 1.3010834455490112 reward 1.188529133796692\n",
      "val loss 2.489612579345703 2.4906649589538574\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.709155701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923077}]\n",
      "______epoch 65 _____\n",
      "train imitation 1.4404096603393555 reward 1.183939814567566\n",
      "val imitation 1.2999775409698486 reward 1.188529133796692\n",
      "val loss 2.48850679397583 2.489612579345703\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5355769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7102521929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128206}]\n",
      "______epoch 66 _____\n",
      "train imitation 1.4000738859176636 reward 1.1829252243041992\n",
      "val imitation 1.2988920211791992 reward 1.1892889738082886\n",
      "val loss 2.4881811141967773 2.48850679397583\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7116228070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7820512820512822}]\n",
      "______epoch 67 _____\n",
      "train imitation 1.3914027214050293 reward 1.1841562986373901\n",
      "val imitation 1.2977758646011353 reward 1.1892889738082886\n",
      "val loss 2.487064838409424 2.4881811141967773\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7135416666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923078}]\n",
      "______epoch 68 _____\n",
      "train imitation 1.4076017141342163 reward 1.1812083721160889\n",
      "val imitation 1.296648621559143 reward 1.189345121383667\n",
      "val loss 2.4859938621520996 2.487064838409424\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5451923076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7151864035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.780448717948718}]\n",
      "______epoch 69 _____\n",
      "train imitation 1.402612328529358 reward 1.1800397634506226\n",
      "val imitation 1.2955902814865112 reward 1.18944251537323\n",
      "val loss 2.485032796859741 2.4859938621520996\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5480769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 70 _____\n",
      "train imitation 1.3793237209320068 reward 1.1817636489868164\n",
      "val imitation 1.2945849895477295 reward 1.18944251537323\n",
      "val loss 2.48402738571167 2.485032796859741\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5485576923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7146381578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 71 _____\n",
      "train imitation 1.3958759307861328 reward 1.1821693181991577\n",
      "val imitation 1.2935923337936401 reward 1.18944251537323\n",
      "val loss 2.48303484916687 2.48402738571167\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5504807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7146381578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871796}]\n",
      "______epoch 72 _____\n",
      "train imitation 1.4024184942245483 reward 1.1830811500549316\n",
      "val imitation 1.2926069498062134 reward 1.1895487308502197\n",
      "val loss 2.4821557998657227 2.48303484916687\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5519230769230768}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7138157894736843}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 73 _____\n",
      "train imitation 1.3937103748321533 reward 1.1821379661560059\n",
      "val imitation 1.291709303855896 reward 1.1892368793487549\n",
      "val loss 2.4809460639953613 2.4821557998657227\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5519230769230768}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7138157894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.780448717948718}]\n",
      "______epoch 74 _____\n",
      "train imitation 1.4114351272583008 reward 1.1830891370773315\n",
      "val imitation 1.2908213138580322 reward 1.1889296770095825\n",
      "val loss 2.4797511100769043 2.4809460639953613\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5562499999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7154605263157894}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 75 _____\n",
      "train imitation 1.369802474975586 reward 1.1827863454818726\n",
      "val imitation 1.2899184226989746 reward 1.1890549659729004\n",
      "val loss 2.478973388671875 2.4797511100769043\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5572115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7176535087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7801282051282052}]\n",
      "______epoch 76 _____\n",
      "train imitation 1.408534049987793 reward 1.181904911994934\n",
      "val imitation 1.2890892028808594 reward 1.1890549659729004\n",
      "val loss 2.4781441688537598 2.478973388671875\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5591346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.71875}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7798076923076923}]\n",
      "______epoch 77 _____\n",
      "train imitation 1.3846361637115479 reward 1.1795367002487183\n",
      "val imitation 1.2883143424987793 reward 1.1901555061340332\n",
      "val loss 2.4784698486328125 2.4781441688537598\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5615384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7182017543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.782051282051282}]\n",
      "______epoch 78 _____\n",
      "train imitation 1.3819453716278076 reward 1.1810126304626465\n",
      "val imitation 1.2874884605407715 reward 1.190068244934082\n",
      "val loss 2.4775567054748535 2.4781441688537598\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5658653846153847}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 79 _____\n",
      "train imitation 1.391754150390625 reward 1.18427312374115\n",
      "val imitation 1.2866829633712769 reward 1.190068244934082\n",
      "val loss 2.4767513275146484 2.4775567054748535\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5682692307692309}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7206688596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 80 _____\n",
      "train imitation 1.3663522005081177 reward 1.1834417581558228\n",
      "val imitation 1.285945177078247 reward 1.190068244934082\n",
      "val loss 2.476013422012329 2.4767513275146484\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5692307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7778846153846155}]\n",
      "______epoch 81 _____\n",
      "train imitation 1.381325602531433 reward 1.1828595399856567\n",
      "val imitation 1.2852575778961182 reward 1.1903281211853027\n",
      "val loss 2.475585699081421 2.476013422012329\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5697115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 82 _____\n",
      "train imitation 1.392754077911377 reward 1.1798515319824219\n",
      "val imitation 1.2845208644866943 reward 1.1903281211853027\n",
      "val loss 2.474848985671997 2.475585699081421\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5716346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 83 _____\n",
      "train imitation 1.3786760568618774 reward 1.1827833652496338\n",
      "val imitation 1.283811330795288 reward 1.190372347831726\n",
      "val loss 2.4741835594177246 2.474848985671997\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5716346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n",
      "______epoch 84 _____\n",
      "train imitation 1.4199111461639404 reward 1.1807448863983154\n",
      "val imitation 1.2831017971038818 reward 1.1902741193771362\n",
      "val loss 2.4733757972717285 2.4741835594177246\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5750000000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897435}]\n",
      "______epoch 85 _____\n",
      "train imitation 1.3347089290618896 reward 1.1840028762817383\n",
      "val imitation 1.2824475765228271 reward 1.1902741193771362\n",
      "val loss 2.472721576690674 2.4733757972717285\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5774038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.721765350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923077}]\n",
      "______epoch 86 _____\n",
      "train imitation 1.3822280168533325 reward 1.1830201148986816\n",
      "val imitation 1.281867504119873 reward 1.1902741193771362\n",
      "val loss 2.472141742706299 2.472721576690674\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5788461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7836538461538461}]\n",
      "______epoch 87 _____\n",
      "train imitation 1.4129117727279663 reward 1.1825841665267944\n",
      "val imitation 1.281275987625122 reward 1.1902741193771362\n",
      "val loss 2.4715499877929688 2.472141742706299\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5793269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7214912280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128206}]\n",
      "______epoch 88 _____\n",
      "train imitation 1.354709267616272 reward 1.1828285455703735\n",
      "val imitation 1.2807115316390991 reward 1.1902741193771362\n",
      "val loss 2.4709856510162354 2.4715499877929688\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5822115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7206688596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7833333333333333}]\n",
      "______epoch 89 _____\n",
      "train imitation 1.3856284618377686 reward 1.1843229532241821\n",
      "val imitation 1.2801778316497803 reward 1.1902741193771362\n",
      "val loss 2.470451831817627 2.4709856510162354\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5841346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923077}]\n",
      "______epoch 90 _____\n",
      "train imitation 1.3781113624572754 reward 1.1843364238739014\n",
      "val imitation 1.279618740081787 reward 1.1907061338424683\n",
      "val loss 2.470324993133545 2.470451831817627\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5836538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7198464912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7823717948717949}]\n",
      "______epoch 91 _____\n",
      "train imitation 1.383028268814087 reward 1.184800386428833\n",
      "val imitation 1.2791131734848022 reward 1.1907061338424683\n",
      "val loss 2.4698193073272705 2.470324993133545\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5855769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897436}]\n",
      "______epoch 92 _____\n",
      "train imitation 1.3672187328338623 reward 1.1823042631149292\n",
      "val imitation 1.2786574363708496 reward 1.1907061338424683\n",
      "val loss 2.4693636894226074 2.4698193073272705\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5889423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 93 _____\n",
      "train imitation 1.3960820436477661 reward 1.1837199926376343\n",
      "val imitation 1.2782007455825806 reward 1.1907892227172852\n",
      "val loss 2.468989849090576 2.4693636894226074\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5899038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n",
      "______epoch 94 _____\n",
      "train imitation 1.3557603359222412 reward 1.1837575435638428\n",
      "val imitation 1.2777199745178223 reward 1.1907099485397339\n",
      "val loss 2.4684300422668457 2.468989849090576\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5932692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7198464912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7798076923076923}]\n",
      "______epoch 95 _____\n",
      "train imitation 1.3615169525146484 reward 1.183587670326233\n",
      "val imitation 1.2772653102874756 reward 1.1907099485397339\n",
      "val loss 2.46797513961792 2.4684300422668457\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5927884615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 96 _____\n",
      "train imitation 1.3364295959472656 reward 1.1820313930511475\n",
      "val imitation 1.2767724990844727 reward 1.1907306909561157\n",
      "val loss 2.467503070831299 2.46797513961792\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5956730769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7209429824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 97 _____\n",
      "train imitation 1.3646348714828491 reward 1.1824588775634766\n",
      "val imitation 1.2763116359710693 reward 1.1902709007263184\n",
      "val loss 2.4665825366973877 2.467503070831299\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5975961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842106}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 98 _____\n",
      "train imitation 1.3688308000564575 reward 1.183287262916565\n",
      "val imitation 1.2758361101150513 reward 1.1894837617874146\n",
      "val loss 2.465319871902466 2.4665825366973877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5995192307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7231359649122808}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666668}]\n",
      "______epoch 99 _____\n",
      "train imitation 1.3362452983856201 reward 1.1807386875152588\n",
      "val imitation 1.2753207683563232 reward 1.1895054578781128\n",
      "val loss 2.4648261070251465 2.465319871902466\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6014423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7234100877192982}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641026}]\n",
      "______epoch 100 _____\n",
      "train imitation 1.3649792671203613 reward 1.1815004348754883\n",
      "val imitation 1.2747596502304077 reward 1.1895054578781128\n",
      "val loss 2.4642651081085205 2.4648261070251465\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6038461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.722861842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410257}]\n",
      "______epoch 101 _____\n",
      "train imitation 1.3465120792388916 reward 1.1835139989852905\n",
      "val imitation 1.2740795612335205 reward 1.189482569694519\n",
      "val loss 2.46356201171875 2.4642651081085205\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6057692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7234100877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 102 _____\n",
      "train imitation 1.3492770195007324 reward 1.1804249286651611\n",
      "val imitation 1.2734383344650269 reward 1.189482569694519\n",
      "val loss 2.462920904159546 2.46356201171875\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6067307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333333}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 103 _____\n",
      "train imitation 1.3360636234283447 reward 1.184448480606079\n",
      "val imitation 1.2727577686309814 reward 1.1893690824508667\n",
      "val loss 2.4621267318725586 2.462920904159546\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6086538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 104 _____\n",
      "train imitation 1.3587414026260376 reward 1.182149052619934\n",
      "val imitation 1.2720887660980225 reward 1.1893690824508667\n",
      "val loss 2.4614577293395996 2.4621267318725586\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6091346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 105 _____\n",
      "train imitation 1.3180114030838013 reward 1.1809723377227783\n",
      "val imitation 1.271437644958496 reward 1.1893690824508667\n",
      "val loss 2.4608068466186523 2.4614577293395996\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6105769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 106 _____\n",
      "train imitation 1.3712893724441528 reward 1.180975317955017\n",
      "val imitation 1.2708349227905273 reward 1.1893690824508667\n",
      "val loss 2.4602041244506836 2.4608068466186523\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6110576923076922}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410257}]\n",
      "______epoch 107 _____\n",
      "train imitation 1.3524739742279053 reward 1.1825501918792725\n",
      "val imitation 1.2701466083526611 reward 1.1893690824508667\n",
      "val loss 2.4595155715942383 2.4602041244506836\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6125}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 108 _____\n",
      "train imitation 1.3721232414245605 reward 1.18122136592865\n",
      "val imitation 1.269491195678711 reward 1.1893690824508667\n",
      "val loss 2.458860397338867 2.4595155715942383\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 109 _____\n",
      "train imitation 1.3514130115509033 reward 1.184711217880249\n",
      "val imitation 1.2687950134277344 reward 1.1893690824508667\n",
      "val loss 2.4581642150878906 2.458860397338867\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6153846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 110 _____\n",
      "train imitation 1.3050346374511719 reward 1.1808472871780396\n",
      "val imitation 1.268112301826477 reward 1.1893690824508667\n",
      "val loss 2.4574813842773438 2.4581642150878906\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6168269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 111 _____\n",
      "train imitation 1.347319483757019 reward 1.1831902265548706\n",
      "val imitation 1.2674108743667603 reward 1.189216136932373\n",
      "val loss 2.4566268920898438 2.4574813842773438\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6187499999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 112 _____\n",
      "train imitation 1.3320608139038086 reward 1.1830140352249146\n",
      "val imitation 1.2668256759643555 reward 1.189216136932373\n",
      "val loss 2.4560418128967285 2.4566268920898438\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6221153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 113 _____\n",
      "train imitation 1.37984037399292 reward 1.1796256303787231\n",
      "val imitation 1.2662888765335083 reward 1.1892341375350952\n",
      "val loss 2.4555230140686035 2.4560418128967285\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6240384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 114 _____\n",
      "train imitation 1.3528804779052734 reward 1.1831068992614746\n",
      "val imitation 1.2657530307769775 reward 1.1892943382263184\n",
      "val loss 2.455047369003296 2.4555230140686035\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6274038461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7737179487179487}]\n",
      "______epoch 115 _____\n",
      "train imitation 1.3141562938690186 reward 1.184229850769043\n",
      "val imitation 1.2651911973953247 reward 1.1892943382263184\n",
      "val loss 2.4544854164123535 2.455047369003296\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6298076923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7737179487179487}]\n",
      "______epoch 116 _____\n",
      "train imitation 1.2847973108291626 reward 1.1819124221801758\n",
      "val imitation 1.2645773887634277 reward 1.1891134977340698\n",
      "val loss 2.453691005706787 2.4544854164123535\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6307692307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.724780701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 117 _____\n",
      "train imitation 1.3051824569702148 reward 1.1802058219909668\n",
      "val imitation 1.263993501663208 reward 1.1891134977340698\n",
      "val loss 2.4531068801879883 2.453691005706787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6326923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7737179487179489}]\n",
      "______epoch 118 _____\n",
      "train imitation 1.3224990367889404 reward 1.1854801177978516\n",
      "val imitation 1.263413667678833 reward 1.1891134977340698\n",
      "val loss 2.4525270462036133 2.4531068801879883\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.633173076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7733974358974358}]\n",
      "______epoch 119 _____\n",
      "train imitation 1.3337832689285278 reward 1.1824721097946167\n",
      "val imitation 1.262838363647461 reward 1.1891134977340698\n",
      "val loss 2.4519519805908203 2.4525270462036133\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6350961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 120 _____\n",
      "train imitation 1.303936243057251 reward 1.182662844657898\n",
      "val imitation 1.2623887062072754 reward 1.1892462968826294\n",
      "val loss 2.4516348838806152 2.4519519805908203\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6360576923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 121 _____\n",
      "train imitation 1.3405015468597412 reward 1.1834237575531006\n",
      "val imitation 1.2619030475616455 reward 1.1893259286880493\n",
      "val loss 2.4512290954589844 2.4516348838806152\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7724358974358975}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 122 _____\n",
      "train imitation 1.3353101015090942 reward 1.1837143898010254\n",
      "val imitation 1.2614336013793945 reward 1.1888949871063232\n",
      "val loss 2.4503285884857178 2.4512290954589844\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375000000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7225877192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n",
      "______epoch 123 _____\n",
      "train imitation 1.3172979354858398 reward 1.183728814125061\n",
      "val imitation 1.2610281705856323 reward 1.1888731718063354\n",
      "val loss 2.4499013423919678 2.4503285884857178\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7225877192982457}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333334}]\n",
      "______epoch 124 _____\n",
      "train imitation 1.2882364988327026 reward 1.1834731101989746\n",
      "val imitation 1.2606478929519653 reward 1.1888731718063354\n",
      "val loss 2.449521064758301 2.4499013423919678\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6399038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842104}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.769551282051282}]\n",
      "______epoch 125 _____\n",
      "train imitation 1.3025254011154175 reward 1.1840914487838745\n",
      "val imitation 1.2602803707122803 reward 1.1888731718063354\n",
      "val loss 2.449153423309326 2.449521064758301\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7217653508771928}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7705128205128204}]\n",
      "______epoch 126 _____\n",
      "train imitation 1.3125977516174316 reward 1.1844685077667236\n",
      "val imitation 1.2598682641983032 reward 1.1888731718063354\n",
      "val loss 2.4487414360046387 2.449153423309326\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7214912280701755}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7692307692307693}]\n",
      "______epoch 127 _____\n",
      "train imitation 1.2825164794921875 reward 1.1828726530075073\n",
      "val imitation 1.259398102760315 reward 1.1891860961914062\n",
      "val loss 2.4485840797424316 2.4487414360046387\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7682692307692308}]\n",
      "______epoch 128 _____\n",
      "train imitation 1.3091931343078613 reward 1.1820803880691528\n",
      "val imitation 1.258992075920105 reward 1.1891860961914062\n",
      "val loss 2.448178291320801 2.4485840797424316\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7225877192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.767948717948718}]\n",
      "______epoch 129 _____\n",
      "train imitation 1.320237398147583 reward 1.1850457191467285\n",
      "val imitation 1.2586112022399902 reward 1.1892048120498657\n",
      "val loss 2.4478158950805664 2.448178291320801\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.722861842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7679487179487179}]\n",
      "______epoch 130 _____\n",
      "train imitation 1.3314268589019775 reward 1.1824209690093994\n",
      "val imitation 1.2581130266189575 reward 1.188891887664795\n",
      "val loss 2.447004795074463 2.4478158950805664\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7676282051282051}]\n",
      "______epoch 131 _____\n",
      "train imitation 1.3050649166107178 reward 1.183779001235962\n",
      "val imitation 1.2575454711914062 reward 1.1889368295669556\n",
      "val loss 2.4464821815490723 2.447004795074463\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7220394736842104}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.766025641025641}]\n",
      "______epoch 132 _____\n",
      "train imitation 1.3038207292556763 reward 1.1806560754776\n",
      "val imitation 1.2570220232009888 reward 1.1888020038604736\n",
      "val loss 2.445824146270752 2.4464821815490723\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6384615384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7214912280701753}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.766025641025641}]\n",
      "______epoch 133 _____\n",
      "train imitation 1.3122029304504395 reward 1.1815584897994995\n",
      "val imitation 1.2565677165985107 reward 1.1887800693511963\n",
      "val loss 2.445347785949707 2.445824146270752\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7209429824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7650641025641026}]\n",
      "______epoch 134 _____\n",
      "train imitation 1.3042027950286865 reward 1.1808799505233765\n",
      "val imitation 1.2560206651687622 reward 1.1887609958648682\n",
      "val loss 2.44478178024292 2.445347785949707\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435897}]\n",
      "______epoch 135 _____\n",
      "train imitation 1.3183387517929077 reward 1.1821346282958984\n",
      "val imitation 1.2555060386657715 reward 1.1886147260665894\n",
      "val loss 2.4441208839416504 2.44478178024292\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435898}]\n",
      "______epoch 136 _____\n",
      "train imitation 1.3020585775375366 reward 1.1818667650222778\n",
      "val imitation 1.254948616027832 reward 1.1886147260665894\n",
      "val loss 2.443563461303711 2.4441208839416504\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7206688596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7644230769230769}]\n",
      "______epoch 137 _____\n",
      "train imitation 1.314558506011963 reward 1.1793965101242065\n",
      "val imitation 1.254420518875122 reward 1.1885590553283691\n",
      "val loss 2.442979574203491 2.443563461303711\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6399038461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7214912280701755}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435898}]\n",
      "______epoch 138 _____\n",
      "train imitation 1.2495321035385132 reward 1.1841706037521362\n",
      "val imitation 1.2539268732070923 reward 1.1884989738464355\n",
      "val loss 2.4424257278442383 2.442979574203491\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.721765350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7650641025641025}]\n",
      "______epoch 139 _____\n",
      "train imitation 1.2627601623535156 reward 1.182856798171997\n",
      "val imitation 1.2535016536712646 reward 1.1884989738464355\n",
      "val loss 2.4420006275177 2.4424257278442383\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6408653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7209429824561403}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7653846153846154}]\n",
      "______epoch 140 _____\n",
      "train imitation 1.2920093536376953 reward 1.18495774269104\n",
      "val imitation 1.25298011302948 reward 1.1884989738464355\n",
      "val loss 2.441479206085205 2.4420006275177\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6418269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7209429824561403}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7650641025641025}]\n",
      "______epoch 141 _____\n",
      "train imitation 1.3116161823272705 reward 1.1807360649108887\n",
      "val imitation 1.252384066581726 reward 1.188625693321228\n",
      "val loss 2.441009759902954 2.441479206085205\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6408653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7209429824561403}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7644230769230769}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 142 _____\n",
      "train imitation 1.308988094329834 reward 1.1827898025512695\n",
      "val imitation 1.2518820762634277 reward 1.188625693321228\n",
      "val loss 2.4405078887939453 2.441009759902954\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6423076923076922}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7198464912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435897}]\n",
      "______epoch 143 _____\n",
      "train imitation 1.2897448539733887 reward 1.1842409372329712\n",
      "val imitation 1.2514846324920654 reward 1.188625693321228\n",
      "val loss 2.440110206604004 2.4405078887939453\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7190241228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7650641025641026}]\n",
      "______epoch 144 _____\n",
      "train imitation 1.2968952655792236 reward 1.1830050945281982\n",
      "val imitation 1.2510011196136475 reward 1.1885663270950317\n",
      "val loss 2.4395675659179688 2.440110206604004\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7190241228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435897}]\n",
      "______epoch 145 _____\n",
      "train imitation 1.3109545707702637 reward 1.179807186126709\n",
      "val imitation 1.2505435943603516 reward 1.1885747909545898\n",
      "val loss 2.4391183853149414 2.4395675659179688\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.71875}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7644230769230769}]\n",
      "______epoch 146 _____\n",
      "train imitation 1.2648417949676514 reward 1.1817713975906372\n",
      "val imitation 1.2501113414764404 reward 1.188513159751892\n",
      "val loss 2.438624382019043 2.4391183853149414\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7190241228070176}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7650641025641025}]\n",
      "______epoch 147 _____\n",
      "train imitation 1.2879383563995361 reward 1.1823536157608032\n",
      "val imitation 1.2495648860931396 reward 1.188513159751892\n",
      "val loss 2.438077926635742 2.438624382019043\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6466346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7198464912280702}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.764423076923077}]\n",
      "______epoch 148 _____\n",
      "train imitation 1.2388492822647095 reward 1.180545687675476\n",
      "val imitation 1.2490686178207397 reward 1.1884589195251465\n",
      "val loss 2.437527656555176 2.438077926635742\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6466346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7195723684210527}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7637820512820512}]\n",
      "______epoch 149 _____\n",
      "train imitation 1.2801975011825562 reward 1.1807713508605957\n",
      "val imitation 1.2486437559127808 reward 1.1884589195251465\n",
      "val loss 2.437102794647217 2.437527656555176\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6456730769230768}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7198464912280702}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.764102564102564}]\n",
      "______epoch 150 _____\n",
      "train imitation 1.3259919881820679 reward 1.1823891401290894\n",
      "val imitation 1.248387098312378 reward 1.1887009143829346\n",
      "val loss 2.4370880126953125 2.437102794647217\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7195723684210527}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.764102564102564}]\n",
      "______epoch 151 _____\n",
      "train imitation 1.294571876525879 reward 1.1801731586456299\n",
      "val imitation 1.2479690313339233 reward 1.188238501548767\n",
      "val loss 2.4362075328826904 2.4370880126953125\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7195723684210527}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7637820512820512}]\n",
      "______epoch 152 _____\n",
      "train imitation 1.2596619129180908 reward 1.1796398162841797\n",
      "val imitation 1.2475507259368896 reward 1.1881773471832275\n",
      "val loss 2.435728073120117 2.4362075328826904\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7192982456140351}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7625}]\n",
      "______epoch 153 _____\n",
      "train imitation 1.3081817626953125 reward 1.1800870895385742\n",
      "val imitation 1.2471152544021606 reward 1.1881773471832275\n",
      "val loss 2.4352927207946777 2.435728073120117\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7195723684210525}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7615384615384615}]\n",
      "______epoch 154 _____\n",
      "train imitation 1.2745018005371094 reward 1.1817554235458374\n",
      "val imitation 1.2467073202133179 reward 1.1884896755218506\n",
      "val loss 2.435196876525879 2.4352927207946777\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.645673076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7190241228070176}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7615384615384615}]\n",
      "______epoch 155 _____\n",
      "train imitation 1.275738000869751 reward 1.1803810596466064\n",
      "val imitation 1.2462083101272583 reward 1.1884064674377441\n",
      "val loss 2.434614658355713 2.435196876525879\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6447115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7195723684210527}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7628205128205128}]\n",
      "______epoch 156 _____\n",
      "train imitation 1.2624576091766357 reward 1.1819853782653809\n",
      "val imitation 1.245836853981018 reward 1.18874192237854\n",
      "val loss 2.4345788955688477 2.434614658355713\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.645673076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7192982456140351}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7631410256410256}]\n",
      "______epoch 157 _____\n",
      "train imitation 1.2690041065216064 reward 1.183503270149231\n",
      "val imitation 1.2454737424850464 reward 1.1888633966445923\n",
      "val loss 2.4343371391296387 2.4345788955688477\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7192982456140351}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7631410256410256}]\n",
      "______epoch 158 _____\n",
      "train imitation 1.2549934387207031 reward 1.1840345859527588\n",
      "val imitation 1.2451382875442505 reward 1.1888633966445923\n",
      "val loss 2.4340016841888428 2.4343371391296387\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7179276315789473}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7625}]\n",
      "______epoch 159 _____\n",
      "train imitation 1.2486801147460938 reward 1.1814929246902466\n",
      "val imitation 1.2447619438171387 reward 1.1888850927352905\n",
      "val loss 2.4336471557617188 2.4340016841888428\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7176535087719298}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7625}]\n",
      "______epoch 160 _____\n",
      "train imitation 1.280448079109192 reward 1.1798996925354004\n",
      "val imitation 1.2445237636566162 reward 1.1888850927352905\n",
      "val loss 2.433408737182617 2.4336471557617188\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7173793859649122}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7628205128205128}]\n",
      "______epoch 161 _____\n",
      "train imitation 1.2255436182022095 reward 1.1820054054260254\n",
      "val imitation 1.244200587272644 reward 1.1888850927352905\n",
      "val loss 2.4330856800079346 2.433408737182617\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.716282894736842}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7628205128205129}]\n",
      "______epoch 162 _____\n",
      "train imitation 1.297701120376587 reward 1.1801804304122925\n",
      "val imitation 1.243902325630188 reward 1.1889177560806274\n",
      "val loss 2.4328200817108154 2.4330856800079346\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7160087719298245}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7628205128205129}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 163 _____\n",
      "train imitation 1.254044771194458 reward 1.1838613748550415\n",
      "val imitation 1.2435396909713745 reward 1.1884181499481201\n",
      "val loss 2.431957721710205 2.4328200817108154\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6427884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7160087719298246}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7628205128205128}]\n",
      "______epoch 164 _____\n",
      "train imitation 1.2578409910202026 reward 1.1831963062286377\n",
      "val imitation 1.2432926893234253 reward 1.1884151697158813\n",
      "val loss 2.4317078590393066 2.431957721710205\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7168311403508771}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7615384615384615}]\n",
      "______epoch 165 _____\n",
      "train imitation 1.2932919263839722 reward 1.1822419166564941\n",
      "val imitation 1.2429471015930176 reward 1.188717246055603\n",
      "val loss 2.43166446685791 2.4317078590393066\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6432692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7168311403508771}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7621794871794871}]\n",
      "______epoch 166 _____\n",
      "train imitation 1.24064040184021 reward 1.1816831827163696\n",
      "val imitation 1.2427924871444702 reward 1.1888083219528198\n",
      "val loss 2.43160080909729 2.43166446685791\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7165570175438597}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 167 _____\n",
      "train imitation 1.2526259422302246 reward 1.179018259048462\n",
      "val imitation 1.2428038120269775 reward 1.1888083219528198\n",
      "val loss 2.431612014770508 2.43160080909729\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7168311403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 168 _____\n",
      "train imitation 1.2940571308135986 reward 1.1824861764907837\n",
      "val imitation 1.2426422834396362 reward 1.1888083219528198\n",
      "val loss 2.431450605392456 2.43160080909729\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7162828947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7621794871794871}]\n",
      "______epoch 169 _____\n",
      "train imitation 1.2095664739608765 reward 1.1828869581222534\n",
      "val imitation 1.242488980293274 reward 1.1887651681900024\n",
      "val loss 2.4312541484832764 2.431450605392456\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6432692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7165570175438597}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7621794871794871}]\n",
      "______epoch 170 _____\n",
      "train imitation 1.273880958557129 reward 1.1799415349960327\n",
      "val imitation 1.2423239946365356 reward 1.188785433769226\n",
      "val loss 2.4311094284057617 2.4312541484832764\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6427884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7162828947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7625}]\n",
      "______epoch 171 _____\n",
      "train imitation 1.2742806673049927 reward 1.1816191673278809\n",
      "val imitation 1.2420622110366821 reward 1.1887931823730469\n",
      "val loss 2.4308552742004395 2.4311094284057617\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6418269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7173793859649124}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7631410256410256}]\n",
      "______epoch 172 _____\n",
      "train imitation 1.2451260089874268 reward 1.1816411018371582\n",
      "val imitation 1.2419805526733398 reward 1.188493251800537\n",
      "val loss 2.430473804473877 2.4308552742004395\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7173793859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7631410256410256}]\n",
      "______epoch 173 _____\n",
      "train imitation 1.282122015953064 reward 1.1792954206466675\n",
      "val imitation 1.2420071363449097 reward 1.188493251800537\n",
      "val loss 2.4305005073547363 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6423076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7179276315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7628205128205128}]\n",
      "______epoch 174 _____\n",
      "train imitation 1.2809760570526123 reward 1.182059407234192\n",
      "val imitation 1.242069959640503 reward 1.188493251800537\n",
      "val loss 2.43056321144104 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6432692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7182017543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7621794871794871}]\n",
      "______epoch 175 _____\n",
      "train imitation 1.225851058959961 reward 1.1789823770523071\n",
      "val imitation 1.2421238422393799 reward 1.188493251800537\n",
      "val loss 2.430617094039917 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7179276315789475}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 176 _____\n",
      "train imitation 1.2378060817718506 reward 1.1815086603164673\n",
      "val imitation 1.2423604726791382 reward 1.1885321140289307\n",
      "val loss 2.4308924674987793 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923077}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7176535087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 177 _____\n",
      "train imitation 1.263075590133667 reward 1.182585597038269\n",
      "val imitation 1.2424832582473755 reward 1.1883172988891602\n",
      "val loss 2.430800437927246 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.645673076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7179276315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 178 _____\n",
      "train imitation 1.247145652770996 reward 1.1820670366287231\n",
      "val imitation 1.242677092552185 reward 1.1883172988891602\n",
      "val loss 2.4309945106506348 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7176535087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "______epoch 179 _____\n",
      "train imitation 1.2403578758239746 reward 1.1825047731399536\n",
      "val imitation 1.2427884340286255 reward 1.1885097026824951\n",
      "val loss 2.43129825592041 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7173793859649122}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7621794871794871}]\n",
      "______epoch 180 _____\n",
      "train imitation 1.2009307146072388 reward 1.1834772825241089\n",
      "val imitation 1.2432277202606201 reward 1.1885097026824951\n",
      "val loss 2.4317374229431152 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7176535087719299}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7615384615384615}]\n",
      "______epoch 181 _____\n",
      "train imitation 1.2237536907196045 reward 1.1829063892364502\n",
      "val imitation 1.2436264753341675 reward 1.1886100769042969\n",
      "val loss 2.432236671447754 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6447115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7162828947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7615384615384615}]\n",
      "______epoch 182 _____\n",
      "train imitation 1.250957727432251 reward 1.1808357238769531\n",
      "val imitation 1.2439526319503784 reward 1.1887258291244507\n",
      "val loss 2.432678461074829 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.645673076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7608974358974359}]\n",
      "______epoch 183 _____\n",
      "train imitation 1.236499309539795 reward 1.1830849647521973\n",
      "val imitation 1.2442173957824707 reward 1.1887258291244507\n",
      "val loss 2.432943344116211 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7160087719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.760576923076923}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 184 _____\n",
      "train imitation 1.253989577293396 reward 1.1804355382919312\n",
      "val imitation 1.2441534996032715 reward 1.1887258291244507\n",
      "val loss 2.4328794479370117 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.760576923076923}]\n",
      "______epoch 185 _____\n",
      "train imitation 1.2083740234375 reward 1.1802603006362915\n",
      "val imitation 1.2442569732666016 reward 1.188940405845642\n",
      "val loss 2.433197498321533 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6466346153846153}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7154605263157894}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7602564102564102}]\n",
      "______epoch 186 _____\n",
      "train imitation 1.2683528661727905 reward 1.1815779209136963\n",
      "val imitation 1.2444853782653809 reward 1.1891231536865234\n",
      "val loss 2.4336085319519043 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.714638157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7596153846153846}]\n",
      "______epoch 187 _____\n",
      "train imitation 1.2090773582458496 reward 1.1809613704681396\n",
      "val imitation 1.244791030883789 reward 1.1891231536865234\n",
      "val loss 2.4339141845703125 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7149122807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 188 _____\n",
      "train imitation 1.2756633758544922 reward 1.1806426048278809\n",
      "val imitation 1.2450783252716064 reward 1.1891123056411743\n",
      "val loss 2.4341907501220703 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7154605263157894}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 189 _____\n",
      "train imitation 1.1936670541763306 reward 1.1806621551513672\n",
      "val imitation 1.245492696762085 reward 1.1900370121002197\n",
      "val loss 2.4355297088623047 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7162828947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "______epoch 190 _____\n",
      "train imitation 1.271897792816162 reward 1.1826105117797852\n",
      "val imitation 1.2456145286560059 reward 1.1900370121002197\n",
      "val loss 2.4356515407562256 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7154605263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n",
      "______epoch 191 _____\n",
      "train imitation 1.227156400680542 reward 1.1817448139190674\n",
      "val imitation 1.246112585067749 reward 1.1901564598083496\n",
      "val loss 2.4362690448760986 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7146381578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n",
      "______epoch 192 _____\n",
      "train imitation 1.2544136047363281 reward 1.1827678680419922\n",
      "val imitation 1.2464828491210938 reward 1.1901564598083496\n",
      "val loss 2.4366393089294434 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7586538461538461}]\n",
      "______epoch 193 _____\n",
      "train imitation 1.1997944116592407 reward 1.181553840637207\n",
      "val imitation 1.2466497421264648 reward 1.1901564598083496\n",
      "val loss 2.4368062019348145 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7151864035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 194 _____\n",
      "train imitation 1.2067599296569824 reward 1.1820447444915771\n",
      "val imitation 1.2466217279434204 reward 1.1901564598083496\n",
      "val loss 2.4367780685424805 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7599358974358974}]\n",
      "______epoch 195 _____\n",
      "train imitation 1.2438697814941406 reward 1.183449149131775\n",
      "val imitation 1.2465358972549438 reward 1.190065622329712\n",
      "val loss 2.4366016387939453 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7160087719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7589743589743589}]\n",
      "______epoch 196 _____\n",
      "train imitation 1.2054845094680786 reward 1.1838830709457397\n",
      "val imitation 1.2464280128479004 reward 1.1900274753570557\n",
      "val loss 2.436455488204956 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6499999999999999}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7157346491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 197 _____\n",
      "train imitation 1.2210681438446045 reward 1.179553508758545\n",
      "val imitation 1.2465218305587769 reward 1.1901183128356934\n",
      "val loss 2.4366402626037598 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7160087719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 198 _____\n",
      "train imitation 1.2563544511795044 reward 1.1834696531295776\n",
      "val imitation 1.2467716932296753 reward 1.1901183128356934\n",
      "val loss 2.436890125274658 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7154605263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7592948717948718}]\n",
      "______epoch 199 _____\n",
      "train imitation 1.220173954963684 reward 1.183813214302063\n",
      "val imitation 1.2471120357513428 reward 1.1896568536758423\n",
      "val loss 2.4367690086364746 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7154605263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7596153846153846}]\n",
      "______epoch 200 _____\n",
      "train imitation 1.2268834114074707 reward 1.1816781759262085\n",
      "val imitation 1.2477266788482666 reward 1.1896135807037354\n",
      "val loss 2.437340259552002 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7146381578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7596153846153846}]\n",
      "______epoch 201 _____\n",
      "train imitation 1.2010232210159302 reward 1.1827237606048584\n",
      "val imitation 1.2481335401535034 reward 1.1898938417434692\n",
      "val loss 2.4380273818969727 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7586538461538461}]\n",
      "______epoch 202 _____\n",
      "train imitation 1.2482179403305054 reward 1.1835192441940308\n",
      "val imitation 1.248490810394287 reward 1.1898938417434692\n",
      "val loss 2.438384532928467 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7589743589743589}]\n",
      "______epoch 203 _____\n",
      "train imitation 1.2424925565719604 reward 1.1816784143447876\n",
      "val imitation 1.2491319179534912 reward 1.1898938417434692\n",
      "val loss 2.43902587890625 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6485576923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 204 _____\n",
      "train imitation 1.2465823888778687 reward 1.1798620223999023\n",
      "val imitation 1.2495278120040894 reward 1.1898938417434692\n",
      "val loss 2.4394216537475586 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n",
      "______epoch 205 _____\n",
      "train imitation 1.220320701599121 reward 1.1817084550857544\n",
      "val imitation 1.2501115798950195 reward 1.1898938417434692\n",
      "val loss 2.440005302429199 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "______epoch 206 _____\n",
      "train imitation 1.243523120880127 reward 1.1805429458618164\n",
      "val imitation 1.2499876022338867 reward 1.1898938417434692\n",
      "val loss 2.4398813247680664 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7576923076923077}]\n",
      "______epoch 207 _____\n",
      "train imitation 1.2373334169387817 reward 1.1844033002853394\n",
      "val imitation 1.2500203847885132 reward 1.1896779537200928\n",
      "val loss 2.4396982192993164 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "______epoch 208 _____\n",
      "train imitation 1.2275508642196655 reward 1.181584358215332\n",
      "val imitation 1.2500501871109009 reward 1.189889669418335\n",
      "val loss 2.4399399757385254 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "______epoch 209 _____\n",
      "train imitation 1.2469868659973145 reward 1.1813709735870361\n",
      "val imitation 1.249611735343933 reward 1.189779281616211\n",
      "val loss 2.4393911361694336 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7576923076923077}]\n",
      "______epoch 210 _____\n",
      "train imitation 1.2492249011993408 reward 1.182634949684143\n",
      "val imitation 1.248620629310608 reward 1.1888647079467773\n",
      "val loss 2.4374852180480957 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7567307692307692}]\n",
      "______epoch 211 _____\n",
      "train imitation 1.2152180671691895 reward 1.1822651624679565\n",
      "val imitation 1.2478958368301392 reward 1.188713788986206\n",
      "val loss 2.4366097450256348 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6499999999999999}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7118969298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7567307692307692}]\n",
      "______epoch 212 _____\n",
      "train imitation 1.234399676322937 reward 1.1821436882019043\n",
      "val imitation 1.2471758127212524 reward 1.1882705688476562\n",
      "val loss 2.435446262359619 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7560897435897436}]\n",
      "______epoch 213 _____\n",
      "train imitation 1.222112774848938 reward 1.1808116436004639\n",
      "val imitation 1.2465060949325562 reward 1.1883373260498047\n",
      "val loss 2.4348435401916504 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7564102564102564}]\n",
      "______epoch 214 _____\n",
      "train imitation 1.2345765829086304 reward 1.1824959516525269\n",
      "val imitation 1.2460612058639526 reward 1.1881214380264282\n",
      "val loss 2.434182643890381 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6514423076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7138157894736842}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7567307692307692}]\n",
      "______epoch 215 _____\n",
      "train imitation 1.2155022621154785 reward 1.1806156635284424\n",
      "val imitation 1.2456324100494385 reward 1.1880515813827515\n",
      "val loss 2.4336838722229004 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230768}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.757051282051282}]\n",
      "______epoch 216 _____\n",
      "train imitation 1.2251925468444824 reward 1.1833909749984741\n",
      "val imitation 1.2454497814178467 reward 1.1880007982254028\n",
      "val loss 2.433450698852539 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6524038461538462}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807018}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7586538461538461}]\n",
      "______epoch 217 _____\n",
      "train imitation 1.2698626518249512 reward 1.1831978559494019\n",
      "val imitation 1.2452586889266968 reward 1.188645362854004\n",
      "val loss 2.4339041709899902 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807018}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7592948717948718}]\n",
      "______epoch 218 _____\n",
      "train imitation 1.2182385921478271 reward 1.180428385734558\n",
      "val imitation 1.2450357675552368 reward 1.188645362854004\n",
      "val loss 2.433681011199951 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615384}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807018}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7586538461538461}]\n",
      "______epoch 219 _____\n",
      "train imitation 1.1903409957885742 reward 1.1809544563293457\n",
      "val imitation 1.244873046875 reward 1.188645362854004\n",
      "val loss 2.433518409729004 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807018}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7586538461538461}]\n",
      "______epoch 220 _____\n",
      "train imitation 1.2059056758880615 reward 1.183467984199524\n",
      "val imitation 1.244553804397583 reward 1.188645362854004\n",
      "val loss 2.433199167251587 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6514423076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7138157894736842}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7596153846153846}]\n",
      "______epoch 221 _____\n",
      "train imitation 1.207362174987793 reward 1.1788374185562134\n",
      "val imitation 1.2444101572036743 reward 1.188628911972046\n",
      "val loss 2.4330391883850098 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6524038461538462}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807017}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7608974358974359}]\n",
      "______epoch 222 _____\n",
      "train imitation 1.1662768125534058 reward 1.1818755865097046\n",
      "val imitation 1.2441877126693726 reward 1.188628911972046\n",
      "val loss 2.432816505432129 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.760897435897436}]\n",
      "______epoch 223 _____\n",
      "train imitation 1.2289910316467285 reward 1.1819730997085571\n",
      "val imitation 1.244147539138794 reward 1.1884442567825317\n",
      "val loss 2.4325919151306152 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.760576923076923}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 224 _____\n",
      "train imitation 1.2258397340774536 reward 1.182205319404602\n",
      "val imitation 1.2443815469741821 reward 1.188377857208252\n",
      "val loss 2.4327592849731445 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7608974358974359}]\n",
      "______epoch 225 _____\n",
      "train imitation 1.2110233306884766 reward 1.1800861358642578\n",
      "val imitation 1.2449017763137817 reward 1.188420057296753\n",
      "val loss 2.433321952819824 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.760576923076923}]\n",
      "______epoch 226 _____\n",
      "train imitation 1.1963790655136108 reward 1.18160080909729\n",
      "val imitation 1.2460083961486816 reward 1.1888593435287476\n",
      "val loss 2.4348678588867188 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6548076923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7140899122807017}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7608974358974359}]\n",
      "______epoch 227 _____\n",
      "train imitation 1.2215907573699951 reward 1.180372953414917\n",
      "val imitation 1.2476222515106201 reward 1.1888593435287476\n",
      "val loss 2.436481475830078 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7612179487179487}]\n",
      "______epoch 228 _____\n",
      "train imitation 1.2081596851348877 reward 1.1817020177841187\n",
      "val imitation 1.2490222454071045 reward 1.1889580488204956\n",
      "val loss 2.4379801750183105 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7612179487179487}]\n",
      "______epoch 229 _____\n",
      "train imitation 1.2374467849731445 reward 1.1831542253494263\n",
      "val imitation 1.2500053644180298 reward 1.1889580488204956\n",
      "val loss 2.4389634132385254 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7612179487179487}]\n",
      "______epoch 230 _____\n",
      "train imitation 1.2297015190124512 reward 1.179460048675537\n",
      "val imitation 1.2500609159469604 reward 1.1884593963623047\n",
      "val loss 2.4385204315185547 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7612179487179487}]\n",
      "______epoch 231 _____\n",
      "train imitation 1.2023147344589233 reward 1.1813852787017822\n",
      "val imitation 1.2503513097763062 reward 1.1884804964065552\n",
      "val loss 2.4388318061828613 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7615384615384615}]\n",
      "______epoch 232 _____\n",
      "train imitation 1.2269905805587769 reward 1.1823756694793701\n",
      "val imitation 1.250669002532959 reward 1.1884804964065552\n",
      "val loss 2.4391493797302246 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7615384615384615}]\n",
      "______epoch 233 _____\n",
      "train imitation 1.193840503692627 reward 1.183099627494812\n",
      "val imitation 1.249878168106079 reward 1.1882565021514893\n",
      "val loss 2.4381346702575684 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6538461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7625}]\n",
      "______epoch 234 _____\n",
      "train imitation 1.1841511726379395 reward 1.181618332862854\n",
      "val imitation 1.2490174770355225 reward 1.1876709461212158\n",
      "val loss 2.4366884231567383 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7625}]\n",
      "______epoch 235 _____\n",
      "train imitation 1.1989558935165405 reward 1.181864619255066\n",
      "val imitation 1.2483673095703125 reward 1.1876710653305054\n",
      "val loss 2.4360384941101074 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6548076923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7618589743589743}]\n",
      "______epoch 236 _____\n",
      "train imitation 1.2622745037078857 reward 1.1787676811218262\n",
      "val imitation 1.2478570938110352 reward 1.187855839729309\n",
      "val loss 2.4357128143310547 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7618589743589743}]\n",
      "______epoch 237 _____\n",
      "train imitation 1.2277631759643555 reward 1.1817487478256226\n",
      "val imitation 1.2471922636032104 reward 1.187855839729309\n",
      "val loss 2.4350481033325195 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692309}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.712719298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7608974358974359}]\n",
      "______epoch 238 _____\n",
      "train imitation 1.225590705871582 reward 1.1794345378875732\n",
      "val imitation 1.2462915182113647 reward 1.187855839729309\n",
      "val loss 2.434147357940674 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615386}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7599358974358974}]\n",
      "______epoch 239 _____\n",
      "train imitation 1.209577202796936 reward 1.1833710670471191\n",
      "val imitation 1.2459516525268555 reward 1.1880006790161133\n",
      "val loss 2.4339523315429688 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712719298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7602564102564102}]\n",
      "______epoch 240 _____\n",
      "train imitation 1.2077287435531616 reward 1.1831992864608765\n",
      "val imitation 1.2454607486724854 reward 1.1880006790161133\n",
      "val loss 2.4334614276885986 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7596153846153846}]\n",
      "______epoch 241 _____\n",
      "train imitation 1.2030398845672607 reward 1.1799378395080566\n",
      "val imitation 1.2449841499328613 reward 1.1880006790161133\n",
      "val loss 2.4329848289489746 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7596153846153846}]\n",
      "______epoch 242 _____\n",
      "train imitation 1.2083457708358765 reward 1.1797266006469727\n",
      "val imitation 1.2449209690093994 reward 1.1880006790161133\n",
      "val loss 2.4329216480255127 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615386}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7586538461538461}]\n",
      "______epoch 243 _____\n",
      "train imitation 1.1786084175109863 reward 1.1833927631378174\n",
      "val imitation 1.2451581954956055 reward 1.1881095170974731\n",
      "val loss 2.433267593383789 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615386}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 244 _____\n",
      "train imitation 1.2084933519363403 reward 1.1809087991714478\n",
      "val imitation 1.2454630136489868 reward 1.1881095170974731\n",
      "val loss 2.43357253074646 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7129934210526315}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 245 _____\n",
      "train imitation 1.1809507608413696 reward 1.1809451580047607\n",
      "val imitation 1.2456588745117188 reward 1.1881095170974731\n",
      "val loss 2.4337682723999023 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7129934210526315}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 246 _____\n",
      "train imitation 1.223212480545044 reward 1.180373191833496\n",
      "val imitation 1.2459386587142944 reward 1.1881095170974731\n",
      "val loss 2.4340481758117676 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6567307692307692}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7580128205128205}]\n",
      "______epoch 247 _____\n",
      "train imitation 1.2651829719543457 reward 1.1809840202331543\n",
      "val imitation 1.245631456375122 reward 1.1879643201828003\n",
      "val loss 2.433595657348633 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 248 _____\n",
      "train imitation 1.2310428619384766 reward 1.1785521507263184\n",
      "val imitation 1.2454650402069092 reward 1.188180923461914\n",
      "val loss 2.4336459636688232 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692307}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7118969298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7576923076923077}]\n",
      "______epoch 249 _____\n",
      "train imitation 1.1791980266571045 reward 1.1812405586242676\n",
      "val imitation 1.2453410625457764 reward 1.188180923461914\n",
      "val loss 2.4335219860076904 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7576923076923077}]\n",
      "______epoch 250 _____\n",
      "train imitation 1.18384850025177 reward 1.1832042932510376\n",
      "val imitation 1.2455171346664429 reward 1.188195824623108\n",
      "val loss 2.433712959289551 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.757051282051282}]\n",
      "______epoch 251 _____\n",
      "train imitation 1.200676441192627 reward 1.1842325925827026\n",
      "val imitation 1.2458436489105225 reward 1.188195824623108\n",
      "val loss 2.43403959274292 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7567307692307692}]\n",
      "______epoch 252 _____\n",
      "train imitation 1.220078706741333 reward 1.1812843084335327\n",
      "val imitation 1.2464524507522583 reward 1.1881239414215088\n",
      "val loss 2.4345765113830566 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7116228070175439}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7573717948717948}]\n",
      "______epoch 253 _____\n",
      "train imitation 1.204667568206787 reward 1.1784216165542603\n",
      "val imitation 1.2471635341644287 reward 1.188144564628601\n",
      "val loss 2.4353079795837402 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7576923076923077}]\n",
      "______epoch 254 _____\n",
      "train imitation 1.2171964645385742 reward 1.182769775390625\n",
      "val imitation 1.247910737991333 reward 1.188144564628601\n",
      "val loss 2.4360551834106445 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712719298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7580128205128205}]\n",
      "______epoch 255 _____\n",
      "train imitation 1.2251834869384766 reward 1.1819875240325928\n",
      "val imitation 1.2480331659317017 reward 1.188144564628601\n",
      "val loss 2.4361777305603027 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 256 _____\n",
      "train imitation 1.2199573516845703 reward 1.1814428567886353\n",
      "val imitation 1.2480391263961792 reward 1.188144564628601\n",
      "val loss 2.4361836910247803 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7586538461538461}]\n",
      "______epoch 257 _____\n",
      "train imitation 1.2308766841888428 reward 1.1822999715805054\n",
      "val imitation 1.248752236366272 reward 1.188278079032898\n",
      "val loss 2.43703031539917 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615386}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712719298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 258 _____\n",
      "train imitation 1.199313998222351 reward 1.1806060075759888\n",
      "val imitation 1.2492175102233887 reward 1.1883187294006348\n",
      "val loss 2.4375362396240234 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7129934210526315}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7586538461538461}]\n",
      "______epoch 259 _____\n",
      "train imitation 1.2189425230026245 reward 1.1837292909622192\n",
      "val imitation 1.249853491783142 reward 1.1883187294006348\n",
      "val loss 2.4381723403930664 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7592948717948718}]\n",
      "______epoch 260 _____\n",
      "train imitation 1.2116721868515015 reward 1.1800258159637451\n",
      "val imitation 1.2503730058670044 reward 1.1882362365722656\n",
      "val loss 2.4386091232299805 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7132675438596492}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7586538461538461}]\n",
      "______epoch 261 _____\n",
      "train imitation 1.214247703552246 reward 1.1828665733337402\n",
      "val imitation 1.2509567737579346 reward 1.188544750213623\n",
      "val loss 2.4395015239715576 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7132675438596492}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7592948717948718}]\n",
      "______epoch 262 _____\n",
      "train imitation 1.1887019872665405 reward 1.1824610233306885\n",
      "val imitation 1.2519304752349854 reward 1.1885465383529663\n",
      "val loss 2.440476894378662 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7132675438596492}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7592948717948718}]\n",
      "______epoch 263 _____\n",
      "train imitation 1.219595193862915 reward 1.181984305381775\n",
      "val imitation 1.253065586090088 reward 1.188556432723999\n",
      "val loss 2.441622018814087 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6586538461538463}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7127192982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7589743589743589}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 264 _____\n",
      "train imitation 1.2176625728607178 reward 1.1809096336364746\n",
      "val imitation 1.2542054653167725 reward 1.1884838342666626\n",
      "val loss 2.4426894187927246 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6581730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7118969298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7583333333333333}]\n",
      "______epoch 265 _____\n",
      "train imitation 1.2210216522216797 reward 1.181593894958496\n",
      "val imitation 1.254934310913086 reward 1.1889853477478027\n",
      "val loss 2.4439196586608887 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6591346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7118969298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7573717948717948}]\n",
      "______epoch 266 _____\n",
      "train imitation 1.1644319295883179 reward 1.180776834487915\n",
      "val imitation 1.2555088996887207 reward 1.189017653465271\n",
      "val loss 2.4445266723632812 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6596153846153847}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7124451754385965}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7573717948717948}]\n",
      "______epoch 267 _____\n",
      "train imitation 1.193751335144043 reward 1.1829907894134521\n",
      "val imitation 1.2564613819122314 reward 1.188879370689392\n",
      "val loss 2.445340633392334 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7573717948717948}]\n",
      "______epoch 268 _____\n",
      "train imitation 1.2170038223266602 reward 1.1822482347488403\n",
      "val imitation 1.2573539018630981 reward 1.1889455318450928\n",
      "val loss 2.4462995529174805 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6605769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.757051282051282}]\n",
      "______epoch 269 _____\n",
      "train imitation 1.193493127822876 reward 1.1828943490982056\n",
      "val imitation 1.2573912143707275 reward 1.187402606010437\n",
      "val loss 2.444793701171875 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6605769230769232}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7116228070175439}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7560897435897436}]\n",
      "______epoch 270 _____\n",
      "train imitation 1.143090009689331 reward 1.183568000793457\n",
      "val imitation 1.256730556488037 reward 1.1870481967926025\n",
      "val loss 2.4437787532806396 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6615384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7557692307692307}]\n",
      "______epoch 271 _____\n",
      "train imitation 1.2348217964172363 reward 1.1856005191802979\n",
      "val imitation 1.2550218105316162 reward 1.1871070861816406\n",
      "val loss 2.442128896713257 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615384}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "______epoch 272 _____\n",
      "train imitation 1.1405954360961914 reward 1.1826026439666748\n",
      "val imitation 1.2533074617385864 reward 1.1869189739227295\n",
      "val loss 2.4402265548706055 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6625}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7108004385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "______epoch 273 _____\n",
      "train imitation 1.175911784172058 reward 1.1821335554122925\n",
      "val imitation 1.2520619630813599 reward 1.1863800287246704\n",
      "val loss 2.4384419918060303 2.430473804473877\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6629807692307692}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.7105263157894737}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7560897435897436}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(2.4305, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7173793859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7631410256410256}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def shuffle_col(v,col=None):\n",
    "    if col is None:\n",
    "        col = np.random.choice([i for i in range(v.shape[1])])\n",
    "    idx = torch.randperm(v.shape[0])\n",
    "    vv = torch.clone(v)\n",
    "    vv[:,col] = vv[idx,col]\n",
    "    return vv\n",
    "    \n",
    "def train_decision_model(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    lr=.0001,\n",
    "    epochs=10000,\n",
    "    patience=100,\n",
    "    weights=[1,1,1], #realtive weight of survival, feeding tube, and aspiration\n",
    "    imitation_weight=1,\n",
    "    shufflecol_chance = 0.1,\n",
    "    reward_weight=10,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    use_attention=False,\n",
    "    verbose=True,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids])\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    def outcome_loss(ypred):\n",
    "        #convert survival to death\n",
    "        loss = torch.mul(torch.mean(-1*(ypred[:,0] - 1)),weights[0])\n",
    "        for i,weight in enumerate(weights[1:]):\n",
    "            newloss = torch.mean(ypred[:,i])*weight\n",
    "            loss = torch.add(loss,torch.mul(newloss,weight))\n",
    "        return loss\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    nllloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            \n",
    "            \n",
    "        ytrain = df_to_torch(outcomedf.loc[ids])\n",
    "        #imitation losses and decision 1\n",
    "        xxtrain = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrain]\n",
    "        o1 = model(torch.cat(xxtrain,axis=1),position=0)\n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1 = o1[:,0]\n",
    "        \n",
    "#         imitation_loss1 = bce(threshold(decision1_imitation),ytrain[:,0])\n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        decision2_imitation = model(torch.cat(x1_imitation,axis=1),position=1)[:,4]\n",
    "        \n",
    "#         imitation_loss2 =  bce(threshold(decision2_imitation),ytrain[:,1])\n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        decision3_imitation = model(torch.cat(x2_imitation,axis=1),position=2)[:,5]\n",
    "        \n",
    "#         imitation_loss3 = bce(threshold(decision3_imitation),ytrain[:,2])\n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        \n",
    "        #reward decisions\n",
    "        xx1 = makeinput(1,ids)\n",
    "        xx2 = makeinput(2,ids)\n",
    "        xx3 = makeinput(3,ids)\n",
    "\n",
    "        baseline_train_base = formatdf(baseline,ids)\n",
    "            \n",
    "        baseline_train = torch.clone(baseline_train_base)\n",
    "        if train and shufflecol_chance > 0.0001:\n",
    "            for col in range(baseline_train_base.shape[1]): \n",
    "                if np.random.random() < shufflecol_chance:\n",
    "                    baseline_train = shuffle_col(baseline_train,col)\n",
    "                    \n",
    "        xi1 = torch.cat([xx1,decision1.view(-1,1)],axis=1)\n",
    "        [ypd1, ynd1, ymod, ydlt1] = tmodel1(xi1)\n",
    "        #this outputs log likelihoods (except for dlts) -> convert to probability\n",
    "        ypd1 = torch.exp(ypd1)\n",
    "        ynd1 = torch.exp(ynd1)\n",
    "        ymod = torch.exp(ymod)\n",
    "        x1 = [baseline_train,ydlt1,formatdf(get_dlt(0),ids),ypd1,ynd1,formatdf(get_cc(1),ids),ymod]\n",
    "        \n",
    "        decision2 = model(torch.cat(x1,axis=1),position=1)[:,1] \n",
    "        \n",
    "        xi2 = torch.cat([xx2,decision1.view(-1,1),decision2.view(-1,1)],axis=1)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = tmodel2(xi2)\n",
    "        ypd2 = torch.exp(ypd2)\n",
    "        ynd2 = torch.exp(ynd2)\n",
    "        ycc = torch.exp(ycc)\n",
    "        x2 = [baseline_train,ydlt1,ydlt2,ypd2,ynd2,ycc,ymod]\n",
    "            \n",
    "        decision3 = model(torch.cat(x2,axis=1),position=2)[:,2]\n",
    "        \n",
    "        decision1 = threshold(decision1)\n",
    "        decision2 = threshold(decision2)\n",
    "        decision3 = threshold(decision3)\n",
    "        \n",
    "        xi3 = torch.cat([xx3,decision1.view(-1,1),decision2.view(-1,1),decision3.view(-1,1)],axis=1)\n",
    "        outcomes = tmodel3(xi3)\n",
    "\n",
    "        reward_loss = outcome_loss(outcomes)\n",
    "        loss = torch.add(imitation_loss1,imitation_loss2)\n",
    "        loss = torch.add(loss,imitation_loss3)\n",
    "        loss = torch.mul(loss,imitation_weight/3)\n",
    "        loss = torch.add(loss,torch.mul(reward_loss,reward_weight))\n",
    "        losses = [imitation_loss1+imitation_loss2+imitation_loss3,reward_loss]\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            for i,decision in enumerate([decision1_imitation,decision2_imitation,decision3_imitation]):\n",
    "                dec = decision.cpu().detach().numpy()\n",
    "                dec0 = (dec > .5).astype(int)\n",
    "                out = ytrain[:,i].cpu().detach().numpy()\n",
    "                acc = accuracy_score(out,dec > .5)\n",
    "                auc = roc_auc_score(out,dec)\n",
    "                scores.append({'decision': i,'accuracy': acc,'auc': auc})\n",
    "            return losses, scores\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('train imitation',losses[0].item(),'reward',losses[1].item())\n",
    "            print('val imitation',val_losses[0].item(),'reward',val_losses[1].item())\n",
    "            print('val loss',vl.item(),best_val_loss.item())\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [600], \n",
    "    'attention_heads': [3], \n",
    "    'embed_size': 210, \n",
    "    'dropout': 0.9, \n",
    "    'input_dropout': 0.5, \n",
    "    'shufflecol_chance': 0.1,\n",
    "}\n",
    "decision_model, _, _ = train_decision_model(model1,model2,model3,lr=.0001,use_attention=True,**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_decision_model(m1,m2,m3):\n",
    "#     model_arglist = [\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500,500],\n",
    "#             'attention_heads': [5,5,5]\n",
    "#         }\n",
    "#     ]\n",
    "    model_arglist = [\n",
    "\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [50,50],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [2,2],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300,300],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [0,100,200]:\n",
    "            #embed_size = 0 skips the firt layer that makes the sizes right\n",
    "            if embed_size == 0 and args['attention_heads'][0] != 1:\n",
    "                continue\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.5,.9,.95]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.35,.45,.55]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    for shufflecol_chance in [.5,.75,.9]:\n",
    "                        args['shufflecol_chance'] = shufflecol_chance\n",
    "                        model,m_metrics,m_loss = train_decision_model(m1,m2,m3,use_attention=True,verbose=False,**args)\n",
    "                        print('done',k,m_loss)\n",
    "                        print('curr best',best_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "\n",
    "from Models import *\n",
    "decision_model = gridsearch_decision_model(model,model2,model3)\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "ds = DTDataset()\n",
    "states = DTDataset().get_states()\n",
    "xdf = [states['baseline'],states['dlt1'],states['dlt2'],states['pd_states2'],states['nd_states2'],states['ccs'],states['modifications']]\n",
    "x = tuple([df_to_torch(xx) for xx in xdf])\n",
    "attributions = decision_model.get_attributions(x)\n",
    "attributions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e098f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_decision_model_statedecisions_input132_dims600_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(decision_model,'../data/models/final_decision_model_' + decision_model.identifier + '.pt')\n",
    "print('../data/models/final_decision_model_' + decision_model.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'../data/models/final_transition1_model_' + model.identifier + '.pt')\n",
    "torch.save(model2,'../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "torch.save(model3,'../data/models/final_outcome_model_' + model3.identifier + '.pt')\n",
    "print('../data/models/final_transition1_model_' + model.identifier + '.pt')\n",
    "print('../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "print('../data/models/final_outcome_model_' + model3.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xatt = []\n",
    "for att,xxdf in zip(list(attributions),xdf):\n",
    "    new = pd.DataFrame(att.cpu().detach().numpy(),columns=xxdf.columns,index=xxdf.index)\n",
    "    xatt.append(new)\n",
    "attributions = pd.concat(xatt,axis=1)\n",
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ca3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(1,1,figsize=(100,100))\n",
    "sns.heatmap(data=attributions.T,ax=fig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakup_state_models(state_model):\n",
    "    #for state 1 and 2\n",
    "    models = {}\n",
    "    models['pd'] = lambda x: state_model(x)[0]\n",
    "    models['nd'] = lambda x: state_model(x)[1]\n",
    "    models['chemo'] = lambda x: state_model(x)[2]\n",
    "    for i,dlt in enumerate(Const.dlt1):\n",
    "        models[dlt] = lambda x: state_model(x)[3][:,i]\n",
    "    return models\n",
    "\n",
    "def breakup_outcome_models(omodel):\n",
    "    models = {}\n",
    "    for i,name in enumerate(Const.outcomes):\n",
    "        models[name] = lambda x: omodel(x)[:,i].reshape(-1,1)\n",
    "    return models\n",
    "\n",
    "def get_all_models(m1,m2,m3):\n",
    "    state1_models = breakup_state_models(m1)\n",
    "    state2_models = breakup_state_models(m2)\n",
    "    state3_models = breakup_outcome_models(m3)\n",
    "    all_models = {}\n",
    "    for i,sm in enumerate([state1_models,state2_models,state3_models]):\n",
    "        for ii,m in sm.items():\n",
    "            all_models[ii +  '_state' + str(i+1)] = m\n",
    "    return all_models\n",
    "\n",
    "all_models = get_all_models(model,model2,model3)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ytrue(name,df):\n",
    "    outcomes=None\n",
    "    value = None\n",
    "    if name == 'pd_state1':\n",
    "        outcomes = df[Const.primary_disease_states]\n",
    "    elif name == 'pd_state2':\n",
    "        outcomes = df[Const.primary_disease_states2]\n",
    "    elif name == 'nd_state1':\n",
    "        outcomes = df[Const.nodal_disease_states]\n",
    "    elif name == 'nd_state2':\n",
    "        outcomes = df[Const.nodal_disease_states2]\n",
    "    elif name == 'chemo_state1':\n",
    "        outcomes = df[Const.modifications]\n",
    "    elif name == 'chemo_state2':\n",
    "        outcomes = df[Const.ccs]   \n",
    "    if outcomes is not None:\n",
    "        value = outcomes.idxmax(axis=1)\n",
    "    if 'DLT' in name:\n",
    "        newname = name.replace('_state', ' ').replace('1','').strip()\n",
    "        value = df[newname]\n",
    "    if name.replace('_state3','') in Const.outcomes:\n",
    "        value = df[name.replace('_state3','')]\n",
    "    if value is None:\n",
    "        print(name,df.columns)\n",
    "    return value\n",
    "\n",
    "def check_impact_of_decisions(model_dict,data):\n",
    "    results = []\n",
    "    #todo: this is wrong fix it\n",
    "    ids = []\n",
    "    df = data.get_data()\n",
    "    outcomedict = {step: pd.concat(data.get_intermediate_outcomes(step=step),axis=1) for step in [1,2,3]}\n",
    "    for decision in Const.decisions:\n",
    "        for name, model in model_dict.items():\n",
    "            step = int(name[-1])\n",
    "            subset0 = dataset.get_input_state(step=step,fixed={decision: 0})\n",
    "            subset1 = dataset.get_input_state(step=step,fixed={decision: 1})\n",
    "            outcomes = outcomedict[step]\n",
    "            ids = subset0.index.values\n",
    "            x0 = df_to_torch(subset0)\n",
    "            x1 = df_to_torch(subset1)\n",
    "            y0 = model(x0).detach().cpu().numpy()\n",
    "            y1 = model(x1).detach().cpu().numpy()\n",
    "            original = data.get_input_state(step=step)\n",
    "            xx = df_to_torch(original)\n",
    "            yy = model(xx).detach().cpu().numpy()\n",
    "            ytrue = get_ytrue(name,outcomes)\n",
    "            if \"DLT\" in name:\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                change = y0 - y1\n",
    "                decision_change = (y0 != y1).astype(int)\n",
    "            elif y0.shape[1] == 1:\n",
    "                change = y1 - y0\n",
    "                decision_change = np.abs((y0 > .5).astype(int) - (y1 > .5).astype(int))\n",
    "            else:\n",
    "                index = np.unravel_index(np.argmax(yy, axis=1), yy.shape)\n",
    "                change = (y0[index] - y1[index]).reshape(-1,1)\n",
    "                decision_change =  (y0.argmax(axis=1).reshape(-1,1) != y1.argmax(axis=1).reshape(-1,1)).astype(int)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "            outcome = name.replace('_state','')\n",
    "            for ii,pid in enumerate(ids):\n",
    "                oo = ytrue.loc[pid]\n",
    "                onew = y0[ii][0]\n",
    "                original_decision = df.loc[pid,decision]\n",
    "                if original_decision > 0:\n",
    "                    onew = y0[ii][0]\n",
    "                oname = Const.name_dict.get(name)\n",
    "                if oname is not None:\n",
    "                    onew = oname[onew]\n",
    "                entry = {'id': pid, 'decision': decision,'outcome': outcome,'original_choice': original_decision, 'original_result': oo, 'alt_result': onew, 'change': change[ii][0], 'decision_change': decision_change[ii][0]}\n",
    "                results.append(entry)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "test = check_impact_of_decisions(all_models,dataset)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db23ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_data()['SD Primary 2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ce1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test[test.outcome == 'pd2'].original_result == 'SD Primary 2').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_impact_of_decisions(all_models,dataset).to_csv('../data/decision_impacts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321249c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
