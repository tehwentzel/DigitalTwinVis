{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "050c878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score,precision_recall_fscore_support\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "import copy\n",
    "from Utils import *\n",
    "from DeepSurvivalModels import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dose</th>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_fraction</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <td>4.7</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDM (months)</th>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>136.033333</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_to_event</th>\n",
       "      <td>4.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>136.033333</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Survival (1=alive, 0=dead)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRC</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasion</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>African American/Black</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_none</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_platinum</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_cetuximab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_others</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_dose_adjustment</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_modified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_delayed</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_delayed_&amp;_modified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regiment_modification</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_CC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_IC+CC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_IC+Radiation alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_Radiation alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Hematological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Dermatological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Neurological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Gastrointestinal 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Hematological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Nephrological 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Vascular 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Infection (Pneumonia) 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Other 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Primary 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Primary 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Primary 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Nodal 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Nodal 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Nodal 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 1 (Induction Chemo) Y/N</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 2 (CC / RT alone)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 3 Neck Dissection (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Survival (4 Years)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Post-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                                      3         5          6          7      \\\n",
       "hpv                                         1         0          1          1   \n",
       "age                                 55.969444     20.95  69.930556  72.319444   \n",
       "packs_per_year                            0.0      38.0       35.0        0.0   \n",
       "gender                                      1         1          0          1   \n",
       "Aspiration rate Pre-therapy                 0         0          1          0   \n",
       "total_dose                               66.0      72.0       70.0       70.0   \n",
       "dose_fraction                             2.2       1.8   2.121212   2.121212   \n",
       "OS (Calculated)                      6.033333  7.333333   7.466667        7.8   \n",
       "Locoregional control (Time)               4.7  7.333333   7.466667        7.8   \n",
       "FDM (months)                         6.033333  7.333333   7.466667        7.8   \n",
       "time_to_event                             4.7       6.0        6.0        6.0   \n",
       "Overall Survival (1=alive, 0=dead)          0         0          0          0   \n",
       "LRC                                         0         1          1          1   \n",
       "DC                                          1         1          1          1   \n",
       "bilateral                               False     False       True      False   \n",
       "White/Caucasion                          True      True       True       True   \n",
       "Hispanic/Latino                         False     False      False      False   \n",
       "African American/Black                  False     False      False      False   \n",
       "Asian                                   False     False      False      False   \n",
       "cc_none                                     0         0          0          1   \n",
       "cc_platinum                                 0         1          1          0   \n",
       "cc_cetuximab                                1         0          0          0   \n",
       "cc_others                                   0         0          0          0   \n",
       "no_dose_adjustment                          1         1          1          1   \n",
       "dose_modified                               0         0          0          0   \n",
       "dose_delayed                                0         0          0          0   \n",
       "dose_cancelled                              0         0          0          0   \n",
       "dose_delayed_&_modified                     0         0          0          0   \n",
       "regiment_modification                       0         0          0          0   \n",
       "T-category_1                                0         0          0          1   \n",
       "T-category_2                                1         0          0          0   \n",
       "T-category_3                                0         0          0          0   \n",
       "T-category_4                                0         1          1          0   \n",
       "N-category_0                                0         0          0          0   \n",
       "N-category_1                                1         0          0          0   \n",
       "N-category_2                                0         1          1          1   \n",
       "N-category_3                                0         0          0          0   \n",
       "AJCC_1                                      1         0          0          0   \n",
       "AJCC_2                                      0         0          0          1   \n",
       "AJCC_3                                      0         0          1          0   \n",
       "AJCC_4                                      0         1          0          0   \n",
       "Pathological Grade_0                        1         0          0          1   \n",
       "Pathological Grade_1                        0         0          0          0   \n",
       "Pathological Grade_2                        0         1          1          0   \n",
       "Pathological Grade_3                        0         0          0          0   \n",
       "Pathological Grade_4                        0         0          0          0   \n",
       "subsite_BOT                                 1         1          1          0   \n",
       "subsite_GPS                                 0         0          0          0   \n",
       "subsite_NOS                                 0         0          0          1   \n",
       "subsite_Soft palate                         0         0          0          0   \n",
       "subsite_Tonsil                              0         0          0          0   \n",
       "treatment_CC                                1         1          1          0   \n",
       "treatment_IC+CC                             0         0          0          0   \n",
       "treatment_IC+Radiation alone                0         0          0          0   \n",
       "treatment_Radiation alone                   0         0          0          1   \n",
       "DLT_Dermatological                        0.0       0.0        0.0        0.0   \n",
       "DLT_Neurological                          0.0       0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                      0.0       0.0        0.0        0.0   \n",
       "DLT_Hematological                         0.0       0.0        0.0        0.0   \n",
       "DLT_Nephrological                           0         0          0          0   \n",
       "DLT_Vascular                                0         0          0          0   \n",
       "DLT_Infection (Pneumonia)                   0         0          0          0   \n",
       "DLT_Other                                 0.0       0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                      0.0       0.0        0.0        0.0   \n",
       "DLT_Neurological 2                        0.0       0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                    0.0       0.0        0.0        0.0   \n",
       "DLT_Hematological 2                       0.0       0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                         0         0          0          0   \n",
       "DLT_Vascular 2                              0         0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                 0         0          0          0   \n",
       "DLT_Other 2                               0.0       0.0        0.0        0.0   \n",
       "CR Primary                                  0         0          0          0   \n",
       "PR Primary                                  0         0          0          0   \n",
       "SD Primary                                  0         0          0          0   \n",
       "CR Nodal                                    0         0          0          0   \n",
       "PR Nodal                                    0         0          0          0   \n",
       "SD Nodal                                    0         0          0          0   \n",
       "CR Primary 2                                0         1          0          1   \n",
       "PR Primary 2                                1         0          1          0   \n",
       "SD Primary 2                                0         0          0          0   \n",
       "CR Nodal 2                                  0         1          1          1   \n",
       "PR Nodal 2                                  1         0          0          0   \n",
       "SD Nodal 2                                  0         0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N            0         0          0          0   \n",
       "Decision 2 (CC / RT alone)                  1         1          1          0   \n",
       "Decision 3 Neck Dissection (Y/N)            0         0          0          0   \n",
       "Overall Survival (4 Years)                  0         0          0          0   \n",
       "FT                                          0         1          1          1   \n",
       "Aspiration rate Post-therapy                0         0          1          0   \n",
       "1A_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "1A_contra                                 0.0       0.0        0.0        0.0   \n",
       "1B_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "1B_contra                                 0.0       0.0        0.0        1.0   \n",
       "2A_ipsi                                   0.0       1.0        1.0        0.0   \n",
       "2A_contra                                 1.0       0.0        1.0        0.0   \n",
       "2B_ipsi                                   0.0       1.0        1.0        0.0   \n",
       "2B_contra                                 1.0       0.0        1.0        0.0   \n",
       "3_ipsi                                    0.0       0.0        1.0        0.0   \n",
       "3_contra                                  0.0       0.0        1.0        0.0   \n",
       "4_ipsi                                    0.0       0.0        0.0        0.0   \n",
       "4_contra                                  0.0       0.0        0.0        0.0   \n",
       "5A_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "5A_contra                                 0.0       0.0        0.0        0.0   \n",
       "5B_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "5B_contra                                 0.0       0.0        0.0        0.0   \n",
       "6_ipsi                                    0.0       0.0        0.0        0.0   \n",
       "6_contra                                  0.0       0.0        0.0        0.0   \n",
       "RPLN_ipsi                                 0.0       0.0        0.0        0.0   \n",
       "RPLN_contra                               0.0       0.0        0.0        0.0   \n",
       "\n",
       "id                                      8          9          10     \\\n",
       "hpv                                         1          1         -1   \n",
       "age                                 59.730556  60.083333  67.708333   \n",
       "packs_per_year                            0.0        0.0       40.0   \n",
       "gender                                      1          1          1   \n",
       "Aspiration rate Pre-therapy                 0          0          0   \n",
       "total_dose                               66.0       66.0      69.96   \n",
       "dose_fraction                             2.2        2.2       2.12   \n",
       "OS (Calculated)                      8.066667   8.733333        9.1   \n",
       "Locoregional control (Time)          8.066667   8.733333        6.7   \n",
       "FDM (months)                         8.066667   6.633333        9.1   \n",
       "time_to_event                        8.066667   6.633333        6.0   \n",
       "Overall Survival (1=alive, 0=dead)          0          0          0   \n",
       "LRC                                         1          1          0   \n",
       "DC                                          1          0          1   \n",
       "bilateral                               False      False      False   \n",
       "White/Caucasion                         False       True       True   \n",
       "Hispanic/Latino                         False      False      False   \n",
       "African American/Black                  False      False      False   \n",
       "Asian                                   False      False      False   \n",
       "cc_none                                     1          0          0   \n",
       "cc_platinum                                 0          0          0   \n",
       "cc_cetuximab                                0          1          1   \n",
       "cc_others                                   0          0          0   \n",
       "no_dose_adjustment                          1          1          1   \n",
       "dose_modified                               0          0          0   \n",
       "dose_delayed                                0          0          0   \n",
       "dose_cancelled                              0          0          0   \n",
       "dose_delayed_&_modified                     0          0          0   \n",
       "regiment_modification                       0          0          0   \n",
       "T-category_1                                1          1          0   \n",
       "T-category_2                                0          0          0   \n",
       "T-category_3                                0          0          1   \n",
       "T-category_4                                0          0          0   \n",
       "N-category_0                                0          0          0   \n",
       "N-category_1                                1          1          1   \n",
       "N-category_2                                0          0          0   \n",
       "N-category_3                                0          0          0   \n",
       "AJCC_1                                      1          1          0   \n",
       "AJCC_2                                      0          0          0   \n",
       "AJCC_3                                      0          0          1   \n",
       "AJCC_4                                      0          0          0   \n",
       "Pathological Grade_0                        0          0          0   \n",
       "Pathological Grade_1                        0          0          0   \n",
       "Pathological Grade_2                        0          0          1   \n",
       "Pathological Grade_3                        1          1          0   \n",
       "Pathological Grade_4                        0          0          0   \n",
       "subsite_BOT                                 0          1          1   \n",
       "subsite_GPS                                 0          0          0   \n",
       "subsite_NOS                                 0          0          0   \n",
       "subsite_Soft palate                         0          0          0   \n",
       "subsite_Tonsil                              1          0          0   \n",
       "treatment_CC                                0          1          1   \n",
       "treatment_IC+CC                             0          0          0   \n",
       "treatment_IC+Radiation alone                0          0          0   \n",
       "treatment_Radiation alone                   1          0          0   \n",
       "DLT_Dermatological                        0.0        0.0        0.0   \n",
       "DLT_Neurological                          0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                      0.0        0.0        0.0   \n",
       "DLT_Hematological                         0.0        0.0        0.0   \n",
       "DLT_Nephrological                           0          0          0   \n",
       "DLT_Vascular                                0          0          0   \n",
       "DLT_Infection (Pneumonia)                   0          0          0   \n",
       "DLT_Other                                 0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                      0.0        0.0        0.0   \n",
       "DLT_Neurological 2                        0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                    0.0        0.0        0.0   \n",
       "DLT_Hematological 2                       0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                         0          0          0   \n",
       "DLT_Vascular 2                              0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                 0          0          0   \n",
       "DLT_Other 2                               0.0        0.0        0.0   \n",
       "CR Primary                                  0          0          0   \n",
       "PR Primary                                  0          0          0   \n",
       "SD Primary                                  0          0          0   \n",
       "CR Nodal                                    0          0          0   \n",
       "PR Nodal                                    0          0          0   \n",
       "SD Nodal                                    0          0          0   \n",
       "CR Primary 2                                1          0          0   \n",
       "PR Primary 2                                0          1          0   \n",
       "SD Primary 2                                0          0          0   \n",
       "CR Nodal 2                                  1          0          1   \n",
       "PR Nodal 2                                  0          1          0   \n",
       "SD Nodal 2                                  0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N            0          0          0   \n",
       "Decision 2 (CC / RT alone)                  0          1          1   \n",
       "Decision 3 Neck Dissection (Y/N)            0          0          1   \n",
       "Overall Survival (4 Years)                  0          0          0   \n",
       "FT                                          0          0          1   \n",
       "Aspiration rate Post-therapy                0          0          0   \n",
       "1A_ipsi                                   0.0        0.0        0.0   \n",
       "1A_contra                                 0.0        0.0        0.0   \n",
       "1B_ipsi                                   0.0        0.0        0.0   \n",
       "1B_contra                                 0.0        0.0        0.0   \n",
       "2A_ipsi                                   1.0        1.0        1.0   \n",
       "2A_contra                                 0.0        0.0        0.0   \n",
       "2B_ipsi                                   1.0        1.0        1.0   \n",
       "2B_contra                                 0.0        0.0        0.0   \n",
       "3_ipsi                                    0.0        0.0        0.0   \n",
       "3_contra                                  0.0        0.0        0.0   \n",
       "4_ipsi                                    0.0        0.0        0.0   \n",
       "4_contra                                  0.0        0.0        0.0   \n",
       "5A_ipsi                                   0.0        0.0        0.0   \n",
       "5A_contra                                 0.0        0.0        0.0   \n",
       "5B_ipsi                                   0.0        0.0        0.0   \n",
       "5B_contra                                 0.0        0.0        0.0   \n",
       "6_ipsi                                    0.0        0.0        0.0   \n",
       "6_contra                                  0.0        0.0        0.0   \n",
       "RPLN_ipsi                                 0.0        0.0        0.0   \n",
       "RPLN_contra                               0.0        0.0        0.0   \n",
       "\n",
       "id                                      11         13         14     ...  \\\n",
       "hpv                                         1          0          1  ...   \n",
       "age                                 57.858333  51.758333      56.25  ...   \n",
       "packs_per_year                           44.0        0.0       40.0  ...   \n",
       "gender                                      1          1          1  ...   \n",
       "Aspiration rate Pre-therapy                 0          0          0  ...   \n",
       "total_dose                               70.0       70.0       70.0  ...   \n",
       "dose_fraction                        2.121212        2.0   2.121212  ...   \n",
       "OS (Calculated)                           9.8  10.033333  10.033333  ...   \n",
       "Locoregional control (Time)               8.5  10.033333  10.033333  ...   \n",
       "FDM (months)                              9.8  10.033333  10.033333  ...   \n",
       "time_to_event                             8.5        6.0  10.033333  ...   \n",
       "Overall Survival (1=alive, 0=dead)          0          0          0  ...   \n",
       "LRC                                         0          1          1  ...   \n",
       "DC                                          1          1          1  ...   \n",
       "bilateral                               False       True      False  ...   \n",
       "White/Caucasion                          True       True       True  ...   \n",
       "Hispanic/Latino                         False      False      False  ...   \n",
       "African American/Black                  False      False      False  ...   \n",
       "Asian                                   False      False      False  ...   \n",
       "cc_none                                     0          0          0  ...   \n",
       "cc_platinum                                 0          1          0  ...   \n",
       "cc_cetuximab                                1          0          0  ...   \n",
       "cc_others                                   0          0          1  ...   \n",
       "no_dose_adjustment                          1          1          1  ...   \n",
       "dose_modified                               0          0          0  ...   \n",
       "dose_delayed                                0          0          0  ...   \n",
       "dose_cancelled                              0          0          0  ...   \n",
       "dose_delayed_&_modified                     0          0          0  ...   \n",
       "regiment_modification                       0          0          0  ...   \n",
       "T-category_1                                0          0          0  ...   \n",
       "T-category_2                                1          0          1  ...   \n",
       "T-category_3                                0          0          0  ...   \n",
       "T-category_4                                0          1          0  ...   \n",
       "N-category_0                                0          0          0  ...   \n",
       "N-category_1                                1          0          0  ...   \n",
       "N-category_2                                0          1          1  ...   \n",
       "N-category_3                                0          0          0  ...   \n",
       "AJCC_1                                      1          0          0  ...   \n",
       "AJCC_2                                      0          0          1  ...   \n",
       "AJCC_3                                      0          0          0  ...   \n",
       "AJCC_4                                      0          1          0  ...   \n",
       "Pathological Grade_0                        0          0          0  ...   \n",
       "Pathological Grade_1                        0          0          0  ...   \n",
       "Pathological Grade_2                        1          1          0  ...   \n",
       "Pathological Grade_3                        0          0          1  ...   \n",
       "Pathological Grade_4                        0          0          0  ...   \n",
       "subsite_BOT                                 0          1          1  ...   \n",
       "subsite_GPS                                 0          0          0  ...   \n",
       "subsite_NOS                                 1          0          0  ...   \n",
       "subsite_Soft palate                         0          0          0  ...   \n",
       "subsite_Tonsil                              0          0          0  ...   \n",
       "treatment_CC                                1          1          1  ...   \n",
       "treatment_IC+CC                             0          0          0  ...   \n",
       "treatment_IC+Radiation alone                0          0          0  ...   \n",
       "treatment_Radiation alone                   0          0          0  ...   \n",
       "DLT_Dermatological                        0.0        0.0        0.0  ...   \n",
       "DLT_Neurological                          0.0        0.0        0.0  ...   \n",
       "DLT_Gastrointestinal                      0.0        0.0        0.0  ...   \n",
       "DLT_Hematological                         0.0        0.0        0.0  ...   \n",
       "DLT_Nephrological                           0          0          0  ...   \n",
       "DLT_Vascular                                0          0          0  ...   \n",
       "DLT_Infection (Pneumonia)                   0          0          0  ...   \n",
       "DLT_Other                                 0.0        0.0        0.0  ...   \n",
       "DLT_Dermatological 2                      0.0        0.0        0.0  ...   \n",
       "DLT_Neurological 2                        0.0        0.0        0.0  ...   \n",
       "DLT_Gastrointestinal 2                    0.0        0.0        0.0  ...   \n",
       "DLT_Hematological 2                       0.0        0.0        0.0  ...   \n",
       "DLT_Nephrological 2                         0          0          0  ...   \n",
       "DLT_Vascular 2                              0          0          0  ...   \n",
       "DLT_Infection (Pneumonia) 2                 0          0          0  ...   \n",
       "DLT_Other 2                               0.0        0.0        0.0  ...   \n",
       "CR Primary                                  0          0          0  ...   \n",
       "PR Primary                                  0          0          0  ...   \n",
       "SD Primary                                  0          0          0  ...   \n",
       "CR Nodal                                    0          0          0  ...   \n",
       "PR Nodal                                    0          0          0  ...   \n",
       "SD Nodal                                    0          0          0  ...   \n",
       "CR Primary 2                                0          0          1  ...   \n",
       "PR Primary 2                                1          1          0  ...   \n",
       "SD Primary 2                                0          0          0  ...   \n",
       "CR Nodal 2                                  0          0          0  ...   \n",
       "PR Nodal 2                                  1          1          1  ...   \n",
       "SD Nodal 2                                  0          0          0  ...   \n",
       "Decision 1 (Induction Chemo) Y/N            0          0          0  ...   \n",
       "Decision 2 (CC / RT alone)                  1          1          1  ...   \n",
       "Decision 3 Neck Dissection (Y/N)            0          0          0  ...   \n",
       "Overall Survival (4 Years)                  0          0          0  ...   \n",
       "FT                                          0          1          0  ...   \n",
       "Aspiration rate Post-therapy                0          0          0  ...   \n",
       "1A_ipsi                                   0.0        0.0        0.0  ...   \n",
       "1A_contra                                 0.0        0.0        0.0  ...   \n",
       "1B_ipsi                                   0.0        0.0        0.0  ...   \n",
       "1B_contra                                 0.0        0.0        0.0  ...   \n",
       "2A_ipsi                                   1.0        1.0        1.0  ...   \n",
       "2A_contra                                 0.0        1.0        0.0  ...   \n",
       "2B_ipsi                                   1.0        1.0        1.0  ...   \n",
       "2B_contra                                 0.0        1.0        0.0  ...   \n",
       "3_ipsi                                    1.0        0.0        0.0  ...   \n",
       "3_contra                                  0.0        0.0        1.0  ...   \n",
       "4_ipsi                                    0.0        0.0        0.0  ...   \n",
       "4_contra                                  0.0        0.0        0.0  ...   \n",
       "5A_ipsi                                   0.0        0.0        0.0  ...   \n",
       "5A_contra                                 0.0        0.0        0.0  ...   \n",
       "5B_ipsi                                   0.0        0.0        0.0  ...   \n",
       "5B_contra                                 0.0        0.0        0.0  ...   \n",
       "6_ipsi                                    0.0        0.0        0.0  ...   \n",
       "6_contra                                  0.0        0.0        0.0  ...   \n",
       "RPLN_ipsi                                 0.0        0.0        0.0  ...   \n",
       "RPLN_contra                               0.0        0.0        0.0  ...   \n",
       "\n",
       "id                                       10196      10197      10198  \\\n",
       "hpv                                          0          1         -1   \n",
       "age                                  47.619444  50.163889  70.888889   \n",
       "packs_per_year                             5.0        0.0       50.0   \n",
       "gender                                       0          1          0   \n",
       "Aspiration rate Pre-therapy                  0          0          0   \n",
       "total_dose                                70.0       72.0       66.0   \n",
       "dose_fraction                         2.121212        1.8        2.2   \n",
       "OS (Calculated)                     139.033333      139.3      140.6   \n",
       "Locoregional control (Time)         139.033333      139.3      140.6   \n",
       "FDM (months)                        139.033333      139.3      140.6   \n",
       "time_to_event                       139.033333      139.3      140.6   \n",
       "Overall Survival (1=alive, 0=dead)           1          1          1   \n",
       "LRC                                          1          1          1   \n",
       "DC                                           1          1          1   \n",
       "bilateral                                False      False      False   \n",
       "White/Caucasion                           True       True       True   \n",
       "Hispanic/Latino                          False      False      False   \n",
       "African American/Black                   False      False      False   \n",
       "Asian                                    False      False      False   \n",
       "cc_none                                      0          0          1   \n",
       "cc_platinum                                  1          1          0   \n",
       "cc_cetuximab                                 0          0          0   \n",
       "cc_others                                    0          0          0   \n",
       "no_dose_adjustment                           1          0          1   \n",
       "dose_modified                                0          0          0   \n",
       "dose_delayed                                 0          0          0   \n",
       "dose_cancelled                               0          0          0   \n",
       "dose_delayed_&_modified                      0          1          0   \n",
       "regiment_modification                        0          0          0   \n",
       "T-category_1                                 0          0          1   \n",
       "T-category_2                                 1          0          0   \n",
       "T-category_3                                 0          1          0   \n",
       "T-category_4                                 0          0          0   \n",
       "N-category_0                                 0          0          0   \n",
       "N-category_1                                 0          0          0   \n",
       "N-category_2                                 1          0          1   \n",
       "N-category_3                                 0          1          0   \n",
       "AJCC_1                                       0          0          0   \n",
       "AJCC_2                                       0          0          0   \n",
       "AJCC_3                                       0          1          0   \n",
       "AJCC_4                                       1          0          1   \n",
       "Pathological Grade_0                         1          0          0   \n",
       "Pathological Grade_1                         0          0          1   \n",
       "Pathological Grade_2                         0          1          0   \n",
       "Pathological Grade_3                         0          0          0   \n",
       "Pathological Grade_4                         0          0          0   \n",
       "subsite_BOT                                  0          1          0   \n",
       "subsite_GPS                                  0          0          0   \n",
       "subsite_NOS                                  0          0          0   \n",
       "subsite_Soft palate                          0          0          0   \n",
       "subsite_Tonsil                               1          0          1   \n",
       "treatment_CC                                 1          0          0   \n",
       "treatment_IC+CC                              0          1          0   \n",
       "treatment_IC+Radiation alone                 0          0          0   \n",
       "treatment_Radiation alone                    0          0          1   \n",
       "DLT_Dermatological                         0.0        1.0        0.0   \n",
       "DLT_Neurological                           0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                       0.0        0.0        0.0   \n",
       "DLT_Hematological                          0.0        0.0        0.0   \n",
       "DLT_Nephrological                            0          0          0   \n",
       "DLT_Vascular                                 0          0          0   \n",
       "DLT_Infection (Pneumonia)                    0          0          0   \n",
       "DLT_Other                                  0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                       0.0        0.0        0.0   \n",
       "DLT_Neurological 2                         0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                     0.0        0.0        0.0   \n",
       "DLT_Hematological 2                        0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                          0          0          0   \n",
       "DLT_Vascular 2                               0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                  0          0          0   \n",
       "DLT_Other 2                                0.0        0.0        0.0   \n",
       "CR Primary                                   0          0          0   \n",
       "PR Primary                                   0          1          0   \n",
       "SD Primary                                   0          0          0   \n",
       "CR Nodal                                     0          0          0   \n",
       "PR Nodal                                     0          1          0   \n",
       "SD Nodal                                     0          0          0   \n",
       "CR Primary 2                                 1          1          0   \n",
       "PR Primary 2                                 0          0          1   \n",
       "SD Primary 2                                 0          0          0   \n",
       "CR Nodal 2                                   1          1          0   \n",
       "PR Nodal 2                                   0          0          1   \n",
       "SD Nodal 2                                   0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N             0          1          0   \n",
       "Decision 2 (CC / RT alone)                   1          1          0   \n",
       "Decision 3 Neck Dissection (Y/N)             0          0          1   \n",
       "Overall Survival (4 Years)                   1          1          1   \n",
       "FT                                           0          0          0   \n",
       "Aspiration rate Post-therapy                 0          0          0   \n",
       "1A_ipsi                                    0.0        0.0        0.0   \n",
       "1A_contra                                  0.0        0.0        0.0   \n",
       "1B_ipsi                                    0.0        0.0        0.0   \n",
       "1B_contra                                  0.0        0.0        0.0   \n",
       "2A_ipsi                                    0.0        1.0        1.0   \n",
       "2A_contra                                  0.0        0.0        0.0   \n",
       "2B_ipsi                                    0.0        1.0        1.0   \n",
       "2B_contra                                  0.0        0.0        0.0   \n",
       "3_ipsi                                     0.0        0.0        0.0   \n",
       "3_contra                                   0.0        0.0        0.0   \n",
       "4_ipsi                                     0.0        0.0        0.0   \n",
       "4_contra                                   0.0        0.0        0.0   \n",
       "5A_ipsi                                    1.0        0.0        0.0   \n",
       "5A_contra                                  0.0        0.0        0.0   \n",
       "5B_ipsi                                    0.0        0.0        0.0   \n",
       "5B_contra                                  0.0        0.0        0.0   \n",
       "6_ipsi                                     0.0        0.0        0.0   \n",
       "6_contra                                   0.0        0.0        0.0   \n",
       "RPLN_ipsi                                  1.0        0.0        0.0   \n",
       "RPLN_contra                                0.0        0.0        0.0   \n",
       "\n",
       "id                                       10199       10200      10201  \\\n",
       "hpv                                          0           1          1   \n",
       "age                                     67.825   56.336111  49.566667   \n",
       "packs_per_year                             0.0         0.0       30.0   \n",
       "gender                                       1           1          1   \n",
       "Aspiration rate Pre-therapy                  0           0          0   \n",
       "total_dose                                70.0       69.96       70.0   \n",
       "dose_fraction                         2.121212        2.12   2.121212   \n",
       "OS (Calculated)                     142.833333  143.033333      143.2   \n",
       "Locoregional control (Time)         142.833333  143.033333      143.2   \n",
       "FDM (months)                        142.833333  143.033333      143.2   \n",
       "time_to_event                       142.833333  143.033333      143.2   \n",
       "Overall Survival (1=alive, 0=dead)           1           1          1   \n",
       "LRC                                          1           1          1   \n",
       "DC                                           1           1          1   \n",
       "bilateral                                False       False      False   \n",
       "White/Caucasion                           True        True       True   \n",
       "Hispanic/Latino                          False       False      False   \n",
       "African American/Black                   False       False      False   \n",
       "Asian                                    False       False      False   \n",
       "cc_none                                      0           0          0   \n",
       "cc_platinum                                  1           1          1   \n",
       "cc_cetuximab                                 0           0          0   \n",
       "cc_others                                    0           0          0   \n",
       "no_dose_adjustment                           1           1          1   \n",
       "dose_modified                                0           0          0   \n",
       "dose_delayed                                 0           0          0   \n",
       "dose_cancelled                               0           0          0   \n",
       "dose_delayed_&_modified                      0           0          0   \n",
       "regiment_modification                        0           0          0   \n",
       "T-category_1                                 0           0          0   \n",
       "T-category_2                                 1           0          0   \n",
       "T-category_3                                 0           1          1   \n",
       "T-category_4                                 0           0          0   \n",
       "N-category_0                                 0           0          0   \n",
       "N-category_1                                 0           1          1   \n",
       "N-category_2                                 1           0          0   \n",
       "N-category_3                                 0           0          0   \n",
       "AJCC_1                                       0           0          0   \n",
       "AJCC_2                                       0           1          1   \n",
       "AJCC_3                                       0           0          0   \n",
       "AJCC_4                                       1           0          0   \n",
       "Pathological Grade_0                         1           0          0   \n",
       "Pathological Grade_1                         0           0          0   \n",
       "Pathological Grade_2                         0           1          0   \n",
       "Pathological Grade_3                         0           0          1   \n",
       "Pathological Grade_4                         0           0          0   \n",
       "subsite_BOT                                  1           0          1   \n",
       "subsite_GPS                                  0           0          0   \n",
       "subsite_NOS                                  0           1          0   \n",
       "subsite_Soft palate                          0           0          0   \n",
       "subsite_Tonsil                               0           0          0   \n",
       "treatment_CC                                 1           1          1   \n",
       "treatment_IC+CC                              0           0          0   \n",
       "treatment_IC+Radiation alone                 0           0          0   \n",
       "treatment_Radiation alone                    0           0          0   \n",
       "DLT_Dermatological                         0.0         0.0        0.0   \n",
       "DLT_Neurological                           0.0         0.0        0.0   \n",
       "DLT_Gastrointestinal                       0.0         0.0        0.0   \n",
       "DLT_Hematological                          0.0         0.0        0.0   \n",
       "DLT_Nephrological                            0           0          0   \n",
       "DLT_Vascular                                 0           0          0   \n",
       "DLT_Infection (Pneumonia)                    0           0          0   \n",
       "DLT_Other                                  0.0         0.0        0.0   \n",
       "DLT_Dermatological 2                       0.0         0.0        0.0   \n",
       "DLT_Neurological 2                         0.0         0.0        0.0   \n",
       "DLT_Gastrointestinal 2                     1.0         0.0        0.0   \n",
       "DLT_Hematological 2                        0.0         0.0        0.0   \n",
       "DLT_Nephrological 2                          0           0          0   \n",
       "DLT_Vascular 2                               0           0          0   \n",
       "DLT_Infection (Pneumonia) 2                  0           0          0   \n",
       "DLT_Other 2                                0.0         0.0        0.0   \n",
       "CR Primary                                   0           0          0   \n",
       "PR Primary                                   0           0          0   \n",
       "SD Primary                                   0           0          0   \n",
       "CR Nodal                                     0           0          0   \n",
       "PR Nodal                                     0           0          0   \n",
       "SD Nodal                                     0           0          0   \n",
       "CR Primary 2                                 1           1          1   \n",
       "PR Primary 2                                 0           0          0   \n",
       "SD Primary 2                                 0           0          0   \n",
       "CR Nodal 2                                   1           0          0   \n",
       "PR Nodal 2                                   0           1          1   \n",
       "SD Nodal 2                                   0           0          0   \n",
       "Decision 1 (Induction Chemo) Y/N             0           0          0   \n",
       "Decision 2 (CC / RT alone)                   1           1          1   \n",
       "Decision 3 Neck Dissection (Y/N)             0           0          0   \n",
       "Overall Survival (4 Years)                   1           1          1   \n",
       "FT                                           0           0          0   \n",
       "Aspiration rate Post-therapy                 0           0          0   \n",
       "1A_ipsi                                    0.0         0.0        0.0   \n",
       "1A_contra                                  0.0         0.0        0.0   \n",
       "1B_ipsi                                    0.0         0.0        0.0   \n",
       "1B_contra                                  0.0         0.0        0.0   \n",
       "2A_ipsi                                    0.0         0.0        1.0   \n",
       "2A_contra                                  1.0         0.0        0.0   \n",
       "2B_ipsi                                    0.0         0.0        1.0   \n",
       "2B_contra                                  1.0         0.0        0.0   \n",
       "3_ipsi                                     0.0         1.0        0.0   \n",
       "3_contra                                   1.0         0.0        0.0   \n",
       "4_ipsi                                     0.0         0.0        0.0   \n",
       "4_contra                                   0.0         0.0        0.0   \n",
       "5A_ipsi                                    0.0         0.0        0.0   \n",
       "5A_contra                                  0.0         0.0        0.0   \n",
       "5B_ipsi                                    0.0         0.0        0.0   \n",
       "5B_contra                                  0.0         0.0        0.0   \n",
       "6_ipsi                                     0.0         0.0        0.0   \n",
       "6_contra                                   0.0         0.0        0.0   \n",
       "RPLN_ipsi                                  0.0         0.0        0.0   \n",
       "RPLN_contra                                0.0         0.0        0.0   \n",
       "\n",
       "id                                       10202       10203  10204       10205  \n",
       "hpv                                          0           1      0           1  \n",
       "age                                  48.705556   77.116667  45.95   49.733333  \n",
       "packs_per_year                            30.0         0.0    5.0         0.0  \n",
       "gender                                       1           1      1           1  \n",
       "Aspiration rate Pre-therapy                  0           0      0           0  \n",
       "total_dose                                72.0        70.0  69.96       69.96  \n",
       "dose_fraction                         1.714286    2.333333   2.12        2.12  \n",
       "OS (Calculated)                     144.366667  148.366667  152.6  155.533333  \n",
       "Locoregional control (Time)         144.366667  148.366667  152.6  155.533333  \n",
       "FDM (months)                        144.366667  136.033333  152.6  155.533333  \n",
       "time_to_event                              6.0  136.033333  152.6  155.533333  \n",
       "Overall Survival (1=alive, 0=dead)           1           1      1           1  \n",
       "LRC                                          1           1      1           1  \n",
       "DC                                           1           0      1           1  \n",
       "bilateral                                False       False   True       False  \n",
       "White/Caucasion                          False        True   True        True  \n",
       "Hispanic/Latino                           True       False  False       False  \n",
       "African American/Black                   False       False  False       False  \n",
       "Asian                                    False       False  False       False  \n",
       "cc_none                                      0           1      0           0  \n",
       "cc_platinum                                  0           0      1           1  \n",
       "cc_cetuximab                                 0           0      0           0  \n",
       "cc_others                                    1           0      0           0  \n",
       "no_dose_adjustment                           1           1      1           1  \n",
       "dose_modified                                0           0      0           0  \n",
       "dose_delayed                                 0           0      0           0  \n",
       "dose_cancelled                               0           0      0           0  \n",
       "dose_delayed_&_modified                      0           0      0           0  \n",
       "regiment_modification                        0           0      0           0  \n",
       "T-category_1                                 0           1      0           0  \n",
       "T-category_2                                 0           0      0           0  \n",
       "T-category_3                                 0           0      1           0  \n",
       "T-category_4                                 1           0      0           1  \n",
       "N-category_0                                 0           0      0           0  \n",
       "N-category_1                                 0           1      0           1  \n",
       "N-category_2                                 1           0      0           0  \n",
       "N-category_3                                 0           0      1           0  \n",
       "AJCC_1                                       0           1      0           0  \n",
       "AJCC_2                                       0           0      0           0  \n",
       "AJCC_3                                       0           0      0           1  \n",
       "AJCC_4                                       1           0      1           0  \n",
       "Pathological Grade_0                         0           1      0           0  \n",
       "Pathological Grade_1                         0           0      0           0  \n",
       "Pathological Grade_2                         0           0      0           1  \n",
       "Pathological Grade_3                         1           0      1           0  \n",
       "Pathological Grade_4                         0           0      0           0  \n",
       "subsite_BOT                                  0           0      0           1  \n",
       "subsite_GPS                                  0           0      0           0  \n",
       "subsite_NOS                                  1           0      0           0  \n",
       "subsite_Soft palate                          0           0      0           0  \n",
       "subsite_Tonsil                               0           1      1           0  \n",
       "treatment_CC                                 1           0      1           1  \n",
       "treatment_IC+CC                              0           0      0           0  \n",
       "treatment_IC+Radiation alone                 0           0      0           0  \n",
       "treatment_Radiation alone                    0           1      0           0  \n",
       "DLT_Dermatological                         0.0         0.0    0.0         0.0  \n",
       "DLT_Neurological                           0.0         0.0    0.0         0.0  \n",
       "DLT_Gastrointestinal                       0.0         0.0    0.0         0.0  \n",
       "DLT_Hematological                          0.0         0.0    0.0         0.0  \n",
       "DLT_Nephrological                            0           0      0           0  \n",
       "DLT_Vascular                                 0           0      0           0  \n",
       "DLT_Infection (Pneumonia)                    0           0      0           0  \n",
       "DLT_Other                                  0.0         0.0    0.0         0.0  \n",
       "DLT_Dermatological 2                       0.0         0.0    0.0         0.0  \n",
       "DLT_Neurological 2                         0.0         0.0    0.0         0.0  \n",
       "DLT_Gastrointestinal 2                     0.0         0.0    1.0         0.0  \n",
       "DLT_Hematological 2                        0.0         0.0    0.0         0.0  \n",
       "DLT_Nephrological 2                          0           0      0           0  \n",
       "DLT_Vascular 2                               0           0      0           0  \n",
       "DLT_Infection (Pneumonia) 2                  0           0      0           0  \n",
       "DLT_Other 2                                0.0         0.0    0.0         0.0  \n",
       "CR Primary                                   0           0      0           0  \n",
       "PR Primary                                   0           0      0           0  \n",
       "SD Primary                                   0           0      0           0  \n",
       "CR Nodal                                     0           0      0           0  \n",
       "PR Nodal                                     0           0      0           0  \n",
       "SD Nodal                                     0           0      0           0  \n",
       "CR Primary 2                                 0           1      1           1  \n",
       "PR Primary 2                                 1           0      0           0  \n",
       "SD Primary 2                                 0           0      0           0  \n",
       "CR Nodal 2                                   0           0      0           0  \n",
       "PR Nodal 2                                   1           1      1           1  \n",
       "SD Nodal 2                                   0           0      0           0  \n",
       "Decision 1 (Induction Chemo) Y/N             0           0      0           0  \n",
       "Decision 2 (CC / RT alone)                   1           0      1           1  \n",
       "Decision 3 Neck Dissection (Y/N)             1           1      0           1  \n",
       "Overall Survival (4 Years)                   1           1      1           1  \n",
       "FT                                           1           0      0           0  \n",
       "Aspiration rate Post-therapy                 0           0      0           0  \n",
       "1A_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "1A_contra                                  0.0         0.0    0.0         0.0  \n",
       "1B_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "1B_contra                                  0.0         0.0    0.0         0.0  \n",
       "2A_ipsi                                    1.0         1.0    1.0         0.0  \n",
       "2A_contra                                  0.0         0.0    0.0         0.0  \n",
       "2B_ipsi                                    1.0         1.0    1.0         0.0  \n",
       "2B_contra                                  0.0         0.0    0.0         0.0  \n",
       "3_ipsi                                     0.0         1.0    1.0         1.0  \n",
       "3_contra                                   0.0         0.0    0.0         0.0  \n",
       "4_ipsi                                     0.0         0.0    0.0         0.0  \n",
       "4_contra                                   0.0         0.0    0.0         0.0  \n",
       "5A_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "5A_contra                                  0.0         0.0    0.0         0.0  \n",
       "5B_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "5B_contra                                  0.0         0.0    0.0         0.0  \n",
       "6_ipsi                                     0.0         0.0    0.0         0.0  \n",
       "6_contra                                   0.0         0.0    0.0         0.0  \n",
       "RPLN_ipsi                                  0.0         0.0    0.0         0.0  \n",
       "RPLN_contra                                0.0         0.0    0.0         0.0  \n",
       "\n",
       "[109 rows x 536 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False)\n",
    "data.processed_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2937b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSM(\n",
       "  (act): Tanh()\n",
       "  (shape): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 6]\n",
       "      (1): Parameter containing: [torch.float32 of size 6]\n",
       "      (2): Parameter containing: [torch.float32 of size 6]\n",
       "      (3): Parameter containing: [torch.float32 of size 6]\n",
       "  )\n",
       "  (scale): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 6]\n",
       "      (1): Parameter containing: [torch.float32 of size 6]\n",
       "      (2): Parameter containing: [torch.float32 of size 6]\n",
       "      (3): Parameter containing: [torch.float32 of size 6]\n",
       "  )\n",
       "  (gate): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (scaleg): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (shapeg): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=103, out_features=6, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (embedding): Sequential(\n",
       "    (0): Linear(in_features=78, out_features=100, bias=False)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (embedding_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (squish): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1,model2,model3,smodel3 = load_transition_models()\n",
    "smodel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29d259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([108.,   1., 137.]) 147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 1., 0.],\n",
       "         [0., 0., 1.],\n",
       "         [1., 0., 1.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]]),\n",
       " {'pd1': tensor([[9.8764e-01, 1.2365e-02, 2.1092e-22],\n",
       "          [9.8884e-01, 1.0951e-02, 2.0709e-04],\n",
       "          [7.3295e-03, 9.9134e-01, 1.3281e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.5297e-01, 4.3145e-01, 1.5574e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.6773e-01, 1.2479e-01, 7.4802e-03],\n",
       "          [6.3738e-01, 3.4885e-01, 1.3769e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.0819e-01, 1.7962e-01, 1.2188e-02],\n",
       "          [6.4065e-01, 3.5015e-01, 9.1946e-03],\n",
       "          [5.1329e-01, 4.6332e-01, 2.3399e-02],\n",
       "          [7.4908e-01, 2.4044e-01, 1.0485e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.7737e-01, 5.0544e-01, 1.7189e-02],\n",
       "          [8.3595e-01, 1.5205e-01, 1.1999e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.6547e-01, 8.2217e-01, 1.2366e-02],\n",
       "          [7.1757e-01, 2.6265e-01, 1.9783e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.1280e-02, 9.7813e-01, 5.8729e-04],\n",
       "          [1.2777e-05, 9.9999e-01, 1.1482e-25],\n",
       "          [5.5604e-01, 4.2188e-01, 2.2075e-02],\n",
       "          [3.4327e-05, 9.9997e-01, 2.7426e-25],\n",
       "          [8.0444e-01, 1.8908e-01, 6.4870e-03],\n",
       "          [5.5142e-01, 4.3018e-01, 1.8395e-02],\n",
       "          [5.6925e-01, 4.1574e-01, 1.5017e-02],\n",
       "          [8.9836e-01, 9.3142e-02, 8.5027e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.1589e-01, 1.6906e-01, 1.5053e-02],\n",
       "          [9.3921e-01, 5.5289e-02, 5.5052e-03],\n",
       "          [7.4284e-01, 2.4631e-01, 1.0852e-02],\n",
       "          [6.8148e-01, 3.1852e-01, 6.0605e-22],\n",
       "          [6.8914e-01, 2.9557e-01, 1.5292e-02],\n",
       "          [7.6404e-01, 2.1709e-01, 1.8865e-02],\n",
       "          [5.6869e-01, 4.1961e-01, 1.1694e-02],\n",
       "          [6.2995e-01, 3.5704e-01, 1.3007e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.7941e-01, 7.2009e-01, 4.9666e-04],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.4567e-01, 8.4766e-01, 6.6729e-03],\n",
       "          [6.5483e-01, 3.3020e-01, 1.4971e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [9.1389e-01, 7.8943e-02, 7.1675e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.4889e-01, 5.3033e-01, 2.0783e-02],\n",
       "          [3.9954e-01, 5.9370e-01, 6.7675e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.7559e-01, 7.0351e-01, 2.0901e-02],\n",
       "          [6.6688e-01, 3.1237e-01, 2.0741e-02],\n",
       "          [5.5823e-01, 4.2638e-01, 1.5387e-02],\n",
       "          [8.4863e-02, 9.0551e-01, 9.6241e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.8099e-01, 7.1843e-01, 5.7776e-04],\n",
       "          [8.0594e-01, 1.8139e-01, 1.2663e-02],\n",
       "          [9.0591e-01, 8.4535e-02, 9.5594e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.9679e-01, 1.9225e-01, 1.0965e-02],\n",
       "          [8.9627e-01, 9.6801e-02, 6.9306e-03],\n",
       "          [1.4807e-05, 9.9999e-01, 1.1000e-25],\n",
       "          [7.9433e-01, 1.9389e-01, 1.1777e-02],\n",
       "          [6.6989e-01, 3.1297e-01, 1.7144e-02],\n",
       "          [2.5296e-01, 7.3483e-01, 1.2202e-02],\n",
       "          [9.1759e-01, 7.1208e-02, 1.1198e-02],\n",
       "          [8.1185e-01, 1.7522e-01, 1.2937e-02],\n",
       "          [7.2867e-02, 9.2029e-01, 6.8426e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.9631e-01, 1.8737e-01, 1.6320e-02],\n",
       "          [8.7185e-01, 1.1770e-01, 1.0454e-02],\n",
       "          [5.6442e-01, 4.2909e-01, 6.4925e-03],\n",
       "          [4.3463e-01, 5.5703e-01, 8.3394e-03],\n",
       "          [3.2122e-03, 9.9599e-01, 7.9948e-04],\n",
       "          [6.4189e-02, 9.2839e-01, 7.4257e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.9226e-01, 3.9428e-01, 1.3465e-02],\n",
       "          [7.9153e-01, 1.9506e-01, 1.3405e-02],\n",
       "          [3.2604e-01, 6.5642e-01, 1.7544e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.5289e-01, 1.4186e-01, 5.2480e-03],\n",
       "          [8.0581e-01, 1.8494e-01, 9.2558e-03],\n",
       "          [4.5738e-01, 5.2824e-01, 1.4383e-02],\n",
       "          [5.0804e-01, 4.8419e-01, 7.7729e-03],\n",
       "          [7.6900e-01, 2.1815e-01, 1.2852e-02],\n",
       "          [8.2287e-01, 1.7713e-01, 7.8732e-22],\n",
       "          [5.9366e-01, 3.8917e-01, 1.7173e-02],\n",
       "          [8.1929e-01, 1.7202e-01, 8.6826e-03],\n",
       "          [2.2348e-01, 7.6218e-01, 1.4339e-02],\n",
       "          [7.1681e-01, 2.7119e-01, 1.1999e-02],\n",
       "          [1.2988e-01, 8.6954e-01, 5.8069e-04],\n",
       "          [1.6479e-01, 8.3005e-01, 5.1663e-03],\n",
       "          [8.1170e-01, 1.6930e-01, 1.9002e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.2702e-01, 1.5931e-01, 1.3668e-02],\n",
       "          [2.5411e-02, 9.7133e-01, 3.2600e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [8.8733e-01, 1.0309e-01, 9.5871e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.3970e-01, 8.5510e-01, 5.2007e-03],\n",
       "          [8.2311e-01, 1.6204e-01, 1.4849e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.9870e-01, 1.8768e-01, 1.3615e-02],\n",
       "          [6.7941e-01, 3.0718e-01, 1.3412e-02],\n",
       "          [8.0132e-01, 1.9142e-01, 7.2648e-03],\n",
       "          [6.5926e-01, 3.1756e-01, 2.3176e-02],\n",
       "          [1.5347e-01, 8.3434e-01, 1.2189e-02],\n",
       "          [8.6540e-01, 1.2228e-01, 1.2321e-02],\n",
       "          [7.2576e-01, 2.5669e-01, 1.7549e-02],\n",
       "          [2.0522e-01, 7.8110e-01, 1.3679e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.0077e-01, 4.7694e-01, 2.2286e-02],\n",
       "          [6.1337e-01, 3.7079e-01, 1.5836e-02],\n",
       "          [4.8523e-01, 4.9119e-01, 2.3585e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.4163e-01, 8.4644e-01, 1.1933e-02],\n",
       "          [7.6623e-01, 2.2093e-01, 1.2846e-02],\n",
       "          [2.7939e-01, 7.0283e-01, 1.7779e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.7062e-01, 4.0711e-01, 2.2275e-02],\n",
       "          [8.0645e-01, 1.7930e-01, 1.4250e-02],\n",
       "          [9.0734e-01, 8.3298e-02, 9.3665e-03],\n",
       "          [8.8078e-02, 9.0690e-01, 5.0239e-03],\n",
       "          [1.7901e-01, 8.1551e-01, 5.4812e-03],\n",
       "          [8.8291e-01, 1.1334e-01, 3.7490e-03],\n",
       "          [8.0144e-01, 1.8437e-01, 1.4194e-02],\n",
       "          [5.0753e-01, 4.8151e-01, 1.0962e-02],\n",
       "          [5.6766e-01, 4.1734e-01, 1.4994e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.8407e-01, 1.9987e-01, 1.6053e-02],\n",
       "          [7.5628e-01, 2.2635e-01, 1.7364e-02],\n",
       "          [7.0421e-01, 2.7779e-01, 1.7999e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [9.3644e-01, 6.3063e-02, 5.0097e-04],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.2175e-01, 6.6714e-01, 1.1105e-02],\n",
       "          [5.6450e-01, 4.2040e-01, 1.5101e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01]], grad_fn=<CopySlices>),\n",
       "  'nd1': tensor([[1.1739e-34, 1.0000e+00, 1.1739e-34],\n",
       "          [2.9576e-05, 9.9994e-01, 2.9764e-05],\n",
       "          [2.3385e-03, 9.9528e-01, 2.3865e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.3273e-03, 9.9330e-01, 3.3689e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.9965e-03, 9.9599e-01, 2.0118e-03],\n",
       "          [3.0586e-03, 9.9386e-01, 3.0823e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.4482e-03, 9.9103e-01, 4.5263e-03],\n",
       "          [1.9618e-03, 9.9604e-01, 1.9949e-03],\n",
       "          [8.9483e-03, 9.8190e-01, 9.1493e-03],\n",
       "          [2.0289e-03, 9.9592e-01, 2.0506e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.6923e-03, 9.9059e-01, 4.7144e-03],\n",
       "          [4.8443e-03, 9.9019e-01, 4.9707e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.6937e-03, 9.9055e-01, 4.7525e-03],\n",
       "          [6.9029e-03, 9.8600e-01, 7.0983e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.5063e-04, 9.9970e-01, 1.5263e-04],\n",
       "          [1.4899e-37, 1.0000e+00, 1.4899e-37],\n",
       "          [6.1768e-03, 9.8752e-01, 6.2998e-03],\n",
       "          [2.3945e-37, 1.0000e+00, 2.3945e-37],\n",
       "          [1.0887e-03, 9.9779e-01, 1.1203e-03],\n",
       "          [5.6910e-03, 9.8842e-01, 5.8932e-03],\n",
       "          [3.0025e-03, 9.9396e-01, 3.0356e-03],\n",
       "          [3.4671e-03, 9.9303e-01, 3.4983e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.5248e-03, 9.8675e-01, 6.7230e-03],\n",
       "          [3.4352e-03, 9.9316e-01, 3.4095e-03],\n",
       "          [2.5029e-03, 9.9495e-01, 2.5492e-03],\n",
       "          [9.5742e-35, 1.0000e+00, 9.5742e-35],\n",
       "          [5.9525e-03, 9.8811e-01, 5.9358e-03],\n",
       "          [7.4201e-03, 9.8493e-01, 7.6478e-03],\n",
       "          [2.9069e-03, 9.9414e-01, 2.9558e-03],\n",
       "          [2.4667e-03, 9.9505e-01, 2.4857e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.2816e-05, 9.9997e-01, 1.2904e-05],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.0945e-03, 9.9573e-01, 2.1707e-03],\n",
       "          [3.8121e-03, 9.9231e-01, 3.8736e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.0050e-03, 9.9394e-01, 3.0517e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.6702e-03, 9.8658e-01, 6.7486e-03],\n",
       "          [1.0531e-03, 9.9788e-01, 1.0682e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.9396e-03, 9.8588e-01, 7.1769e-03],\n",
       "          [7.8237e-03, 9.8417e-01, 8.0043e-03],\n",
       "          [3.1322e-03, 9.9370e-01, 3.1689e-03],\n",
       "          [6.5774e-03, 9.8662e-01, 6.8031e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.5540e-05, 9.9995e-01, 2.5664e-05],\n",
       "          [4.1295e-03, 9.9178e-01, 4.0873e-03],\n",
       "          [4.7454e-03, 9.9037e-01, 4.8836e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.4190e-03, 9.9110e-01, 4.4833e-03],\n",
       "          [2.8608e-03, 9.9422e-01, 2.9226e-03],\n",
       "          [1.7308e-37, 1.0000e+00, 1.7308e-37],\n",
       "          [3.3995e-03, 9.9313e-01, 3.4746e-03],\n",
       "          [5.4077e-03, 9.8895e-01, 5.6401e-03],\n",
       "          [4.9223e-03, 9.9017e-01, 4.9048e-03],\n",
       "          [6.4917e-03, 9.8708e-01, 6.4277e-03],\n",
       "          [5.0862e-03, 9.8967e-01, 5.2442e-03],\n",
       "          [4.7550e-03, 9.9037e-01, 4.8788e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.9419e-03, 9.8589e-01, 7.1664e-03],\n",
       "          [4.2520e-03, 9.9139e-01, 4.3539e-03],\n",
       "          [1.1798e-03, 9.9764e-01, 1.1789e-03],\n",
       "          [1.7898e-03, 9.9641e-01, 1.8032e-03],\n",
       "          [1.4842e-03, 9.9699e-01, 1.5219e-03],\n",
       "          [5.8561e-03, 9.8806e-01, 6.0882e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [2.9339e-03, 9.9412e-01, 2.9480e-03],\n",
       "          [5.1362e-03, 9.8970e-01, 5.1595e-03],\n",
       "          [5.9563e-03, 9.8793e-01, 6.1105e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.2096e-03, 9.9757e-01, 1.2191e-03],\n",
       "          [2.2729e-03, 9.9544e-01, 2.2908e-03],\n",
       "          [3.6431e-03, 9.9268e-01, 3.6788e-03],\n",
       "          [1.0145e-03, 9.9797e-01, 1.0198e-03],\n",
       "          [3.6673e-03, 9.9258e-01, 3.7546e-03],\n",
       "          [1.5527e-34, 1.0000e+00, 1.5527e-34],\n",
       "          [4.8350e-03, 9.9016e-01, 5.0074e-03],\n",
       "          [2.1344e-03, 9.9572e-01, 2.1492e-03],\n",
       "          [7.3301e-03, 9.8526e-01, 7.4136e-03],\n",
       "          [2.8585e-03, 9.9425e-01, 2.8942e-03],\n",
       "          [4.2530e-05, 9.9991e-01, 4.2853e-05],\n",
       "          [1.2760e-03, 9.9741e-01, 1.3116e-03],\n",
       "          [8.6234e-03, 9.8278e-01, 8.5927e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.8150e-03, 9.8821e-01, 5.9793e-03],\n",
       "          [2.5409e-03, 9.9489e-01, 2.5710e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.7158e-03, 9.9260e-01, 3.6806e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [1.8114e-03, 9.9633e-01, 1.8634e-03],\n",
       "          [5.0706e-03, 9.8972e-01, 5.2054e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [4.5429e-03, 9.9095e-01, 4.5031e-03],\n",
       "          [3.2302e-03, 9.9350e-01, 3.2728e-03],\n",
       "          [1.7693e-03, 9.9646e-01, 1.7724e-03],\n",
       "          [6.4478e-03, 9.8689e-01, 6.6628e-03],\n",
       "          [4.7991e-03, 9.9021e-01, 4.9915e-03],\n",
       "          [4.9801e-03, 9.8989e-01, 5.1301e-03],\n",
       "          [6.0839e-03, 9.8768e-01, 6.2382e-03],\n",
       "          [4.5032e-03, 9.9086e-01, 4.6385e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.0170e-03, 9.8770e-01, 6.2797e-03],\n",
       "          [4.2812e-03, 9.9134e-01, 4.3776e-03],\n",
       "          [8.9705e-03, 9.8183e-01, 9.1972e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.2954e-03, 9.8919e-01, 5.5097e-03],\n",
       "          [4.5447e-03, 9.9094e-01, 4.5155e-03],\n",
       "          [7.7315e-03, 9.8459e-01, 7.6737e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [7.7806e-03, 9.8421e-01, 8.0114e-03],\n",
       "          [7.0062e-03, 9.8578e-01, 7.2113e-03],\n",
       "          [4.6435e-03, 9.9058e-01, 4.7773e-03],\n",
       "          [2.4570e-03, 9.9509e-01, 2.4492e-03],\n",
       "          [1.1783e-03, 9.9763e-01, 1.1946e-03],\n",
       "          [8.7794e-04, 9.9824e-01, 8.7731e-04],\n",
       "          [5.4107e-03, 9.8905e-01, 5.5407e-03],\n",
       "          [2.5093e-03, 9.9496e-01, 2.5347e-03],\n",
       "          [2.9765e-03, 9.9401e-01, 3.0090e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [6.4384e-03, 9.8699e-01, 6.5700e-03],\n",
       "          [7.5168e-03, 9.8483e-01, 7.6520e-03],\n",
       "          [6.2753e-03, 9.8746e-01, 6.2686e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [5.9120e-05, 9.9988e-01, 5.9278e-05],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01],\n",
       "          [3.6430e-03, 9.9263e-01, 3.7317e-03],\n",
       "          [4.3593e-03, 9.9125e-01, 4.3913e-03],\n",
       "          [0.0000e+00, 0.0000e+00, 3.3333e-01]], grad_fn=<CopySlices>),\n",
       "  'nd2': tensor([[8.9800e-01, 9.0795e-02, 1.1205e-02],\n",
       "          [9.2503e-01, 7.4380e-02, 5.8676e-04],\n",
       "          [8.1229e-01, 1.7999e-01, 7.7274e-03],\n",
       "          [7.0420e-01, 2.7009e-01, 2.5706e-02],\n",
       "          [7.0417e-01, 2.6431e-01, 3.1519e-02],\n",
       "          [6.4214e-01, 3.2395e-01, 3.3915e-02],\n",
       "          [6.8696e-01, 3.0055e-01, 1.2492e-02],\n",
       "          [6.4081e-01, 3.3420e-01, 2.4987e-02],\n",
       "          [6.8065e-01, 2.8372e-01, 3.5626e-02],\n",
       "          [5.7438e-01, 3.9279e-01, 3.2829e-02],\n",
       "          [5.8210e-01, 3.7691e-01, 4.0990e-02],\n",
       "          [7.9597e-01, 1.9665e-01, 7.3840e-03],\n",
       "          [5.7389e-01, 3.7136e-01, 5.4745e-02],\n",
       "          [5.8059e-01, 3.8736e-01, 3.2046e-02],\n",
       "          [7.0935e-01, 2.6189e-01, 2.8767e-02],\n",
       "          [6.4435e-01, 3.2607e-01, 2.9586e-02],\n",
       "          [8.5915e-01, 1.3896e-01, 1.8933e-03],\n",
       "          [6.3992e-01, 3.1009e-01, 4.9993e-02],\n",
       "          [5.6149e-01, 3.9130e-01, 4.7202e-02],\n",
       "          [6.8676e-01, 2.8921e-01, 2.4028e-02],\n",
       "          [7.0773e-01, 2.6393e-01, 2.8335e-02],\n",
       "          [6.6188e-01, 2.9936e-01, 3.8757e-02],\n",
       "          [6.6219e-01, 3.0164e-01, 3.6169e-02],\n",
       "          [7.7436e-01, 2.1442e-01, 1.1222e-02],\n",
       "          [7.5824e-01, 2.4087e-01, 8.8820e-04],\n",
       "          [7.0467e-01, 2.6826e-01, 2.7067e-02],\n",
       "          [7.9605e-01, 2.0318e-01, 7.7160e-04],\n",
       "          [7.7470e-01, 2.1537e-01, 9.9362e-03],\n",
       "          [5.7425e-01, 3.8556e-01, 4.0191e-02],\n",
       "          [6.1971e-01, 3.4441e-01, 3.5881e-02],\n",
       "          [5.7489e-01, 3.8278e-01, 4.2338e-02],\n",
       "          [6.2564e-01, 3.3435e-01, 4.0006e-02],\n",
       "          [5.8859e-01, 3.6356e-01, 4.7856e-02],\n",
       "          [6.8560e-01, 2.7611e-01, 3.8294e-02],\n",
       "          [6.9344e-01, 2.8090e-01, 2.5662e-02],\n",
       "          [8.5665e-01, 1.2965e-01, 1.3702e-02],\n",
       "          [6.3221e-01, 3.2479e-01, 4.3005e-02],\n",
       "          [6.7715e-01, 2.8508e-01, 3.7773e-02],\n",
       "          [5.9622e-01, 3.7438e-01, 2.9399e-02],\n",
       "          [6.0778e-01, 3.5767e-01, 3.4547e-02],\n",
       "          [6.8395e-01, 2.8297e-01, 3.3079e-02],\n",
       "          [8.6080e-01, 1.3771e-01, 1.4957e-03],\n",
       "          [7.6942e-01, 2.0838e-01, 2.2197e-02],\n",
       "          [8.1652e-01, 1.7532e-01, 8.1614e-03],\n",
       "          [6.3190e-01, 3.2878e-01, 3.9317e-02],\n",
       "          [7.8103e-01, 2.1127e-01, 7.6986e-03],\n",
       "          [7.7190e-01, 2.1209e-01, 1.6005e-02],\n",
       "          [6.7683e-01, 3.0174e-01, 2.1429e-02],\n",
       "          [6.1603e-01, 3.4736e-01, 3.6609e-02],\n",
       "          [6.1094e-01, 3.4602e-01, 4.3043e-02],\n",
       "          [8.3405e-01, 1.5522e-01, 1.0734e-02],\n",
       "          [6.5548e-01, 3.0310e-01, 4.1427e-02],\n",
       "          [7.8033e-01, 1.9119e-01, 2.8482e-02],\n",
       "          [6.0064e-01, 3.4597e-01, 5.3383e-02],\n",
       "          [6.2475e-01, 3.3943e-01, 3.5813e-02],\n",
       "          [5.7484e-01, 3.8084e-01, 4.4320e-02],\n",
       "          [7.2581e-01, 2.4948e-01, 2.4706e-02],\n",
       "          [5.7656e-01, 3.8489e-01, 3.8553e-02],\n",
       "          [9.3224e-01, 6.7087e-02, 6.7419e-04],\n",
       "          [5.9005e-01, 3.5886e-01, 5.1095e-02],\n",
       "          [6.0438e-01, 3.5455e-01, 4.1073e-02],\n",
       "          [6.0906e-01, 3.5395e-01, 3.6992e-02],\n",
       "          [5.8431e-01, 3.6876e-01, 4.6932e-02],\n",
       "          [6.0548e-01, 3.5527e-01, 3.9248e-02],\n",
       "          [7.3577e-01, 2.6305e-01, 1.1801e-03],\n",
       "          [6.0257e-01, 3.6134e-01, 3.6089e-02],\n",
       "          [5.7725e-01, 3.7757e-01, 4.5186e-02],\n",
       "          [5.8931e-01, 3.6401e-01, 4.6671e-02],\n",
       "          [6.1769e-01, 3.3687e-01, 4.5439e-02],\n",
       "          [6.2356e-01, 3.3156e-01, 4.4883e-02],\n",
       "          [5.6874e-01, 3.9086e-01, 4.0404e-02],\n",
       "          [6.8582e-01, 2.7913e-01, 3.5055e-02],\n",
       "          [6.0917e-01, 3.4479e-01, 4.6038e-02],\n",
       "          [6.5918e-01, 3.1394e-01, 2.6877e-02],\n",
       "          [6.8269e-01, 2.9161e-01, 2.5699e-02],\n",
       "          [6.2272e-01, 3.4749e-01, 2.9790e-02],\n",
       "          [7.4487e-01, 2.4029e-01, 1.4848e-02],\n",
       "          [5.5927e-01, 3.9368e-01, 4.7054e-02],\n",
       "          [7.0081e-01, 2.7977e-01, 1.9421e-02],\n",
       "          [6.0733e-01, 3.6938e-01, 2.3288e-02],\n",
       "          [6.3655e-01, 3.3092e-01, 3.2530e-02],\n",
       "          [7.2420e-01, 2.4539e-01, 3.0413e-02],\n",
       "          [6.3898e-01, 3.2042e-01, 4.0600e-02],\n",
       "          [6.7590e-01, 3.0163e-01, 2.2470e-02],\n",
       "          [8.4919e-01, 1.4263e-01, 8.1896e-03],\n",
       "          [6.0860e-01, 3.6213e-01, 2.9267e-02],\n",
       "          [6.5500e-01, 2.9996e-01, 4.5038e-02],\n",
       "          [6.5218e-01, 3.2746e-01, 2.0362e-02],\n",
       "          [6.2441e-01, 3.4068e-01, 3.4907e-02],\n",
       "          [8.8888e-01, 9.9622e-02, 1.1502e-02],\n",
       "          [5.5758e-01, 4.0394e-01, 3.8483e-02],\n",
       "          [5.9897e-01, 3.7153e-01, 2.9502e-02],\n",
       "          [6.0621e-01, 3.4418e-01, 4.9616e-02],\n",
       "          [5.9897e-01, 3.6158e-01, 3.9448e-02],\n",
       "          [7.4426e-01, 2.4902e-01, 6.7190e-03],\n",
       "          [6.9452e-01, 2.8113e-01, 2.4346e-02],\n",
       "          [5.9476e-01, 3.6183e-01, 4.3412e-02],\n",
       "          [8.7001e-01, 1.2580e-01, 4.1953e-03],\n",
       "          [5.7540e-01, 3.7658e-01, 4.8024e-02],\n",
       "          [7.4895e-01, 2.3385e-01, 1.7202e-02],\n",
       "          [6.7142e-01, 3.0468e-01, 2.3901e-02],\n",
       "          [5.9537e-01, 3.5690e-01, 4.7726e-02],\n",
       "          [6.2131e-01, 3.3867e-01, 4.0022e-02],\n",
       "          [7.1634e-01, 2.7686e-01, 6.8009e-03],\n",
       "          [6.3981e-01, 3.2622e-01, 3.3966e-02],\n",
       "          [6.9039e-01, 2.7672e-01, 3.2899e-02],\n",
       "          [6.1076e-01, 3.3935e-01, 4.9897e-02],\n",
       "          [6.6348e-01, 3.0354e-01, 3.2974e-02],\n",
       "          [6.0641e-01, 3.6626e-01, 2.7335e-02],\n",
       "          [6.2112e-01, 3.5261e-01, 2.6270e-02],\n",
       "          [5.9765e-01, 3.6277e-01, 3.9581e-02],\n",
       "          [6.6142e-01, 3.0052e-01, 3.8064e-02],\n",
       "          [5.7425e-01, 3.7648e-01, 4.9269e-02],\n",
       "          [7.9547e-01, 1.8442e-01, 2.0106e-02],\n",
       "          [6.2546e-01, 3.3748e-01, 3.7061e-02],\n",
       "          [6.2336e-01, 3.4431e-01, 3.2333e-02],\n",
       "          [5.7127e-01, 3.8497e-01, 4.3757e-02],\n",
       "          [5.9628e-01, 3.5255e-01, 5.1166e-02],\n",
       "          [6.5746e-01, 3.2006e-01, 2.2483e-02],\n",
       "          [5.6758e-01, 3.9166e-01, 4.0756e-02],\n",
       "          [7.7191e-01, 2.0344e-01, 2.4641e-02],\n",
       "          [6.9681e-01, 2.5779e-01, 4.5402e-02],\n",
       "          [6.4077e-01, 3.2199e-01, 3.7231e-02],\n",
       "          [6.3717e-01, 3.1308e-01, 4.9744e-02],\n",
       "          [6.1184e-01, 3.3964e-01, 4.8513e-02],\n",
       "          [6.0192e-01, 3.5695e-01, 4.1128e-02],\n",
       "          [6.2780e-01, 3.3529e-01, 3.6903e-02],\n",
       "          [6.9101e-01, 2.9440e-01, 1.4583e-02],\n",
       "          [6.9380e-01, 2.8950e-01, 1.6701e-02],\n",
       "          [5.9988e-01, 3.5590e-01, 4.4225e-02],\n",
       "          [6.7737e-01, 2.9549e-01, 2.7137e-02],\n",
       "          [6.1902e-01, 3.4500e-01, 3.5979e-02],\n",
       "          [6.4905e-01, 3.1891e-01, 3.2046e-02],\n",
       "          [5.9889e-01, 3.5553e-01, 4.5582e-02],\n",
       "          [5.7776e-01, 3.7084e-01, 5.1403e-02],\n",
       "          [7.1270e-01, 2.5097e-01, 3.6322e-02],\n",
       "          [6.7371e-01, 2.8936e-01, 3.6932e-02],\n",
       "          [6.1076e-01, 3.5800e-01, 3.1239e-02],\n",
       "          [5.2589e-01, 4.3378e-01, 4.0328e-02],\n",
       "          [7.2191e-01, 2.4913e-01, 2.8964e-02],\n",
       "          [5.7375e-01, 3.9475e-01, 3.1499e-02],\n",
       "          [6.5576e-01, 3.1336e-01, 3.0881e-02],\n",
       "          [7.6518e-01, 2.3446e-01, 3.6310e-04],\n",
       "          [7.1509e-01, 2.7367e-01, 1.1249e-02],\n",
       "          [5.7594e-01, 3.8161e-01, 4.2442e-02],\n",
       "          [7.0939e-01, 2.4747e-01, 4.3140e-02],\n",
       "          [6.4624e-01, 3.2618e-01, 2.7578e-02]], grad_fn=<CopySlices>),\n",
       "  'pd2': tensor([[9.9669e-01, 1.6669e-03, 1.6447e-03],\n",
       "          [9.9999e-01, 3.6121e-06, 3.6106e-06],\n",
       "          [9.9889e-01, 5.5532e-04, 5.5134e-04],\n",
       "          [9.8933e-01, 5.4192e-03, 5.2552e-03],\n",
       "          [9.8520e-01, 7.5194e-03, 7.2843e-03],\n",
       "          [9.8731e-01, 6.4248e-03, 6.2655e-03],\n",
       "          [9.9815e-01, 9.3011e-04, 9.2290e-04],\n",
       "          [9.9257e-01, 3.7504e-03, 3.6816e-03],\n",
       "          [9.8502e-01, 7.5884e-03, 7.3947e-03],\n",
       "          [9.8671e-01, 6.7203e-03, 6.5662e-03],\n",
       "          [9.8174e-01, 9.2674e-03, 8.9955e-03],\n",
       "          [9.9913e-01, 4.3502e-04, 4.3141e-04],\n",
       "          [9.6553e-01, 1.7536e-02, 1.6939e-02],\n",
       "          [9.9043e-01, 4.8344e-03, 4.7355e-03],\n",
       "          [9.8837e-01, 5.8879e-03, 5.7468e-03],\n",
       "          [9.8604e-01, 7.0754e-03, 6.8858e-03],\n",
       "          [9.9988e-01, 5.8137e-05, 5.8043e-05],\n",
       "          [9.6975e-01, 1.5402e-02, 1.4846e-02],\n",
       "          [9.7733e-01, 1.1499e-02, 1.1175e-02],\n",
       "          [9.9326e-01, 3.3994e-03, 3.3405e-03],\n",
       "          [9.8959e-01, 5.2656e-03, 5.1477e-03],\n",
       "          [9.7998e-01, 1.0161e-02, 9.8558e-03],\n",
       "          [9.8345e-01, 8.3771e-03, 8.1760e-03],\n",
       "          [9.9825e-01, 8.7839e-04, 8.6900e-04],\n",
       "          [9.9999e-01, 5.9207e-06, 5.9163e-06],\n",
       "          [9.9097e-01, 4.5673e-03, 4.4591e-03],\n",
       "          [9.9999e-01, 4.4399e-06, 4.4371e-06],\n",
       "          [9.9892e-01, 5.4331e-04, 5.3911e-04],\n",
       "          [9.8364e-01, 8.3237e-03, 8.0385e-03],\n",
       "          [9.8638e-01, 6.8951e-03, 6.7237e-03],\n",
       "          [9.7956e-01, 1.0341e-02, 1.0102e-02],\n",
       "          [9.7919e-01, 1.0571e-02, 1.0236e-02],\n",
       "          [9.7561e-01, 1.2389e-02, 1.2003e-02],\n",
       "          [9.8139e-01, 9.4157e-03, 9.1938e-03],\n",
       "          [9.9263e-01, 3.7176e-03, 3.6499e-03],\n",
       "          [9.9630e-01, 1.8625e-03, 1.8362e-03],\n",
       "          [9.8090e-01, 9.6757e-03, 9.4244e-03],\n",
       "          [9.8538e-01, 7.4293e-03, 7.1869e-03],\n",
       "          [9.9104e-01, 4.5305e-03, 4.4277e-03],\n",
       "          [9.8803e-01, 6.0495e-03, 5.9157e-03],\n",
       "          [9.8478e-01, 7.7278e-03, 7.4934e-03],\n",
       "          [9.9995e-01, 2.3278e-05, 2.3240e-05],\n",
       "          [9.9248e-01, 3.8000e-03, 3.7214e-03],\n",
       "          [9.9891e-01, 5.4870e-04, 5.4374e-04],\n",
       "          [9.8132e-01, 9.4716e-03, 9.2132e-03],\n",
       "          [9.9916e-01, 4.1990e-04, 4.1703e-04],\n",
       "          [9.9576e-01, 2.1413e-03, 2.1032e-03],\n",
       "          [9.9475e-01, 2.6469e-03, 2.6070e-03],\n",
       "          [9.8278e-01, 8.7269e-03, 8.4939e-03],\n",
       "          [9.7880e-01, 1.0779e-02, 1.0420e-02],\n",
       "          [9.9868e-01, 6.6285e-04, 6.5745e-04],\n",
       "          [9.7594e-01, 1.2248e-02, 1.1811e-02],\n",
       "          [9.8799e-01, 6.0721e-03, 5.9340e-03],\n",
       "          [9.6582e-01, 1.7409e-02, 1.6773e-02],\n",
       "          [9.8627e-01, 6.9527e-03, 6.7764e-03],\n",
       "          [9.7816e-01, 1.1145e-02, 1.0692e-02],\n",
       "          [9.9079e-01, 4.6661e-03, 4.5473e-03],\n",
       "          [9.8123e-01, 9.5147e-03, 9.2576e-03],\n",
       "          [9.9999e-01, 5.5861e-06, 5.5823e-06],\n",
       "          [9.7278e-01, 1.3798e-02, 1.3427e-02],\n",
       "          [9.8202e-01, 9.1102e-03, 8.8655e-03],\n",
       "          [9.8508e-01, 7.5420e-03, 7.3747e-03],\n",
       "          [9.8052e-01, 9.8710e-03, 9.6098e-03],\n",
       "          [9.8218e-01, 9.0284e-03, 8.7944e-03],\n",
       "          [9.9998e-01, 8.4863e-06, 8.4777e-06],\n",
       "          [9.8566e-01, 7.2554e-03, 7.0829e-03],\n",
       "          [9.7868e-01, 1.0801e-02, 1.0518e-02],\n",
       "          [9.7681e-01, 1.1736e-02, 1.1453e-02],\n",
       "          [9.7940e-01, 1.0432e-02, 1.0167e-02],\n",
       "          [9.7920e-01, 1.0514e-02, 1.0287e-02],\n",
       "          [9.8288e-01, 8.6911e-03, 8.4302e-03],\n",
       "          [9.8113e-01, 9.5813e-03, 9.2936e-03],\n",
       "          [9.7652e-01, 1.1929e-02, 1.1546e-02],\n",
       "          [9.9087e-01, 4.6164e-03, 4.5144e-03],\n",
       "          [9.9346e-01, 3.2993e-03, 3.2375e-03],\n",
       "          [9.9184e-01, 4.1099e-03, 4.0463e-03],\n",
       "          [9.9705e-01, 1.4879e-03, 1.4645e-03],\n",
       "          [9.7420e-01, 1.3192e-02, 1.2611e-02],\n",
       "          [9.9611e-01, 1.9589e-03, 1.9314e-03],\n",
       "          [9.9338e-01, 3.3412e-03, 3.2785e-03],\n",
       "          [9.8654e-01, 6.8192e-03, 6.6442e-03],\n",
       "          [9.8808e-01, 6.0323e-03, 5.8884e-03],\n",
       "          [9.8262e-01, 8.8138e-03, 8.5616e-03],\n",
       "          [9.9416e-01, 2.9421e-03, 2.8952e-03],\n",
       "          [9.9905e-01, 4.7472e-04, 4.7123e-04],\n",
       "          [9.9043e-01, 4.8355e-03, 4.7354e-03],\n",
       "          [9.7771e-01, 1.1315e-02, 1.0978e-02],\n",
       "          [9.9543e-01, 2.3004e-03, 2.2687e-03],\n",
       "          [9.8616e-01, 7.0052e-03, 6.8322e-03],\n",
       "          [9.9663e-01, 1.6946e-03, 1.6748e-03],\n",
       "          [9.8511e-01, 7.5095e-03, 7.3839e-03],\n",
       "          [9.9046e-01, 4.8205e-03, 4.7230e-03],\n",
       "          [9.6960e-01, 1.5482e-02, 1.4916e-02],\n",
       "          [9.8259e-01, 8.8116e-03, 8.5949e-03],\n",
       "          [9.9953e-01, 2.3646e-04, 2.3516e-04],\n",
       "          [9.9260e-01, 3.7528e-03, 3.6517e-03],\n",
       "          [9.8274e-01, 8.7238e-03, 8.5320e-03],\n",
       "          [9.9970e-01, 1.4950e-04, 1.4884e-04],\n",
       "          [9.7601e-01, 1.2179e-02, 1.1815e-02],\n",
       "          [9.9621e-01, 1.9109e-03, 1.8811e-03],\n",
       "          [9.9353e-01, 3.2614e-03, 3.2046e-03],\n",
       "          [9.7575e-01, 1.2277e-02, 1.1976e-02],\n",
       "          [9.7941e-01, 1.0454e-02, 1.0132e-02],\n",
       "          [9.9950e-01, 2.4888e-04, 2.4689e-04],\n",
       "          [9.8832e-01, 5.9172e-03, 5.7644e-03],\n",
       "          [9.8565e-01, 7.2783e-03, 7.0704e-03],\n",
       "          [9.7298e-01, 1.3703e-02, 1.3313e-02],\n",
       "          [9.8964e-01, 5.2369e-03, 5.1184e-03],\n",
       "          [9.9176e-01, 4.1558e-03, 4.0819e-03],\n",
       "          [9.9257e-01, 3.7523e-03, 3.6770e-03],\n",
       "          [9.8378e-01, 8.2508e-03, 7.9709e-03],\n",
       "          [9.8183e-01, 9.2289e-03, 8.9460e-03],\n",
       "          [9.7398e-01, 1.3205e-02, 1.2816e-02],\n",
       "          [9.9334e-01, 3.3621e-03, 3.2985e-03],\n",
       "          [9.8169e-01, 9.2917e-03, 9.0180e-03],\n",
       "          [9.8806e-01, 6.0318e-03, 5.9068e-03],\n",
       "          [9.7954e-01, 1.0377e-02, 1.0083e-02],\n",
       "          [9.6878e-01, 1.5879e-02, 1.5340e-02],\n",
       "          [9.9504e-01, 2.5010e-03, 2.4629e-03],\n",
       "          [9.8161e-01, 9.3526e-03, 9.0420e-03],\n",
       "          [9.9101e-01, 4.5299e-03, 4.4586e-03],\n",
       "          [9.7337e-01, 1.3539e-02, 1.3091e-02],\n",
       "          [9.8148e-01, 9.3958e-03, 9.1244e-03],\n",
       "          [9.6761e-01, 1.6513e-02, 1.5878e-02],\n",
       "          [9.7610e-01, 1.2188e-02, 1.1709e-02],\n",
       "          [9.8203e-01, 9.1053e-03, 8.8627e-03],\n",
       "          [9.8643e-01, 6.8706e-03, 6.6961e-03],\n",
       "          [9.9753e-01, 1.2420e-03, 1.2302e-03],\n",
       "          [9.9748e-01, 1.2658e-03, 1.2542e-03],\n",
       "          [9.7844e-01, 1.0947e-02, 1.0615e-02],\n",
       "          [9.9215e-01, 3.9705e-03, 3.8830e-03],\n",
       "          [9.8631e-01, 6.9292e-03, 6.7563e-03],\n",
       "          [9.8823e-01, 5.9575e-03, 5.8114e-03],\n",
       "          [9.8132e-01, 9.5121e-03, 9.1713e-03],\n",
       "          [9.7213e-01, 1.4175e-02, 1.3696e-02],\n",
       "          [9.8300e-01, 8.5863e-03, 8.4148e-03],\n",
       "          [9.8297e-01, 8.6417e-03, 8.3921e-03],\n",
       "          [9.8921e-01, 5.4492e-03, 5.3417e-03],\n",
       "          [9.8399e-01, 8.1195e-03, 7.8911e-03],\n",
       "          [9.8746e-01, 6.3659e-03, 6.1753e-03],\n",
       "          [9.8668e-01, 6.7584e-03, 6.5642e-03],\n",
       "          [9.8607e-01, 7.0744e-03, 6.8529e-03],\n",
       "          [1.0000e+00, 1.3877e-06, 1.3873e-06],\n",
       "          [9.9835e-01, 8.3028e-04, 8.2213e-04],\n",
       "          [9.7854e-01, 1.0931e-02, 1.0524e-02],\n",
       "          [9.7824e-01, 1.0990e-02, 1.0769e-02],\n",
       "          [9.9053e-01, 4.7851e-03, 4.6812e-03]], grad_fn=<CopySlices>),\n",
       "  'mod': tensor([[1.0000e+00, 6.5619e-27, 6.5619e-27, 6.5619e-27, 6.5619e-27, 6.5619e-27],\n",
       "          [9.9788e-01, 4.1991e-04, 4.2168e-04, 4.2137e-04, 4.2067e-04, 4.3501e-04],\n",
       "          [9.7899e-01, 4.1596e-03, 4.0935e-03, 4.1526e-03, 4.1148e-03, 4.4877e-03],\n",
       "          [1.0000e+00, 1.5512e-18, 1.5512e-18, 1.5512e-18, 1.5512e-18, 1.5512e-18],\n",
       "          [1.0000e+00, 9.2475e-19, 9.2475e-19, 9.2475e-19, 9.2475e-19, 9.2475e-19],\n",
       "          [9.4135e-01, 1.1504e-02, 1.1438e-02, 1.1594e-02, 1.1551e-02, 1.2567e-02],\n",
       "          [1.0000e+00, 1.0678e-18, 1.0678e-18, 1.0678e-18, 1.0678e-18, 1.0678e-18],\n",
       "          [9.6234e-01, 7.4165e-03, 7.3909e-03, 7.4262e-03, 7.4209e-03, 8.0018e-03],\n",
       "          [9.3593e-01, 1.2546e-02, 1.2455e-02, 1.2587e-02, 1.2442e-02, 1.4041e-02],\n",
       "          [1.0000e+00, 1.4125e-18, 1.4125e-18, 1.4125e-18, 1.4125e-18, 1.4125e-18],\n",
       "          [9.3975e-01, 1.1829e-02, 1.1719e-02, 1.1856e-02, 1.1803e-02, 1.3048e-02],\n",
       "          [9.7299e-01, 5.3115e-03, 5.2695e-03, 5.3567e-03, 5.3042e-03, 5.7720e-03],\n",
       "          [9.0598e-01, 1.8398e-02, 1.8173e-02, 1.8643e-02, 1.8252e-02, 2.0556e-02],\n",
       "          [9.5541e-01, 8.7456e-03, 8.7282e-03, 8.7895e-03, 8.7885e-03, 9.5388e-03],\n",
       "          [1.0000e+00, 9.5399e-19, 9.5399e-19, 9.5399e-19, 9.5399e-19, 9.5399e-19],\n",
       "          [1.0000e+00, 1.7406e-18, 1.7406e-18, 1.7406e-18, 1.7406e-18, 1.7406e-18],\n",
       "          [1.0000e+00, 1.5345e-19, 1.5345e-19, 1.5345e-19, 1.5345e-19, 1.5345e-19],\n",
       "          [9.4026e-01, 1.1703e-02, 1.1623e-02, 1.1872e-02, 1.1784e-02, 1.2763e-02],\n",
       "          [9.2630e-01, 1.4374e-02, 1.4282e-02, 1.4470e-02, 1.4337e-02, 1.6234e-02],\n",
       "          [1.0000e+00, 1.0139e-18, 1.0139e-18, 1.0139e-18, 1.0139e-18, 1.0139e-18],\n",
       "          [9.4676e-01, 1.0440e-02, 1.0345e-02, 1.0498e-02, 1.0432e-02, 1.1521e-02],\n",
       "          [8.9564e-01, 2.0481e-02, 2.0135e-02, 2.0625e-02, 2.0112e-02, 2.3004e-02],\n",
       "          [1.0000e+00, 8.6851e-19, 8.6851e-19, 8.6851e-19, 8.6851e-19, 8.6851e-19],\n",
       "          [9.9683e-01, 6.3114e-04, 6.2814e-04, 6.3378e-04, 6.2908e-04, 6.5137e-04],\n",
       "          [1.0000e+00, 1.0418e-30, 1.0418e-30, 1.0418e-30, 1.0418e-30, 1.0418e-30],\n",
       "          [9.3008e-01, 1.3661e-02, 1.3511e-02, 1.3916e-02, 1.3571e-02, 1.5262e-02],\n",
       "          [1.0000e+00, 1.7829e-30, 1.7829e-30, 1.7829e-30, 1.7829e-30, 1.7829e-30],\n",
       "          [9.7386e-01, 5.1371e-03, 5.1106e-03, 5.1961e-03, 5.1517e-03, 5.5488e-03],\n",
       "          [9.1630e-01, 1.6362e-02, 1.6070e-02, 1.6549e-02, 1.6363e-02, 1.8359e-02],\n",
       "          [9.4514e-01, 1.0769e-02, 1.0715e-02, 1.0826e-02, 1.0802e-02, 1.1746e-02],\n",
       "          [9.3788e-01, 1.2128e-02, 1.2127e-02, 1.2245e-02, 1.2191e-02, 1.3430e-02],\n",
       "          [1.0000e+00, 1.0150e-18, 1.0150e-18, 1.0150e-18, 1.0150e-18, 1.0150e-18],\n",
       "          [9.0870e-01, 1.7812e-02, 1.7665e-02, 1.7973e-02, 1.7753e-02, 2.0101e-02],\n",
       "          [9.5659e-01, 8.5403e-03, 8.4999e-03, 8.5913e-03, 8.5438e-03, 9.2357e-03],\n",
       "          [9.5218e-01, 9.3352e-03, 9.3260e-03, 9.4296e-03, 9.3628e-03, 1.0366e-02],\n",
       "          [1.0000e+00, 3.9434e-27, 3.9434e-27, 3.9434e-27, 3.9434e-27, 3.9434e-27],\n",
       "          [9.4236e-01, 1.1316e-02, 1.1278e-02, 1.1439e-02, 1.1391e-02, 1.2219e-02],\n",
       "          [9.0479e-01, 1.8483e-02, 1.8456e-02, 1.8832e-02, 1.8554e-02, 2.0885e-02],\n",
       "          [9.6527e-01, 6.7471e-03, 6.7411e-03, 6.8739e-03, 6.8048e-03, 7.5584e-03],\n",
       "          [9.5086e-01, 9.6548e-03, 9.6089e-03, 9.7066e-03, 9.6663e-03, 1.0506e-02],\n",
       "          [1.0000e+00, 7.3325e-19, 7.3325e-19, 7.3325e-19, 7.3325e-19, 7.3325e-19],\n",
       "          [9.9931e-01, 1.3775e-04, 1.3775e-04, 1.3831e-04, 1.3790e-04, 1.4158e-04],\n",
       "          [1.0000e+00, 9.4924e-19, 9.4924e-19, 9.4924e-19, 9.4924e-19, 9.4924e-19],\n",
       "          [9.7270e-01, 5.3749e-03, 5.3249e-03, 5.4183e-03, 5.3368e-03, 5.8469e-03],\n",
       "          [9.3311e-01, 1.3107e-02, 1.3025e-02, 1.3224e-02, 1.3085e-02, 1.4451e-02],\n",
       "          [1.0000e+00, 1.1037e-18, 1.1037e-18, 1.1037e-18, 1.1037e-18, 1.1037e-18],\n",
       "          [1.0000e+00, 1.5004e-18, 1.5004e-18, 1.5004e-18, 1.5004e-18, 1.5004e-18],\n",
       "          [9.4224e-01, 1.1243e-02, 1.1230e-02, 1.1485e-02, 1.1218e-02, 1.2589e-02],\n",
       "          [1.0000e+00, 1.0380e-18, 1.0380e-18, 1.0380e-18, 1.0380e-18, 1.0380e-18],\n",
       "          [9.2440e-01, 1.4815e-02, 1.4641e-02, 1.5005e-02, 1.4761e-02, 1.6380e-02],\n",
       "          [9.8005e-01, 3.9088e-03, 3.9188e-03, 3.9801e-03, 3.9254e-03, 4.2162e-03],\n",
       "          [1.0000e+00, 8.7857e-19, 8.7857e-19, 8.7857e-19, 8.7857e-19, 8.7857e-19],\n",
       "          [9.0699e-01, 1.8143e-02, 1.7846e-02, 1.8292e-02, 1.8057e-02, 2.0670e-02],\n",
       "          [8.9820e-01, 1.9877e-02, 1.9666e-02, 2.0128e-02, 1.9714e-02, 2.2415e-02],\n",
       "          [9.4380e-01, 1.1030e-02, 1.0973e-02, 1.1093e-02, 1.1068e-02, 1.2036e-02],\n",
       "          [9.4938e-01, 9.9446e-03, 9.7522e-03, 1.0079e-02, 9.9358e-03, 1.0906e-02],\n",
       "          [1.0000e+00, 1.0032e-18, 1.0032e-18, 1.0032e-18, 1.0032e-18, 1.0032e-18],\n",
       "          [1.0000e+00, 1.4947e-18, 1.4947e-18, 1.4947e-18, 1.4947e-18, 1.4947e-18],\n",
       "          [9.9919e-01, 1.6048e-04, 1.6063e-04, 1.6098e-04, 1.6063e-04, 1.6446e-04],\n",
       "          [9.4305e-01, 1.1160e-02, 1.1148e-02, 1.1242e-02, 1.1214e-02, 1.2182e-02],\n",
       "          [9.1805e-01, 1.6018e-02, 1.5941e-02, 1.6112e-02, 1.5958e-02, 1.7918e-02],\n",
       "          [1.0000e+00, 1.2392e-18, 1.2392e-18, 1.2392e-18, 1.2392e-18, 1.2392e-18],\n",
       "          [9.4811e-01, 1.0219e-02, 1.0132e-02, 1.0327e-02, 1.0216e-02, 1.0999e-02],\n",
       "          [9.4928e-01, 9.9537e-03, 9.8653e-03, 9.9918e-03, 9.9207e-03, 1.0986e-02],\n",
       "          [1.0000e+00, 9.4881e-31, 9.4881e-31, 9.4881e-31, 9.4881e-31, 9.4881e-31],\n",
       "          [9.3850e-01, 1.2036e-02, 1.1997e-02, 1.2109e-02, 1.2046e-02, 1.3318e-02],\n",
       "          [9.1179e-01, 1.7201e-02, 1.6995e-02, 1.7603e-02, 1.7189e-02, 1.9223e-02],\n",
       "          [9.6127e-01, 7.6204e-03, 7.5803e-03, 7.6845e-03, 7.6453e-03, 8.2001e-03],\n",
       "          [9.1241e-01, 1.7088e-02, 1.7130e-02, 1.7121e-02, 1.7321e-02, 1.8927e-02],\n",
       "          [9.1542e-01, 1.6489e-02, 1.6408e-02, 1.6684e-02, 1.6502e-02, 1.8498e-02],\n",
       "          [9.6323e-01, 7.2379e-03, 7.1628e-03, 7.3081e-03, 7.2535e-03, 7.8052e-03],\n",
       "          [1.0000e+00, 1.1476e-18, 1.1476e-18, 1.1476e-18, 1.1476e-18, 1.1476e-18],\n",
       "          [9.0386e-01, 1.8771e-02, 1.8590e-02, 1.8958e-02, 1.8693e-02, 2.1125e-02],\n",
       "          [9.3025e-01, 1.3738e-02, 1.3572e-02, 1.3753e-02, 1.3628e-02, 1.5061e-02],\n",
       "          [9.8472e-01, 3.0127e-03, 3.0046e-03, 3.0401e-03, 3.0156e-03, 3.2039e-03],\n",
       "          [9.7731e-01, 4.4599e-03, 4.4480e-03, 4.4885e-03, 4.4994e-03, 4.7970e-03],\n",
       "          [9.8558e-01, 2.8387e-03, 2.8004e-03, 2.8681e-03, 2.8228e-03, 3.0921e-03],\n",
       "          [9.5322e-01, 9.1898e-03, 9.0312e-03, 9.3421e-03, 9.1728e-03, 1.0043e-02],\n",
       "          [1.0000e+00, 1.4151e-18, 1.4151e-18, 1.4151e-18, 1.4151e-18, 1.4151e-18],\n",
       "          [1.0000e+00, 1.9093e-18, 1.9093e-18, 1.9093e-18, 1.9093e-18, 1.9093e-18],\n",
       "          [9.5438e-01, 8.9818e-03, 8.9264e-03, 9.0130e-03, 8.9823e-03, 9.7152e-03],\n",
       "          [9.2746e-01, 1.4257e-02, 1.4061e-02, 1.4232e-02, 1.4067e-02, 1.5924e-02],\n",
       "          [9.4043e-01, 1.1562e-02, 1.1570e-02, 1.1865e-02, 1.1668e-02, 1.2907e-02],\n",
       "          [1.0000e+00, 1.1661e-18, 1.1661e-18, 1.1661e-18, 1.1661e-18, 1.1661e-18],\n",
       "          [9.7936e-01, 4.0527e-03, 4.0365e-03, 4.0748e-03, 4.0586e-03, 4.4154e-03],\n",
       "          [9.6055e-01, 7.7585e-03, 7.7294e-03, 7.7733e-03, 7.7719e-03, 8.4159e-03],\n",
       "          [9.4827e-01, 1.0166e-02, 1.0068e-02, 1.0343e-02, 1.0169e-02, 1.0982e-02],\n",
       "          [9.7991e-01, 3.9539e-03, 3.9514e-03, 3.9866e-03, 3.9707e-03, 4.2258e-03],\n",
       "          [9.3516e-01, 1.2694e-02, 1.2638e-02, 1.2775e-02, 1.2697e-02, 1.4034e-02],\n",
       "          [1.0000e+00, 6.8563e-27, 6.8563e-27, 6.8563e-27, 6.8563e-27, 6.8563e-27],\n",
       "          [9.1742e-01, 1.6081e-02, 1.5918e-02, 1.6398e-02, 1.6099e-02, 1.8088e-02],\n",
       "          [9.6219e-01, 7.4371e-03, 7.4116e-03, 7.4490e-03, 7.4493e-03, 8.0600e-03],\n",
       "          [9.3650e-01, 1.2418e-02, 1.2313e-02, 1.2645e-02, 1.2405e-02, 1.3722e-02],\n",
       "          [9.4665e-01, 1.0458e-02, 1.0420e-02, 1.0529e-02, 1.0434e-02, 1.1506e-02],\n",
       "          [9.9850e-01, 2.9718e-04, 2.9672e-04, 2.9766e-04, 2.9722e-04, 3.0777e-04],\n",
       "          [9.8518e-01, 2.9101e-03, 2.8945e-03, 2.9548e-03, 2.9167e-03, 3.1481e-03],\n",
       "          [9.1235e-01, 1.7012e-02, 1.7136e-02, 1.7110e-02, 1.7379e-02, 1.9009e-02],\n",
       "          [1.0000e+00, 5.6509e-19, 5.6509e-19, 5.6509e-19, 5.6509e-19, 5.6509e-19],\n",
       "          [9.1616e-01, 1.6353e-02, 1.6234e-02, 1.6482e-02, 1.6303e-02, 1.8468e-02],\n",
       "          [9.7687e-01, 4.5443e-03, 4.5234e-03, 4.5828e-03, 4.5700e-03, 4.9088e-03],\n",
       "          [1.0000e+00, 1.0603e-18, 1.0603e-18, 1.0603e-18, 1.0603e-18, 1.0603e-18],\n",
       "          [9.4573e-01, 1.0624e-02, 1.0620e-02, 1.0690e-02, 1.0720e-02, 1.1621e-02],\n",
       "          [1.0000e+00, 9.9960e-19, 9.9960e-19, 9.9960e-19, 9.9960e-19, 9.9960e-19],\n",
       "          [9.7918e-01, 4.1074e-03, 4.0636e-03, 4.1148e-03, 4.0824e-03, 4.4509e-03],\n",
       "          [9.1477e-01, 1.6692e-02, 1.6554e-02, 1.6764e-02, 1.6726e-02, 1.8494e-02],\n",
       "          [1.0000e+00, 1.0207e-18, 1.0207e-18, 1.0207e-18, 1.0207e-18, 1.0207e-18],\n",
       "          [9.3660e-01, 1.2424e-02, 1.2394e-02, 1.2546e-02, 1.2498e-02, 1.3534e-02],\n",
       "          [9.3467e-01, 1.2770e-02, 1.2633e-02, 1.2784e-02, 1.2719e-02, 1.4426e-02],\n",
       "          [9.7320e-01, 5.2811e-03, 5.2583e-03, 5.3008e-03, 5.3076e-03, 5.6540e-03],\n",
       "          [8.9742e-01, 2.0171e-02, 1.9953e-02, 2.0161e-02, 2.0167e-02, 2.2131e-02],\n",
       "          [9.5118e-01, 9.5220e-03, 9.4133e-03, 9.6529e-03, 9.4893e-03, 1.0740e-02],\n",
       "          [9.1732e-01, 1.6193e-02, 1.6066e-02, 1.6229e-02, 1.6102e-02, 1.8089e-02],\n",
       "          [9.1592e-01, 1.6472e-02, 1.6322e-02, 1.6590e-02, 1.6352e-02, 1.8348e-02],\n",
       "          [9.3318e-01, 1.3031e-02, 1.2807e-02, 1.3243e-02, 1.2865e-02, 1.4874e-02],\n",
       "          [1.0000e+00, 9.7904e-19, 9.7904e-19, 9.7904e-19, 9.7904e-19, 9.7904e-19],\n",
       "          [9.0673e-01, 1.8203e-02, 1.7992e-02, 1.8742e-02, 1.8212e-02, 2.0118e-02],\n",
       "          [9.3400e-01, 1.2893e-02, 1.2825e-02, 1.2990e-02, 1.2915e-02, 1.4379e-02],\n",
       "          [9.0450e-01, 1.8704e-02, 1.8449e-02, 1.8975e-02, 1.8546e-02, 2.0826e-02],\n",
       "          [1.0000e+00, 1.3513e-18, 1.3513e-18, 1.3513e-18, 1.3513e-18, 1.3513e-18],\n",
       "          [9.4382e-01, 1.0983e-02, 1.0889e-02, 1.1161e-02, 1.1054e-02, 1.2096e-02],\n",
       "          [9.3619e-01, 1.2510e-02, 1.2469e-02, 1.2495e-02, 1.2515e-02, 1.3821e-02],\n",
       "          [9.1951e-01, 1.5663e-02, 1.5492e-02, 1.5820e-02, 1.5591e-02, 1.7920e-02],\n",
       "          [1.0000e+00, 8.6275e-19, 8.6275e-19, 8.6275e-19, 8.6275e-19, 8.6275e-19],\n",
       "          [9.0209e-01, 1.9135e-02, 1.8902e-02, 1.9377e-02, 1.8985e-02, 2.1512e-02],\n",
       "          [9.1490e-01, 1.6647e-02, 1.6433e-02, 1.6869e-02, 1.6595e-02, 1.8559e-02],\n",
       "          [9.1933e-01, 1.5767e-02, 1.5694e-02, 1.5859e-02, 1.5710e-02, 1.7640e-02],\n",
       "          [9.8375e-01, 3.2146e-03, 3.1941e-03, 3.2216e-03, 3.2031e-03, 3.4158e-03],\n",
       "          [9.8175e-01, 3.5948e-03, 3.5718e-03, 3.6230e-03, 3.5828e-03, 3.8812e-03],\n",
       "          [9.8465e-01, 3.0278e-03, 3.0243e-03, 3.0438e-03, 3.0334e-03, 3.2176e-03],\n",
       "          [9.1128e-01, 1.7277e-02, 1.7148e-02, 1.7483e-02, 1.7241e-02, 1.9570e-02],\n",
       "          [9.6159e-01, 7.5292e-03, 7.4890e-03, 7.6087e-03, 7.5600e-03, 8.2279e-03],\n",
       "          [9.4554e-01, 1.0692e-02, 1.0639e-02, 1.0747e-02, 1.0724e-02, 1.1660e-02],\n",
       "          [1.0000e+00, 1.3793e-18, 1.3793e-18, 1.3793e-18, 1.3793e-18, 1.3793e-18],\n",
       "          [9.2838e-01, 1.4028e-02, 1.3901e-02, 1.4111e-02, 1.4056e-02, 1.5524e-02],\n",
       "          [9.1071e-01, 1.7494e-02, 1.7306e-02, 1.7660e-02, 1.7297e-02, 1.9528e-02],\n",
       "          [9.2880e-01, 1.4011e-02, 1.3878e-02, 1.4084e-02, 1.3970e-02, 1.5252e-02],\n",
       "          [1.0000e+00, 1.2290e-18, 1.2290e-18, 1.2290e-18, 1.2290e-18, 1.2290e-18],\n",
       "          [1.0000e+00, 1.0944e-18, 1.0944e-18, 1.0944e-18, 1.0944e-18, 1.0944e-18],\n",
       "          [1.0000e+00, 1.4072e-18, 1.4072e-18, 1.4072e-18, 1.4072e-18, 1.4072e-18],\n",
       "          [1.0000e+00, 1.0243e-18, 1.0243e-18, 1.0243e-18, 1.0243e-18, 1.0243e-18],\n",
       "          [1.0000e+00, 1.1982e-18, 1.1982e-18, 1.1982e-18, 1.1982e-18, 1.1982e-18],\n",
       "          [1.0000e+00, 1.5668e-18, 1.5668e-18, 1.5668e-18, 1.5668e-18, 1.5668e-18],\n",
       "          [9.9800e-01, 3.9764e-04, 3.9727e-04, 3.9824e-04, 3.9767e-04, 4.0754e-04],\n",
       "          [1.0000e+00, 9.7689e-19, 9.7689e-19, 9.7689e-19, 9.7689e-19, 9.7689e-19],\n",
       "          [9.5855e-01, 8.1412e-03, 8.0276e-03, 8.2434e-03, 8.1271e-03, 8.9068e-03],\n",
       "          [9.3045e-01, 1.3540e-02, 1.3463e-02, 1.3650e-02, 1.3527e-02, 1.5369e-02],\n",
       "          [1.0000e+00, 1.2750e-18, 1.2750e-18, 1.2750e-18, 1.2750e-18, 1.2750e-18]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  'cc': tensor([[0.1039, 0.7794, 0.0623, 0.0544],\n",
       "          [0.0088, 0.9822, 0.0046, 0.0044],\n",
       "          [0.0559, 0.8749, 0.0367, 0.0325],\n",
       "          [0.1239, 0.7159, 0.0870, 0.0732],\n",
       "          [0.1244, 0.7126, 0.0884, 0.0746],\n",
       "          [0.1523, 0.6722, 0.0955, 0.0799],\n",
       "          [0.0685, 0.8436, 0.0471, 0.0408],\n",
       "          [0.1334, 0.7176, 0.0807, 0.0683],\n",
       "          [0.1534, 0.6606, 0.1012, 0.0848],\n",
       "          [0.1395, 0.6946, 0.0904, 0.0755],\n",
       "          [0.1556, 0.6542, 0.1032, 0.0869],\n",
       "          [0.0734, 0.8490, 0.0412, 0.0363],\n",
       "          [0.1738, 0.6061, 0.1185, 0.1015],\n",
       "          [0.1471, 0.6874, 0.0905, 0.0750],\n",
       "          [0.1145, 0.7321, 0.0821, 0.0712],\n",
       "          [0.1275, 0.7108, 0.0878, 0.0738],\n",
       "          [0.0139, 0.9681, 0.0093, 0.0087],\n",
       "          [0.1639, 0.6274, 0.1112, 0.0975],\n",
       "          [0.1719, 0.6207, 0.1130, 0.0944],\n",
       "          [0.0990, 0.7734, 0.0687, 0.0589],\n",
       "          [0.1170, 0.7359, 0.0783, 0.0688],\n",
       "          [0.1559, 0.6565, 0.1011, 0.0865],\n",
       "          [0.1282, 0.7029, 0.0911, 0.0778],\n",
       "          [0.0631, 0.8598, 0.0409, 0.0362],\n",
       "          [0.0106, 0.9778, 0.0059, 0.0057],\n",
       "          [0.1332, 0.7102, 0.0849, 0.0717],\n",
       "          [0.0095, 0.9804, 0.0052, 0.0050],\n",
       "          [0.0666, 0.8588, 0.0394, 0.0352],\n",
       "          [0.1508, 0.6795, 0.0916, 0.0780],\n",
       "          [0.1579, 0.6620, 0.0982, 0.0819],\n",
       "          [0.1657, 0.6395, 0.1057, 0.0891],\n",
       "          [0.1342, 0.6861, 0.0978, 0.0819],\n",
       "          [0.1721, 0.6185, 0.1138, 0.0956],\n",
       "          [0.1519, 0.6538, 0.1052, 0.0891],\n",
       "          [0.1389, 0.7080, 0.0828, 0.0703],\n",
       "          [0.0900, 0.7998, 0.0585, 0.0517],\n",
       "          [0.1456, 0.6590, 0.1060, 0.0894],\n",
       "          [0.1452, 0.6832, 0.0916, 0.0800],\n",
       "          [0.1125, 0.7460, 0.0767, 0.0648],\n",
       "          [0.1531, 0.6736, 0.0946, 0.0787],\n",
       "          [0.1275, 0.7081, 0.0883, 0.0761],\n",
       "          [0.0174, 0.9646, 0.0093, 0.0087],\n",
       "          [0.1045, 0.7616, 0.0712, 0.0627],\n",
       "          [0.0689, 0.8518, 0.0421, 0.0373],\n",
       "          [0.1652, 0.6441, 0.1036, 0.0872],\n",
       "          [0.0653, 0.8631, 0.0381, 0.0335],\n",
       "          [0.0876, 0.8017, 0.0592, 0.0515],\n",
       "          [0.1065, 0.7656, 0.0688, 0.0592],\n",
       "          [0.1391, 0.6921, 0.0912, 0.0776],\n",
       "          [0.1512, 0.6536, 0.1057, 0.0895],\n",
       "          [0.0614, 0.8631, 0.0396, 0.0359],\n",
       "          [0.1377, 0.6798, 0.0986, 0.0838],\n",
       "          [0.1418, 0.6854, 0.0921, 0.0808],\n",
       "          [0.1731, 0.6081, 0.1183, 0.1006],\n",
       "          [0.1578, 0.6618, 0.0984, 0.0821],\n",
       "          [0.1409, 0.6837, 0.0940, 0.0814],\n",
       "          [0.1185, 0.7272, 0.0828, 0.0715],\n",
       "          [0.1412, 0.6845, 0.0949, 0.0795],\n",
       "          [0.0102, 0.9783, 0.0059, 0.0056],\n",
       "          [0.1651, 0.6308, 0.1092, 0.0949],\n",
       "          [0.1642, 0.6443, 0.1039, 0.0876],\n",
       "          [0.1308, 0.7045, 0.0887, 0.0760],\n",
       "          [0.1501, 0.6582, 0.1042, 0.0876],\n",
       "          [0.1658, 0.6393, 0.1062, 0.0888],\n",
       "          [0.0108, 0.9766, 0.0064, 0.0061],\n",
       "          [0.1633, 0.6517, 0.1008, 0.0841],\n",
       "          [0.1623, 0.6380, 0.1078, 0.0918],\n",
       "          [0.1499, 0.6445, 0.1112, 0.0944],\n",
       "          [0.1528, 0.6619, 0.1001, 0.0852],\n",
       "          [0.1546, 0.6463, 0.1082, 0.0909],\n",
       "          [0.1382, 0.6855, 0.0951, 0.0812],\n",
       "          [0.1273, 0.7040, 0.0909, 0.0778],\n",
       "          [0.1686, 0.6261, 0.1114, 0.0939],\n",
       "          [0.1281, 0.7226, 0.0805, 0.0688],\n",
       "          [0.1045, 0.7662, 0.0689, 0.0604],\n",
       "          [0.1237, 0.7270, 0.0797, 0.0695],\n",
       "          [0.0662, 0.8530, 0.0428, 0.0380],\n",
       "          [0.1414, 0.6755, 0.0983, 0.0847],\n",
       "          [0.0895, 0.8027, 0.0571, 0.0507],\n",
       "          [0.1059, 0.7685, 0.0674, 0.0582],\n",
       "          [0.1498, 0.6788, 0.0926, 0.0788],\n",
       "          [0.1384, 0.6868, 0.0954, 0.0794],\n",
       "          [0.1400, 0.6845, 0.0941, 0.0814],\n",
       "          [0.0958, 0.7812, 0.0663, 0.0567],\n",
       "          [0.0741, 0.8451, 0.0428, 0.0380],\n",
       "          [0.1427, 0.6951, 0.0881, 0.0741],\n",
       "          [0.1492, 0.6543, 0.1049, 0.0916],\n",
       "          [0.1079, 0.7635, 0.0688, 0.0598],\n",
       "          [0.1611, 0.6561, 0.0996, 0.0833],\n",
       "          [0.0897, 0.8015, 0.0581, 0.0507],\n",
       "          [0.1516, 0.6710, 0.0958, 0.0816],\n",
       "          [0.1430, 0.6950, 0.0881, 0.0739],\n",
       "          [0.1439, 0.6509, 0.1096, 0.0956],\n",
       "          [0.1637, 0.6482, 0.1025, 0.0856],\n",
       "          [0.0437, 0.9109, 0.0236, 0.0219],\n",
       "          [0.0904, 0.7922, 0.0628, 0.0545],\n",
       "          [0.1526, 0.6563, 0.1035, 0.0876],\n",
       "          [0.0308, 0.9296, 0.0205, 0.0190],\n",
       "          [0.1728, 0.6174, 0.1141, 0.0956],\n",
       "          [0.0845, 0.8088, 0.0568, 0.0498],\n",
       "          [0.1108, 0.7528, 0.0730, 0.0633],\n",
       "          [0.1660, 0.6355, 0.1063, 0.0922],\n",
       "          [0.1342, 0.6866, 0.0975, 0.0816],\n",
       "          [0.0451, 0.9001, 0.0288, 0.0260],\n",
       "          [0.1459, 0.6850, 0.0919, 0.0772],\n",
       "          [0.1300, 0.7050, 0.0898, 0.0752],\n",
       "          [0.1649, 0.6307, 0.1094, 0.0951],\n",
       "          [0.1449, 0.6872, 0.0912, 0.0767],\n",
       "          [0.1448, 0.6969, 0.0856, 0.0727],\n",
       "          [0.1229, 0.7343, 0.0770, 0.0659],\n",
       "          [0.1365, 0.6993, 0.0882, 0.0760],\n",
       "          [0.1604, 0.6504, 0.1020, 0.0872],\n",
       "          [0.1751, 0.6178, 0.1117, 0.0954],\n",
       "          [0.1207, 0.7381, 0.0762, 0.0649],\n",
       "          [0.1365, 0.6897, 0.0936, 0.0803],\n",
       "          [0.1373, 0.6948, 0.0908, 0.0772],\n",
       "          [0.1737, 0.6206, 0.1126, 0.0931],\n",
       "          [0.1676, 0.6205, 0.1141, 0.0978],\n",
       "          [0.0935, 0.7848, 0.0654, 0.0564],\n",
       "          [0.1448, 0.6733, 0.0981, 0.0837],\n",
       "          [0.1200, 0.7197, 0.0868, 0.0735],\n",
       "          [0.1521, 0.6450, 0.1083, 0.0946],\n",
       "          [0.1319, 0.6991, 0.0918, 0.0773],\n",
       "          [0.1687, 0.6171, 0.1151, 0.0991],\n",
       "          [0.1501, 0.6522, 0.1067, 0.0909],\n",
       "          [0.1643, 0.6441, 0.1040, 0.0876],\n",
       "          [0.1160, 0.7269, 0.0849, 0.0722],\n",
       "          [0.0939, 0.8098, 0.0517, 0.0446],\n",
       "          [0.0775, 0.8243, 0.0525, 0.0456],\n",
       "          [0.1584, 0.6452, 0.1070, 0.0895],\n",
       "          [0.1312, 0.7133, 0.0830, 0.0725],\n",
       "          [0.1583, 0.6613, 0.0984, 0.0820],\n",
       "          [0.1160, 0.7332, 0.0811, 0.0697],\n",
       "          [0.1512, 0.6607, 0.1012, 0.0869],\n",
       "          [0.1654, 0.6184, 0.1186, 0.0976],\n",
       "          [0.1452, 0.6712, 0.0990, 0.0846],\n",
       "          [0.1363, 0.6821, 0.0974, 0.0843],\n",
       "          [0.1245, 0.7131, 0.0877, 0.0748],\n",
       "          [0.1284, 0.7050, 0.0900, 0.0766],\n",
       "          [0.1215, 0.7228, 0.0845, 0.0713],\n",
       "          [0.1270, 0.7067, 0.0900, 0.0762],\n",
       "          [0.1322, 0.6974, 0.0925, 0.0779],\n",
       "          [0.0040, 0.9911, 0.0025, 0.0024],\n",
       "          [0.0675, 0.8550, 0.0414, 0.0360],\n",
       "          [0.1495, 0.6633, 0.1004, 0.0869],\n",
       "          [0.1589, 0.6365, 0.1101, 0.0945],\n",
       "          [0.1148, 0.7389, 0.0783, 0.0681]], grad_fn=<CopySlices>),\n",
       "  'dlt1': tensor([[2.6884e-12, 3.0606e-12, 2.2386e-12, 1.4847e-07, 1.1598e-09],\n",
       "          [7.6894e-02, 1.7989e-02, 7.5580e-02, 1.5388e-01, 4.7084e-02],\n",
       "          [8.3443e-02, 7.7187e-02, 6.6682e-02, 1.3936e-01, 1.6940e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.1683e-02, 9.2118e-02, 1.3079e-01, 1.4200e-01, 2.4553e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.5081e-02, 9.5774e-02, 1.1880e-01, 9.6851e-02, 1.7882e-01],\n",
       "          [9.4512e-02, 8.4728e-02, 1.6996e-01, 1.4912e-01, 3.8647e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0688e-01, 1.7186e-01, 1.0705e-01, 1.0964e-01, 1.3774e-01],\n",
       "          [7.0793e-02, 2.1543e-01, 9.1918e-02, 1.1770e-01, 1.1627e-01],\n",
       "          [9.6373e-02, 2.1139e-01, 1.1579e-01, 2.0292e-01, 1.8180e-01],\n",
       "          [6.0521e-02, 7.4300e-02, 1.3433e-01, 1.0341e-01, 2.4227e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.3061e-02, 8.6676e-02, 1.7011e-01, 1.4451e-01, 2.2200e-01],\n",
       "          [9.6749e-02, 1.6937e-01, 1.2436e-01, 1.4043e-01, 1.9386e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.9731e-02, 1.2301e-01, 1.5815e-01, 1.3859e-01, 1.6295e-01],\n",
       "          [1.0247e-01, 2.1247e-01, 1.5120e-01, 2.1809e-01, 2.6059e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8497e-02, 1.1651e-01, 4.4267e-02, 1.7456e-01, 5.7287e-02],\n",
       "          [1.5571e-14, 6.0451e-15, 1.6746e-12, 4.6538e-10, 2.5680e-10],\n",
       "          [9.2214e-02, 1.9766e-01, 1.0474e-01, 2.1778e-01, 1.4148e-01],\n",
       "          [3.6815e-14, 1.2705e-14, 1.7599e-12, 8.2569e-10, 2.0252e-10],\n",
       "          [1.1597e-01, 7.2060e-02, 6.8561e-02, 2.8687e-01, 1.1909e-01],\n",
       "          [1.0718e-01, 1.9356e-01, 1.3136e-01, 2.0220e-01, 1.8063e-01],\n",
       "          [6.0461e-02, 8.5349e-02, 1.3210e-01, 1.2648e-01, 2.6126e-01],\n",
       "          [8.1648e-02, 9.8526e-02, 1.6766e-01, 1.2786e-01, 2.7226e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0804e-01, 2.0626e-01, 1.3401e-01, 1.6383e-01, 1.8310e-01],\n",
       "          [1.0028e-01, 1.6307e-01, 1.3577e-01, 8.4406e-02, 1.4210e-01],\n",
       "          [9.7990e-02, 9.0395e-02, 1.3610e-01, 1.2410e-01, 2.4831e-01],\n",
       "          [1.6375e-12, 2.5959e-12, 1.4036e-12, 1.0990e-07, 9.4170e-10],\n",
       "          [1.1882e-01, 1.0596e-01, 1.1417e-01, 1.5598e-01, 1.1068e-01],\n",
       "          [1.9692e-01, 1.9107e-01, 1.2433e-01, 2.0968e-01, 1.8474e-01],\n",
       "          [1.6562e-01, 1.2161e-01, 9.3723e-02, 1.4737e-01, 6.2729e-02],\n",
       "          [5.6039e-02, 7.4921e-02, 1.3059e-01, 1.1753e-01, 2.8399e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.3090e-02, 3.8654e-02, 6.6469e-02, 1.1339e-01, 2.9970e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1300e-01, 1.1848e-01, 7.4500e-02, 1.6078e-01, 1.5681e-01],\n",
       "          [7.0493e-02, 1.0596e-01, 1.4369e-01, 1.4785e-01, 2.5119e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3535e-01, 1.5569e-01, 1.5176e-01, 2.2886e-01, 1.3107e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.5959e-02, 1.5459e-01, 1.0578e-01, 1.5305e-01, 1.7744e-01],\n",
       "          [6.0819e-02, 5.5694e-02, 1.2873e-01, 1.8502e-01, 1.3614e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3617e-01, 1.7083e-01, 1.3838e-01, 2.4756e-01, 3.1787e-01],\n",
       "          [9.9275e-02, 1.9569e-01, 1.3247e-01, 1.9197e-01, 2.0601e-01],\n",
       "          [6.1271e-02, 8.7830e-02, 1.3216e-01, 1.2976e-01, 2.5606e-01],\n",
       "          [8.3003e-02, 1.4578e-01, 6.8033e-02, 1.6485e-01, 1.0933e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4101e-02, 7.1365e-03, 8.6349e-02, 6.9842e-02, 6.3235e-02],\n",
       "          [7.1994e-02, 6.5318e-02, 1.9581e-01, 1.2942e-01, 3.2499e-01],\n",
       "          [1.0704e-01, 1.8156e-01, 1.3546e-01, 1.7255e-01, 2.0633e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.4658e-02, 1.3107e-01, 6.6683e-02, 1.8404e-01, 1.5610e-01],\n",
       "          [6.8217e-02, 2.5975e-01, 1.1880e-01, 1.2652e-01, 1.7245e-01],\n",
       "          [2.4843e-14, 8.0800e-15, 1.2002e-12, 4.6819e-10, 8.7028e-11],\n",
       "          [7.7690e-02, 1.0776e-01, 1.4790e-01, 1.2696e-01, 2.2701e-01],\n",
       "          [9.5819e-02, 2.3368e-01, 1.1045e-01, 2.7611e-01, 1.8833e-01],\n",
       "          [9.3000e-02, 1.0043e-01, 9.8457e-02, 1.1306e-01, 1.0854e-01],\n",
       "          [1.2622e-01, 1.1351e-01, 1.7801e-01, 1.7742e-01, 2.2822e-01],\n",
       "          [1.1958e-01, 1.3366e-01, 9.7287e-02, 2.3539e-01, 2.2120e-01],\n",
       "          [1.0731e-01, 1.3601e-01, 6.3563e-02, 1.2828e-01, 8.3271e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1178e-01, 2.2381e-01, 1.3581e-01, 1.7685e-01, 1.7246e-01],\n",
       "          [1.0870e-01, 2.1643e-01, 1.2935e-01, 1.4620e-01, 1.8093e-01],\n",
       "          [8.7021e-02, 6.4046e-02, 7.2436e-02, 8.8446e-02, 1.0223e-01],\n",
       "          [4.5843e-02, 7.1505e-02, 8.8346e-02, 7.8541e-02, 1.2813e-01],\n",
       "          [4.1120e-02, 1.4587e-01, 4.7483e-02, 1.2907e-01, 9.3721e-02],\n",
       "          [9.1308e-02, 1.5842e-01, 6.6196e-02, 2.0614e-01, 9.0282e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.6330e-02, 9.7894e-02, 1.1502e-01, 1.0026e-01, 1.9050e-01],\n",
       "          [1.3940e-01, 1.2130e-01, 1.2073e-01, 1.7350e-01, 2.0659e-01],\n",
       "          [1.2866e-01, 1.2975e-01, 1.0294e-01, 2.0459e-01, 1.1371e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.5019e-01, 1.0319e-01, 9.0264e-02, 9.2875e-02, 2.1468e-01],\n",
       "          [7.1734e-02, 9.7608e-02, 1.1790e-01, 8.8710e-02, 1.8092e-01],\n",
       "          [8.7413e-02, 9.8634e-02, 1.6444e-01, 1.4953e-01, 1.9748e-01],\n",
       "          [8.6586e-02, 8.0861e-02, 1.2531e-01, 1.0988e-01, 1.0027e-01],\n",
       "          [8.0482e-02, 1.1463e-01, 1.5089e-01, 1.3578e-01, 2.1100e-01],\n",
       "          [2.2331e-12, 2.2478e-12, 1.6036e-12, 9.1754e-08, 9.3318e-10],\n",
       "          [8.6742e-02, 2.5862e-01, 9.7456e-02, 2.6510e-01, 2.3419e-01],\n",
       "          [7.0426e-02, 9.3858e-02, 1.1660e-01, 8.5443e-02, 1.8611e-01],\n",
       "          [8.3446e-02, 1.0656e-01, 1.1957e-01, 1.4540e-01, 1.5410e-01],\n",
       "          [6.4199e-02, 8.8444e-02, 1.4192e-01, 1.2248e-01, 2.8412e-01],\n",
       "          [1.7886e-02, 2.7561e-02, 3.1596e-02, 3.9416e-02, 5.5183e-02],\n",
       "          [8.3540e-02, 9.8732e-02, 5.0275e-02, 1.8818e-01, 5.9962e-02],\n",
       "          [1.4320e-01, 1.1199e-01, 1.4818e-01, 1.5905e-01, 1.3987e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0338e-01, 1.8861e-01, 1.3009e-01, 1.5265e-01, 1.8874e-01],\n",
       "          [6.8216e-02, 6.3676e-02, 7.9062e-02, 9.8671e-02, 1.0215e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.9894e-02, 7.2484e-02, 1.9275e-01, 1.1090e-01, 2.4107e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.9372e-02, 9.1960e-02, 4.7893e-02, 1.4479e-01, 6.9812e-02],\n",
       "          [9.7169e-02, 1.7173e-01, 1.3420e-01, 1.8634e-01, 1.7339e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.4600e-02, 7.2617e-02, 1.9506e-01, 1.4537e-01, 3.1536e-01],\n",
       "          [1.1108e-01, 1.2224e-01, 1.3010e-01, 1.7220e-01, 2.8102e-01],\n",
       "          [4.7120e-02, 1.6560e-01, 9.7848e-02, 7.2999e-02, 1.4713e-01],\n",
       "          [1.1708e-01, 2.3123e-01, 1.5323e-01, 2.0539e-01, 1.9426e-01],\n",
       "          [1.3733e-01, 1.4739e-01, 7.6860e-02, 1.6316e-01, 1.0123e-01],\n",
       "          [1.1813e-01, 1.9672e-01, 1.4090e-01, 1.7903e-01, 1.5299e-01],\n",
       "          [9.2350e-02, 1.9650e-01, 1.2207e-01, 2.1641e-01, 2.0800e-01],\n",
       "          [1.4274e-01, 2.1831e-01, 1.2957e-01, 2.3716e-01, 2.2516e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.0239e-02, 2.5372e-01, 1.0444e-01, 2.7380e-01, 2.1268e-01],\n",
       "          [7.5559e-02, 1.1636e-01, 1.4915e-01, 1.1444e-01, 2.1475e-01],\n",
       "          [9.8235e-02, 2.2198e-01, 1.1278e-01, 2.1665e-01, 1.6551e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.3433e-01, 1.5647e-01, 8.3217e-02, 1.9579e-01, 8.4313e-02],\n",
       "          [1.9687e-01, 8.9678e-02, 1.3886e-01, 1.2564e-01, 1.6371e-01],\n",
       "          [1.4211e-01, 1.0807e-01, 1.6627e-01, 1.7880e-01, 2.6424e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.0346e-01, 2.0784e-01, 1.2815e-01, 1.9612e-01, 1.6213e-01],\n",
       "          [1.2743e-01, 1.4640e-01, 9.2786e-02, 2.3478e-01, 1.4200e-01],\n",
       "          [1.0622e-01, 1.7924e-01, 1.3483e-01, 1.7034e-01, 2.0761e-01],\n",
       "          [5.4719e-02, 7.8391e-02, 8.4807e-02, 8.3905e-02, 7.4138e-02],\n",
       "          [3.5537e-02, 5.8520e-02, 1.0401e-01, 8.0697e-02, 1.9281e-01],\n",
       "          [1.0252e-01, 5.3470e-02, 6.5411e-02, 1.2169e-01, 8.3757e-02],\n",
       "          [1.2016e-01, 2.0434e-01, 1.4741e-01, 2.0025e-01, 1.6547e-01],\n",
       "          [5.4687e-02, 6.5350e-02, 1.3843e-01, 8.4311e-02, 1.9335e-01],\n",
       "          [6.0422e-02, 8.5146e-02, 1.3201e-01, 1.2558e-01, 2.6036e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.1245e-01, 1.2247e-01, 8.1431e-02, 1.7204e-01, 1.4623e-01],\n",
       "          [8.8443e-02, 1.7377e-01, 1.0987e-01, 1.8970e-01, 1.5914e-01],\n",
       "          [9.8421e-02, 1.5603e-01, 1.7530e-01, 1.4761e-01, 1.9522e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.4129e-02, 1.9304e-02, 2.9868e-02, 3.6084e-02, 3.9578e-02],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.7957e-02, 1.9537e-01, 7.7148e-02, 1.3207e-01, 9.9043e-02],\n",
       "          [1.1036e-01, 8.8843e-02, 1.9386e-01, 1.6794e-01, 3.0773e-01],\n",
       "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "         grad_fn=<CopySlices>),\n",
       "  'dlt2': tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0008, 0.0006, 0.0004, 0.0011, 0.0003],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<CopySlices>)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def temporal_loss(timestoevents,weights=None,maxtime=48,threshold=True):\n",
    "    #list of expected times to events, usualy in order of Const.temporal_outcomes\n",
    "    #basically longer = better, we count > maxtime (weeks) as no event\n",
    "    if weights is None: \n",
    "        weights = [1 for i in range(len(timestoevents))]\n",
    "    scores =  [(w*maxtime/t)for w,t in zip(weights,timestoevents)]\n",
    "    if threshold:\n",
    "        scores = [s*torch.lt(t,maxtime) for s,t in zip(scores,timestoevents)]\n",
    "    scores = torch.stack(scores).sum(axis=0)\n",
    "    return scores\n",
    "\n",
    "def outcome_loss(ypred,weights=None):\n",
    "    #default weights is bad\n",
    "    if weights is None: \n",
    "        print('using default outcome loss weights, which is probably wrong since bad stuff should be negative')\n",
    "        weights = [1 for i in range(ypred.shape[1])]\n",
    "    l = torch.mul(ypred[:,0],weights[0])\n",
    "    for i,weight in enumerate(weights[1:]):\n",
    "        #weights with negative values will invert the outcome so e.g. Regional control becomes no regional control\n",
    "        #so the penaly is correct\n",
    "        newloss = torch.mul(ypred[:,i+1],weight)\n",
    "        l = torch.add(l,newloss)\n",
    "    return l\n",
    "\n",
    "def calc_optimal_decisions(dataset,ids,m1,m2,m3,sm3,\n",
    "                           weights=[0,0.5,.5,0], #weight for OS, FT, AS, and LRC as binary probabilities\n",
    "                           tweights=[1,1,1,1], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "                           outcome_loss_func=None,\n",
    "                           threshold_temporal_loss = False,\n",
    "                           maxtime=48,\n",
    "                           get_transitions=True):\n",
    "    m1.eval()\n",
    "    m2.eval()\n",
    "    m3.eval()\n",
    "    sm3.eval()\n",
    "    device = m1.get_device()\n",
    "    data = dataset.processed_df.copy().loc[ids]\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        #this should have an ic condition but we don't use it anumore anywa\n",
    "        return res\n",
    "        \n",
    "    def formatdf(d):\n",
    "        d = df_to_torch(d).to(device)\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline').loc[ids]\n",
    "    baseline_input = formatdf(baseline)\n",
    "\n",
    "        \n",
    "    if outcome_loss_func is None:\n",
    "        outcome_loss_func = outcome_loss\n",
    "    \n",
    "    cat = lambda x: torch.cat([xx.to(device) for xx in x],axis=1).to(device)\n",
    "    format_transition = lambda x: x.to(device)\n",
    "    def get_outcome(d1,d2,d3):\n",
    "        d1 = torch.full((len(ids),1),d1).type(torch.FloatTensor)\n",
    "        d2 = torch.full((len(ids),1),d2).type(torch.FloatTensor)\n",
    "        d3 = torch.full((len(ids),1),d3).type(torch.FloatTensor)\n",
    "        \n",
    "        tinput1 = cat([baseline_input,d1])\n",
    "        ytransition = m1(tinput1)\n",
    "        [ypd1,ynd1,ymod,ydlt1] = [format_transition(xx) for xx in ytransition['predictions']]\n",
    "        d1_thresh = torch.gt(d1,.5).view(-1,1).to(device)\n",
    "        ypd1[:,0:2] = ypd1[:,0:2]*d1_thresh\n",
    "        ynd1[:,0:2] = ynd1[:,0:2]*d1_thresh\n",
    "        \n",
    "        tinput2 = cat([baseline_input,ypd1,ynd1,ymod,ydlt1,d1,d2])\n",
    "        ytransition2 = m2(tinput2)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = [format_transition(xx) for xx in ytransition2['predictions']]\n",
    "        \n",
    "        input3 = cat([baseline_input, ypd2, ynd2, ycc, ydlt2, d1, d2,d3])\n",
    "        outcome = m3(input3)['predictions']\n",
    "        temporal_outcomes = sm3.time_to_event(input3,n_samples=1)\n",
    "        \n",
    "        transitions = {\n",
    "            'pd1': ypd1,\n",
    "            'nd1': ynd1,\n",
    "            'nd2': ynd2,\n",
    "            'pd2': ypd2,\n",
    "            'mod': ymod,\n",
    "            'cc': ycc,\n",
    "            'dlt1': ydlt1,\n",
    "            'dlt2': ydlt2,\n",
    "        }\n",
    "        return outcome, temporal_outcomes, transitions\n",
    "\n",
    "    losses = []\n",
    "    loss_order = []\n",
    "    transitions = {}\n",
    "    for d1 in [0,1]:\n",
    "        for d2 in [0,1]:\n",
    "            for d3 in [0,1]:\n",
    "                outcomes, tte, transition_entry = get_outcome(d1,d2,d3)\n",
    "                loss = outcome_loss_func(outcomes,weights)\n",
    "                tloss = temporal_loss(tte,tweights,maxtime=maxtime,threshold=threshold_temporal_loss)\n",
    "                loss += tloss\n",
    "                losses.append(loss)\n",
    "                loss_order.append([d1,d2,d3])\n",
    "                transitions[str(d1)+str(d2)+str(d3)] = transition_entry\n",
    "    losses = torch.stack(losses,axis=1)\n",
    "    optimal_decisions = [loss_order[i] for i in torch.argmin(losses,axis=1)]\n",
    "    result = torch.tensor(optimal_decisions).type(torch.FloatTensor)\n",
    "    print(result.sum(axis=0),result.shape[0])\n",
    "    if get_transitions:\n",
    "        opt_transitions = {k: torch.zeros(v.shape).type(torch.FloatTensor) for k,v in transitions['000'].items()}\n",
    "        for i,od in enumerate(optimal_decisions):\n",
    "            key = ''.join([str(o) for o in od])\n",
    "            entry = transitions[key]\n",
    "            for kk,vv in entry.items():\n",
    "                opt_transitions[kk][i,:] = vv[i,:]\n",
    "        return result, opt_transitions\n",
    "    return result\n",
    "\n",
    "test, testtest = get_tt_split()\n",
    "calc_optimal_decisions(DTDataset(),\n",
    "                       testtest,model1,model2,model3,smodel3,\n",
    "                       threshold_temporal_loss=False,\n",
    "                       maxtime=48,\n",
    "                       weights=[0,0,0,0],\n",
    "                       tweights=[2,0.1,0,0],\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "122ee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([201.,  20.,   3.]) 389\n",
      "tensor([68., 14.,  3.]) 147\n",
      "torch.Size([3, 536, 86])\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 0 _____\n",
      "val reward 1.3812651634216309\n",
      "imitation reward 2.2770237922668457\n",
      "distance losses 0.3070072829723358 0.26523053646087646\n",
      "distributions [0.6608559489250183, 0.0013942900113761425, 0.0014365359675139189]\n",
      "[{'decision': 0, 'optimal_auc': 0.860945644080417, 'imitation_auc': 0.7461832061068702, 'optimal_acc': 0.6326530612244898, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.7400644468313642, 'imitation_auc': 0.6491847826086956, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.5694444444444443, 'imitation_auc': 0.7339478703115068, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 1 _____\n",
      "val reward 1.5529539585113525\n",
      "imitation reward 1.4362828731536865\n",
      "distance losses 0.29145562648773193 0.18252798914909363\n",
      "distributions [0.17012782394886017, 0.0008198085706681013, 0.00020158020197413862]\n",
      "[{'decision': 0, 'optimal_auc': 0.875837676842889, 'imitation_auc': 0.5558206106870229, 'optimal_acc': 0.5578231292517006, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9393125671321161, 'imitation_auc': 0.6869565217391304, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.043981481481481476, 'imitation_auc': 0.6748251748251748, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 2 _____\n",
      "val reward 2.2038514614105225\n",
      "imitation reward 1.2935727834701538\n",
      "distance losses 0.2838287353515625 0.1564299464225769\n",
      "distributions [0.9317506551742554, 0.0004751302767544985, 0.00013786941417492926]\n",
      "[{'decision': 0, 'optimal_auc': 0.875837676842889, 'imitation_auc': 0.5305343511450382, 'optimal_acc': 0.46258503401360546, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9532760472610098, 'imitation_auc': 0.6154891304347827, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.37037037037037035, 'imitation_auc': 0.6557533375715193, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 3 _____\n",
      "val reward 1.2781599760055542\n",
      "imitation reward 1.1910414695739746\n",
      "distance losses 0.3030492067337036 0.14030574262142181\n",
      "distributions [0.6551939249038696, 0.0019168979488313198, 0.00013257474347483367]\n",
      "[{'decision': 0, 'optimal_auc': 0.8862620997766195, 'imitation_auc': 0.5758587786259541, 'optimal_acc': 0.7142857142857143, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9505907626208377, 'imitation_auc': 0.6269021739130434, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.1712962962962963, 'imitation_auc': 0.7101080737444374, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 4 _____\n",
      "val reward 1.2548866271972656\n",
      "imitation reward 1.166854977607727\n",
      "distance losses 0.32122427225112915 0.15780621767044067\n",
      "distributions [0.220308318734169, 0.005876379553228617, 8.173631795216352e-05]\n",
      "[{'decision': 0, 'optimal_auc': 0.889240506329114, 'imitation_auc': 0.6192748091603053, 'optimal_acc': 0.5714285714285714, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9393125671321159, 'imitation_auc': 0.6366847826086957, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.10416666666666666, 'imitation_auc': 0.7418944691671965, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 5 _____\n",
      "val reward 1.0491859912872314\n",
      "imitation reward 1.1756409406661987\n",
      "distance losses 0.3322226107120514 0.1436036229133606\n",
      "distributions [0.2639658749103546, 0.026733482256531715, 0.00014111775089986622]\n",
      "[{'decision': 0, 'optimal_auc': 0.8901712583767685, 'imitation_auc': 0.6393129770992367, 'optimal_acc': 0.6394557823129252, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9516648764769067, 'imitation_auc': 0.6296195652173913, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.14120370370370372, 'imitation_auc': 0.7520661157024794, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 6 _____\n",
      "val reward 0.8611578941345215\n",
      "imitation reward 1.1606088876724243\n",
      "distance losses 0.33264949917793274 0.15708599984645844\n",
      "distributions [0.4907516539096832, 0.08045005798339844, 0.00035342518822290003]\n",
      "[{'decision': 0, 'optimal_auc': 0.8940804169769173, 'imitation_auc': 0.6502862595419847, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9763694951664876, 'imitation_auc': 0.6274456521739131, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.2152777777777778, 'imitation_auc': 0.7498410680228862, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 7 _____\n",
      "val reward 0.9263328313827515\n",
      "imitation reward 1.1399073600769043\n",
      "distance losses 0.3086884021759033 0.1503739356994629\n",
      "distributions [0.6506460905075073, 0.11400019377470016, 0.0006518717273138463]\n",
      "[{'decision': 0, 'optimal_auc': 0.89668652271035, 'imitation_auc': 0.6479007633587786, 'optimal_acc': 0.7142857142857143, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9790547798066596, 'imitation_auc': 0.6372282608695652, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.5231481481481481, 'imitation_auc': 0.7542911633820725, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 8 _____\n",
      "val reward 0.9030743837356567\n",
      "imitation reward 1.104392409324646\n",
      "distance losses 0.3306109309196472 0.1527308225631714\n",
      "distributions [0.6421906352043152, 0.1176280826330185, 0.0009871647926047444]\n",
      "[{'decision': 0, 'optimal_auc': 0.8991064780342517, 'imitation_auc': 0.6240458015267176, 'optimal_acc': 0.7142857142857143, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.976906552094522, 'imitation_auc': 0.6567934782608695, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.5925925925925926, 'imitation_auc': 0.7666878575969486, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 9 _____\n",
      "val reward 0.8033456206321716\n",
      "imitation reward 1.0704530477523804\n",
      "distance losses 0.3423425555229187 0.1474168747663498\n",
      "distributions [0.5293752551078796, 0.10117296874523163, 0.0010297313565388322]\n",
      "[{'decision': 0, 'optimal_auc': 0.9011541325390916, 'imitation_auc': 0.6264312977099237, 'optimal_acc': 0.7619047619047619, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9736842105263158, 'imitation_auc': 0.6692934782608695, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.7615740740740741, 'imitation_auc': 0.782581055308328, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 10 _____\n",
      "val reward 0.8358815908432007\n",
      "imitation reward 1.1106407642364502\n",
      "distance losses 0.3098074197769165 0.13830861449241638\n",
      "distributions [0.4312589466571808, 0.04904383793473244, 0.0005870883469469845]\n",
      "[{'decision': 0, 'optimal_auc': 0.9024571854058079, 'imitation_auc': 0.6278625954198472, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9763694951664876, 'imitation_auc': 0.6671195652173914, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.8819444444444444, 'imitation_auc': 0.7972027972027972, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 11 _____\n",
      "val reward 0.8791236877441406\n",
      "imitation reward 1.1967928409576416\n",
      "distance losses 0.31566545367240906 0.14824198186397552\n",
      "distributions [0.4095092713832855, 0.023562829941511154, 0.00031847116770222783]\n",
      "[{'decision': 0, 'optimal_auc': 0.9050632911392404, 'imitation_auc': 0.6183206106870229, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9801288936627283, 'imitation_auc': 0.6581521739130436, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9652777777777778, 'imitation_auc': 0.8041958041958042, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 12 _____\n",
      "val reward 0.8810580372810364\n",
      "imitation reward 1.1940629482269287\n",
      "distance losses 0.3171918988227844 0.1387118548154831\n",
      "distributions [0.484589546918869, 0.017544729635119438, 0.0003339853137731552]\n",
      "[{'decision': 0, 'optimal_auc': 0.9065524944154877, 'imitation_auc': 0.6030534351145038, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9822771213748658, 'imitation_auc': 0.6532608695652173, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9884259259259259, 'imitation_auc': 0.8051493960584869, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 13 _____\n",
      "val reward 0.9200687408447266\n",
      "imitation reward 1.184970498085022\n",
      "distance losses 0.33162760734558105 0.14527425169944763\n",
      "distributions [0.6040650606155396, 0.017153408378362656, 0.0004754922993015498]\n",
      "[{'decision': 0, 'optimal_auc': 0.9067386448250186, 'imitation_auc': 0.58587786259542, 'optimal_acc': 0.7278911564625851, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9828141783029002, 'imitation_auc': 0.6510869565217392, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8026064844246663, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 14 _____\n",
      "val reward 0.880521297454834\n",
      "imitation reward 1.2893576622009277\n",
      "distance losses 0.3295678496360779 0.13389234244823456\n",
      "distributions [0.6473808884620667, 0.029992273077368736, 0.0006187630933709443]\n",
      "[{'decision': 0, 'optimal_auc': 0.9028294862248698, 'imitation_auc': 0.5629770992366412, 'optimal_acc': 0.673469387755102, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9758324382384532, 'imitation_auc': 0.647554347826087, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7797202797202798, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 15 _____\n",
      "val reward 1.0612571239471436\n",
      "imitation reward 1.3871850967407227\n",
      "distance losses 0.27791228890419006 0.16149960458278656\n",
      "distributions [0.6665121912956238, 0.01411596592515707, 0.0008520690607838333]\n",
      "[{'decision': 0, 'optimal_auc': 0.8955696202531646, 'imitation_auc': 0.5310114503816794, 'optimal_acc': 0.5782312925170068, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9774436090225563, 'imitation_auc': 0.6108695652173913, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7301335028607756, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 16 _____\n",
      "val reward 0.9596737623214722\n",
      "imitation reward 1.3306944370269775\n",
      "distance losses 0.29569536447525024 0.16094323992729187\n",
      "distributions [0.5476529002189636, 0.016182610765099525, 0.0015322029357776046]\n",
      "[{'decision': 0, 'optimal_auc': 0.9011541325390916, 'imitation_auc': 0.5052480916030534, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.979591836734694, 'imitation_auc': 0.6043478260869566, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7266369993642722, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 17 _____\n",
      "val reward 0.9124611616134644\n",
      "imitation reward 1.2714513540267944\n",
      "distance losses 0.2732261121273041 0.14595264196395874\n",
      "distributions [0.5023889541625977, 0.016603786498308182, 0.0022514499723911285]\n",
      "[{'decision': 0, 'optimal_auc': 0.9026433358153388, 'imitation_auc': 0.5047709923664121, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9833512352309345, 'imitation_auc': 0.6385869565217391, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8216783216783217, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 18 _____\n",
      "val reward 0.9166473150253296\n",
      "imitation reward 1.305475115776062\n",
      "distance losses 0.3032243549823761 0.12712723016738892\n",
      "distributions [0.5570096969604492, 0.014893942512571812, 0.0026831687428057194]\n",
      "[{'decision': 0, 'optimal_auc': 0.9056217423678332, 'imitation_auc': 0.5181297709923665, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.6660326086956521, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8347107438016528, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 19 _____\n",
      "val reward 0.9387377500534058\n",
      "imitation reward 1.3600444793701172\n",
      "distance losses 0.2856285274028778 0.1506538689136505\n",
      "distributions [0.6207674145698547, 0.014869701117277145, 0.0031666886061429977]\n",
      "[{'decision': 0, 'optimal_auc': 0.9115785554728221, 'imitation_auc': 0.5190839694656488, 'optimal_acc': 0.6666666666666666, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9849624060150376, 'imitation_auc': 0.6739130434782609, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8347107438016529, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 20 _____\n",
      "val reward 0.9073687791824341\n",
      "imitation reward 1.3361259698867798\n",
      "distance losses 0.31127458810806274 0.13325411081314087\n",
      "distributions [0.6283007860183716, 0.01772920973598957, 0.004452687222510576]\n",
      "[{'decision': 0, 'optimal_auc': 0.9164184661206255, 'imitation_auc': 0.5200381679389313, 'optimal_acc': 0.6666666666666666, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.6793478260869565, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8312142403051495, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 21 _____\n",
      "val reward 0.856887698173523\n",
      "imitation reward 1.3254096508026123\n",
      "distance losses 0.31874585151672363 0.1280149221420288\n",
      "distributions [0.5996151566505432, 0.021629134193062782, 0.006198293529450893]\n",
      "[{'decision': 0, 'optimal_auc': 0.9182799702159345, 'imitation_auc': 0.5119274809160306, 'optimal_acc': 0.7074829931972789, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9865735767991408, 'imitation_auc': 0.6872282608695652, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8286713286713288, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 22 _____\n",
      "val reward 0.8904733657836914\n",
      "imitation reward 1.4018275737762451\n",
      "distance losses 0.28110724687576294 0.1115868091583252\n",
      "distributions [0.588032603263855, 0.016389036551117897, 0.006613300181925297]\n",
      "[{'decision': 0, 'optimal_auc': 0.9195830230826507, 'imitation_auc': 0.4971374045801527, 'optimal_acc': 0.7210884353741497, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6902173913043479, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8165924984106803, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 23 _____\n",
      "val reward 0.9138354659080505\n",
      "imitation reward 1.4510201215744019\n",
      "distance losses 0.30525776743888855 0.12184251099824905\n",
      "distributions [0.5702221989631653, 0.014176243916153908, 0.007108546327799559]\n",
      "[{'decision': 0, 'optimal_auc': 0.9205137751303052, 'imitation_auc': 0.49952290076335876, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6942934782608696, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8067387158296249, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 24 _____\n",
      "val reward 0.9365888237953186\n",
      "imitation reward 1.4231836795806885\n",
      "distance losses 0.2932285964488983 0.11906924843788147\n",
      "distributions [0.5805608034133911, 0.013464869931340218, 0.007678762543946505]\n",
      "[{'decision': 0, 'optimal_auc': 0.9214445271779598, 'imitation_auc': 0.5209923664122138, 'optimal_acc': 0.7074829931972789, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.7035326086956522, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8064208518753974, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 25 _____\n",
      "val reward 0.9342376589775085\n",
      "imitation reward 1.4055521488189697\n",
      "distance losses 0.29859596490859985 0.13463392853736877\n",
      "distributions [0.595481812953949, 0.014236748218536377, 0.008272634819149971]\n",
      "[{'decision': 0, 'optimal_auc': 0.9255398361876396, 'imitation_auc': 0.5281488549618321, 'optimal_acc': 0.7006802721088435, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.7078804347826086, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8108709472345836, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 26 _____\n",
      "val reward 0.8996478319168091\n",
      "imitation reward 1.3008854389190674\n",
      "distance losses 0.2818010747432709 0.1354074627161026\n",
      "distributions [0.5903609991073608, 0.015631424263119698, 0.009553777985274792]\n",
      "[{'decision': 0, 'optimal_auc': 0.9314966492926285, 'imitation_auc': 0.5295801526717557, 'optimal_acc': 0.7142857142857143, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.7135869565217391, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.813731722822632, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 27 _____\n",
      "val reward 0.8904550671577454\n",
      "imitation reward 1.2791314125061035\n",
      "distance losses 0.28722575306892395 0.11412008106708527\n",
      "distributions [0.585299551486969, 0.014173940755426884, 0.009288857690989971]\n",
      "[{'decision': 0, 'optimal_auc': 0.9326135517498138, 'imitation_auc': 0.5233778625954199, 'optimal_acc': 0.7619047619047619, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.7165760869565216, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8124602670057215, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 28 _____\n",
      "val reward 0.8708393573760986\n",
      "imitation reward 1.2797534465789795\n",
      "distance losses 0.27940478920936584 0.12756110727787018\n",
      "distributions [0.5731468796730042, 0.013854315504431725, 0.008240961469709873]\n",
      "[{'decision': 0, 'optimal_auc': 0.9348473566641847, 'imitation_auc': 0.5176526717557252, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.722554347826087, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.810553083280356, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 29 _____\n",
      "val reward 0.8142117261886597\n",
      "imitation reward 1.2488183975219727\n",
      "distance losses 0.3211416006088257 0.15623530745506287\n",
      "distributions [0.5841286778450012, 0.014656923711299896, 0.009773751720786095]\n",
      "[{'decision': 0, 'optimal_auc': 0.9352196574832464, 'imitation_auc': 0.5100190839694656, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9865735767991406, 'imitation_auc': 0.7380434782608696, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7984742530197075, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 30 _____\n",
      "val reward 0.8813683390617371\n",
      "imitation reward 1.2360399961471558\n",
      "distance losses 0.30634358525276184 0.1247749999165535\n",
      "distributions [0.5948569178581238, 0.013017183169722557, 0.007206249982118607]\n",
      "[{'decision': 0, 'optimal_auc': 0.9370811615785556, 'imitation_auc': 0.5009541984732825, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.7339673913043478, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8076923076923077, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 31 _____\n",
      "val reward 0.8657846450805664\n",
      "imitation reward 1.1756223440170288\n",
      "distance losses 0.26870036125183105 0.10799790173768997\n",
      "distributions [0.5784479379653931, 0.013607112690806389, 0.007293845526874065]\n",
      "[{'decision': 0, 'optimal_auc': 0.9372673119880863, 'imitation_auc': 0.4957061068702289, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9865735767991407, 'imitation_auc': 0.7339673913043477, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8048315321042594, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 32 _____\n",
      "val reward 0.8657886981964111\n",
      "imitation reward 1.1488635540008545\n",
      "distance losses 0.28515639901161194 0.13197320699691772\n",
      "distributions [0.5702590942382812, 0.011942108161747456, 0.006987938191741705]\n",
      "[{'decision': 0, 'optimal_auc': 0.9368950111690246, 'imitation_auc': 0.49713740458015265, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.7350543478260869, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7975206611570248, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 33 _____\n",
      "val reward 0.9018863439559937\n",
      "imitation reward 1.177304744720459\n",
      "distance losses 0.2850901782512665 0.1240999773144722\n",
      "distributions [0.5839257836341858, 0.008829777128994465, 0.006210726220160723]\n",
      "[{'decision': 0, 'optimal_auc': 0.9348473566641846, 'imitation_auc': 0.5033396946564885, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9849624060150377, 'imitation_auc': 0.7353260869565217, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7870311506675143, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 34 _____\n",
      "val reward 0.8888338208198547\n",
      "imitation reward 1.1864805221557617\n",
      "distance losses 0.2901221811771393 0.1295384168624878\n",
      "distributions [0.577458381652832, 0.00908784568309784, 0.0063637495040893555]\n",
      "[{'decision': 0, 'optimal_auc': 0.9355919583023083, 'imitation_auc': 0.5114503816793893, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9849624060150377, 'imitation_auc': 0.7369565217391305, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.784170375079466, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 35 _____\n",
      "val reward 0.9680966138839722\n",
      "imitation reward 1.1518733501434326\n",
      "distance losses 0.26968780159950256 0.1272358000278473\n",
      "distributions [0.670503556728363, 0.007281266152858734, 0.005929368082433939]\n",
      "[{'decision': 0, 'optimal_auc': 0.9363365599404319, 'imitation_auc': 0.5248091603053435, 'optimal_acc': 0.6326530612244898, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.7358695652173913, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7797202797202797, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 36 _____\n",
      "val reward 1.0436803102493286\n",
      "imitation reward 1.1085877418518066\n",
      "distance losses 0.28052160143852234 0.12112078070640564\n",
      "distributions [0.7083050012588501, 0.005062876734882593, 0.005298099480569363]\n",
      "[{'decision': 0, 'optimal_auc': 0.932241250930752, 'imitation_auc': 0.5333969465648855, 'optimal_acc': 0.5714285714285714, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.7336956521739131, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7765416401780038, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 37 _____\n",
      "val reward 1.12729012966156\n",
      "imitation reward 1.1068493127822876\n",
      "distance losses 0.29950153827667236 0.13168734312057495\n",
      "distributions [0.7462292909622192, 0.003930915147066116, 0.004779181443154812]\n",
      "[{'decision': 0, 'optimal_auc': 0.9257259865971705, 'imitation_auc': 0.5357824427480916, 'optimal_acc': 0.5102040816326531, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.7266304347826087, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7720915448188175, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 38 _____\n",
      "val reward 1.1882420778274536\n",
      "imitation reward 1.1108403205871582\n",
      "distance losses 0.2907862365245819 0.1461605280637741\n",
      "distributions [0.7683026194572449, 0.003313629422336817, 0.004362420178949833]\n",
      "[{'decision': 0, 'optimal_auc': 0.9205137751303054, 'imitation_auc': 0.5376908396946565, 'optimal_acc': 0.5034013605442177, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.71875, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7717736808645899, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 39 _____\n",
      "val reward 1.220602035522461\n",
      "imitation reward 1.1051008701324463\n",
      "distance losses 0.2848203182220459 0.1508880853652954\n",
      "distributions [0.7747495770454407, 0.002781025832518935, 0.003838530508801341]\n",
      "[{'decision': 0, 'optimal_auc': 0.9190245718540581, 'imitation_auc': 0.5357824427480916, 'optimal_acc': 0.4897959183673469, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.7130434782608696, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7867132867132867, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 40 _____\n",
      "val reward 1.312091588973999\n",
      "imitation reward 1.10417902469635\n",
      "distance losses 0.28520625829696655 0.13852174580097198\n",
      "distributions [0.8067997694015503, 0.002380549442023039, 0.0031856405548751354]\n",
      "[{'decision': 0, 'optimal_auc': 0.9121370067014147, 'imitation_auc': 0.5395992366412213, 'optimal_acc': 0.47619047619047616, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.7103260869565217, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7911633820724729, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 41 _____\n",
      "val reward 1.1692907810211182\n",
      "imitation reward 1.099037766456604\n",
      "distance losses 0.25994643568992615 0.1341121643781662\n",
      "distributions [0.7803218364715576, 0.004293070174753666, 0.0042338864877820015]\n",
      "[{'decision': 0, 'optimal_auc': 0.9112062546537602, 'imitation_auc': 0.53912213740458, 'optimal_acc': 0.5238095238095238, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9876476906552095, 'imitation_auc': 0.7051630434782609, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8061029879211697, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 42 _____\n",
      "val reward 1.2230504751205444\n",
      "imitation reward 1.0821049213409424\n",
      "distance losses 0.2699574828147888 0.12921252846717834\n",
      "distributions [0.8017002940177917, 0.004344683140516281, 0.0035302371252328157]\n",
      "[{'decision': 0, 'optimal_auc': 0.9110201042442293, 'imitation_auc': 0.54293893129771, 'optimal_acc': 0.4965986394557823, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.6997282608695652, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.8086458995549904, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 43 _____\n",
      "val reward 1.2052173614501953\n",
      "imitation reward 1.1181154251098633\n",
      "distance losses 0.3039485812187195 0.12373325973749161\n",
      "distributions [0.7956199645996094, 0.005043555982410908, 0.0028869742527604103]\n",
      "[{'decision': 0, 'optimal_auc': 0.9115785554728221, 'imitation_auc': 0.549618320610687, 'optimal_acc': 0.5238095238095238, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.6959239130434782, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.796567069294342, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 44 _____\n",
      "val reward 1.1159098148345947\n",
      "imitation reward 1.1364083290100098\n",
      "distance losses 0.2695266604423523 0.13182352483272552\n",
      "distributions [0.7634029388427734, 0.006473764311522245, 0.0029707918874919415]\n",
      "[{'decision': 0, 'optimal_auc': 0.9143708116157855, 'imitation_auc': 0.5424618320610687, 'optimal_acc': 0.54421768707483, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9849624060150377, 'imitation_auc': 0.6915760869565217, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7781309599491418, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 45 _____\n",
      "val reward 1.0195633172988892\n",
      "imitation reward 1.1211339235305786\n",
      "distance losses 0.28122010827064514 0.1242663711309433\n",
      "distributions [0.7225973010063171, 0.007789247669279575, 0.003584628226235509]\n",
      "[{'decision': 0, 'optimal_auc': 0.9182799702159345, 'imitation_auc': 0.5391221374045801, 'optimal_acc': 0.5918367346938775, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9849624060150377, 'imitation_auc': 0.688858695652174, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7682771773680864, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 46 _____\n",
      "val reward 0.9802661538124084\n",
      "imitation reward 1.1344490051269531\n",
      "distance losses 0.27199140191078186 0.1320081204175949\n",
      "distributions [0.6977336406707764, 0.007980801165103912, 0.0037607874255627394]\n",
      "[{'decision': 0, 'optimal_auc': 0.917163067758749, 'imitation_auc': 0.5434160305343512, 'optimal_acc': 0.6326530612244898, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9838882921589689, 'imitation_auc': 0.6986413043478261, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7724094087730452, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 47 _____\n",
      "val reward 0.9858570694923401\n",
      "imitation reward 1.1337831020355225\n",
      "distance losses 0.2749391198158264 0.12754078209400177\n",
      "distributions [0.7039373517036438, 0.008448089472949505, 0.003274189541116357]\n",
      "[{'decision': 0, 'optimal_auc': 0.9179076693968726, 'imitation_auc': 0.5477099236641222, 'optimal_acc': 0.6054421768707483, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9838882921589688, 'imitation_auc': 0.6934782608695652, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7819453273998729, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 48 _____\n",
      "val reward 0.9797208905220032\n",
      "imitation reward 1.1179885864257812\n",
      "distance losses 0.29759612679481506 0.1340177357196808\n",
      "distributions [0.7284489274024963, 0.012948678806424141, 0.003028330858796835]\n",
      "[{'decision': 0, 'optimal_auc': 0.9171630677587491, 'imitation_auc': 0.5515267175572519, 'optimal_acc': 0.564625850340136, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9833512352309345, 'imitation_auc': 0.6891304347826087, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7828989192625556, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 49 _____\n",
      "val reward 1.0412155389785767\n",
      "imitation reward 1.1209052801132202\n",
      "distance losses 0.25600001215934753 0.11994411051273346\n",
      "distributions [0.7643389105796814, 0.014771949499845505, 0.002711058361455798]\n",
      "[{'decision': 0, 'optimal_auc': 0.913626209977662, 'imitation_auc': 0.5477099236641222, 'optimal_acc': 0.5238095238095238, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9828141783029001, 'imitation_auc': 0.6774456521739132, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7822631913541005, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 50 _____\n",
      "val reward 1.0985736846923828\n",
      "imitation reward 1.1602646112442017\n",
      "distance losses 0.2818407118320465 0.1250348687171936\n",
      "distributions [0.7693947553634644, 0.010514184832572937, 0.0020722560584545135]\n",
      "[{'decision': 0, 'optimal_auc': 0.9093447505584512, 'imitation_auc': 0.5429389312977099, 'optimal_acc': 0.5170068027210885, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9833512352309344, 'imitation_auc': 0.672554347826087, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7759059122695486, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 51 _____\n",
      "val reward 1.0372352600097656\n",
      "imitation reward 1.1261224746704102\n",
      "distance losses 0.29972779750823975 0.13951271772384644\n",
      "distributions [0.7333919405937195, 0.009786181151866913, 0.001979109365493059]\n",
      "[{'decision': 0, 'optimal_auc': 0.9065524944154877, 'imitation_auc': 0.5481870229007634, 'optimal_acc': 0.5510204081632653, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9838882921589689, 'imitation_auc': 0.6823369565217391, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7638270820089001, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 52 _____\n",
      "val reward 1.0222703218460083\n",
      "imitation reward 1.1161720752716064\n",
      "distance losses 0.2771972417831421 0.1419009119272232\n",
      "distributions [0.7085260152816772, 0.007107494864612818, 0.0018729409202933311]\n",
      "[{'decision': 0, 'optimal_auc': 0.9050632911392404, 'imitation_auc': 0.5586832061068702, 'optimal_acc': 0.5986394557823129, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9854994629430719, 'imitation_auc': 0.6902173913043479, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7635092180546726, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 53 _____\n",
      "val reward 0.9219735860824585\n",
      "imitation reward 1.1065751314163208\n",
      "distance losses 0.2987755835056305 0.13088323175907135\n",
      "distributions [0.6737456917762756, 0.010211445391178131, 0.002617418998852372]\n",
      "[{'decision': 0, 'optimal_auc': 0.9048771407297096, 'imitation_auc': 0.5663167938931297, 'optimal_acc': 0.6666666666666666, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6907608695652174, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7762237762237763, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 54 _____\n",
      "val reward 0.8874837160110474\n",
      "imitation reward 1.0922331809997559\n",
      "distance losses 0.2942092716693878 0.12380948662757874\n",
      "distributions [0.6990323662757874, 0.01790410652756691, 0.006470796186476946]\n",
      "[{'decision': 0, 'optimal_auc': 0.9043186895011169, 'imitation_auc': 0.5806297709923663, 'optimal_acc': 0.6190476190476191, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.698913043478261, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7803560076287349, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 55 _____\n",
      "val reward 0.8980113863945007\n",
      "imitation reward 1.1283552646636963\n",
      "distance losses 0.3042174279689789 0.12132095545530319\n",
      "distributions [0.705113410949707, 0.02212892472743988, 0.004563449416309595]\n",
      "[{'decision': 0, 'optimal_auc': 0.8985480268056589, 'imitation_auc': 0.5854007633587786, 'optimal_acc': 0.5918367346938775, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9876476906552094, 'imitation_auc': 0.689945652173913, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.770184361093452, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 56 _____\n",
      "val reward 0.8281864523887634\n",
      "imitation reward 1.1775517463684082\n",
      "distance losses 0.30676475167274475 0.12882724404335022\n",
      "distributions [0.6700541973114014, 0.03263627365231514, 0.004660240840166807]\n",
      "[{'decision': 0, 'optimal_auc': 0.8972449739389428, 'imitation_auc': 0.592557251908397, 'optimal_acc': 0.673469387755102, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6888586956521738, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7596948506039415, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 57 _____\n",
      "val reward 0.7938557863235474\n",
      "imitation reward 1.1577916145324707\n",
      "distance losses 0.2880581021308899 0.12566158175468445\n",
      "distributions [0.6264358162879944, 0.027159765362739563, 0.0067853378131985664]\n",
      "[{'decision': 0, 'optimal_auc': 0.8918466120625466, 'imitation_auc': 0.6006679389312977, 'optimal_acc': 0.7346938775510204, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9887218045112782, 'imitation_auc': 0.6894021739130436, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.766369993642721, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 58 _____\n",
      "val reward 0.785392165184021\n",
      "imitation reward 1.1307837963104248\n",
      "distance losses 0.30350637435913086 0.12636414170265198\n",
      "distributions [0.5992278456687927, 0.025171704590320587, 0.00762862479314208]\n",
      "[{'decision': 0, 'optimal_auc': 0.8864482501861504, 'imitation_auc': 0.6040076335877862, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9892588614393125, 'imitation_auc': 0.6880434782608695, 'optimal_acc': 0.8979591836734694, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7670057215511761, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 59 _____\n",
      "val reward 0.7230725884437561\n",
      "imitation reward 1.110142469406128\n",
      "distance losses 0.30025434494018555 0.1301613301038742\n",
      "distributions [0.5869306921958923, 0.04170237481594086, 0.009914916940033436]\n",
      "[{'decision': 0, 'optimal_auc': 0.8890543559195829, 'imitation_auc': 0.6083015267175572, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6839673913043478, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7733630006357279, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 60 _____\n",
      "val reward 0.7383961081504822\n",
      "imitation reward 1.1293458938598633\n",
      "distance losses 0.3029487133026123 0.1302337497472763\n",
      "distributions [0.6027379631996155, 0.038105081766843796, 0.009661611169576645]\n",
      "[{'decision': 0, 'optimal_auc': 0.8907297096053611, 'imitation_auc': 0.601145038167939, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9892588614393126, 'imitation_auc': 0.6725543478260869, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.782581055308328, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 61 _____\n",
      "val reward 0.7404773235321045\n",
      "imitation reward 1.1321115493774414\n",
      "distance losses 0.3056532144546509 0.12009097635746002\n",
      "distributions [0.6160601377487183, 0.04031817242503166, 0.0076286750845611095]\n",
      "[{'decision': 0, 'optimal_auc': 0.892777364110201, 'imitation_auc': 0.6040076335877862, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832437, 'imitation_auc': 0.6720108695652174, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7892561983471074, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 62 _____\n",
      "val reward 0.7914788722991943\n",
      "imitation reward 1.1231579780578613\n",
      "distance losses 0.29372212290763855 0.15969650447368622\n",
      "distributions [0.6539754867553711, 0.03779200464487076, 0.005603681784123182]\n",
      "[{'decision': 0, 'optimal_auc': 0.8955696202531647, 'imitation_auc': 0.6001908396946565, 'optimal_acc': 0.7142857142857143, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9876476906552094, 'imitation_auc': 0.6755434782608696, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7933884297520661, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 63 _____\n",
      "val reward 0.8301101326942444\n",
      "imitation reward 1.1062811613082886\n",
      "distance losses 0.3010958433151245 0.1530432552099228\n",
      "distributions [0.6855307817459106, 0.036416348069906235, 0.006181981880217791]\n",
      "[{'decision': 0, 'optimal_auc': 0.8957557706626954, 'imitation_auc': 0.5935114503816794, 'optimal_acc': 0.6802721088435374, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9865735767991408, 'imitation_auc': 0.6847826086956522, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7937062937062938, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 64 _____\n",
      "val reward 0.7915433645248413\n",
      "imitation reward 1.1374435424804688\n",
      "distance losses 0.3220972418785095 0.13964125514030457\n",
      "distributions [0.6955392956733704, 0.050867658108472824, 0.010749148204922676]\n",
      "[{'decision': 0, 'optimal_auc': 0.8925912137006701, 'imitation_auc': 0.5911259541984732, 'optimal_acc': 0.6598639455782312, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6902173913043478, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.8016528925619835, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 65 _____\n",
      "val reward 0.6806148290634155\n",
      "imitation reward 1.1997342109680176\n",
      "distance losses 0.3544135093688965 0.1211046352982521\n",
      "distributions [0.6506213545799255, 0.06637375801801682, 0.020838379859924316]\n",
      "[{'decision': 0, 'optimal_auc': 0.8950111690245719, 'imitation_auc': 0.5854007633587786, 'optimal_acc': 0.7551020408163265, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6861413043478259, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.8035600762873489, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 66 _____\n",
      "val reward 0.7992141246795654\n",
      "imitation reward 1.1310806274414062\n",
      "distance losses 0.3061271607875824 0.14379945397377014\n",
      "distributions [0.6479529142379761, 0.0185040645301342, 0.01696191541850567]\n",
      "[{'decision': 0, 'optimal_auc': 0.8957557706626955, 'imitation_auc': 0.5834923664122137, 'optimal_acc': 0.7482993197278912, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.989795918367347, 'imitation_auc': 0.6894021739130435, 'optimal_acc': 0.9047619047619048, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7937062937062938, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 67 _____\n",
      "val reward 0.7096480131149292\n",
      "imitation reward 1.1401312351226807\n",
      "distance losses 0.3463682532310486 0.13381615281105042\n",
      "distributions [0.6141204833984375, 0.041295815259218216, 0.020004753023386]\n",
      "[{'decision': 0, 'optimal_auc': 0.8978034251675355, 'imitation_auc': 0.5782442748091603, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9892588614393125, 'imitation_auc': 0.6951086956521738, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.782581055308328, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 68 _____\n",
      "val reward 0.5767427682876587\n",
      "imitation reward 1.1508301496505737\n",
      "distance losses 0.3535268306732178 0.15139514207839966\n",
      "distributions [0.5323647260665894, 0.07781343907117844, 0.01949615217745304]\n",
      "[{'decision': 0, 'optimal_auc': 0.8989203276247207, 'imitation_auc': 0.5877862595419847, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9876476906552094, 'imitation_auc': 0.6926630434782609, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7778130959949142, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 69 _____\n",
      "val reward 0.6324717998504639\n",
      "imitation reward 1.1243400573730469\n",
      "distance losses 0.33185768127441406 0.12859956920146942\n",
      "distributions [0.5074111819267273, 0.05597776174545288, 0.011443064548075199]\n",
      "[{'decision': 0, 'optimal_auc': 0.8925912137006702, 'imitation_auc': 0.5844465648854962, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9887218045112782, 'imitation_auc': 0.688858695652174, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7959183673469388}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.770184361093452, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 70 _____\n",
      "val reward 0.7002300024032593\n",
      "imitation reward 1.1233073472976685\n",
      "distance losses 0.27718865871429443 0.12272915244102478\n",
      "distributions [0.49470436573028564, 0.036773260682821274, 0.010276388376951218]\n",
      "[{'decision': 0, 'optimal_auc': 0.8879374534623976, 'imitation_auc': 0.5729961832061069, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.989795918367347, 'imitation_auc': 0.6807065217391304, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7558804831532104, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 71 _____\n",
      "val reward 0.6499476432800293\n",
      "imitation reward 1.1142796277999878\n",
      "distance losses 0.31047117710113525 0.10624393820762634\n",
      "distributions [0.47817039489746094, 0.0532861165702343, 0.013461279682815075]\n",
      "[{'decision': 0, 'optimal_auc': 0.887379002233805, 'imitation_auc': 0.5691793893129771, 'optimal_acc': 0.8435374149659864, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9887218045112782, 'imitation_auc': 0.6855978260869565, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7520661157024794, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 72 _____\n",
      "val reward 0.601324737071991\n",
      "imitation reward 1.1602108478546143\n",
      "distance losses 0.3301126956939697 0.10959266126155853\n",
      "distributions [0.5092313885688782, 0.0776311531662941, 0.017585642635822296]\n",
      "[{'decision': 0, 'optimal_auc': 0.890915860014892, 'imitation_auc': 0.5791984732824427, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9876476906552094, 'imitation_auc': 0.6885869565217391, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9953703703703703, 'imitation_auc': 0.7428480610298792, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 73 _____\n",
      "val reward 0.5891631841659546\n",
      "imitation reward 1.2026870250701904\n",
      "distance losses 0.33390486240386963 0.13975760340690613\n",
      "distributions [0.5388872027397156, 0.08272002637386322, 0.018791865557432175]\n",
      "[{'decision': 0, 'optimal_auc': 0.8922189128816084, 'imitation_auc': 0.6001908396946566, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9865735767991407, 'imitation_auc': 0.6739130434782608, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7210884353741497}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7479338842975206, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 74 _____\n",
      "val reward 0.6139727830886841\n",
      "imitation reward 1.2223525047302246\n",
      "distance losses 0.3375854790210724 0.11972563713788986\n",
      "distributions [0.5728489756584167, 0.06873539835214615, 0.014943680725991726]\n",
      "[{'decision': 0, 'optimal_auc': 0.8922189128816084, 'imitation_auc': 0.5951812977099237, 'optimal_acc': 0.7687074829931972, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6608695652173914, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7596948506039415, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 75 _____\n",
      "val reward 0.7260035872459412\n",
      "imitation reward 1.1942718029022217\n",
      "distance losses 0.30494779348373413 0.12331143766641617\n",
      "distributions [0.6317734122276306, 0.039165571331977844, 0.012734699063003063]\n",
      "[{'decision': 0, 'optimal_auc': 0.8911020104244229, 'imitation_auc': 0.5892175572519084, 'optimal_acc': 0.7278911564625851, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9887218045112782, 'imitation_auc': 0.675, 'optimal_acc': 0.9115646258503401, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7571519389701208, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 76 _____\n",
      "val reward 0.7153046131134033\n",
      "imitation reward 1.1949968338012695\n",
      "distance losses 0.3044489324092865 0.11896151304244995\n",
      "distributions [0.6375234127044678, 0.04778372868895531, 0.013475326821208]\n",
      "[{'decision': 0, 'optimal_auc': 0.887192851824274, 'imitation_auc': 0.5811068702290076, 'optimal_acc': 0.7414965986394558, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6758152173913043, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7074829931972789}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7606484424666242, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8435374149659864}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 77 _____\n",
      "val reward 0.6172623634338379\n",
      "imitation reward 1.2377021312713623\n",
      "distance losses 0.30820712447166443 0.11522190272808075\n",
      "distributions [0.5834125876426697, 0.08263914287090302, 0.01528183277696371]\n",
      "[{'decision': 0, 'optimal_auc': 0.8879374534623976, 'imitation_auc': 0.5844465648854962, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711063, 'imitation_auc': 0.6625, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.6938775510204082}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7577876668785759, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 78 _____\n",
      "val reward 0.6023326516151428\n",
      "imitation reward 1.23009192943573\n",
      "distance losses 0.3191601634025574 0.11162585020065308\n",
      "distributions [0.5555200576782227, 0.07848711311817169, 0.01593424752354622]\n",
      "[{'decision': 0, 'optimal_auc': 0.8907297096053611, 'imitation_auc': 0.5954198473282443, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6586956521739131, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7142857142857143}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7596948506039415, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 79 _____\n",
      "val reward 0.619178831577301\n",
      "imitation reward 1.2061846256256104\n",
      "distance losses 0.2994919419288635 0.12957142293453217\n",
      "distributions [0.5264737010002136, 0.059304431080818176, 0.015648869797587395]\n",
      "[{'decision': 0, 'optimal_auc': 0.8924050632911392, 'imitation_auc': 0.6025763358778625, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9887218045112782, 'imitation_auc': 0.6573369565217392, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7698664971392245, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 80 _____\n",
      "val reward 0.6623262763023376\n",
      "imitation reward 1.2443398237228394\n",
      "distance losses 0.296032190322876 0.12174597382545471\n",
      "distributions [0.5080709457397461, 0.04388749226927757, 0.014896444976329803]\n",
      "[{'decision': 0, 'optimal_auc': 0.8944527177959791, 'imitation_auc': 0.5958969465648856, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9881847475832438, 'imitation_auc': 0.6459239130434782, 'optimal_acc': 0.9183673469387755, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.770184361093452, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 81 _____\n",
      "val reward 0.6649887561798096\n",
      "imitation reward 1.2941553592681885\n",
      "distance losses 0.30627644062042236 0.1284698247909546\n",
      "distributions [0.5094080567359924, 0.04502708092331886, 0.01776190660893917]\n",
      "[{'decision': 0, 'optimal_auc': 0.89668652271035, 'imitation_auc': 0.5939885496183206, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9860365198711064, 'imitation_auc': 0.6361413043478261, 'optimal_acc': 0.9251700680272109, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7590591226954863, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 82 _____\n",
      "val reward 0.6294474601745605\n",
      "imitation reward 1.3115774393081665\n",
      "distance losses 0.30831581354141235 0.12920959293842316\n",
      "distributions [0.5094791054725647, 0.06028369814157486, 0.022458696737885475]\n",
      "[{'decision': 0, 'optimal_auc': 0.8965003723008191, 'imitation_auc': 0.5982824427480915, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.6369565217391304, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9930555555555556, 'imitation_auc': 0.740623013350286, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 83 _____\n",
      "val reward 0.6064351201057434\n",
      "imitation reward 1.3299384117126465\n",
      "distance losses 0.3509010076522827 0.1330564022064209\n",
      "distributions [0.5061029195785522, 0.0728926807641983, 0.02158888429403305]\n",
      "[{'decision': 0, 'optimal_auc': 0.8935219657483247, 'imitation_auc': 0.6073473282442748, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9833512352309345, 'imitation_auc': 0.6467391304347826, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7374443738080102, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 84 _____\n",
      "val reward 0.6088544726371765\n",
      "imitation reward 1.3317501544952393\n",
      "distance losses 0.3243544399738312 0.15500468015670776\n",
      "distributions [0.5034375190734863, 0.0695076733827591, 0.01607135497033596]\n",
      "[{'decision': 0, 'optimal_auc': 0.8888682055100522, 'imitation_auc': 0.5920801526717557, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.6440217391304348, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7364907819453274, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 85 _____\n",
      "val reward 0.6150609850883484\n",
      "imitation reward 1.354034423828125\n",
      "distance losses 0.2978237271308899 0.12511788308620453\n",
      "distributions [0.513409435749054, 0.07069482654333115, 0.01334596797823906]\n",
      "[{'decision': 0, 'optimal_auc': 0.8817944899478778, 'imitation_auc': 0.6016221374045801, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.6394021739130435, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7253655435473617, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 86 _____\n",
      "val reward 0.6462626457214355\n",
      "imitation reward 1.3542194366455078\n",
      "distance losses 0.2875015437602997 0.143330380320549\n",
      "distributions [0.5697508454322815, 0.07381574809551239, 0.01107671670615673]\n",
      "[{'decision': 0, 'optimal_auc': 0.877885331347729, 'imitation_auc': 0.6083015267175572, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.9047619047619048}, {'decision': 1, 'optimal_auc': 0.9865735767991406, 'imitation_auc': 0.6334239130434783, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7136045772409408, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 87 _____\n",
      "val reward 0.6734218001365662\n",
      "imitation reward 1.2828192710876465\n",
      "distance losses 0.293478786945343 0.15105192363262177\n",
      "distributions [0.6003362536430359, 0.07806269079446793, 0.009830069728195667]\n",
      "[{'decision': 0, 'optimal_auc': 0.8806775874906925, 'imitation_auc': 0.5968511450381679, 'optimal_acc': 0.782312925170068, 'imitation_acc': 0.9047619047619048}, {'decision': 1, 'optimal_auc': 0.9865735767991407, 'imitation_auc': 0.638586956521739, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.6999364272091545, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8027210884353742}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 88 _____\n",
      "val reward 0.6630216240882874\n",
      "imitation reward 1.2478861808776855\n",
      "distance losses 0.27409058809280396 0.12709058821201324\n",
      "distributions [0.6041780710220337, 0.07407663017511368, 0.014067531563341618]\n",
      "[{'decision': 0, 'optimal_auc': 0.8884959046909903, 'imitation_auc': 0.6059160305343512, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9871106337271751, 'imitation_auc': 0.6350543478260869, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7253655435473617, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 89 _____\n",
      "val reward 0.6345511674880981\n",
      "imitation reward 1.2493547201156616\n",
      "distance losses 0.29062482714653015 0.1512180119752884\n",
      "distributions [0.5849603414535522, 0.07529805600643158, 0.016627367585897446]\n",
      "[{'decision': 0, 'optimal_auc': 0.8940804169769173, 'imitation_auc': 0.6102099236641221, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.6309782608695652, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7425301970756516, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 90 _____\n",
      "val reward 0.616217315196991\n",
      "imitation reward 1.2343761920928955\n",
      "distance losses 0.31531479954719543 0.14553692936897278\n",
      "distributions [0.5693230032920837, 0.07563409209251404, 0.017916470766067505]\n",
      "[{'decision': 0, 'optimal_auc': 0.8972449739389426, 'imitation_auc': 0.6140267175572519, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9844253490870032, 'imitation_auc': 0.6440217391304347, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7539732994278449, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 91 _____\n",
      "val reward 0.6257807612419128\n",
      "imitation reward 1.227034330368042\n",
      "distance losses 0.309050977230072 0.12406931817531586\n",
      "distributions [0.560836911201477, 0.06485825777053833, 0.01701934076845646]\n",
      "[{'decision': 0, 'optimal_auc': 0.8976172747580045, 'imitation_auc': 0.6154580152671756, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9838882921589689, 'imitation_auc': 0.6546195652173913, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7571519389701207, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 92 _____\n",
      "val reward 0.6298246383666992\n",
      "imitation reward 1.2364884614944458\n",
      "distance losses 0.33574244379997253 0.12015029788017273\n",
      "distributions [0.542767345905304, 0.05991388112306595, 0.01614428497850895]\n",
      "[{'decision': 0, 'optimal_auc': 0.898548026805659, 'imitation_auc': 0.612118320610687, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9828141783029001, 'imitation_auc': 0.6586956521739131, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7587412587412588, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 93 _____\n",
      "val reward 0.6301358342170715\n",
      "imitation reward 1.2054927349090576\n",
      "distance losses 0.3251424729824066 0.13078849017620087\n",
      "distributions [0.5227364301681519, 0.061289139091968536, 0.014964602887630463]\n",
      "[{'decision': 0, 'optimal_auc': 0.9017125837676844, 'imitation_auc': 0.6030534351145038, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.6616847826086957, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7549268912905278, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 94 _____\n",
      "val reward 0.6212673783302307\n",
      "imitation reward 1.189321756362915\n",
      "distance losses 0.31300088763237 0.11405976116657257\n",
      "distributions [0.5132982134819031, 0.067092664539814, 0.014867603778839111]\n",
      "[{'decision': 0, 'optimal_auc': 0.904132539091586, 'imitation_auc': 0.5911259541984732, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9854994629430719, 'imitation_auc': 0.6478260869565218, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7530197075651621, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 95 _____\n",
      "val reward 0.6070913076400757\n",
      "imitation reward 1.1915357112884521\n",
      "distance losses 0.2947748601436615 0.11373304575681686\n",
      "distributions [0.5138780474662781, 0.07739751040935516, 0.01462133415043354]\n",
      "[{'decision': 0, 'optimal_auc': 0.9039463886820551, 'imitation_auc': 0.5873091603053435, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9838882921589689, 'imitation_auc': 0.6334239130434782, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7561983471074379, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 96 _____\n",
      "val reward 0.5815593600273132\n",
      "imitation reward 1.2388675212860107\n",
      "distance losses 0.3125167489051819 0.1170186921954155\n",
      "distributions [0.5158404111862183, 0.09949064999818802, 0.01543210819363594]\n",
      "[{'decision': 0, 'optimal_auc': 0.9063663440059568, 'imitation_auc': 0.6020992366412214, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9833512352309345, 'imitation_auc': 0.6309782608695652, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7625556261919899, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 97 _____\n",
      "val reward 0.5785965919494629\n",
      "imitation reward 1.2884199619293213\n",
      "distance losses 0.29748401045799255 0.11824911832809448\n",
      "distributions [0.5076019167900085, 0.0973464772105217, 0.015894446521997452]\n",
      "[{'decision': 0, 'optimal_auc': 0.9052494415487714, 'imitation_auc': 0.6130725190839694, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6293478260869566, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7619198982835347, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 98 _____\n",
      "val reward 0.6065911054611206\n",
      "imitation reward 1.3041296005249023\n",
      "distance losses 0.30000749230384827 0.12410340458154678\n",
      "distributions [0.4978748857975006, 0.07392814755439758, 0.016242459416389465]\n",
      "[{'decision': 0, 'optimal_auc': 0.9015264333581534, 'imitation_auc': 0.616412213740458, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9790547798066596, 'imitation_auc': 0.6421195652173913, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7527018436109346, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 99 _____\n",
      "val reward 0.6271182894706726\n",
      "imitation reward 1.3261520862579346\n",
      "distance losses 0.2937755286693573 0.11962384730577469\n",
      "distributions [0.4684772491455078, 0.06483998894691467, 0.01654449850320816]\n",
      "[{'decision': 0, 'optimal_auc': 0.9013402829486225, 'imitation_auc': 0.6063931297709924, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6603260869565217, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7418944691671964, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8435374149659864}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 100 _____\n",
      "val reward 0.6170574426651001\n",
      "imitation reward 1.2978616952896118\n",
      "distance losses 0.3059794306755066 0.12351895123720169\n",
      "distributions [0.4630011320114136, 0.06961279362440109, 0.017957031726837158]\n",
      "[{'decision': 0, 'optimal_auc': 0.9015264333581533, 'imitation_auc': 0.5868320610687023, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9806659505907627, 'imitation_auc': 0.6684782608695652, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7323585505403687, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8367346938775511}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 101 _____\n",
      "val reward 0.5927851796150208\n",
      "imitation reward 1.3022072315216064\n",
      "distance losses 0.3069724142551422 0.12605324387550354\n",
      "distributions [0.47113731503486633, 0.0884355753660202, 0.018312808126211166]\n",
      "[{'decision': 0, 'optimal_auc': 0.9048771407297096, 'imitation_auc': 0.5834923664122137, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9774436090225564, 'imitation_auc': 0.670108695652174, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7326764144945963, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 102 _____\n",
      "val reward 0.5843705534934998\n",
      "imitation reward 1.3187305927276611\n",
      "distance losses 0.32867440581321716 0.13590963184833527\n",
      "distributions [0.47962722182273865, 0.08822068572044373, 0.018449567258358]\n",
      "[{'decision': 0, 'optimal_auc': 0.9037602382725243, 'imitation_auc': 0.5997137404580153, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9774436090225564, 'imitation_auc': 0.6616847826086957, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7380801017164653, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 103 _____\n",
      "val reward 0.5813685059547424\n",
      "imitation reward 1.3274955749511719\n",
      "distance losses 0.3139364421367645 0.11529770493507385\n",
      "distributions [0.5127803087234497, 0.08161626011133194, 0.0157285388559103]\n",
      "[{'decision': 0, 'optimal_auc': 0.9032017870439315, 'imitation_auc': 0.6221374045801527, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6535326086956522, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7466624284806104, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 104 _____\n",
      "val reward 0.5973803400993347\n",
      "imitation reward 1.3130638599395752\n",
      "distance losses 0.3257668614387512 0.12935590744018555\n",
      "distributions [0.5460648536682129, 0.08441886305809021, 0.014125199988484383]\n",
      "[{'decision': 0, 'optimal_auc': 0.8976172747580045, 'imitation_auc': 0.6307251908396947, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9822771213748658, 'imitation_auc': 0.6451086956521739, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7482517482517483, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 105 _____\n",
      "val reward 0.6381867527961731\n",
      "imitation reward 1.354820728302002\n",
      "distance losses 0.31008368730545044 0.11423339694738388\n",
      "distributions [0.5928585529327393, 0.08414539694786072, 0.012138628400862217]\n",
      "[{'decision': 0, 'optimal_auc': 0.8931496649292628, 'imitation_auc': 0.6288167938931297, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9833512352309344, 'imitation_auc': 0.6315217391304349, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7469802924348379, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 106 _____\n",
      "val reward 0.6563310027122498\n",
      "imitation reward 1.3834222555160522\n",
      "distance losses 0.2798846662044525 0.11239150166511536\n",
      "distributions [0.6028515100479126, 0.0892375260591507, 0.011648254469037056]\n",
      "[{'decision': 0, 'optimal_auc': 0.8884959046909904, 'imitation_auc': 0.6307251908396946, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9822771213748657, 'imitation_auc': 0.6290760869565217, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7476160203432931, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 107 _____\n",
      "val reward 0.6208961606025696\n",
      "imitation reward 1.3667337894439697\n",
      "distance losses 0.312192440032959 0.1186072826385498\n",
      "distributions [0.5339046716690063, 0.10223915427923203, 0.01327458769083023]\n",
      "[{'decision': 0, 'optimal_auc': 0.887379002233805, 'imitation_auc': 0.6235687022900763, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9817400644468313, 'imitation_auc': 0.6241847826086956, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7530197075651621, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 108 _____\n",
      "val reward 0.6141377687454224\n",
      "imitation reward 1.3158717155456543\n",
      "distance losses 0.3061232566833496 0.11413691937923431\n",
      "distributions [0.4601399004459381, 0.1097579076886177, 0.014693203382194042]\n",
      "[{'decision': 0, 'optimal_auc': 0.8899851079672375, 'imitation_auc': 0.6216603053435115, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6269021739130435, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7546090273363, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 109 _____\n",
      "val reward 0.6069000363349915\n",
      "imitation reward 1.294365644454956\n",
      "distance losses 0.28530991077423096 0.12911218404769897\n",
      "distributions [0.4761374294757843, 0.09608080238103867, 0.014590620063245296]\n",
      "[{'decision': 0, 'optimal_auc': 0.8931496649292628, 'imitation_auc': 0.6135496183206106, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9801288936627283, 'imitation_auc': 0.6266304347826087, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7492053401144311, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 110 _____\n",
      "val reward 0.6155935525894165\n",
      "imitation reward 1.40386962890625\n",
      "distance losses 0.29833221435546875 0.12069926410913467\n",
      "distributions [0.5363115668296814, 0.07960920035839081, 0.014504714868962765]\n",
      "[{'decision': 0, 'optimal_auc': 0.8946388682055101, 'imitation_auc': 0.6035305343511451, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9822771213748658, 'imitation_auc': 0.6350543478260868, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.742212333121424, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7414965986394558}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 111 _____\n",
      "val reward 0.6159168481826782\n",
      "imitation reward 1.500162124633789\n",
      "distance losses 0.3182598948478699 0.13164684176445007\n",
      "distributions [0.5565698146820068, 0.0772586539387703, 0.01625848188996315]\n",
      "[{'decision': 0, 'optimal_auc': 0.8946388682055101, 'imitation_auc': 0.5968511450381679, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6269021739130434, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7552447552447552, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7346938775510204}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 112 _____\n",
      "val reward 0.6010769009590149\n",
      "imitation reward 1.407806634902954\n",
      "distance losses 0.33702051639556885 0.13782988488674164\n",
      "distributions [0.5250335931777954, 0.0827556923031807, 0.020167626440525055]\n",
      "[{'decision': 0, 'optimal_auc': 0.8925912137006701, 'imitation_auc': 0.5939885496183206, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.979591836734694, 'imitation_auc': 0.6472826086956522, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7590591226954864, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 113 _____\n",
      "val reward 0.5889943242073059\n",
      "imitation reward 1.3397624492645264\n",
      "distance losses 0.30759140849113464 0.12551572918891907\n",
      "distributions [0.4891805946826935, 0.09224491566419601, 0.020074615254998207]\n",
      "[{'decision': 0, 'optimal_auc': 0.8937081161578556, 'imitation_auc': 0.5906488549618321, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9801288936627283, 'imitation_auc': 0.6527173913043478, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7644628099173554, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 114 _____\n",
      "val reward 0.5889711380004883\n",
      "imitation reward 1.3436263799667358\n",
      "distance losses 0.30990129709243774 0.13053831458091736\n",
      "distributions [0.4791680574417114, 0.08893432468175888, 0.017579009756445885]\n",
      "[{'decision': 0, 'optimal_auc': 0.8940804169769174, 'imitation_auc': 0.583969465648855, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9790547798066596, 'imitation_auc': 0.6570652173913043, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7616020343293071, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 115 _____\n",
      "val reward 0.5861035585403442\n",
      "imitation reward 1.4425811767578125\n",
      "distance losses 0.3344576060771942 0.1270914226770401\n",
      "distributions [0.47718530893325806, 0.09007073193788528, 0.015256853774189949]\n",
      "[{'decision': 0, 'optimal_auc': 0.8937081161578555, 'imitation_auc': 0.5987595419847329, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.978517722878625, 'imitation_auc': 0.6567934782608695, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7689129052765417, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 116 _____\n",
      "val reward 0.6035224199295044\n",
      "imitation reward 1.504044532775879\n",
      "distance losses 0.34081679582595825 0.14482177793979645\n",
      "distributions [0.5048758387565613, 0.08461367338895798, 0.013474400155246258]\n",
      "[{'decision': 0, 'optimal_auc': 0.8858897989575577, 'imitation_auc': 0.6006679389312978, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9763694951664876, 'imitation_auc': 0.65625, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7762237762237763, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 117 _____\n",
      "val reward 0.6349669098854065\n",
      "imitation reward 1.383885145187378\n",
      "distance losses 0.28120917081832886 0.11893074214458466\n",
      "distributions [0.5331980586051941, 0.07506363838911057, 0.012821909040212631]\n",
      "[{'decision': 0, 'optimal_auc': 0.8830975428145942, 'imitation_auc': 0.5916030534351145, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9817400644468313, 'imitation_auc': 0.6551630434782609, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7590591226954863, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 118 _____\n",
      "val reward 0.6460985541343689\n",
      "imitation reward 1.360117793083191\n",
      "distance losses 0.29112952947616577 0.13192212581634521\n",
      "distributions [0.5424039959907532, 0.07196313887834549, 0.013519112020730972]\n",
      "[{'decision': 0, 'optimal_auc': 0.883469843633656, 'imitation_auc': 0.5834923664122137, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9801288936627283, 'imitation_auc': 0.6521739130434783, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7891156462585034}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7555626191989828, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 119 _____\n",
      "val reward 0.6216179132461548\n",
      "imitation reward 1.4044504165649414\n",
      "distance losses 0.287435919046402 0.11197579652070999\n",
      "distributions [0.5176255702972412, 0.07954709231853485, 0.013873063027858734]\n",
      "[{'decision': 0, 'optimal_auc': 0.8894266567386448, 'imitation_auc': 0.5744274809160306, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9795918367346939, 'imitation_auc': 0.6510869565217392, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7555626191989829, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 120 _____\n",
      "val reward 0.604424774646759\n",
      "imitation reward 1.4853482246398926\n",
      "distance losses 0.3219885230064392 0.13131871819496155\n",
      "distributions [0.49123767018318176, 0.09058927744626999, 0.015273229219019413]\n",
      "[{'decision': 0, 'optimal_auc': 0.892777364110201, 'imitation_auc': 0.5625, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6391304347826087, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7625556261919898, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 121 _____\n",
      "val reward 0.5985997319221497\n",
      "imitation reward 1.525499939918518\n",
      "distance losses 0.3214562237262726 0.11402206867933273\n",
      "distributions [0.43890178203582764, 0.10138414800167084, 0.017555363476276398]\n",
      "[{'decision': 0, 'optimal_auc': 0.8914743112434846, 'imitation_auc': 0.5663167938931297, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6320652173913044, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7616020343293071, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 122 _____\n",
      "val reward 0.6066659688949585\n",
      "imitation reward 1.5294181108474731\n",
      "distance losses 0.2903165817260742 0.10768583416938782\n",
      "distributions [0.43991410732269287, 0.0871838927268982, 0.018777996301651]\n",
      "[{'decision': 0, 'optimal_auc': 0.8916604616530156, 'imitation_auc': 0.5691793893129772, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6296195652173914, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7568340750158932, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 123 _____\n",
      "val reward 0.6327829360961914\n",
      "imitation reward 1.447356104850769\n",
      "distance losses 0.27512505650520325 0.10406538844108582\n",
      "distributions [0.510368824005127, 0.07232483476400375, 0.016064653173089027]\n",
      "[{'decision': 0, 'optimal_auc': 0.8903574087862993, 'imitation_auc': 0.5634541984732825, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.979591836734694, 'imitation_auc': 0.642663043478261, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7438016528925621, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 124 _____\n",
      "val reward 0.6744991540908813\n",
      "imitation reward 1.4264867305755615\n",
      "distance losses 0.29628986120224 0.1162872165441513\n",
      "distributions [0.5722448825836182, 0.06961508095264435, 0.01381327211856842]\n",
      "[{'decision': 0, 'optimal_auc': 0.8812360387192852, 'imitation_auc': 0.5620229007633588, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6448369565217392, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7425301970756517, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 125 _____\n",
      "val reward 0.6450427770614624\n",
      "imitation reward 1.418363094329834\n",
      "distance losses 0.3097245395183563 0.12129796296358109\n",
      "distributions [0.5527161955833435, 0.08044064790010452, 0.014147060923278332]\n",
      "[{'decision': 0, 'optimal_auc': 0.8832836932241251, 'imitation_auc': 0.5567748091603053, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6527173913043479, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7463445645263828, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 126 _____\n",
      "val reward 0.6085397601127625\n",
      "imitation reward 1.4201891422271729\n",
      "distance losses 0.302034854888916 0.12053956836462021\n",
      "distributions [0.4871157109737396, 0.09770940989255905, 0.016990814357995987]\n",
      "[{'decision': 0, 'optimal_auc': 0.8905435591958302, 'imitation_auc': 0.5534351145038168, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6546195652173913, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.763191354100445, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 127 _____\n",
      "val reward 0.6033596396446228\n",
      "imitation reward 1.4537643194198608\n",
      "distance losses 0.3406805098056793 0.10858726501464844\n",
      "distributions [0.46371564269065857, 0.10372859239578247, 0.019910981878638268]\n",
      "[{'decision': 0, 'optimal_auc': 0.8944527177959791, 'imitation_auc': 0.5543893129770991, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6589673913043478, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7654164017800381, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 128 _____\n",
      "val reward 0.6045299172401428\n",
      "imitation reward 1.4914031028747559\n",
      "distance losses 0.3363824784755707 0.1239408403635025\n",
      "distributions [0.46056443452835083, 0.0992448627948761, 0.02456524968147278]\n",
      "[{'decision': 0, 'optimal_auc': 0.8946388682055101, 'imitation_auc': 0.5644083969465649, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6682065217391304, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7666878575969485, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 129 _____\n",
      "val reward 0.6094111800193787\n",
      "imitation reward 1.466423511505127\n",
      "distance losses 0.3426949083805084 0.13616220653057098\n",
      "distributions [0.4774971306324005, 0.08211699873209, 0.02443576417863369]\n",
      "[{'decision': 0, 'optimal_auc': 0.8951973194341029, 'imitation_auc': 0.5811068702290076, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9752953813104189, 'imitation_auc': 0.6747282608695653, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.770184361093452, 'optimal_acc': 0.9795918367346939, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 130 _____\n",
      "val reward 0.6312358975410461\n",
      "imitation reward 1.397688865661621\n",
      "distance losses 0.30513256788253784 0.11309897154569626\n",
      "distributions [0.5072665810585022, 0.06230965256690979, 0.020275214686989784]\n",
      "[{'decision': 0, 'optimal_auc': 0.8944527177959791, 'imitation_auc': 0.5901717557251909, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6671195652173912, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.768595041322314, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 131 _____\n",
      "val reward 0.6411458253860474\n",
      "imitation reward 1.3645823001861572\n",
      "distance losses 0.30409422516822815 0.11583261936903\n",
      "distributions [0.5295904874801636, 0.057170115411281586, 0.018142227083444595]\n",
      "[{'decision': 0, 'optimal_auc': 0.8959419210722264, 'imitation_auc': 0.5973282442748091, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9769065520945219, 'imitation_auc': 0.6603260869565217, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7687074829931972}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7654164017800381, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7891156462585034}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 132 _____\n",
      "val reward 0.5973051190376282\n",
      "imitation reward 1.4189292192459106\n",
      "distance losses 0.31826677918434143 0.10679791867733002\n",
      "distributions [0.5151381492614746, 0.07181533426046371, 0.01768389344215393]\n",
      "[{'decision': 0, 'optimal_auc': 0.8991064780342517, 'imitation_auc': 0.6159351145038168, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9790547798066596, 'imitation_auc': 0.648641304347826, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.782312925170068}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7666878575969486, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 133 _____\n",
      "val reward 0.5644837021827698\n",
      "imitation reward 1.4795217514038086\n",
      "distance losses 0.3014083206653595 0.12117301672697067\n",
      "distributions [0.4863700568675995, 0.09358162432909012, 0.018344929441809654]\n",
      "[{'decision': 0, 'optimal_auc': 0.900223380491437, 'imitation_auc': 0.6259541984732825, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9812030075187971, 'imitation_auc': 0.6442934782608695, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7641449459631279, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 134 _____\n",
      "val reward 0.5695478916168213\n",
      "imitation reward 1.5220086574554443\n",
      "distance losses 0.3486248850822449 0.12501275539398193\n",
      "distributions [0.462881863117218, 0.11183156073093414, 0.020394518971443176]\n",
      "[{'decision': 0, 'optimal_auc': 0.8981757259865972, 'imitation_auc': 0.6173664122137404, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6486413043478261, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7210884353741497}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7581055308328036, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 135 _____\n",
      "val reward 0.5814899802207947\n",
      "imitation reward 1.5996686220169067\n",
      "distance losses 0.36407119035720825 0.12384779006242752\n",
      "distributions [0.44536736607551575, 0.1099155843257904, 0.02217976748943329]\n",
      "[{'decision': 0, 'optimal_auc': 0.892777364110201, 'imitation_auc': 0.6059160305343512, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9790547798066594, 'imitation_auc': 0.6551630434782608, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7476160203432931, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 136 _____\n",
      "val reward 0.5945900082588196\n",
      "imitation reward 1.5374945402145386\n",
      "distance losses 0.3591517508029938 0.11986846476793289\n",
      "distributions [0.4155154824256897, 0.10911910235881805, 0.022157970815896988]\n",
      "[{'decision': 0, 'optimal_auc': 0.8916604616530156, 'imitation_auc': 0.6111641221374047, 'optimal_acc': 0.8367346938775511, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9779806659505907, 'imitation_auc': 0.6467391304347826, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7441195168467897, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 137 _____\n",
      "val reward 0.6116267442703247\n",
      "imitation reward 1.5298659801483154\n",
      "distance losses 0.3147273063659668 0.09216289967298508\n",
      "distributions [0.3819102644920349, 0.09881998598575592, 0.018177898600697517]\n",
      "[{'decision': 0, 'optimal_auc': 0.8894266567386448, 'imitation_auc': 0.626908396946565, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9726100966702471, 'imitation_auc': 0.6236413043478262, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7406230133502861, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 138 _____\n",
      "val reward 0.6226073503494263\n",
      "imitation reward 1.559462308883667\n",
      "distance losses 0.3380976915359497 0.12461518496274948\n",
      "distributions [0.378551721572876, 0.09343412518501282, 0.01661079190671444]\n",
      "[{'decision': 0, 'optimal_auc': 0.8840282948622487, 'imitation_auc': 0.6431297709923665, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9683136412459721, 'imitation_auc': 0.6124999999999999, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7393515575333758, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 139 _____\n",
      "val reward 0.6244029998779297\n",
      "imitation reward 1.5512678623199463\n",
      "distance losses 0.3102874457836151 0.0949385017156601\n",
      "distributions [0.38729771971702576, 0.0945655107498169, 0.014055943116545677]\n",
      "[{'decision': 0, 'optimal_auc': 0.8830975428145942, 'imitation_auc': 0.6512404580152671, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9699248120300752, 'imitation_auc': 0.5986413043478261, 'optimal_acc': 0.9727891156462585, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7317228226319136, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8231292517006803}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 140 _____\n",
      "val reward 0.6161202192306519\n",
      "imitation reward 1.5710504055023193\n",
      "distance losses 0.32371777296066284 0.12059691548347473\n",
      "distributions [0.4019872844219208, 0.11212146282196045, 0.013394546695053577]\n",
      "[{'decision': 0, 'optimal_auc': 0.8842144452717796, 'imitation_auc': 0.64456106870229, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9763694951664876, 'imitation_auc': 0.6005434782608695, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7269548633184997, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 141 _____\n",
      "val reward 0.6071357131004333\n",
      "imitation reward 1.5742979049682617\n",
      "distance losses 0.3476783335208893 0.12954646348953247\n",
      "distributions [0.4228131175041199, 0.12820500135421753, 0.013601680286228657]\n",
      "[{'decision': 0, 'optimal_auc': 0.8858897989575577, 'imitation_auc': 0.6264312977099237, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9806659505907627, 'imitation_auc': 0.6133152173913043, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7205975842339479, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 142 _____\n",
      "val reward 0.5872027277946472\n",
      "imitation reward 1.5543062686920166\n",
      "distance losses 0.37191054224967957 0.12490718811750412\n",
      "distributions [0.45536917448043823, 0.12899106740951538, 0.013822686858475208]\n",
      "[{'decision': 0, 'optimal_auc': 0.8931496649292627, 'imitation_auc': 0.6125954198473282, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9817400644468314, 'imitation_auc': 0.6206521739130435, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.724411951684679, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7755102040816326}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 143 _____\n",
      "val reward 0.5704048275947571\n",
      "imitation reward 1.5037356615066528\n",
      "distance losses 0.3293847441673279 0.1083701103925705\n",
      "distributions [0.49506741762161255, 0.09959698468446732, 0.012629622593522072]\n",
      "[{'decision': 0, 'optimal_auc': 0.9024571854058079, 'imitation_auc': 0.603530534351145, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.981203007518797, 'imitation_auc': 0.6046195652173914, 'optimal_acc': 0.9659863945578231, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7225047679593134, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 144 _____\n",
      "val reward 0.5913370251655579\n",
      "imitation reward 1.447631597518921\n",
      "distance losses 0.30481791496276855 0.11312922090291977\n",
      "distributions [0.5331571698188782, 0.07525189220905304, 0.01267344318330288]\n",
      "[{'decision': 0, 'optimal_auc': 0.9050632911392404, 'imitation_auc': 0.5939885496183206, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9817400644468313, 'imitation_auc': 0.6051630434782608, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7551020408163265}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7266369993642721, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 145 _____\n",
      "val reward 0.6008161306381226\n",
      "imitation reward 1.4376462697982788\n",
      "distance losses 0.3084610104560852 0.13804426789283752\n",
      "distributions [0.5582616329193115, 0.07706175744533539, 0.01584470458328724]\n",
      "[{'decision': 0, 'optimal_auc': 0.9018987341772152, 'imitation_auc': 0.579675572519084, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9785177228786252, 'imitation_auc': 0.6103260869565218, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7619047619047619}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7339478703115068, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 146 _____\n",
      "val reward 0.5886257886886597\n",
      "imitation reward 1.4728844165802002\n",
      "distance losses 0.38248488306999207 0.1051487848162651\n",
      "distributions [0.5490339398384094, 0.09662245959043503, 0.022926414385437965]\n",
      "[{'decision': 0, 'optimal_auc': 0.9000372300819062, 'imitation_auc': 0.5663167938931297, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.976906552094522, 'imitation_auc': 0.6192934782608696, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7349014621741894, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7755102040816326}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 147 _____\n",
      "val reward 0.5909948348999023\n",
      "imitation reward 1.457584261894226\n",
      "distance losses 0.324901282787323 0.13057111203670502\n",
      "distributions [0.5137979984283447, 0.12085848301649094, 0.029798109084367752]\n",
      "[{'decision': 0, 'optimal_auc': 0.9018987341772151, 'imitation_auc': 0.5553435114503817, 'optimal_acc': 0.8163265306122449, 'imitation_acc': 0.8707482993197279}, {'decision': 1, 'optimal_auc': 0.976906552094522, 'imitation_auc': 0.6269021739130435, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7422123331214241, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 148 _____\n",
      "val reward 0.5931427478790283\n",
      "imitation reward 1.3760464191436768\n",
      "distance losses 0.32208675146102905 0.13393577933311462\n",
      "distributions [0.49160492420196533, 0.11247722059488297, 0.02765902318060398]\n",
      "[{'decision': 0, 'optimal_auc': 0.8987341772151899, 'imitation_auc': 0.5596374045801527, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9752953813104189, 'imitation_auc': 0.6019021739130435, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.746026700572155, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 149 _____\n",
      "val reward 0.6033316850662231\n",
      "imitation reward 1.3971149921417236\n",
      "distance losses 0.3211992681026459 0.1274348348379135\n",
      "distributions [0.5040351152420044, 0.09562142193317413, 0.02217809110879898]\n",
      "[{'decision': 0, 'optimal_auc': 0.892963514519732, 'imitation_auc': 0.553912213740458, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9774436090225563, 'imitation_auc': 0.5956521739130435, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7414965986394558}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7364907819453275, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.7482993197278912}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 150 _____\n",
      "val reward 0.6215848922729492\n",
      "imitation reward 1.4277185201644897\n",
      "distance losses 0.3294275403022766 0.15340889990329742\n",
      "distributions [0.5143105387687683, 0.08790309727191925, 0.019298633560538292]\n",
      "[{'decision': 0, 'optimal_auc': 0.8864482501861505, 'imitation_auc': 0.5472328244274809, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9801288936627283, 'imitation_auc': 0.6054347826086957, 'optimal_acc': 0.9319727891156463, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7291799109980929, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7414965986394558}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 151 _____\n",
      "val reward 0.6238143444061279\n",
      "imitation reward 1.5115180015563965\n",
      "distance losses 0.30402833223342896 0.13438932597637177\n",
      "distributions [0.5007199645042419, 0.10418853908777237, 0.020058374851942062]\n",
      "[{'decision': 0, 'optimal_auc': 0.8817944899478779, 'imitation_auc': 0.5286259541984732, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9774436090225564, 'imitation_auc': 0.6065217391304347, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7210884353741497}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7399872854418309, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7687074829931972}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 152 _____\n",
      "val reward 0.628352165222168\n",
      "imitation reward 1.5930625200271606\n",
      "distance losses 0.3263864517211914 0.12397415935993195\n",
      "distributions [0.4660084545612335, 0.11865288764238358, 0.02421632781624794]\n",
      "[{'decision': 0, 'optimal_auc': 0.8844005956813105, 'imitation_auc': 0.5300572519083969, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.9763694951664877, 'imitation_auc': 0.6051630434782609, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7006802721088435}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7616020343293071, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 153 _____\n",
      "val reward 0.643446147441864\n",
      "imitation reward 1.5407401323318481\n",
      "distance losses 0.31981998682022095 0.11965174227952957\n",
      "distributions [0.43551209568977356, 0.12388873100280762, 0.02981211245059967]\n",
      "[{'decision': 0, 'optimal_auc': 0.8868205510052122, 'imitation_auc': 0.5314885496183206, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9742212674543502, 'imitation_auc': 0.6078804347826086, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.6938775510204082}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7670057215511761, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8231292517006803}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 154 _____\n",
      "val reward 0.6525501608848572\n",
      "imitation reward 1.4187020063400269\n",
      "distance losses 0.321209192276001 0.14503581821918488\n",
      "distributions [0.43197667598724365, 0.12321449816226959, 0.03163734823465347]\n",
      "[{'decision': 0, 'optimal_auc': 0.8845867460908414, 'imitation_auc': 0.5305343511450382, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9709989258861439, 'imitation_auc': 0.5983695652173914, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.7006802721088435}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7774952320406865, 'optimal_acc': 0.9931972789115646, 'imitation_acc': 0.8299319727891157}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 155 _____\n",
      "val reward 0.6496842503547668\n",
      "imitation reward 1.3265411853790283\n",
      "distance losses 0.3342142105102539 0.13281628489494324\n",
      "distributions [0.4474368989467621, 0.11524534970521927, 0.0269108135253191]\n",
      "[{'decision': 0, 'optimal_auc': 0.8862620997766195, 'imitation_auc': 0.5353053435114504, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9650912996777659, 'imitation_auc': 0.589945652173913, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9953703703703705, 'imitation_auc': 0.7803560076287349, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8163265306122449}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 156 _____\n",
      "val reward 0.6424888372421265\n",
      "imitation reward 1.3498963117599487\n",
      "distance losses 0.3176461160182953 0.11933223158121109\n",
      "distributions [0.48809659481048584, 0.10529313236474991, 0.020138658583164215]\n",
      "[{'decision': 0, 'optimal_auc': 0.8851451973194341, 'imitation_auc': 0.5391221374045801, 'optimal_acc': 0.8299319727891157, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.966702470461869, 'imitation_auc': 0.5885869565217392, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7755102040816326}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7800381436745073, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 157 _____\n",
      "val reward 0.6650829315185547\n",
      "imitation reward 1.4321727752685547\n",
      "distance losses 0.334820032119751 0.12877097725868225\n",
      "distributions [0.5567359328269958, 0.09224904328584671, 0.01601024903357029]\n",
      "[{'decision': 0, 'optimal_auc': 0.8788160833953834, 'imitation_auc': 0.5458015267175572, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9704618689581095, 'imitation_auc': 0.5978260869565217, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7784488239033693, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 158 _____\n",
      "val reward 0.6883158683776855\n",
      "imitation reward 1.5022594928741455\n",
      "distance losses 0.3259749412536621 0.14691217243671417\n",
      "distributions [0.5925620198249817, 0.08228328078985214, 0.01420622132718563]\n",
      "[{'decision': 0, 'optimal_auc': 0.8786299329858526, 'imitation_auc': 0.5567748091603053, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9699248120300752, 'imitation_auc': 0.6125, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7803560076287349, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 159 _____\n",
      "val reward 0.6602987051010132\n",
      "imitation reward 1.5497872829437256\n",
      "distance losses 0.3480416238307953 0.12931105494499207\n",
      "distributions [0.5845546722412109, 0.08950687944889069, 0.014692085795104504]\n",
      "[{'decision': 0, 'optimal_auc': 0.8847728965003724, 'imitation_auc': 0.5639312977099237, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.891156462585034}, {'decision': 1, 'optimal_auc': 0.978517722878625, 'imitation_auc': 0.61875, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7210884353741497}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.786395422759059, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 160 _____\n",
      "val reward 0.6315515041351318\n",
      "imitation reward 1.5964001417160034\n",
      "distance losses 0.35455816984176636 0.1386488974094391\n",
      "distributions [0.5584856271743774, 0.093768410384655, 0.01592993177473545]\n",
      "[{'decision': 0, 'optimal_auc': 0.8901712583767685, 'imitation_auc': 0.5548664122137406, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9790547798066596, 'imitation_auc': 0.6258152173913043, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7210884353741497}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7848061029879212, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 161 _____\n",
      "val reward 0.6105342507362366\n",
      "imitation reward 1.6058707237243652\n",
      "distance losses 0.3585337698459625 0.14021152257919312\n",
      "distributions [0.5192552208900452, 0.10009050369262695, 0.018931888043880463]\n",
      "[{'decision': 0, 'optimal_auc': 0.8924050632911392, 'imitation_auc': 0.549618320610687, 'optimal_acc': 0.8231292517006803, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9774436090225563, 'imitation_auc': 0.61875, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7835346471710107, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 162 _____\n",
      "val reward 0.6118358969688416\n",
      "imitation reward 1.5624946355819702\n",
      "distance losses 0.36837270855903625 0.13708633184432983\n",
      "distributions [0.48388952016830444, 0.0953933447599411, 0.020917706191539764]\n",
      "[{'decision': 0, 'optimal_auc': 0.8957557706626955, 'imitation_auc': 0.5391221374045801, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9731471535982814, 'imitation_auc': 0.592391304347826, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7800381436745074, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 163 _____\n",
      "val reward 0.6306962966918945\n",
      "imitation reward 1.571838617324829\n",
      "distance losses 0.3444085121154785 0.1301892250776291\n",
      "distributions [0.5058488249778748, 0.08502503484487534, 0.02127210795879364]\n",
      "[{'decision': 0, 'optimal_auc': 0.8937081161578555, 'imitation_auc': 0.5415076335877863, 'optimal_acc': 0.8095238095238095, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9758324382384533, 'imitation_auc': 0.5826086956521739, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7346938775510204}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7673235855054037, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 164 _____\n",
      "val reward 0.6284844875335693\n",
      "imitation reward 1.5483875274658203\n",
      "distance losses 0.3477432429790497 0.1437026411294937\n",
      "distributions [0.4782158434391022, 0.08806826174259186, 0.023036984726786613]\n",
      "[{'decision': 0, 'optimal_auc': 0.8957557706626954, 'imitation_auc': 0.5601145038167938, 'optimal_acc': 0.8027210884353742, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9828141783029002, 'imitation_auc': 0.5804347826086956, 'optimal_acc': 0.9387755102040817, 'imitation_acc': 0.7278911564625851}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7705022250476796, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.782312925170068}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 165 _____\n",
      "val reward 0.6154537200927734\n",
      "imitation reward 1.6241118907928467\n",
      "distance losses 0.33017733693122864 0.1390685886144638\n",
      "distributions [0.46317410469055176, 0.0951215848326683, 0.024412168189883232]\n",
      "[{'decision': 0, 'optimal_auc': 0.8959419210722264, 'imitation_auc': 0.5768129770992366, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9865735767991407, 'imitation_auc': 0.5774456521739131, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.6938775510204082}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7727272727272727, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7891156462585034}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 166 _____\n",
      "val reward 0.6076890826225281\n",
      "imitation reward 1.7246925830841064\n",
      "distance losses 0.36433151364326477 0.16672579944133759\n",
      "distributions [0.46101903915405273, 0.09932193905115128, 0.02406221441924572]\n",
      "[{'decision': 0, 'optimal_auc': 0.8938942665673865, 'imitation_auc': 0.5896946564885496, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.985499462943072, 'imitation_auc': 0.5752717391304347, 'optimal_acc': 0.9523809523809523, 'imitation_acc': 0.6870748299319728}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7749523204068659, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8095238095238095}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 167 _____\n",
      "val reward 0.6076530814170837\n",
      "imitation reward 1.7439271211624146\n",
      "distance losses 0.338766485452652 0.13971766829490662\n",
      "distributions [0.46861720085144043, 0.10742545127868652, 0.022846367210149765]\n",
      "[{'decision': 0, 'optimal_auc': 0.892963514519732, 'imitation_auc': 0.5958969465648855, 'optimal_acc': 0.7959183673469388, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9838882921589689, 'imitation_auc': 0.5853260869565218, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.6870748299319728}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.768595041322314, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 168 _____\n",
      "val reward 0.6142953038215637\n",
      "imitation reward 1.674389123916626\n",
      "distance losses 0.361009806394577 0.1339932680130005\n",
      "distributions [0.46899205446243286, 0.10490094870328903, 0.02172240987420082]\n",
      "[{'decision': 0, 'optimal_auc': 0.8920327624720774, 'imitation_auc': 0.5949427480916031, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8843537414965986}, {'decision': 1, 'optimal_auc': 0.9822771213748657, 'imitation_auc': 0.5839673913043479, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7006802721088435}, {'decision': 2, 'optimal_auc': 1.0, 'imitation_auc': 0.7638270820089001, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "tensor([0.4626, 0.0952, 0.0204], grad_fn=<MeanBackward1>)\n",
      "______epoch 169 _____\n",
      "val reward 0.6287020444869995\n",
      "imitation reward 1.6400294303894043\n",
      "distance losses 0.3546861410140991 0.12764698266983032\n",
      "distributions [0.45553579926490784, 0.0973823294043541, 0.023019282147288322]\n",
      "[{'decision': 0, 'optimal_auc': 0.8950111690245719, 'imitation_auc': 0.5925572519083969, 'optimal_acc': 0.7891156462585034, 'imitation_acc': 0.8775510204081632}, {'decision': 1, 'optimal_auc': 0.9795918367346939, 'imitation_auc': 0.585054347826087, 'optimal_acc': 0.9455782312925171, 'imitation_acc': 0.7006802721088435}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7581055308328036, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.8027210884353742}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(1.2333, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'optimal_auc': 0.8989203276247207, 'imitation_auc': 0.5877862595419847, 'optimal_acc': 0.7755102040816326, 'imitation_acc': 0.8979591836734694}, {'decision': 1, 'optimal_auc': 0.9876476906552094, 'imitation_auc': 0.6926630434782609, 'optimal_acc': 0.9591836734693877, 'imitation_acc': 0.7482993197278912}, {'decision': 2, 'optimal_auc': 0.9976851851851852, 'imitation_auc': 0.7778130959949142, 'optimal_acc': 0.9863945578231292, 'imitation_acc': 0.7959183673469388}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionAttentionModel(\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=1000, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (relu): Softplus(beta=1, threshold=20)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (final_opt_layer): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (final_imitation_layer): Linear(in_features=1000, out_features=100, bias=True)\n",
       "  (final_layer): Linear(in_features=1000, out_features=6, bias=True)\n",
       "  (resize_layer): Linear(in_features=90, out_features=100, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_sequence(array):\n",
    "    #converts a row of boolean values to a unique number e.g. [1,1,0] => 11, [0,0,1] => 100\n",
    "    uniqueify = lambda r: torch.sum(torch.stack([i*(10**ii) for ii,i in enumerate(r)]))\n",
    "    return torch_apply_along_axis(uniqueify,array)\n",
    "\n",
    "def train_decision_model_triplet(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    smodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    use_attention=True,\n",
    "    lr=.001,\n",
    "    epochs=10000,\n",
    "    patience=5,\n",
    "    weights=[0,.5,.5,0], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,1,0], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "    opt_weights=[1,1,1], #weights for policy model for optimal decisions\n",
    "    imitation_weights=[.5,1,1],#weights of imitation decisions, because ic overtrains too quickly\n",
    "    imitation_weight=1,\n",
    "    reward_weight=1,\n",
    "    imitation_triplet_weight=2,\n",
    "    reward_triplet_weight = 2,\n",
    "    shufflecol_chance = 0.2,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    verbose=True,\n",
    "    use_gpu=False,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "\n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    true_ids = train_ids + test_ids #for saving memory without upsampling\n",
    "\n",
    "    dataset = DTDataset()\n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        #this should have an ic condition but we don't use it anumore anywa\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids]).to(model.get_device())\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model_kwargs = {k:v for k,v in model_kwargs.items() if 'attention' not in k and 'embed' not in k}\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "        \n",
    "    device = 'cpu'\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        \n",
    "    model.set_device(device)\n",
    "\n",
    "    tmodel1.set_device(device)\n",
    "    tmodel2.set_device(device)\n",
    "    tmodel3.set_device(device)\n",
    "    smodel3.set_device(device)\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    \n",
    "    optimal_train,transitions_train = calc_optimal_decisions(dataset,train_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                           weights=weights,tweights=tweights,\n",
    "                                          )\n",
    "    optimal_test,transitions_test = calc_optimal_decisions(dataset,test_ids,tmodel1,tmodel2,tmodel3,smodel3,\n",
    "                                          weights=weights,tweights=tweights,\n",
    "                                         )\n",
    "    optimal_train = optimal_train.to(model.get_device())\n",
    "    optimal_test = optimal_test.to(model.get_device())\n",
    "    mse = torch.nn.MSELoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,torch.rand(x.shape[0])).type(torch.FloatTensor)\n",
    "\n",
    "    randchoice = lambda x: x[torch.randint(len(x),(1,))[0]]\n",
    "    tloss_func = torch.nn.TripletMarginLoss()\n",
    "    def get_tloss(row,step,yt,x,imitation=True):\n",
    "        if yt[:,step].std() < .001:\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive_idx= torch.nonzero(yt[:,step] == yt[row,step])\n",
    "        if len(positive_idx) <= 1:\n",
    "            print('no losses','n positive',len(positive_idx),'yt',yt[row,step],'row',row,'step',step,'imitation',imitation,end='\\r')\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive_idx = torch.stack([ii for ii in positive_idx if ii != row]).view(-1)\n",
    "        negative_idx = torch.tensor([ii for ii in range(x.shape[0]) if ii not in positive_idx and ii != row])\n",
    "        if len(positive_idx) < 1 or len(negative_idx) < 1:\n",
    "            print('no losses','n positive',len(positive_idx),'n negative',len(negative_idx),'yt',yt[row,step],'row',row,'step',step,'imitation',imitation,end='\\r')\n",
    "            return torch.tensor([0]).to(device)\n",
    "        positive = x[randchoice(positive_idx)]\n",
    "        negative = x[randchoice(negative_idx)]\n",
    "        anchor = x[row]\n",
    "        if use_attention:\n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,use_saved_memory=True) for xx in [anchor,positive,negative]]\n",
    "        else:    \n",
    "            [anchor_embedding,pos_embedding,neg_embedding] = [model.get_embedding(xx.view(1,-1),position=step,concatenate=False)[int(imitation)] for xx in [anchor,positive,negative]]\n",
    "        tloss = tloss_func(anchor_embedding,pos_embedding,neg_embedding)\n",
    "        return tloss\n",
    "    #save the inputs from the whole dataset for future reference\n",
    "    if use_attention:\n",
    "        full_data = []\n",
    "        for mstep in [0,1,2]:\n",
    "            full_data_step = [baseline, get_dlt(min(mstep,1)),\n",
    "                         get_dlt(mstep),get_pd(mstep),get_nd(mstep),get_cc(mstep),get_mod(mstep)]\n",
    "            full_data_step = torch.cat([formatdf(fd,true_ids) for fd in full_data_step],axis=1)\n",
    "            full_data.append(full_data_step)\n",
    "        full_data = torch.stack(full_data)\n",
    "        model.save_memory(full_data)\n",
    "        print(full_data.shape)\n",
    "        \n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            tmodel1.train(True)\n",
    "            tmodel2.train(True)\n",
    "            tmodel3.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "            y_opt = makegrad(optimal_train)\n",
    "            transition_dict = {k: torch.clone(v).detach() for k,v in transitions_train.items()}\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            tmodel1.eval()\n",
    "            tmodel2.eval()\n",
    "            tmodel3.eval()\n",
    "            y_opt = makegrad(optimal_test)\n",
    "            print(y_opt.mean(axis=0))\n",
    "            transition_dict = {k: torch.clone(v).detach() for k,v in transitions_test.items()}\n",
    "        model.set_device(device)\n",
    "        ytrain = df_to_torch(outcomedf.loc[ids]).to(device)\n",
    "        #imitation losses and decision 1\n",
    "        xxtrained = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrained]\n",
    "        xxtrain = torch.cat(xxtrain,axis=1).to(device)\n",
    "        o1 = model(xxtrain,position=0,use_saved_memory= (not train))\n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1_opt = o1[:,0]\n",
    "    \n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        imitation_loss1 = torch.mul(imitation_loss1,imitation_weights[0])\n",
    "        opt_loss1 = bce(decision1_opt,y_opt[:,0])\n",
    "        opt_loss1 = torch.mul(opt_loss1,opt_weights[0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        x1_imitation = torch.cat(x1_imitation,axis=1).to(device)\n",
    "        \n",
    "        o2 = model(x1_imitation,position=1,use_saved_memory= (not train))\n",
    "            \n",
    "        decision2_imitation = o2[:,4]\n",
    "            \n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        imitation_loss2 = torch.mul(imitation_loss2,imitation_weights[1])\n",
    "        \n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "        \n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        x2_imitation = torch.cat(x2_imitation,axis=1).to(device)\n",
    "        \n",
    "        \n",
    "        o3 = model(x2_imitation,position=2,use_saved_memory= (not train))\n",
    "        \n",
    "        decision3_imitation = o3[:,5]\n",
    "        \n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        imitation_loss3 = torch.mul(imitation_loss3,imitation_weights[2])\n",
    "        \n",
    "        opt_input2 = [\n",
    "            formatdf(baseline,ids), \n",
    "            transition_dict['dlt1'],\n",
    "            formatdf(get_dlt(0),ids),\n",
    "            transition_dict['pd1'],\n",
    "            transition_dict['nd1'], \n",
    "            formatdf(get_cc(0),ids),\n",
    "            transition_dict['mod']\n",
    "                 ]\n",
    "        opt_input2 = [o.to(device) for o in opt_input2]\n",
    "\n",
    "        opt_input2 = torch.cat(opt_input2,axis=1).to(device)\n",
    "        decision2_opt = model(opt_input2,position=1,use_saved_memory= (not train))[:,1]\n",
    "        \n",
    "        opt_loss2 = bce(decision2_opt,y_opt[:,1])\n",
    "        opt_loss2 = torch.mul(opt_loss2,opt_weights[1])\n",
    "        \n",
    "        opt_input3 = [\n",
    "            formatdf(baseline,ids),\n",
    "            transition_dict['dlt1'],\n",
    "            transition_dict['dlt2'],\n",
    "            transition_dict['pd2'],\n",
    "            transition_dict['nd2'],\n",
    "            transition_dict['cc'],\n",
    "            transition_dict['mod'],\n",
    "        ]\n",
    "        opt_input3 = [o.to(device) for o in opt_input3]\n",
    "        opt_input3 = torch.cat(opt_input3,axis=1).to(device)\n",
    "        decision3_opt = model(opt_input3,position=2,use_saved_memory= (not train))[:,2]\n",
    "        \n",
    "        opt_loss3 = bce(decision3_opt,y_opt[:,2])\n",
    "        opt_loss3 = torch.mul(opt_loss3,opt_weights[2])\n",
    "        \n",
    "        iloss = torch.add(torch.add(imitation_loss1,imitation_loss2),imitation_loss3)\n",
    "        iloss = torch.mul(iloss,imitation_weight)\n",
    "        \n",
    "        reward_loss = torch.add(torch.add(opt_loss1,opt_loss2),opt_loss3)\n",
    "        reward_loss =torch.mul(reward_loss,reward_weight)\n",
    "        \n",
    "        loss = torch.add(iloss,reward_loss)\n",
    "        \n",
    "        imitation_tloss = torch.FloatTensor([0]).to(device)\n",
    "        opt_tloss = torch.FloatTensor([0]).to(device)\n",
    "        n_rows = xxtrain.shape[0]\n",
    "        if reward_triplet_weight + imitation_triplet_weight > 0.0001:\n",
    "            for i in range(n_rows):\n",
    "                \n",
    "                if imitation_triplet_weight > .0001:\n",
    "                    imitation_tloss += get_tloss(i,0,ytrain,xxtrain,True)\n",
    "                    imitation_tloss += get_tloss(i,1,ytrain,x1_imitation,True)\n",
    "                    imitation_tloss += get_tloss(i,2,ytrain,x2_imitation,True)\n",
    "                if reward_triplet_weight > .0001:\n",
    "                    opt_tloss += get_tloss(i,0,y_opt,xxtrain,False)\n",
    "                    opt_tloss += get_tloss(i,1,y_opt,opt_input2,False)\n",
    "                    opt_tloss += get_tloss(i,2,y_opt,opt_input3,False)\n",
    "            loss += torch.mul(imitation_tloss[0],imitation_triplet_weight/n_rows)\n",
    "            loss += torch.mul(opt_tloss[0],reward_triplet_weight/n_rows)\n",
    "        losses = [iloss,reward_loss,imitation_tloss*imitation_triplet_weight/n_rows,opt_tloss*reward_triplet_weight/n_rows]\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            distributions = [decision1_opt.mean().item(),decision2_opt.mean().item(),decision3_opt.mean().item()]\n",
    "            imitation = [decision1_imitation,decision2_imitation,decision3_imitation]\n",
    "            optimal = [decision1_opt,decision2_opt,decision3_opt]\n",
    "            for i,decision_im in enumerate(imitation):\n",
    "                deci = decision_im.cpu().detach().numpy()\n",
    "                deci0 = (deci > .5).astype(int)\n",
    "                iout = ytrain[:,i].cpu().detach().numpy()\n",
    "                acci = accuracy_score(iout,deci0)\n",
    "                try:\n",
    "                    auci = roc_auc_score(iout,deci)\n",
    "                except:\n",
    "                    auci = -1\n",
    "                \n",
    "                deco = optimal[i].cpu().detach().numpy()\n",
    "                deci0 = (deco > .5).astype(int)\n",
    "                oout = y_opt[:,i].cpu().detach().numpy()\n",
    "                acco = accuracy_score(oout,deci0)\n",
    "                try:\n",
    "                    auco = roc_auc_score(oout,deco)\n",
    "                except:\n",
    "                    auco=-1\n",
    "                scores.append({'decision': i,'optimal_auc': auco,'imitation_auc': auci,'optimal_acc': acco,'imitation_acc': acci})\n",
    "            return losses, scores, distributions\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics,val_distributions = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        for vm in val_metrics:\n",
    "            vl += (-((vm['optimal_auc']*reward_weight) + (vm['imitation_auc']*imitation_weight)))/10\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('val reward',val_losses[1].item())\n",
    "            print('imitation reward', val_losses[0].item())\n",
    "            print('distance losses',val_losses[2].item(),val_losses[-1].item())\n",
    "            print('distributions',val_distributions)\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            best_val_distributions = val_distributions\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss, best_val_distributions\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [1000,1000], \n",
    "    'opt_layer_size': 20, \n",
    "    'imitation_layer_size': 20, \n",
    "    'dropout': 0.25, \n",
    "    'input_dropout': 0.1, \n",
    "    'shufflecol_chance': 0.5\n",
    "}\n",
    "\n",
    "#1.8424\n",
    "decision_model, decision_score, decision_loss, _ = train_decision_model_triplet(\n",
    "    model1,model2,model3,smodel3,\n",
    "    lr=.01,\n",
    "    imitation_weight=1,\n",
    "    reward_weight=1,\n",
    "    patience=100,\n",
    "    imitation_triplet_weight=0.1,\n",
    "    reward_triplet_weight =0.1, \n",
    "    verbose=True,\n",
    "    weights=[1,1,1,1], #realtive weight of survival, feeding tube, aspiration, andl lrc\n",
    "    tweights=[1,1,1,0], #weight for OS, LRC, FDM, and event (any + FT or AS at 6m) as time to event in weeks\n",
    "    use_attention=True,\n",
    "    **args)\n",
    "\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5687255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>optimal_auc</th>\n",
       "      <th>imitation_auc</th>\n",
       "      <th>optimal_acc</th>\n",
       "      <th>imitation_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.908600</td>\n",
       "      <td>0.581107</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.891156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.687228</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.768707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807057</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.823129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision  optimal_auc  imitation_auc  optimal_acc  imitation_acc\n",
       "0         0     0.908600       0.581107     0.843537       0.891156\n",
       "1         1     0.964017       0.687228     0.904762       0.768707\n",
       "2         2     1.000000       0.807057     0.979592       0.823129"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(decision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f37f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision</th>\n",
       "      <th>optimal_auc</th>\n",
       "      <th>imitation_auc</th>\n",
       "      <th>optimal_acc</th>\n",
       "      <th>imitation_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.841137</td>\n",
       "      <td>0.582061</td>\n",
       "      <td>0.789116</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.972805</td>\n",
       "      <td>0.730978</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945078</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   decision  optimal_auc  imitation_auc  optimal_acc  imitation_acc\n",
       "0         0     0.841137       0.582061     0.789116       0.877551\n",
       "1         1     0.972805       0.730978     0.925170       0.775510\n",
       "2         2     0.945078       0.793388     0.897959       0.809524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model.set_device('cpu')\n",
    "torch.save(decision_model,'../resources/decision_model.pt')\n",
    "pd.DataFrame(decision_score).to_csv('../results/policy_model_score.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
