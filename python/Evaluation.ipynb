{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fa9329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from Constants import *\n",
    "import simplejson\n",
    "from Preprocessing import *\n",
    "from Utils import *\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0847c358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransitionEnsemble(\n",
       "  (base_models): ModuleList(\n",
       "    (0-1): 2 x OutcomeSimulator(\n",
       "      (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=57, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (batchnorm): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.9, inplace=False)\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softmax): LogSoftmax(dim=1)\n",
       "      (disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (nodal_disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (dlt_layers): ModuleList(\n",
       "        (0-7): 8 x Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "      (treatment_layer): Linear(in_features=400, out_features=7, bias=True)\n",
       "    )\n",
       "    (2-3): 2 x OutcomeSimulator(\n",
       "      (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=57, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (batchnorm): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.7, inplace=False)\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softmax): LogSoftmax(dim=1)\n",
       "      (disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (nodal_disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (dlt_layers): ModuleList(\n",
       "        (0-7): 8 x Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "      (treatment_layer): Linear(in_features=400, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (error_models): ModuleList(\n",
       "    (0-19): 20 x OutcomeSimulator(\n",
       "      (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=57, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (batchnorm): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.9, inplace=False)\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softmax): LogSoftmax(dim=1)\n",
       "      (disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (nodal_disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (dlt_layers): ModuleList(\n",
       "        (0-7): 8 x Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "      (treatment_layer): Linear(in_features=400, out_features=7, bias=True)\n",
       "    )\n",
       "    (20-39): 20 x OutcomeSimulator(\n",
       "      (input_dropout): Dropout(p=0.2, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=57, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (batchnorm): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout): Dropout(p=0.7, inplace=False)\n",
       "      (relu): Softplus(beta=1, threshold=20)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softmax): LogSoftmax(dim=1)\n",
       "      (disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (nodal_disease_layer): Linear(in_features=400, out_features=3, bias=True)\n",
       "      (dlt_layers): ModuleList(\n",
       "        (0-7): 8 x Linear(in_features=400, out_features=1, bias=True)\n",
       "      )\n",
       "      (treatment_layer): Linear(in_features=400, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model,transition_model1,transition_model2, outcome_model = load_models()\n",
    "transition_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1207ba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:249: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "         0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 1.]),\n",
       " tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1.])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def transition_sample(state):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    #only train on people with  IC for state 1 since other people can't have any outcomes otherwise\n",
    "    require = None\n",
    "    if state == 1:\n",
    "        require = Const.decisions[0] #we don't expect a state update if there is no treatment\n",
    "        valid_ids = dataset.get_input_state(require=require).index.values\n",
    "        train_ids = [t for t in train_ids if t in valid_ids]\n",
    "        test_ids = [t for t in test_ids if t in valid_ids]\n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids,require=require)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids,require=require)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids,require=require)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids,require=require)\n",
    "\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    return xtrain,xtest,ytrain,ytest\n",
    "\n",
    "transition_sample(0)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411f01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:249: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9402394215953539, 'roc_macro': -1},\n",
       " 'nd': {'accuracy': 0.34658491561181437,\n",
       "  'roc_micro': 0.7366762108707683,\n",
       "  'roc_macro': 0.5140288263382775},\n",
       " 'mod': {'accuracy': 0.34658491561181437,\n",
       "  'roc_micro': 0.7366762108707683,\n",
       "  'roc_macro': 0.5140288263382775},\n",
       " 'dlts': {'accuracy': [1.0,\n",
       "   1.0,\n",
       "   0.9794520547945206,\n",
       "   0.952054794520548,\n",
       "   0.9657534246575342,\n",
       "   0.9657534246575342,\n",
       "   0.9178082191780822,\n",
       "   1.0],\n",
       "  'accuracy_mean': 0.9726027397260274,\n",
       "  'auc': [-1,\n",
       "   -1,\n",
       "   0.592074592074592,\n",
       "   0.6536485097636178,\n",
       "   0.7219858156028368,\n",
       "   0.5333333333333333,\n",
       "   0.5404228855721394,\n",
       "   -1],\n",
       "  'auc_mean': 0.6082930272693039}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mc_metrics(yt,yp,numpy=False,is_dlt=False):\n",
    "    if not numpy:\n",
    "        yt = yt.cpu().detach().numpy()\n",
    "        yp = yp.cpu().detach().numpy()\n",
    "    #dlt prediction (binary)\n",
    "    if is_dlt:\n",
    "        acc = accuracy_score(yt,yp>.5)\n",
    "        if yt.sum() > 1:\n",
    "            auc = roc_auc_score(yt,yp)\n",
    "        else:\n",
    "            auc=-1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': acc, 'mse': error, 'auc': auc}\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    elif yt.ndim > 1:\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        except:\n",
    "            roc_micro=-1\n",
    "        try:\n",
    "            roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        except:\n",
    "            roc_macro = -1\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    #outcomes (binary)\n",
    "    else:\n",
    "        if yp.ndim > 1:\n",
    "            yp = yp.argmax(axis=1)\n",
    "        try:\n",
    "            bacc = accuracy_score(yt,yp)\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc = roc_auc_score(yt,yp)\n",
    "        except:\n",
    "            roc = -1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred,numpy=False):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0],numpy=numpy)\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i].view(-1),is_dlt=True)\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    \n",
    "    acc_mean = np.mean([a for a in dlt_acc if a >= 0])\n",
    "    auc_mean = np.mean([a for a in dlt_auc if a >= 0])\n",
    "    results = {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,\n",
    "               'dlts': {'accuracy': dlt_acc,'accuracy_mean': acc_mean,'auc': dlt_auc,'auc_mean': auc_mean}\n",
    "              }\n",
    "    return results\n",
    "def outcome_metrics(ytrue,ypred,numpy=False):\n",
    "    res = {}\n",
    "    for i, outcome in enumerate(Const.outcomes):\n",
    "        metrics = mc_metrics(ytrue[i],ypred[:,i])\n",
    "        res[outcome] = metrics\n",
    "    return res\n",
    "\n",
    "def evaluate_transition_model(model,state):\n",
    "    [xtrain,xtest, ytrain,ytest] = transition_sample(state)\n",
    "    xtest = xtest.to(model.get_device())\n",
    "    ytest = [yy.to(model.get_device()) for yy in ytest]\n",
    "    ypred = model(xtest)['predictions']\n",
    "    \n",
    "    if state < 3:\n",
    "        metrics = state_metrics(ytest,ypred)\n",
    "    return metrics\n",
    "\n",
    "evaluate_transition_model(transition_model2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcab063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2473621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
