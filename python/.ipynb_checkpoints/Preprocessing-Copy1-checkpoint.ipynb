{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no_dose_adjustment',\n",
       " 1: 'dose_modified',\n",
       " 2: 'dose_delayed',\n",
       " 3: 'dose_cancelled',\n",
       " 4: 'dose_delayed_&_modified',\n",
       " 5: 'regiment_modification',\n",
       " 9: 'unknown'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Const:\n",
    "    data_dir = '../data'\n",
    "    twin_data = data_dir + 'digital_twin_data.csv'\n",
    "    twin_ln_data = data_dir + 'digital_twin_ln_data.csv'\n",
    "    \n",
    "    rename_dict = {\n",
    "        'Dummy ID': 'id',\n",
    "        'Age at Diagnosis (Calculated)': 'age',\n",
    "        'Feeding tube 6m': 'FT',\n",
    "        'Affected Lymph node UPPER': 'affected_nodes',\n",
    "        'Aspiration rate(Y/N)': 'AS',\n",
    "        'Neck boost (Y/N)': 'neck_boost',\n",
    "        'Gender': 'gender',\n",
    "        'Tm Laterality (R/L)': 'laterality',\n",
    "        'AJCC 8th edition': 'ajcc8',\n",
    "        'AJCC 7th edition':'ajcc7',\n",
    "        'N_category_full': 'N-category',\n",
    "        'HPV/P16 status': 'hpv',\n",
    "        'Tumor subsite (BOT/Tonsil/Soft Palate/Pharyngeal wall/GPS/NOS)': 'subsite',\n",
    "        'Total dose': 'total_dose',\n",
    "        'Therapeutic combination': 'treatment',\n",
    "        'Smoking status at Diagnosis (Never/Former/Current)': 'smoking_status',\n",
    "        'Smoking status (Packs/Year)': 'packs_per_year',\n",
    "        'Overall Survival (1=alive,0=dead)': 'os',\n",
    "        'Dose/fraction (Gy)': 'dose_fraction'\n",
    "    }\n",
    "    \n",
    "    dlt_dict = {\n",
    "         'Allergic reaction to Cetuximab': 'DLT_Other',\n",
    "         'Cardiological (A-fib)': 'DLT_Other',\n",
    "         'Dermatological': 'DLT_Dermatological',\n",
    "         'Failure to Thrive': 'DLT_Other',\n",
    "         'Failure to thrive': 'DLT_Other',\n",
    "         'GIT [elevated liver enzymes]': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestina': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestinal': 'DLT_Gastrointestinal',\n",
    "         'General': 'DLT_Other',\n",
    "         'Hematological': 'DLT_Hematological',\n",
    "         'Hematological (Neutropenia)': 'DLT_Hematological',\n",
    "         'Hyponatremia': 'DLT_Other',\n",
    "         'Immunological': 'DLT_Other',\n",
    "         'Infection': 'DLT_Infection (Pneumonia)',\n",
    "         'NOS': 'DLT_Other',\n",
    "         'Nephrological': 'DLT_Nephrological',\n",
    "         'Nephrological (ARF)': 'DLT_Nephrological',\n",
    "         'Neurological': 'DLT_Neurological',\n",
    "         'Neutropenia': 'DLT_Hematological',\n",
    "         'Nutritional': 'DLT_Other',\n",
    "         'Pancreatitis': 'DLT_Other',\n",
    "         'Pulmonary': 'DLT_Other',\n",
    "         'Respiratory (Pneumonia)': 'DLT_Infection (Pneumonia)',\n",
    "         'Sepsis': 'DLT_Infection (Pneumonia)',\n",
    "         'Suboptimal response to treatment' : 'DLT_Other',\n",
    "         'Vascular': 'DLT_Vascular'\n",
    "    }\n",
    "    \n",
    "    decision1 = 'Decision 1 (Induction Chemo) Y/N'\n",
    "    decision2 = 'Decision 2 (CC / RT alone)'\n",
    "    decision3 = 'Decision 3 Neck Dissection (Y/N)'\n",
    "    decisions = [decision1,decision2, decision3]\n",
    "    outcomes = ['Overall Survival (4 Years)', 'FT', 'Aspiration rate Post-therapy']\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    primary_disease_states = ['CR Primary','PR Primary','SD Primary']\n",
    "    nodal_disease_states = [t.replace('Primary','Nodal') for t in primary_disease_states]\n",
    "    dlt1 = list(set(dlt_dict.values()))\n",
    "    state2 = list(modification_types.values()) + primary_disease_states+nodal_disease_states +dlt1 #+['No imaging 0=N,1=Y']\n",
    "    \n",
    "    primary_disease_states2 = [t + ' 2' for t in primary_disease_states]\n",
    "    nodal_disease_states2 = [t + ' 2' for t in nodal_disease_states]\n",
    "    dlt2 = [d + ' 2' for d in dlt1]\n",
    "    \n",
    "    state3 = list(cc_types.values()) + primary_disease_states2 + nodal_disease_states2 + dlt2\n",
    "    \n",
    "Const.modification_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d02b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_cleaned):\n",
    "    #this was Elisa's preprocessing except I removed all the Ifs because that's dumb\n",
    "    if len(data_cleaned.shape) < 2:\n",
    "        data_cleaned = pd.DataFrame([data], columns=data.index)\n",
    "        \n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'N', 'Aspiration rate Pre-therapy'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'Y', 'Aspiration rate Pre-therapy'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'I', 'Pathological Grade'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'II', 'Pathological Grade'] = 2\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'III', 'Pathological Grade'] = 3\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'IV', 'Pathological Grade'] = 4\n",
    "\n",
    "    data_cleaned.loc[(data_cleaned['T-category'] == 'Tx') | (data_cleaned['T-category'] == 'Tis'), 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T1', 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T2', 'T-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T3', 'T-category'] = 3\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T4', 'T-category'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N0', 'N-category'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N1', 'N-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N2', 'N-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N3', 'N-category'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N0', 'N-category_8th_edition'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N1', 'N-category_8th_edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N2', 'N-category_8th_edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N3', 'N-category_8th_edition'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'I', 'AJCC 7th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'II', 'AJCC 7th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'III', 'AJCC 7th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'IV', 'AJCC 7th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'I', 'AJCC 8th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'II', 'AJCC 8th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'III', 'AJCC 8th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'IV', 'AJCC 8th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Male', 'Gender'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Female', 'Gender'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Positive', 'HPV/P16 status'] = 1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Negative', 'HPV/P16 status'] = -1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Unknown', 'HPV/P16 status'] = 0\n",
    "\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Formar', 'Smoking status at Diagnosis (Never/Former/Current)'] = .5\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Current', 'Smoking status at Diagnosis (Never/Former/Current)'] = 1\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Never', 'Smoking status at Diagnosis (Never/Former/Current)'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Chemo Modification (Y/N)'] == 'Y', 'Chemo Modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'N', 'DLT (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'Y', 'DLT (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Other'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT_Type'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT_Type']):\n",
    "            if i.strip() != '' and data_cleaned.loc[index, Const.dlt_dict[i.strip()]] == 0:\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()]] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'RT alone', 'Decision 2 (CC / RT alone)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'CC', 'Decision 2 (CC / RT alone)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'N', 'CC modification (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'Y', 'CC modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Dermatological 2'] = 0\n",
    "    data_cleaned['DLT_Neurological 2'] = 0\n",
    "    data_cleaned['DLT_Gastrointestinal 2'] = 0\n",
    "    data_cleaned['DLT_Hematological 2'] = 0\n",
    "    data_cleaned['DLT_Nephrological 2'] = 0\n",
    "    data_cleaned['DLT_Vascular 2'] = 0\n",
    "    data_cleaned['DLT_Infection (Pneumonia) 2'] = 0\n",
    "    data_cleaned['DLT_Other 2'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT 2'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT 2']):\n",
    "            if i.strip() != '':\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()] + ' 2'] = 1\n",
    "\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'N', 'Decision 3 Neck Dissection (Y/N)'] = 0\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'Y', 'Decision 3 Neck Dissection (Y/N)'] = 1\n",
    "\n",
    "    return data_cleaned\n",
    "\n",
    "def merge_editions(row,basecol='AJCC 8th edition',fallback='AJCC 7th edition'):\n",
    "    if pd.isnull(row[basecol]):\n",
    "        return row[fallback]\n",
    "    return row[basecol]\n",
    "\n",
    "\n",
    "def preprocess_dt_data(df,extra_to_keep=None):\n",
    "    \n",
    "    to_keep = ['id','hpv','age','packs_per_year','smoking_status','gender','Aspiration rate Pre-therapy','total_dose','dose_fraction'] \n",
    "    to_onehot = ['T-category','N-category','AJCC','Pathological Grade','subsite','treatment','ln_cluster']\n",
    "    if extra_to_keep is not None:\n",
    "        to_keep = to_keep + [c for c in extra_to_keep if c not in to_keep and c not in to_onehot]\n",
    "    \n",
    "    decisions =Const.decisions\n",
    "    outcomes = Const.outcomes\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    for k,v in Const.cc_types.items():\n",
    "        df[v] = df['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)'].apply(lambda x: int(Const.cc_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    for k,v in Const.modification_types.items():\n",
    "        name = 'Modification Type (0= no dose adjustment, 1=dose modified, 2=dose delayed, 3=dose cancelled, 4=dose delayed & modified, 5=regimen modification, 9=unknown)'\n",
    "        df[v] = df[name].apply(lambda x: int(Const.modification_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    #Features to keep. I think gender is is in \n",
    "    \n",
    "    keywords = []\n",
    "    for keyword in keywords:\n",
    "        toadd = [c for c in df.columns if keyword in c and c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    \n",
    "    df['packs_per_year'] = df['packs_per_year'].apply(lambda x: str(x).replace('>','').replace('<','')).astype(float).fillna(0)\n",
    "    #so I'm actually not sure if this is biological sex or gender given this is texas\n",
    "    df['AJCC'] = df.apply(lambda row: merge_editions(row,'ajcc8','ajcc7'),axis=1)\n",
    "    df['N-category'] = df.apply(lambda row: merge_editions(row,'N-category_8th_edition','N-category'),axis=1)\n",
    "    \n",
    "    dummy_df = pd.get_dummies(df[to_onehot].fillna(0).astype(str),drop_first=False)\n",
    "    for col in dummy_df.columns:\n",
    "        df[col] = dummy_df[col]\n",
    "        to_keep.append(col)\n",
    "        \n",
    "    yn_to_binary = ['FT','Aspiration rate Post-therapy']\n",
    "    for col in yn_to_binary:\n",
    "        df[col] = df[col].apply(lambda x: int(x == 'Y'))\n",
    "        \n",
    "    to_keep = to_keep + [c for c in df.columns if 'DLT' in c]\n",
    "    \n",
    "        \n",
    "    for statelist in [Const.state2,Const.state3,Const.decisions,Const.outcomes]:\n",
    "        toadd = [c for c in statelist if c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    return df[to_keep].set_index('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e719a1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/947294080.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/947294080.py:17: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/947294080.py:18: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_dose_adjustment</th>\n",
       "      <th>dose_modified</th>\n",
       "      <th>dose_delayed</th>\n",
       "      <th>dose_cancelled</th>\n",
       "      <th>dose_delayed_&amp;_modified</th>\n",
       "      <th>regiment_modification</th>\n",
       "      <th>unknown</th>\n",
       "      <th>CR Primary</th>\n",
       "      <th>PR Primary</th>\n",
       "      <th>SD Primary</th>\n",
       "      <th>...</th>\n",
       "      <th>PR Nodal</th>\n",
       "      <th>SD Nodal</th>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <th>DLT_Other</th>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <th>DLT_Hematological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_dose_adjustment  dose_modified  dose_delayed  dose_cancelled  \\\n",
       "id                                                                       \n",
       "3                       1              0             0               0   \n",
       "5                       1              0             0               0   \n",
       "6                       1              0             0               0   \n",
       "7                       1              0             0               0   \n",
       "8                       1              0             0               0   \n",
       "...                   ...            ...           ...             ...   \n",
       "10201                   1              0             0               0   \n",
       "10202                   1              0             0               0   \n",
       "10203                   1              0             0               0   \n",
       "10204                   1              0             0               0   \n",
       "10205                   1              0             0               0   \n",
       "\n",
       "       dose_delayed_&_modified  regiment_modification  unknown  CR Primary  \\\n",
       "id                                                                           \n",
       "3                            0                      0        0           0   \n",
       "5                            0                      0        0           0   \n",
       "6                            0                      0        0           0   \n",
       "7                            0                      0        0           0   \n",
       "8                            0                      0        0           0   \n",
       "...                        ...                    ...      ...         ...   \n",
       "10201                        0                      0        0           0   \n",
       "10202                        0                      0        0           0   \n",
       "10203                        0                      0        0           0   \n",
       "10204                        0                      0        0           0   \n",
       "10205                        0                      0        0           0   \n",
       "\n",
       "       PR Primary  SD Primary  ...  PR Nodal  SD Nodal  DLT_Gastrointestinal  \\\n",
       "id                             ...                                             \n",
       "3               0           0  ...         0         0                     0   \n",
       "5               0           0  ...         0         0                     0   \n",
       "6               0           0  ...         0         0                     0   \n",
       "7               0           0  ...         0         0                     0   \n",
       "8               0           0  ...         0         0                     0   \n",
       "...           ...         ...  ...       ...       ...                   ...   \n",
       "10201           0           0  ...         0         0                     0   \n",
       "10202           0           0  ...         0         0                     0   \n",
       "10203           0           0  ...         0         0                     0   \n",
       "10204           0           0  ...         0         0                     0   \n",
       "10205           0           0  ...         0         0                     0   \n",
       "\n",
       "       DLT_Other  DLT_Neurological  DLT_Dermatological  \\\n",
       "id                                                       \n",
       "3              0                 0                   0   \n",
       "5              0                 0                   0   \n",
       "6              0                 0                   0   \n",
       "7              0                 0                   0   \n",
       "8              0                 0                   0   \n",
       "...          ...               ...                 ...   \n",
       "10201          0                 0                   0   \n",
       "10202          0                 0                   0   \n",
       "10203          0                 0                   0   \n",
       "10204          0                 0                   0   \n",
       "10205          0                 0                   0   \n",
       "\n",
       "       DLT_Infection (Pneumonia)  DLT_Vascular  DLT_Nephrological  \\\n",
       "id                                                                  \n",
       "3                              0             0                  0   \n",
       "5                              0             0                  0   \n",
       "6                              0             0                  0   \n",
       "7                              0             0                  0   \n",
       "8                              0             0                  0   \n",
       "...                          ...           ...                ...   \n",
       "10201                          0             0                  0   \n",
       "10202                          0             0                  0   \n",
       "10203                          0             0                  0   \n",
       "10204                          0             0                  0   \n",
       "10205                          0             0                  0   \n",
       "\n",
       "       DLT_Hematological  \n",
       "id                        \n",
       "3                      0  \n",
       "5                      0  \n",
       "6                      0  \n",
       "7                      0  \n",
       "8                      0  \n",
       "...                  ...  \n",
       "10201                  0  \n",
       "10202                  0  \n",
       "10203                  0  \n",
       "10204                  0  \n",
       "10205                  0  \n",
       "\n",
       "[536 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DTDataset():\n",
    "    \n",
    "    def __init__(self,data_file = '../data/digital_twin_data.csv',ln_data_file = '../data/digital_twin_ln_data.csv'):\n",
    "        df = pd.read_csv(data_file)\n",
    "        \n",
    "        df = preprocess(df)\n",
    "        df = df.rename(columns = Const.rename_dict).copy()\n",
    "        df = df.drop('MRN OPC',axis=1)\n",
    "\n",
    "        ln_data = pd.read_csv(ln_data_file)\n",
    "        ln_data = ln_data.rename(columns={'cluster':'ln_cluster'})\n",
    "        self.ln_cols = [c for c in ln_data.columns if c not in df.columns]\n",
    "        df = df.merge(ln_data,on='id')\n",
    "        self.df=df\n",
    "        self.processed_df = preprocess_dt_data(df,self.ln_cols).fillna(0)\n",
    "        \n",
    "        self.means = self.processed_df.mean(axis=0)\n",
    "        self.stds = self.processed_df.std(axis=0)\n",
    "        self.maxes = self.processed_df.max(axis=0)\n",
    "        self.mins = self.processed_df.min(axis=0)\n",
    "        \n",
    "        arrays = self.get_states()\n",
    "        self.state_sizes = {k: (v.shape[1] if v.ndim > 1 else 1) for k,v in arrays.items()}\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.processed_df\n",
    "    \n",
    "    def sample(self,frac=.5):\n",
    "        return self.processed_df.sample(frac=frac)\n",
    "    \n",
    "    def split_sample(self,ratio = .3):\n",
    "        assert(ratio > 0 and ratio <= 1)\n",
    "        df1 = self.processed_df.sample(frac=1-ratio)\n",
    "        df2 = self.processed_df.drop(index=df1.index)\n",
    "        return df1,df2\n",
    "    \n",
    "    def get_states(self,fixed=None,ids = None):\n",
    "        processed_df = self.processed_df.copy()\n",
    "        if ids is not None:\n",
    "            processed_df = processed_df.loc[ids]\n",
    "        if fixed is not None:\n",
    "            for col,val in fixed.items():\n",
    "                if col in processed_df.columns:\n",
    "                    processed_df[col] = val\n",
    "                else:\n",
    "                    print('bad fixed entry',col)\n",
    "                    \n",
    "        to_skip = ['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)','DLT_Type','DLT 2'] + [c for c in processed_df.columns if 'treatment' in c]\n",
    "        other_states = set(Const.decisions + Const.state3 + Const.state2 + Const.outcomes  + to_skip)\n",
    "\n",
    "        base_state = sorted([c for c in processed_df.columns if c not in other_states])\n",
    "\n",
    "        dlt1 = Const.dlt1\n",
    "        state2 = Const.state2 \n",
    "        state3 =  Const.state3 \n",
    "\n",
    "        outcomes = Const.outcomes\n",
    "        decisions= Const.decisions\n",
    "        #intermediate states are only udated values. Models should use baseline + state2 etc\n",
    "        results = {\n",
    "            'baseline': processed_df[base_state],\n",
    "            'state2': processed_df[state2],\n",
    "            'state3': processed_df[state3],\n",
    "            'outcomes': processed_df[outcomes],\n",
    "            'decision1': processed_df[decisions[0]],\n",
    "            'decision2': processed_df[decisions[1]],\n",
    "            'decision3': processed_df[decisions[2]],\n",
    "        }\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def normalize(self,df):\n",
    "        means = self.means[df.columns]\n",
    "        std = self.stds[df.columns]\n",
    "        return ((df - means)/std).fillna(0)\n",
    "    \n",
    "    def get_state(self,num=1,normalize=False,**kwargs):\n",
    "        states = self.get_states(**kwargs)\n",
    "        state = states['baseline']\n",
    "        assert(num in [1,2,3])\n",
    "        if num > 1:\n",
    "            state = state.merge(states['state'+str(num)],on='id')\n",
    "        if normalize:\n",
    "            return self.normalize(state)\n",
    "        return state\n",
    "    \n",
    "    def get_intermediate_outcomes(self,num=2,**kwargs):\n",
    "        states = self.get_states(**kwargs)\n",
    "        assert(num in [2,3])\n",
    "        return states['state'+str(num)]\n",
    "    \n",
    "    def get_outcomes(self,**kwargs):\n",
    "        states = self.get_outcomes(**kwargs)\n",
    "        return states['outcomes']\n",
    "    \n",
    "data = DTDataset()\n",
    "data.get_intermediate_outcomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c221016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chemo Modification (Y/N)',\n",
       " 'Modification Type (0= no dose adjustment, 1=dose modified, 2=dose delayed, 3=dose cancelled, 4=dose delayed & modified, 5=regimen modification, 9=unknown)',\n",
       " 'CC modification (Y/N)',\n",
       " 'regiment_modification']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in data.df.columns if 'modification' in c.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e31769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433, -1.1674],\n",
       "        [34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433,  0.5397],\n",
       "        [34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433,  0.5570],\n",
       "        ...,\n",
       "        [34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433,  1.4192],\n",
       "        [34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433,  0.5570],\n",
       "        [34.7387, -0.1063,  0.0000,  ..., -0.1063, -0.8433,  0.5397]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)\n",
    "\n",
    "df_to_torch(data.get_state(1,fixed={'1A': 3},normalize=True,ids=data.split_sample()[1].index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a87a4d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5358, 0.5109, 0.5215,  ..., 0.5798, 0.3287, 0.4508],\n",
       "        [0.3211, 0.4001, 0.7209,  ..., 0.5084, 0.4035, 0.5867],\n",
       "        [0.3345, 0.7183, 0.4821,  ..., 0.1275, 0.3235, 0.4268],\n",
       "        ...,\n",
       "        [0.3504, 0.5385, 0.2055,  ..., 0.3352, 0.5954, 0.3697],\n",
       "        [0.4871, 0.4768, 0.5843,  ..., 0.5876, 0.7455, 0.1747],\n",
       "        [0.5662, 0.6564, 0.2497,  ..., 0.5460, 0.4809, 0.3786]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OutcomeSimulator1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_layers = [1000],\n",
    "                 dropout = .5,\n",
    "                 input_dropout=0,\n",
    "                ):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        \n",
    "        self.input_dropout = torch.nn.Dropout(input_dropout)\n",
    "        \n",
    "        first_layer =torch.nn.Linear(input_size,hidden_layers[0],bias=True)\n",
    "        layers = [first_layer,torch.nn.ReLU()]\n",
    "        curr_size = hidden_layers[0]\n",
    "        for ndim in hidden_layers[1:]:\n",
    "            layer = torch.nn.Linear(curr_size,ndim)\n",
    "            curr_size = ndim\n",
    "            layers.append(layer)\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(hidden_layers[-1])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.primary_disease_states))\n",
    "        self.nodal_disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.nodal_disease_states))\n",
    "#         final_layers = []\n",
    "#         for size in output_sizes:\n",
    "#             sin= torch.nn.Linear(hidden_layers[-1],output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "outcomes1_model = OutcomeSimulator(data.state_sizes['baseline'],data.state_sizes['state2'])\n",
    "outcomes2_model = OutcomeSimulator(data.state_sizes['baseline']+data.state_sizes['state2'],data.state_sizes['state3'])\n",
    "x = df_to_torch(data.get_state(1,normalize=True))\n",
    "y = df_to_torch(data.get_intermediate_outcomes(2))\n",
    "outcomes1_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a73b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 3., 3., 3., 4., 1., 3., 1., 1., 4., 1., 1., 1.,\n",
       "       1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.detach().numpy().max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20c9c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score , f1_score\n",
    "def multi_bce_loss(ypred,target,weights=None):\n",
    "    #loss for predicting multiple of non-exclusive binary values\n",
    "    nclasses = ypred.shape[1]\n",
    "    if weights is None:\n",
    "        weights = torch.ones(nclasses).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    bce = torch.nn.BCELoss()\n",
    "    total_loss = torch.tensor([0],dtype=torch.float32,device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for i in range(nclasses):\n",
    "        closs = bce(ypred[:,i],target[:,i])\n",
    "        total_loss += weights[i]*closs.item()\n",
    "    return total_loss\n",
    "\n",
    "def multiclass_metrics(ypred,target):\n",
    "    nclasses = ypred.shape[1]\n",
    "    ypred = ypred.cpu().detach().numpy().astype(float)\n",
    "    target = (target.cpu().detach().numpy() > 0).astype(float)\n",
    "    aucs = []\n",
    "    f1s = []\n",
    "    for i in range(nclasses):\n",
    "        if target[:,i].std() < .0001 and ypred[:].argmax(axis=1).sum() > 0:\n",
    "            auc_score = -1\n",
    "            f1_scores = -1\n",
    "        else:\n",
    "            auc_score = roc_auc_score(target[:,i],ypred[:,i])\n",
    "            f1_scores = f1_score(target[:,i],ypred[:].argmax(axis=1) == i)\n",
    "        aucs.append(auc_score)\n",
    "        f1s.append(f1_scores)\n",
    "    return {'auc': aucs, 'f1': f1s}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f90f373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([536, 21])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f3d5fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "16.000381469726562\n",
      "epoch 0 train loss 16.000381469726562\n",
      "val loss 15.041558265686035 0.43012409908877586 -0.04082214082214083\n",
      "0 0\n",
      "16.07006072998047\n",
      "epoch 1 train loss 16.07006072998047\n",
      "val loss 15.024404525756836 0.429974817128273 -0.042326121244220326\n",
      "0 0\n",
      "16.033220291137695\n",
      "epoch 2 train loss 16.033220291137695\n",
      "val loss 15.009340286254883 0.4302254228160023 -0.045679855632437476\n",
      "0 0\n",
      "15.986144065856934\n",
      "epoch 3 train loss 15.986144065856934\n",
      "val loss 14.99630355834961 0.4295757641202247 -0.044862971014732536\n",
      "0 0\n",
      "15.930232048034668\n",
      "epoch 4 train loss 15.930232048034668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 14.985233306884766 0.4296094158072125 -0.04244945428520308\n",
      "0 0\n",
      "16.050121307373047\n",
      "epoch 5 train loss 16.050121307373047\n",
      "val loss 14.976068496704102 0.42996292784929985 -0.03620637169182446\n",
      "0 0\n",
      "16.150718688964844\n",
      "epoch 6 train loss 16.150718688964844\n",
      "val loss 14.968751907348633 0.4296945457580045 -0.03686327304748358\n",
      "0 0\n",
      "16.164289474487305\n",
      "epoch 7 train loss 16.164289474487305\n",
      "val loss 14.963224411010742 0.4294917381651211 -0.0319042944042944\n",
      "0 0\n",
      "16.07388687133789\n",
      "epoch 8 train loss 16.07388687133789\n",
      "val loss 14.95942497253418 0.42881449973886465 -0.03105395426823998\n",
      "0 0\n",
      "16.04673194885254\n",
      "epoch 9 train loss 16.04673194885254\n",
      "val loss 14.95728874206543 0.4282160876946966 -0.031189428087924333\n",
      "0 0\n",
      "16.081722259521484\n",
      "epoch 10 train loss 16.081722259521484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1436: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  precision = _prf_divide(tp_sum, pred_sum,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 14.956747055053711 0.4286299139100457 -0.03131795453224025\n",
      "0 0\n",
      "15.944466590881348\n",
      "epoch 11 train loss 15.944466590881348\n",
      "val loss 14.95772647857666 0.4290229554605365 -0.03131795453224025\n",
      "0 0\n",
      "15.902392387390137\n",
      "epoch 12 train loss 15.902392387390137\n",
      "val loss 14.960153579711914 0.428694135064083 -0.030930807803630094\n",
      "0 0\n",
      "15.986706733703613\n",
      "epoch 13 train loss 15.986706733703613\n",
      "val loss 14.963940620422363 0.42908663948198733 -0.03290525611954183\n",
      "0 0\n",
      "16.095243453979492\n",
      "epoch 14 train loss 16.095243453979492\n",
      "val loss 14.969000816345215 0.42945346846836074 -0.032381969881969876\n",
      "0 0\n",
      "16.13425636291504\n",
      "epoch 15 train loss 16.13425636291504\n",
      "val loss 14.975238800048828 0.42949804386162427 -0.03273210993799229\n",
      "0 0\n",
      "15.939824104309082\n",
      "epoch 16 train loss 15.939824104309082\n",
      "val loss 14.982558250427246 0.4293163071994378 -0.03480781201369437\n",
      "0 0\n",
      "15.958976745605469\n",
      "epoch 17 train loss 15.958976745605469\n",
      "val loss 14.990853309631348 0.4291753922555666 -0.036697614056104624\n",
      "0 0\n",
      "16.049705505371094\n",
      "epoch 18 train loss 16.049705505371094\n",
      "val loss 15.00001335144043 0.42905640575598336 -0.036365587408288505\n",
      "0 0\n",
      "15.98098373413086\n",
      "epoch 19 train loss 15.98098373413086\n",
      "val loss 15.009932518005371 0.4294698289369285 -0.03564408668678778\n",
      "0 0\n",
      "16.032108306884766\n",
      "epoch 20 train loss 16.032108306884766\n",
      "val loss 15.020491600036621 0.43014866355968817 -0.03502891238740295\n",
      "0 0\n",
      "16.02883529663086\n",
      "epoch 21 train loss 16.02883529663086\n",
      "val loss 15.031584739685059 0.43022607925745554 -0.03523454855899893\n",
      "best loss 14.956747055053711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(OutcomeSimulator(\n",
       "   (input_dropout): Dropout(p=0, inplace=False)\n",
       "   (layers): ModuleList(\n",
       "     (0): Linear(in_features=61, out_features=1000, bias=True)\n",
       "     (1): ReLU()\n",
       "   )\n",
       "   (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (dropout): Dropout(p=0.5, inplace=False)\n",
       "   (final_layer): Linear(in_features=1000, out_features=21, bias=True)\n",
       "   (sigmoid): Sigmoid()\n",
       " ),\n",
       " {'auc': [0.6376716808371485,\n",
       "   0.8075268817204301,\n",
       "   0.3080168776371308,\n",
       "   0.43312101910828027,\n",
       "   0.4789029535864979,\n",
       "   0.4365591397849462,\n",
       "   -1,\n",
       "   0.5909367396593674,\n",
       "   0.5472636815920398,\n",
       "   0.2515923566878981,\n",
       "   0.6217948717948718,\n",
       "   0.4561302681992337,\n",
       "   0.8016877637130801,\n",
       "   0.6419354838709677,\n",
       "   0.7628205128205129,\n",
       "   0.7064516129032259,\n",
       "   0.6666666666666666,\n",
       "   0.41874999999999996,\n",
       "   -1,\n",
       "   0.81875,\n",
       "   0.6146496815286624],\n",
       "  'f1': [0.2625,\n",
       "   0.2222222222222222,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   -1,\n",
       "   0.3333333333333333,\n",
       "   0.10256410256410256,\n",
       "   0.0,\n",
       "   0.15384615384615385,\n",
       "   0.0,\n",
       "   0.14285714285714288,\n",
       "   0.125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   -1,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'loss': 14.956747055053711})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_state1(dataset,model_args={},lr=.00001,epochs=1000,patience=10):\n",
    "    model = OutcomeSimulator(dataset.state_sizes['baseline'],dataset.state_sizes['state2'],**model_args)\n",
    "    for param in model.parameters():\n",
    "        param.required_grad=True\n",
    "    train_idx,test_idx = [i.index for i in dataset.split_sample()]\n",
    "    xtrain = df_to_torch(dataset.get_state(1,normalize=False,ids=train_idx))\n",
    "    xtest = df_to_torch(dataset.get_state(1,normalize=False,ids=test_idx))\n",
    "    ytrain = df_to_torch(data.get_intermediate_outcomes(2,ids=train_idx),torch.LongTensor)\n",
    "    ytest = df_to_torch(data.get_intermediate_outcomes(2,ids=test_idx),torch.LongTensor)\n",
    "    \n",
    "    maxy = torch.max(torch.tensor([ytrain.max(),ytest.max()]))\n",
    "    ytrain = (ytrain > 0).type(torch.FloatTensor)\n",
    "    ytest = (ytest > 0).type(torch.FloatTensor)\n",
    "    model = model.to('cuda')\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to('cuda')\n",
    "        xtrain = xtrain.to('cuda')\n",
    "        xtest = xtest.to('cuda')\n",
    "        ytrain = ytrain.to('cuda')\n",
    "        ytest = ytest.to('cuda')\n",
    "        \n",
    "   \n",
    "    \n",
    "    ytrain.requires_grad=True\n",
    "    normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "    unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_val_metrics = {}\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ypred = model(normalize(xtrain))\n",
    "        print(ypred.get_device(),ytrain.get_device())\n",
    "        loss = multi_bce_loss(ypred.to('cuda'),ytrain.to('cuda'))\n",
    "        loss.requires_grad=True\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.train(False)\n",
    "        yval = model(normalize(xtest))\n",
    "        val_loss = multi_bce_loss(yval,ytest)\n",
    "        val_metrics = multiclass_metrics(yval,ytest)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_val_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        print('val loss',val_loss.item(),np.mean(val_metrics['auc']),np.mean(val_metrics['f1']))\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss)\n",
    "    best_val_metrics['loss']= best_val_loss\n",
    "    return model, best_val_metrics\n",
    "train_state1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
