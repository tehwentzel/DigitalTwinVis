{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "050c878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score,precision_recall_fscore_support\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "import copy\n",
    "from Utils import *\n",
    "pd.set_option('display.max_rows', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be070e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>L1A</th>\n",
       "      <th>L1B</th>\n",
       "      <th>L2A</th>\n",
       "      <th>L2B</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5A</th>\n",
       "      <th>L5B</th>\n",
       "      <th>L6</th>\n",
       "      <th>...</th>\n",
       "      <th>R1A</th>\n",
       "      <th>R1B</th>\n",
       "      <th>R2A</th>\n",
       "      <th>R2B</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5A</th>\n",
       "      <th>R5B</th>\n",
       "      <th>R6</th>\n",
       "      <th>RRPLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>10203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>10204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  L1A  L1B  L2A  L2B   L3   L4  L5A  L5B   L6  ...  R1A  R1B  R2A  \\\n",
       "0        3  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1        5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "2        6  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "3        7  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "..     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "531  10201  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "532  10202  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "533  10203  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "534  10204  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "535  10205  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "     R2B   R3   R4  R5A  R5B   R6  RRPLN  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "2    1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "..   ...  ...  ...  ...  ...  ...    ...  \n",
       "531  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "532  1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "533  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "534  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "535  0.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "\n",
       "[536 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/digital_twin_ln_monograms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <td>4.7</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>148.366667</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDM (months)</th>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.466667</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>144.366667</td>\n",
       "      <td>136.033333</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_to_event</th>\n",
       "      <td>4.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.066667</td>\n",
       "      <td>6.633333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>139.033333</td>\n",
       "      <td>139.3</td>\n",
       "      <td>140.6</td>\n",
       "      <td>142.833333</td>\n",
       "      <td>143.033333</td>\n",
       "      <td>143.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>136.033333</td>\n",
       "      <td>152.6</td>\n",
       "      <td>155.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Survival (1=alive, 0=dead)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LRC</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/Caucasion</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic/Latino</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>African American/Black</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_none</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_platinum</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_cetuximab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_others</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_dose_adjustment</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_modified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_delayed</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_cancelled</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_delayed_&amp;_modified</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regiment_modification</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_CC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_IC+CC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_IC+Radiation alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_Radiation alone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Hematological</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Other</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Dermatological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Neurological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Gastrointestinal 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Hematological 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Nephrological 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Vascular 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Infection (Pneumonia) 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Other 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Primary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Nodal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Primary 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Primary 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Primary 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR Nodal 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PR Nodal 2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD Nodal 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 1 (Induction Chemo) Y/N</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 2 (CC / RT alone)</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision 3 Neck Dissection (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall Survival (4 Years)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Post-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                                      3         5          6          7      \\\n",
       "hpv                                         1         0          1          1   \n",
       "age                                 55.969444     20.95  69.930556  72.319444   \n",
       "packs_per_year                            0.0      38.0       35.0        0.0   \n",
       "gender                                      1         1          0          1   \n",
       "smoking_status                            0.0       1.0        1.0        1.0   \n",
       "Aspiration rate Pre-therapy                 0         0          1          0   \n",
       "OS (Calculated)                      6.033333  7.333333   7.466667        7.8   \n",
       "Locoregional control (Time)               4.7  7.333333   7.466667        7.8   \n",
       "FDM (months)                         6.033333  7.333333   7.466667        7.8   \n",
       "time_to_event                             4.7       6.0        6.0        6.0   \n",
       "Overall Survival (1=alive, 0=dead)          0         0          0          0   \n",
       "LRC                                         0         1          1          1   \n",
       "DC                                          1         1          1          1   \n",
       "bilateral                               False     False       True      False   \n",
       "White/Caucasion                          True      True       True       True   \n",
       "Hispanic/Latino                         False     False      False      False   \n",
       "African American/Black                  False     False      False      False   \n",
       "Asian                                   False     False      False      False   \n",
       "cc_none                                     0         0          0          1   \n",
       "cc_platinum                                 0         1          1          0   \n",
       "cc_cetuximab                                1         0          0          0   \n",
       "cc_others                                   0         0          0          0   \n",
       "no_dose_adjustment                          1         1          1          1   \n",
       "dose_modified                               0         0          0          0   \n",
       "dose_delayed                                0         0          0          0   \n",
       "dose_cancelled                              0         0          0          0   \n",
       "dose_delayed_&_modified                     0         0          0          0   \n",
       "regiment_modification                       0         0          0          0   \n",
       "T-category_1                                0         0          0          1   \n",
       "T-category_2                                1         0          0          0   \n",
       "T-category_3                                0         0          0          0   \n",
       "T-category_4                                0         1          1          0   \n",
       "N-category_0                                0         0          0          0   \n",
       "N-category_1                                1         0          0          0   \n",
       "N-category_2                                0         1          1          1   \n",
       "N-category_3                                0         0          0          0   \n",
       "AJCC_1                                      1         0          0          0   \n",
       "AJCC_2                                      0         0          0          1   \n",
       "AJCC_3                                      0         0          1          0   \n",
       "AJCC_4                                      0         1          0          0   \n",
       "Pathological Grade_0                        1         0          0          1   \n",
       "Pathological Grade_1                        0         0          0          0   \n",
       "Pathological Grade_2                        0         1          1          0   \n",
       "Pathological Grade_3                        0         0          0          0   \n",
       "Pathological Grade_4                        0         0          0          0   \n",
       "subsite_BOT                                 1         1          1          0   \n",
       "subsite_GPS                                 0         0          0          0   \n",
       "subsite_NOS                                 0         0          0          1   \n",
       "subsite_Soft palate                         0         0          0          0   \n",
       "subsite_Tonsil                              0         0          0          0   \n",
       "treatment_CC                                1         1          1          0   \n",
       "treatment_IC+CC                             0         0          0          0   \n",
       "treatment_IC+Radiation alone                0         0          0          0   \n",
       "treatment_Radiation alone                   0         0          0          1   \n",
       "DLT_Dermatological                        0.0       0.0        0.0        0.0   \n",
       "DLT_Neurological                          0.0       0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                      0.0       0.0        0.0        0.0   \n",
       "DLT_Hematological                         0.0       0.0        0.0        0.0   \n",
       "DLT_Nephrological                           0         0          0          0   \n",
       "DLT_Vascular                                0         0          0          0   \n",
       "DLT_Infection (Pneumonia)                   0         0          0          0   \n",
       "DLT_Other                                 0.0       0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                      0.0       0.0        0.0        0.0   \n",
       "DLT_Neurological 2                        0.0       0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                    0.0       0.0        0.0        0.0   \n",
       "DLT_Hematological 2                       0.0       0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                         0         0          0          0   \n",
       "DLT_Vascular 2                              0         0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                 0         0          0          0   \n",
       "DLT_Other 2                               0.0       0.0        0.0        0.0   \n",
       "CR Primary                                  0         0          0          0   \n",
       "PR Primary                                  0         0          0          0   \n",
       "SD Primary                                  0         0          0          0   \n",
       "CR Nodal                                    0         0          0          0   \n",
       "PR Nodal                                    0         0          0          0   \n",
       "SD Nodal                                    0         0          0          0   \n",
       "CR Primary 2                                0         1          0          1   \n",
       "PR Primary 2                                1         0          1          0   \n",
       "SD Primary 2                                0         0          0          0   \n",
       "CR Nodal 2                                  0         1          1          1   \n",
       "PR Nodal 2                                  1         0          0          0   \n",
       "SD Nodal 2                                  0         0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N            0         0          0          0   \n",
       "Decision 2 (CC / RT alone)                  1         1          1          0   \n",
       "Decision 3 Neck Dissection (Y/N)            0         0          0          0   \n",
       "Overall Survival (4 Years)                  0         0          0          0   \n",
       "FT                                          0         1          1          1   \n",
       "Aspiration rate Post-therapy                0         0          1          0   \n",
       "1A_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "1A_contra                                 0.0       0.0        0.0        0.0   \n",
       "1B_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "1B_contra                                 0.0       0.0        0.0        1.0   \n",
       "2A_ipsi                                   0.0       1.0        1.0        0.0   \n",
       "2A_contra                                 1.0       0.0        1.0        0.0   \n",
       "2B_ipsi                                   0.0       1.0        1.0        0.0   \n",
       "2B_contra                                 1.0       0.0        1.0        0.0   \n",
       "3_ipsi                                    0.0       0.0        1.0        0.0   \n",
       "3_contra                                  0.0       0.0        1.0        0.0   \n",
       "4_ipsi                                    0.0       0.0        0.0        0.0   \n",
       "4_contra                                  0.0       0.0        0.0        0.0   \n",
       "5A_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "5A_contra                                 0.0       0.0        0.0        0.0   \n",
       "5B_ipsi                                   0.0       0.0        0.0        0.0   \n",
       "5B_contra                                 0.0       0.0        0.0        0.0   \n",
       "6_ipsi                                    0.0       0.0        0.0        0.0   \n",
       "6_contra                                  0.0       0.0        0.0        0.0   \n",
       "RPLN_ipsi                                 0.0       0.0        0.0        0.0   \n",
       "RPLN_contra                               0.0       0.0        0.0        0.0   \n",
       "\n",
       "id                                      8          9          10     \\\n",
       "hpv                                         1          1         -1   \n",
       "age                                 59.730556  60.083333  67.708333   \n",
       "packs_per_year                            0.0        0.0       40.0   \n",
       "gender                                      1          1          1   \n",
       "smoking_status                            0.0        0.0        1.0   \n",
       "Aspiration rate Pre-therapy                 0          0          0   \n",
       "OS (Calculated)                      8.066667   8.733333        9.1   \n",
       "Locoregional control (Time)          8.066667   8.733333        6.7   \n",
       "FDM (months)                         8.066667   6.633333        9.1   \n",
       "time_to_event                        8.066667   6.633333        6.0   \n",
       "Overall Survival (1=alive, 0=dead)          0          0          0   \n",
       "LRC                                         1          1          0   \n",
       "DC                                          1          0          1   \n",
       "bilateral                               False      False      False   \n",
       "White/Caucasion                         False       True       True   \n",
       "Hispanic/Latino                         False      False      False   \n",
       "African American/Black                  False      False      False   \n",
       "Asian                                   False      False      False   \n",
       "cc_none                                     1          0          0   \n",
       "cc_platinum                                 0          0          0   \n",
       "cc_cetuximab                                0          1          1   \n",
       "cc_others                                   0          0          0   \n",
       "no_dose_adjustment                          1          1          1   \n",
       "dose_modified                               0          0          0   \n",
       "dose_delayed                                0          0          0   \n",
       "dose_cancelled                              0          0          0   \n",
       "dose_delayed_&_modified                     0          0          0   \n",
       "regiment_modification                       0          0          0   \n",
       "T-category_1                                1          1          0   \n",
       "T-category_2                                0          0          0   \n",
       "T-category_3                                0          0          1   \n",
       "T-category_4                                0          0          0   \n",
       "N-category_0                                0          0          0   \n",
       "N-category_1                                1          1          1   \n",
       "N-category_2                                0          0          0   \n",
       "N-category_3                                0          0          0   \n",
       "AJCC_1                                      1          1          0   \n",
       "AJCC_2                                      0          0          0   \n",
       "AJCC_3                                      0          0          1   \n",
       "AJCC_4                                      0          0          0   \n",
       "Pathological Grade_0                        0          0          0   \n",
       "Pathological Grade_1                        0          0          0   \n",
       "Pathological Grade_2                        0          0          1   \n",
       "Pathological Grade_3                        1          1          0   \n",
       "Pathological Grade_4                        0          0          0   \n",
       "subsite_BOT                                 0          1          1   \n",
       "subsite_GPS                                 0          0          0   \n",
       "subsite_NOS                                 0          0          0   \n",
       "subsite_Soft palate                         0          0          0   \n",
       "subsite_Tonsil                              1          0          0   \n",
       "treatment_CC                                0          1          1   \n",
       "treatment_IC+CC                             0          0          0   \n",
       "treatment_IC+Radiation alone                0          0          0   \n",
       "treatment_Radiation alone                   1          0          0   \n",
       "DLT_Dermatological                        0.0        0.0        0.0   \n",
       "DLT_Neurological                          0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                      0.0        0.0        0.0   \n",
       "DLT_Hematological                         0.0        0.0        0.0   \n",
       "DLT_Nephrological                           0          0          0   \n",
       "DLT_Vascular                                0          0          0   \n",
       "DLT_Infection (Pneumonia)                   0          0          0   \n",
       "DLT_Other                                 0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                      0.0        0.0        0.0   \n",
       "DLT_Neurological 2                        0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                    0.0        0.0        0.0   \n",
       "DLT_Hematological 2                       0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                         0          0          0   \n",
       "DLT_Vascular 2                              0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                 0          0          0   \n",
       "DLT_Other 2                               0.0        0.0        0.0   \n",
       "CR Primary                                  0          0          0   \n",
       "PR Primary                                  0          0          0   \n",
       "SD Primary                                  0          0          0   \n",
       "CR Nodal                                    0          0          0   \n",
       "PR Nodal                                    0          0          0   \n",
       "SD Nodal                                    0          0          0   \n",
       "CR Primary 2                                1          0          0   \n",
       "PR Primary 2                                0          1          0   \n",
       "SD Primary 2                                0          0          0   \n",
       "CR Nodal 2                                  1          0          1   \n",
       "PR Nodal 2                                  0          1          0   \n",
       "SD Nodal 2                                  0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N            0          0          0   \n",
       "Decision 2 (CC / RT alone)                  0          1          1   \n",
       "Decision 3 Neck Dissection (Y/N)            0          0          1   \n",
       "Overall Survival (4 Years)                  0          0          0   \n",
       "FT                                          0          0          1   \n",
       "Aspiration rate Post-therapy                0          0          0   \n",
       "1A_ipsi                                   0.0        0.0        0.0   \n",
       "1A_contra                                 0.0        0.0        0.0   \n",
       "1B_ipsi                                   0.0        0.0        0.0   \n",
       "1B_contra                                 0.0        0.0        0.0   \n",
       "2A_ipsi                                   1.0        1.0        1.0   \n",
       "2A_contra                                 0.0        0.0        0.0   \n",
       "2B_ipsi                                   1.0        1.0        1.0   \n",
       "2B_contra                                 0.0        0.0        0.0   \n",
       "3_ipsi                                    0.0        0.0        0.0   \n",
       "3_contra                                  0.0        0.0        0.0   \n",
       "4_ipsi                                    0.0        0.0        0.0   \n",
       "4_contra                                  0.0        0.0        0.0   \n",
       "5A_ipsi                                   0.0        0.0        0.0   \n",
       "5A_contra                                 0.0        0.0        0.0   \n",
       "5B_ipsi                                   0.0        0.0        0.0   \n",
       "5B_contra                                 0.0        0.0        0.0   \n",
       "6_ipsi                                    0.0        0.0        0.0   \n",
       "6_contra                                  0.0        0.0        0.0   \n",
       "RPLN_ipsi                                 0.0        0.0        0.0   \n",
       "RPLN_contra                               0.0        0.0        0.0   \n",
       "\n",
       "id                                      11         13         14     ...  \\\n",
       "hpv                                         1          0          1  ...   \n",
       "age                                 57.858333  51.758333      56.25  ...   \n",
       "packs_per_year                           44.0        0.0       40.0  ...   \n",
       "gender                                      1          1          1  ...   \n",
       "smoking_status                            1.0        0.0        1.0  ...   \n",
       "Aspiration rate Pre-therapy                 0          0          0  ...   \n",
       "OS (Calculated)                           9.8  10.033333  10.033333  ...   \n",
       "Locoregional control (Time)               8.5  10.033333  10.033333  ...   \n",
       "FDM (months)                              9.8  10.033333  10.033333  ...   \n",
       "time_to_event                             8.5        6.0  10.033333  ...   \n",
       "Overall Survival (1=alive, 0=dead)          0          0          0  ...   \n",
       "LRC                                         0          1          1  ...   \n",
       "DC                                          1          1          1  ...   \n",
       "bilateral                               False       True      False  ...   \n",
       "White/Caucasion                          True       True       True  ...   \n",
       "Hispanic/Latino                         False      False      False  ...   \n",
       "African American/Black                  False      False      False  ...   \n",
       "Asian                                   False      False      False  ...   \n",
       "cc_none                                     0          0          0  ...   \n",
       "cc_platinum                                 0          1          0  ...   \n",
       "cc_cetuximab                                1          0          0  ...   \n",
       "cc_others                                   0          0          1  ...   \n",
       "no_dose_adjustment                          1          1          1  ...   \n",
       "dose_modified                               0          0          0  ...   \n",
       "dose_delayed                                0          0          0  ...   \n",
       "dose_cancelled                              0          0          0  ...   \n",
       "dose_delayed_&_modified                     0          0          0  ...   \n",
       "regiment_modification                       0          0          0  ...   \n",
       "T-category_1                                0          0          0  ...   \n",
       "T-category_2                                1          0          1  ...   \n",
       "T-category_3                                0          0          0  ...   \n",
       "T-category_4                                0          1          0  ...   \n",
       "N-category_0                                0          0          0  ...   \n",
       "N-category_1                                1          0          0  ...   \n",
       "N-category_2                                0          1          1  ...   \n",
       "N-category_3                                0          0          0  ...   \n",
       "AJCC_1                                      1          0          0  ...   \n",
       "AJCC_2                                      0          0          1  ...   \n",
       "AJCC_3                                      0          0          0  ...   \n",
       "AJCC_4                                      0          1          0  ...   \n",
       "Pathological Grade_0                        0          0          0  ...   \n",
       "Pathological Grade_1                        0          0          0  ...   \n",
       "Pathological Grade_2                        1          1          0  ...   \n",
       "Pathological Grade_3                        0          0          1  ...   \n",
       "Pathological Grade_4                        0          0          0  ...   \n",
       "subsite_BOT                                 0          1          1  ...   \n",
       "subsite_GPS                                 0          0          0  ...   \n",
       "subsite_NOS                                 1          0          0  ...   \n",
       "subsite_Soft palate                         0          0          0  ...   \n",
       "subsite_Tonsil                              0          0          0  ...   \n",
       "treatment_CC                                1          1          1  ...   \n",
       "treatment_IC+CC                             0          0          0  ...   \n",
       "treatment_IC+Radiation alone                0          0          0  ...   \n",
       "treatment_Radiation alone                   0          0          0  ...   \n",
       "DLT_Dermatological                        0.0        0.0        0.0  ...   \n",
       "DLT_Neurological                          0.0        0.0        0.0  ...   \n",
       "DLT_Gastrointestinal                      0.0        0.0        0.0  ...   \n",
       "DLT_Hematological                         0.0        0.0        0.0  ...   \n",
       "DLT_Nephrological                           0          0          0  ...   \n",
       "DLT_Vascular                                0          0          0  ...   \n",
       "DLT_Infection (Pneumonia)                   0          0          0  ...   \n",
       "DLT_Other                                 0.0        0.0        0.0  ...   \n",
       "DLT_Dermatological 2                      0.0        0.0        0.0  ...   \n",
       "DLT_Neurological 2                        0.0        0.0        0.0  ...   \n",
       "DLT_Gastrointestinal 2                    0.0        0.0        0.0  ...   \n",
       "DLT_Hematological 2                       0.0        0.0        0.0  ...   \n",
       "DLT_Nephrological 2                         0          0          0  ...   \n",
       "DLT_Vascular 2                              0          0          0  ...   \n",
       "DLT_Infection (Pneumonia) 2                 0          0          0  ...   \n",
       "DLT_Other 2                               0.0        0.0        0.0  ...   \n",
       "CR Primary                                  0          0          0  ...   \n",
       "PR Primary                                  0          0          0  ...   \n",
       "SD Primary                                  0          0          0  ...   \n",
       "CR Nodal                                    0          0          0  ...   \n",
       "PR Nodal                                    0          0          0  ...   \n",
       "SD Nodal                                    0          0          0  ...   \n",
       "CR Primary 2                                0          0          1  ...   \n",
       "PR Primary 2                                1          1          0  ...   \n",
       "SD Primary 2                                0          0          0  ...   \n",
       "CR Nodal 2                                  0          0          0  ...   \n",
       "PR Nodal 2                                  1          1          1  ...   \n",
       "SD Nodal 2                                  0          0          0  ...   \n",
       "Decision 1 (Induction Chemo) Y/N            0          0          0  ...   \n",
       "Decision 2 (CC / RT alone)                  1          1          1  ...   \n",
       "Decision 3 Neck Dissection (Y/N)            0          0          0  ...   \n",
       "Overall Survival (4 Years)                  0          0          0  ...   \n",
       "FT                                          0          1          0  ...   \n",
       "Aspiration rate Post-therapy                0          0          0  ...   \n",
       "1A_ipsi                                   0.0        0.0        0.0  ...   \n",
       "1A_contra                                 0.0        0.0        0.0  ...   \n",
       "1B_ipsi                                   0.0        0.0        0.0  ...   \n",
       "1B_contra                                 0.0        0.0        0.0  ...   \n",
       "2A_ipsi                                   1.0        1.0        1.0  ...   \n",
       "2A_contra                                 0.0        1.0        0.0  ...   \n",
       "2B_ipsi                                   1.0        1.0        1.0  ...   \n",
       "2B_contra                                 0.0        1.0        0.0  ...   \n",
       "3_ipsi                                    1.0        0.0        0.0  ...   \n",
       "3_contra                                  0.0        0.0        1.0  ...   \n",
       "4_ipsi                                    0.0        0.0        0.0  ...   \n",
       "4_contra                                  0.0        0.0        0.0  ...   \n",
       "5A_ipsi                                   0.0        0.0        0.0  ...   \n",
       "5A_contra                                 0.0        0.0        0.0  ...   \n",
       "5B_ipsi                                   0.0        0.0        0.0  ...   \n",
       "5B_contra                                 0.0        0.0        0.0  ...   \n",
       "6_ipsi                                    0.0        0.0        0.0  ...   \n",
       "6_contra                                  0.0        0.0        0.0  ...   \n",
       "RPLN_ipsi                                 0.0        0.0        0.0  ...   \n",
       "RPLN_contra                               0.0        0.0        0.0  ...   \n",
       "\n",
       "id                                       10196      10197      10198  \\\n",
       "hpv                                          0          1         -1   \n",
       "age                                  47.619444  50.163889  70.888889   \n",
       "packs_per_year                             5.0        0.0       50.0   \n",
       "gender                                       0          1          0   \n",
       "smoking_status                             0.5        0.0        0.5   \n",
       "Aspiration rate Pre-therapy                  0          0          0   \n",
       "OS (Calculated)                     139.033333      139.3      140.6   \n",
       "Locoregional control (Time)         139.033333      139.3      140.6   \n",
       "FDM (months)                        139.033333      139.3      140.6   \n",
       "time_to_event                       139.033333      139.3      140.6   \n",
       "Overall Survival (1=alive, 0=dead)           1          1          1   \n",
       "LRC                                          1          1          1   \n",
       "DC                                           1          1          1   \n",
       "bilateral                                False      False      False   \n",
       "White/Caucasion                           True       True       True   \n",
       "Hispanic/Latino                          False      False      False   \n",
       "African American/Black                   False      False      False   \n",
       "Asian                                    False      False      False   \n",
       "cc_none                                      0          0          1   \n",
       "cc_platinum                                  1          1          0   \n",
       "cc_cetuximab                                 0          0          0   \n",
       "cc_others                                    0          0          0   \n",
       "no_dose_adjustment                           1          0          1   \n",
       "dose_modified                                0          0          0   \n",
       "dose_delayed                                 0          0          0   \n",
       "dose_cancelled                               0          0          0   \n",
       "dose_delayed_&_modified                      0          1          0   \n",
       "regiment_modification                        0          0          0   \n",
       "T-category_1                                 0          0          1   \n",
       "T-category_2                                 1          0          0   \n",
       "T-category_3                                 0          1          0   \n",
       "T-category_4                                 0          0          0   \n",
       "N-category_0                                 0          0          0   \n",
       "N-category_1                                 0          0          0   \n",
       "N-category_2                                 1          0          1   \n",
       "N-category_3                                 0          1          0   \n",
       "AJCC_1                                       0          0          0   \n",
       "AJCC_2                                       0          0          0   \n",
       "AJCC_3                                       0          1          0   \n",
       "AJCC_4                                       1          0          1   \n",
       "Pathological Grade_0                         1          0          0   \n",
       "Pathological Grade_1                         0          0          1   \n",
       "Pathological Grade_2                         0          1          0   \n",
       "Pathological Grade_3                         0          0          0   \n",
       "Pathological Grade_4                         0          0          0   \n",
       "subsite_BOT                                  0          1          0   \n",
       "subsite_GPS                                  0          0          0   \n",
       "subsite_NOS                                  0          0          0   \n",
       "subsite_Soft palate                          0          0          0   \n",
       "subsite_Tonsil                               1          0          1   \n",
       "treatment_CC                                 1          0          0   \n",
       "treatment_IC+CC                              0          1          0   \n",
       "treatment_IC+Radiation alone                 0          0          0   \n",
       "treatment_Radiation alone                    0          0          1   \n",
       "DLT_Dermatological                         0.0        1.0        0.0   \n",
       "DLT_Neurological                           0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal                       0.0        0.0        0.0   \n",
       "DLT_Hematological                          0.0        0.0        0.0   \n",
       "DLT_Nephrological                            0          0          0   \n",
       "DLT_Vascular                                 0          0          0   \n",
       "DLT_Infection (Pneumonia)                    0          0          0   \n",
       "DLT_Other                                  0.0        0.0        0.0   \n",
       "DLT_Dermatological 2                       0.0        0.0        0.0   \n",
       "DLT_Neurological 2                         0.0        0.0        0.0   \n",
       "DLT_Gastrointestinal 2                     0.0        0.0        0.0   \n",
       "DLT_Hematological 2                        0.0        0.0        0.0   \n",
       "DLT_Nephrological 2                          0          0          0   \n",
       "DLT_Vascular 2                               0          0          0   \n",
       "DLT_Infection (Pneumonia) 2                  0          0          0   \n",
       "DLT_Other 2                                0.0        0.0        0.0   \n",
       "CR Primary                                   0          0          0   \n",
       "PR Primary                                   0          1          0   \n",
       "SD Primary                                   0          0          0   \n",
       "CR Nodal                                     0          0          0   \n",
       "PR Nodal                                     0          1          0   \n",
       "SD Nodal                                     0          0          0   \n",
       "CR Primary 2                                 1          1          0   \n",
       "PR Primary 2                                 0          0          1   \n",
       "SD Primary 2                                 0          0          0   \n",
       "CR Nodal 2                                   1          1          0   \n",
       "PR Nodal 2                                   0          0          1   \n",
       "SD Nodal 2                                   0          0          0   \n",
       "Decision 1 (Induction Chemo) Y/N             0          1          0   \n",
       "Decision 2 (CC / RT alone)                   1          1          0   \n",
       "Decision 3 Neck Dissection (Y/N)             0          0          1   \n",
       "Overall Survival (4 Years)                   1          1          1   \n",
       "FT                                           0          0          0   \n",
       "Aspiration rate Post-therapy                 0          0          0   \n",
       "1A_ipsi                                    0.0        0.0        0.0   \n",
       "1A_contra                                  0.0        0.0        0.0   \n",
       "1B_ipsi                                    0.0        0.0        0.0   \n",
       "1B_contra                                  0.0        0.0        0.0   \n",
       "2A_ipsi                                    0.0        1.0        1.0   \n",
       "2A_contra                                  0.0        0.0        0.0   \n",
       "2B_ipsi                                    0.0        1.0        1.0   \n",
       "2B_contra                                  0.0        0.0        0.0   \n",
       "3_ipsi                                     0.0        0.0        0.0   \n",
       "3_contra                                   0.0        0.0        0.0   \n",
       "4_ipsi                                     0.0        0.0        0.0   \n",
       "4_contra                                   0.0        0.0        0.0   \n",
       "5A_ipsi                                    1.0        0.0        0.0   \n",
       "5A_contra                                  0.0        0.0        0.0   \n",
       "5B_ipsi                                    0.0        0.0        0.0   \n",
       "5B_contra                                  0.0        0.0        0.0   \n",
       "6_ipsi                                     0.0        0.0        0.0   \n",
       "6_contra                                   0.0        0.0        0.0   \n",
       "RPLN_ipsi                                  1.0        0.0        0.0   \n",
       "RPLN_contra                                0.0        0.0        0.0   \n",
       "\n",
       "id                                       10199       10200      10201  \\\n",
       "hpv                                          0           1          1   \n",
       "age                                     67.825   56.336111  49.566667   \n",
       "packs_per_year                             0.0         0.0       30.0   \n",
       "gender                                       1           1          1   \n",
       "smoking_status                             0.0         0.0        1.0   \n",
       "Aspiration rate Pre-therapy                  0           0          0   \n",
       "OS (Calculated)                     142.833333  143.033333      143.2   \n",
       "Locoregional control (Time)         142.833333  143.033333      143.2   \n",
       "FDM (months)                        142.833333  143.033333      143.2   \n",
       "time_to_event                       142.833333  143.033333      143.2   \n",
       "Overall Survival (1=alive, 0=dead)           1           1          1   \n",
       "LRC                                          1           1          1   \n",
       "DC                                           1           1          1   \n",
       "bilateral                                False       False      False   \n",
       "White/Caucasion                           True        True       True   \n",
       "Hispanic/Latino                          False       False      False   \n",
       "African American/Black                   False       False      False   \n",
       "Asian                                    False       False      False   \n",
       "cc_none                                      0           0          0   \n",
       "cc_platinum                                  1           1          1   \n",
       "cc_cetuximab                                 0           0          0   \n",
       "cc_others                                    0           0          0   \n",
       "no_dose_adjustment                           1           1          1   \n",
       "dose_modified                                0           0          0   \n",
       "dose_delayed                                 0           0          0   \n",
       "dose_cancelled                               0           0          0   \n",
       "dose_delayed_&_modified                      0           0          0   \n",
       "regiment_modification                        0           0          0   \n",
       "T-category_1                                 0           0          0   \n",
       "T-category_2                                 1           0          0   \n",
       "T-category_3                                 0           1          1   \n",
       "T-category_4                                 0           0          0   \n",
       "N-category_0                                 0           0          0   \n",
       "N-category_1                                 0           1          1   \n",
       "N-category_2                                 1           0          0   \n",
       "N-category_3                                 0           0          0   \n",
       "AJCC_1                                       0           0          0   \n",
       "AJCC_2                                       0           1          1   \n",
       "AJCC_3                                       0           0          0   \n",
       "AJCC_4                                       1           0          0   \n",
       "Pathological Grade_0                         1           0          0   \n",
       "Pathological Grade_1                         0           0          0   \n",
       "Pathological Grade_2                         0           1          0   \n",
       "Pathological Grade_3                         0           0          1   \n",
       "Pathological Grade_4                         0           0          0   \n",
       "subsite_BOT                                  1           0          1   \n",
       "subsite_GPS                                  0           0          0   \n",
       "subsite_NOS                                  0           1          0   \n",
       "subsite_Soft palate                          0           0          0   \n",
       "subsite_Tonsil                               0           0          0   \n",
       "treatment_CC                                 1           1          1   \n",
       "treatment_IC+CC                              0           0          0   \n",
       "treatment_IC+Radiation alone                 0           0          0   \n",
       "treatment_Radiation alone                    0           0          0   \n",
       "DLT_Dermatological                         0.0         0.0        0.0   \n",
       "DLT_Neurological                           0.0         0.0        0.0   \n",
       "DLT_Gastrointestinal                       0.0         0.0        0.0   \n",
       "DLT_Hematological                          0.0         0.0        0.0   \n",
       "DLT_Nephrological                            0           0          0   \n",
       "DLT_Vascular                                 0           0          0   \n",
       "DLT_Infection (Pneumonia)                    0           0          0   \n",
       "DLT_Other                                  0.0         0.0        0.0   \n",
       "DLT_Dermatological 2                       0.0         0.0        0.0   \n",
       "DLT_Neurological 2                         0.0         0.0        0.0   \n",
       "DLT_Gastrointestinal 2                     1.0         0.0        0.0   \n",
       "DLT_Hematological 2                        0.0         0.0        0.0   \n",
       "DLT_Nephrological 2                          0           0          0   \n",
       "DLT_Vascular 2                               0           0          0   \n",
       "DLT_Infection (Pneumonia) 2                  0           0          0   \n",
       "DLT_Other 2                                0.0         0.0        0.0   \n",
       "CR Primary                                   0           0          0   \n",
       "PR Primary                                   0           0          0   \n",
       "SD Primary                                   0           0          0   \n",
       "CR Nodal                                     0           0          0   \n",
       "PR Nodal                                     0           0          0   \n",
       "SD Nodal                                     0           0          0   \n",
       "CR Primary 2                                 1           1          1   \n",
       "PR Primary 2                                 0           0          0   \n",
       "SD Primary 2                                 0           0          0   \n",
       "CR Nodal 2                                   1           0          0   \n",
       "PR Nodal 2                                   0           1          1   \n",
       "SD Nodal 2                                   0           0          0   \n",
       "Decision 1 (Induction Chemo) Y/N             0           0          0   \n",
       "Decision 2 (CC / RT alone)                   1           1          1   \n",
       "Decision 3 Neck Dissection (Y/N)             0           0          0   \n",
       "Overall Survival (4 Years)                   1           1          1   \n",
       "FT                                           0           0          0   \n",
       "Aspiration rate Post-therapy                 0           0          0   \n",
       "1A_ipsi                                    0.0         0.0        0.0   \n",
       "1A_contra                                  0.0         0.0        0.0   \n",
       "1B_ipsi                                    0.0         0.0        0.0   \n",
       "1B_contra                                  0.0         0.0        0.0   \n",
       "2A_ipsi                                    0.0         0.0        1.0   \n",
       "2A_contra                                  1.0         0.0        0.0   \n",
       "2B_ipsi                                    0.0         0.0        1.0   \n",
       "2B_contra                                  1.0         0.0        0.0   \n",
       "3_ipsi                                     0.0         1.0        0.0   \n",
       "3_contra                                   1.0         0.0        0.0   \n",
       "4_ipsi                                     0.0         0.0        0.0   \n",
       "4_contra                                   0.0         0.0        0.0   \n",
       "5A_ipsi                                    0.0         0.0        0.0   \n",
       "5A_contra                                  0.0         0.0        0.0   \n",
       "5B_ipsi                                    0.0         0.0        0.0   \n",
       "5B_contra                                  0.0         0.0        0.0   \n",
       "6_ipsi                                     0.0         0.0        0.0   \n",
       "6_contra                                   0.0         0.0        0.0   \n",
       "RPLN_ipsi                                  0.0         0.0        0.0   \n",
       "RPLN_contra                                0.0         0.0        0.0   \n",
       "\n",
       "id                                       10202       10203  10204       10205  \n",
       "hpv                                          0           1      0           1  \n",
       "age                                  48.705556   77.116667  45.95   49.733333  \n",
       "packs_per_year                            30.0         0.0    5.0         0.0  \n",
       "gender                                       1           1      1           1  \n",
       "smoking_status                             1.0         0.0    0.5         0.0  \n",
       "Aspiration rate Pre-therapy                  0           0      0           0  \n",
       "OS (Calculated)                     144.366667  148.366667  152.6  155.533333  \n",
       "Locoregional control (Time)         144.366667  148.366667  152.6  155.533333  \n",
       "FDM (months)                        144.366667  136.033333  152.6  155.533333  \n",
       "time_to_event                              6.0  136.033333  152.6  155.533333  \n",
       "Overall Survival (1=alive, 0=dead)           1           1      1           1  \n",
       "LRC                                          1           1      1           1  \n",
       "DC                                           1           0      1           1  \n",
       "bilateral                                False       False   True       False  \n",
       "White/Caucasion                          False        True   True        True  \n",
       "Hispanic/Latino                           True       False  False       False  \n",
       "African American/Black                   False       False  False       False  \n",
       "Asian                                    False       False  False       False  \n",
       "cc_none                                      0           1      0           0  \n",
       "cc_platinum                                  0           0      1           1  \n",
       "cc_cetuximab                                 0           0      0           0  \n",
       "cc_others                                    1           0      0           0  \n",
       "no_dose_adjustment                           1           1      1           1  \n",
       "dose_modified                                0           0      0           0  \n",
       "dose_delayed                                 0           0      0           0  \n",
       "dose_cancelled                               0           0      0           0  \n",
       "dose_delayed_&_modified                      0           0      0           0  \n",
       "regiment_modification                        0           0      0           0  \n",
       "T-category_1                                 0           1      0           0  \n",
       "T-category_2                                 0           0      0           0  \n",
       "T-category_3                                 0           0      1           0  \n",
       "T-category_4                                 1           0      0           1  \n",
       "N-category_0                                 0           0      0           0  \n",
       "N-category_1                                 0           1      0           1  \n",
       "N-category_2                                 1           0      0           0  \n",
       "N-category_3                                 0           0      1           0  \n",
       "AJCC_1                                       0           1      0           0  \n",
       "AJCC_2                                       0           0      0           0  \n",
       "AJCC_3                                       0           0      0           1  \n",
       "AJCC_4                                       1           0      1           0  \n",
       "Pathological Grade_0                         0           1      0           0  \n",
       "Pathological Grade_1                         0           0      0           0  \n",
       "Pathological Grade_2                         0           0      0           1  \n",
       "Pathological Grade_3                         1           0      1           0  \n",
       "Pathological Grade_4                         0           0      0           0  \n",
       "subsite_BOT                                  0           0      0           1  \n",
       "subsite_GPS                                  0           0      0           0  \n",
       "subsite_NOS                                  1           0      0           0  \n",
       "subsite_Soft palate                          0           0      0           0  \n",
       "subsite_Tonsil                               0           1      1           0  \n",
       "treatment_CC                                 1           0      1           1  \n",
       "treatment_IC+CC                              0           0      0           0  \n",
       "treatment_IC+Radiation alone                 0           0      0           0  \n",
       "treatment_Radiation alone                    0           1      0           0  \n",
       "DLT_Dermatological                         0.0         0.0    0.0         0.0  \n",
       "DLT_Neurological                           0.0         0.0    0.0         0.0  \n",
       "DLT_Gastrointestinal                       0.0         0.0    0.0         0.0  \n",
       "DLT_Hematological                          0.0         0.0    0.0         0.0  \n",
       "DLT_Nephrological                            0           0      0           0  \n",
       "DLT_Vascular                                 0           0      0           0  \n",
       "DLT_Infection (Pneumonia)                    0           0      0           0  \n",
       "DLT_Other                                  0.0         0.0    0.0         0.0  \n",
       "DLT_Dermatological 2                       0.0         0.0    0.0         0.0  \n",
       "DLT_Neurological 2                         0.0         0.0    0.0         0.0  \n",
       "DLT_Gastrointestinal 2                     0.0         0.0    1.0         0.0  \n",
       "DLT_Hematological 2                        0.0         0.0    0.0         0.0  \n",
       "DLT_Nephrological 2                          0           0      0           0  \n",
       "DLT_Vascular 2                               0           0      0           0  \n",
       "DLT_Infection (Pneumonia) 2                  0           0      0           0  \n",
       "DLT_Other 2                                0.0         0.0    0.0         0.0  \n",
       "CR Primary                                   0           0      0           0  \n",
       "PR Primary                                   0           0      0           0  \n",
       "SD Primary                                   0           0      0           0  \n",
       "CR Nodal                                     0           0      0           0  \n",
       "PR Nodal                                     0           0      0           0  \n",
       "SD Nodal                                     0           0      0           0  \n",
       "CR Primary 2                                 0           1      1           1  \n",
       "PR Primary 2                                 1           0      0           0  \n",
       "SD Primary 2                                 0           0      0           0  \n",
       "CR Nodal 2                                   0           0      0           0  \n",
       "PR Nodal 2                                   1           1      1           1  \n",
       "SD Nodal 2                                   0           0      0           0  \n",
       "Decision 1 (Induction Chemo) Y/N             0           0      0           0  \n",
       "Decision 2 (CC / RT alone)                   1           0      1           1  \n",
       "Decision 3 Neck Dissection (Y/N)             1           1      0           1  \n",
       "Overall Survival (4 Years)                   1           1      1           1  \n",
       "FT                                           1           0      0           0  \n",
       "Aspiration rate Post-therapy                 0           0      0           0  \n",
       "1A_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "1A_contra                                  0.0         0.0    0.0         0.0  \n",
       "1B_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "1B_contra                                  0.0         0.0    0.0         0.0  \n",
       "2A_ipsi                                    1.0         1.0    1.0         0.0  \n",
       "2A_contra                                  0.0         0.0    0.0         0.0  \n",
       "2B_ipsi                                    1.0         1.0    1.0         0.0  \n",
       "2B_contra                                  0.0         0.0    0.0         0.0  \n",
       "3_ipsi                                     0.0         1.0    1.0         1.0  \n",
       "3_contra                                   0.0         0.0    0.0         0.0  \n",
       "4_ipsi                                     0.0         0.0    0.0         0.0  \n",
       "4_contra                                   0.0         0.0    0.0         0.0  \n",
       "5A_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "5A_contra                                  0.0         0.0    0.0         0.0  \n",
       "5B_ipsi                                    0.0         0.0    0.0         0.0  \n",
       "5B_contra                                  0.0         0.0    0.0         0.0  \n",
       "6_ipsi                                     0.0         0.0    0.0         0.0  \n",
       "6_contra                                   0.0         0.0    0.0         0.0  \n",
       "RPLN_ipsi                                  0.0         0.0    0.0         0.0  \n",
       "RPLN_contra                                0.0         0.0    0.0         0.0  \n",
       "\n",
       "[108 rows x 536 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False)\n",
    "data.processed_df.T\n",
    "# data.processed_df#.shape, len(data.processed_df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_loss(ytrue,ypred,subweights=None,weights=None):\n",
    "    if weights is None:\n",
    "        weights = [1,1,1,1]\n",
    "    if subweights is None:\n",
    "        subweights = [None,None,None]\n",
    "    pd_loss = torch.mul(mc_loss(ytrue[0],ypred[0],weights=subweights[0]),weights[0])\n",
    "    nd_loss = torch.mul(mc_loss(ytrue[1],ypred[1],weights=subweights[1]),weights[1])\n",
    "    mod_loss = torch.mul(mc_loss(ytrue[2],ypred[2],weights=subweights[2]),weights[2])\n",
    "    loss = torch.add(pd_loss,torch.add(nd_loss,mod_loss))\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "#     nloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = bce(dlt_pred[:,i].view(-1),dlt_true[:,i].view(-1))\n",
    "        dlt_loss = torch.mul(dlt_loss,weights[3]/ndlt)\n",
    "        loss = torch.add(loss,dlt_loss)\n",
    "    return loss\n",
    "\n",
    "def outcome_loss(ytrue,ypred,weights=None,**kwargs):\n",
    "    if weights is None:\n",
    "        weights = [1,1,1,1]\n",
    "    loss = 0\n",
    "    nloss = torch.nn.BCELoss()\n",
    "    for i in range(len(weights)):\n",
    "        iloss = nloss(ypred[:,i],ytrue[i])*weights[i]\n",
    "        loss += iloss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "91c4445c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "epoch 0 train loss 3.059873580932617\n",
      "val loss 3.0475687980651855\n",
      "______________\n",
      "epoch 1 train loss 3.0519778728485107\n",
      "val loss 3.037947654724121\n",
      "______________\n",
      "epoch 2 train loss 3.028034210205078\n",
      "val loss 3.0285582542419434\n",
      "______________\n",
      "epoch 3 train loss 3.010204315185547\n",
      "val loss 3.019425392150879\n",
      "______________\n",
      "epoch 4 train loss 3.007395029067993\n",
      "val loss 3.0104711055755615\n",
      "______________\n",
      "epoch 5 train loss 3.004073143005371\n",
      "val loss 3.00177264213562\n",
      "______________\n",
      "epoch 6 train loss 2.992194175720215\n",
      "val loss 2.993199586868286\n",
      "______________\n",
      "epoch 7 train loss 2.9642019271850586\n",
      "val loss 2.984776020050049\n",
      "______________\n",
      "epoch 8 train loss 2.9612057209014893\n",
      "val loss 2.976506471633911\n",
      "______________\n",
      "epoch 9 train loss 2.954024314880371\n",
      "val loss 2.968346357345581\n",
      "______________\n",
      "epoch 10 train loss 2.929110050201416\n",
      "val loss 2.9602959156036377\n",
      "______________\n",
      "epoch 11 train loss 2.926525354385376\n",
      "val loss 2.9523372650146484\n",
      "______________\n",
      "epoch 12 train loss 2.913980722427368\n",
      "val loss 2.9444947242736816\n",
      "______________\n",
      "epoch 13 train loss 2.9114084243774414\n",
      "val loss 2.9367189407348633\n",
      "______________\n",
      "epoch 14 train loss 2.894822359085083\n",
      "val loss 2.929055690765381\n",
      "______________\n",
      "epoch 15 train loss 2.8848717212677\n",
      "val loss 2.9214885234832764\n",
      "______________\n",
      "epoch 16 train loss 2.8733201026916504\n",
      "val loss 2.914003849029541\n",
      "______________\n",
      "epoch 17 train loss 2.8726634979248047\n",
      "val loss 2.9066238403320312\n",
      "______________\n",
      "epoch 18 train loss 2.8843441009521484\n",
      "val loss 2.8993682861328125\n",
      "______________\n",
      "epoch 19 train loss 2.8534305095672607\n",
      "val loss 2.8922393321990967\n",
      "______________\n",
      "epoch 20 train loss 2.8459107875823975\n",
      "val loss 2.8852460384368896\n",
      "______________\n",
      "epoch 21 train loss 2.836996555328369\n",
      "val loss 2.878268003463745\n",
      "______________\n",
      "epoch 22 train loss 2.839963674545288\n",
      "val loss 2.871385097503662\n",
      "______________\n",
      "epoch 23 train loss 2.819617986679077\n",
      "val loss 2.8645706176757812\n",
      "______________\n",
      "epoch 24 train loss 2.7887213230133057\n",
      "val loss 2.857929229736328\n",
      "______________\n",
      "epoch 25 train loss 2.804683208465576\n",
      "val loss 2.851389169692993\n",
      "______________\n",
      "epoch 26 train loss 2.7983689308166504\n",
      "val loss 2.844956874847412\n",
      "______________\n",
      "epoch 27 train loss 2.79081130027771\n",
      "val loss 2.838679075241089\n",
      "______________\n",
      "epoch 28 train loss 2.782582998275757\n",
      "val loss 2.8325157165527344\n",
      "______________\n",
      "epoch 29 train loss 2.77901291847229\n",
      "val loss 2.8265397548675537\n",
      "______________\n",
      "epoch 30 train loss 2.7591099739074707\n",
      "val loss 2.8207204341888428\n",
      "______________\n",
      "epoch 31 train loss 2.7607035636901855\n",
      "val loss 2.815061569213867\n",
      "______________\n",
      "epoch 32 train loss 2.7654151916503906\n",
      "val loss 2.8096046447753906\n",
      "______________\n",
      "epoch 33 train loss 2.7576560974121094\n",
      "val loss 2.8043410778045654\n",
      "______________\n",
      "epoch 34 train loss 2.736394166946411\n",
      "val loss 2.799211025238037\n",
      "______________\n",
      "epoch 35 train loss 2.743544340133667\n",
      "val loss 2.7942445278167725\n",
      "______________\n",
      "epoch 36 train loss 2.7462525367736816\n",
      "val loss 2.7894504070281982\n",
      "______________\n",
      "epoch 37 train loss 2.717481851577759\n",
      "val loss 2.784825325012207\n",
      "______________\n",
      "epoch 38 train loss 2.728344440460205\n",
      "val loss 2.780496120452881\n",
      "______________\n",
      "epoch 39 train loss 2.7449886798858643\n",
      "val loss 2.776370048522949\n",
      "______________\n",
      "epoch 40 train loss 2.720160484313965\n",
      "val loss 2.7724993228912354\n",
      "______________\n",
      "epoch 41 train loss 2.708954334259033\n",
      "val loss 2.768712282180786\n",
      "______________\n",
      "epoch 42 train loss 2.6806752681732178\n",
      "val loss 2.7651760578155518\n",
      "______________\n",
      "epoch 43 train loss 2.696028232574463\n",
      "val loss 2.7618227005004883\n",
      "______________\n",
      "epoch 44 train loss 2.6971468925476074\n",
      "val loss 2.758700370788574\n",
      "______________\n",
      "epoch 45 train loss 2.7083942890167236\n",
      "val loss 2.7557296752929688\n",
      "______________\n",
      "epoch 46 train loss 2.688323736190796\n",
      "val loss 2.753025531768799\n",
      "______________\n",
      "epoch 47 train loss 2.699768543243408\n",
      "val loss 2.7505853176116943\n",
      "______________\n",
      "epoch 48 train loss 2.7020325660705566\n",
      "val loss 2.748283863067627\n",
      "______________\n",
      "epoch 49 train loss 2.7007029056549072\n",
      "val loss 2.7460741996765137\n",
      "______________\n",
      "epoch 50 train loss 2.666865348815918\n",
      "val loss 2.744025945663452\n",
      "______________\n",
      "epoch 51 train loss 2.7092010974884033\n",
      "val loss 2.742006301879883\n",
      "______________\n",
      "epoch 52 train loss 2.688278913497925\n",
      "val loss 2.740070343017578\n",
      "______________\n",
      "epoch 53 train loss 2.662301778793335\n",
      "val loss 2.738194465637207\n",
      "______________\n",
      "epoch 54 train loss 2.656886100769043\n",
      "val loss 2.7363977432250977\n",
      "______________\n",
      "epoch 55 train loss 2.670961856842041\n",
      "val loss 2.7346911430358887\n",
      "______________\n",
      "epoch 56 train loss 2.6516432762145996\n",
      "val loss 2.7330994606018066\n",
      "______________\n",
      "epoch 57 train loss 2.6650681495666504\n",
      "val loss 2.731619358062744\n",
      "______________\n",
      "epoch 58 train loss 2.691037654876709\n",
      "val loss 2.7303109169006348\n",
      "______________\n",
      "epoch 59 train loss 2.643090009689331\n",
      "val loss 2.729119300842285\n",
      "______________\n",
      "epoch 60 train loss 2.651214122772217\n",
      "val loss 2.7280430793762207\n",
      "______________\n",
      "epoch 61 train loss 2.6599128246307373\n",
      "val loss 2.7270238399505615\n",
      "______________\n",
      "epoch 62 train loss 2.6406760215759277\n",
      "val loss 2.7260470390319824\n",
      "______________\n",
      "epoch 63 train loss 2.634521722793579\n",
      "val loss 2.7250709533691406\n",
      "______________\n",
      "epoch 64 train loss 2.6770684719085693\n",
      "val loss 2.724214553833008\n",
      "______________\n",
      "epoch 65 train loss 2.664093017578125\n",
      "val loss 2.7234129905700684\n",
      "______________\n",
      "epoch 66 train loss 2.6307313442230225\n",
      "val loss 2.7226243019104004\n",
      "______________\n",
      "epoch 67 train loss 2.638129472732544\n",
      "val loss 2.721845865249634\n",
      "______________\n",
      "epoch 68 train loss 2.6187093257904053\n",
      "val loss 2.721086025238037\n",
      "______________\n",
      "epoch 69 train loss 2.620730400085449\n",
      "val loss 2.720349073410034\n",
      "______________\n",
      "epoch 70 train loss 2.631575107574463\n",
      "val loss 2.7196805477142334\n",
      "______________\n",
      "epoch 71 train loss 2.625905990600586\n",
      "val loss 2.7191100120544434\n",
      "______________\n",
      "epoch 72 train loss 2.6136410236358643\n",
      "val loss 2.718698501586914\n",
      "______________\n",
      "epoch 73 train loss 2.582409381866455\n",
      "val loss 2.7183094024658203\n",
      "______________\n",
      "epoch 74 train loss 2.6189911365509033\n",
      "val loss 2.7179057598114014\n",
      "______________\n",
      "epoch 75 train loss 2.612602710723877\n",
      "val loss 2.717496633529663\n",
      "______________\n",
      "epoch 76 train loss 2.617208480834961\n",
      "val loss 2.7170825004577637\n",
      "______________\n",
      "epoch 77 train loss 2.627380609512329\n",
      "val loss 2.716648578643799\n",
      "______________\n",
      "epoch 78 train loss 2.5909714698791504\n",
      "val loss 2.7162985801696777\n",
      "______________\n",
      "epoch 79 train loss 2.5738773345947266\n",
      "val loss 2.715991973876953\n",
      "______________\n",
      "epoch 80 train loss 2.576753616333008\n",
      "val loss 2.7157464027404785\n",
      "______________\n",
      "epoch 81 train loss 2.591864585876465\n",
      "val loss 2.7154202461242676\n",
      "______________\n",
      "epoch 82 train loss 2.577972412109375\n",
      "val loss 2.7151670455932617\n",
      "______________\n",
      "epoch 83 train loss 2.6124823093414307\n",
      "val loss 2.714902400970459\n",
      "______________\n",
      "epoch 84 train loss 2.606384754180908\n",
      "val loss 2.7146620750427246\n",
      "______________\n",
      "epoch 85 train loss 2.572983980178833\n",
      "val loss 2.7144100666046143\n",
      "______________\n",
      "epoch 86 train loss 2.572675943374634\n",
      "val loss 2.7142395973205566\n",
      "______________\n",
      "epoch 87 train loss 2.5640475749969482\n",
      "val loss 2.7142555713653564\n",
      "______________\n",
      "epoch 88 train loss 2.598365068435669\n",
      "val loss 2.7143094539642334\n",
      "______________\n",
      "epoch 89 train loss 2.575721263885498\n",
      "val loss 2.7143547534942627\n",
      "______________\n",
      "epoch 90 train loss 2.5878119468688965\n",
      "val loss 2.7144293785095215\n",
      "______________\n",
      "epoch 91 train loss 2.5733368396759033\n",
      "val loss 2.7145464420318604\n",
      "______________\n",
      "epoch 92 train loss 2.5418269634246826\n",
      "val loss 2.7145814895629883\n",
      "______________\n",
      "epoch 93 train loss 2.574831962585449\n",
      "val loss 2.7146921157836914\n",
      "______________\n",
      "epoch 94 train loss 2.560450315475464\n",
      "val loss 2.714823007583618\n",
      "______________\n",
      "epoch 95 train loss 2.573591470718384\n",
      "val loss 2.715013027191162\n",
      "______________\n",
      "epoch 96 train loss 2.5566227436065674\n",
      "val loss 2.7151660919189453\n",
      "______________\n",
      "epoch 97 train loss 2.5679752826690674\n",
      "val loss 2.7153093814849854\n",
      "______________\n",
      "best loss 2.7142395973205566 {'pd': {'accuracy': 0.30952380952380953, 'auc_micro': 0.6172164119066773, 'auc_mean': 0.5387440920327916, 'auc_weighted': 0.5826149504786146}, 'nd': {'accuracy': 0.2962962962962963, 'auc_micro': 0.16138374899436847, 'auc_mean': 0.40730715170573667, 'auc_weighted': 0.2785734705546027}, 'mod': {'accuracy': 0.2962962962962963, 'auc_micro': 0.16138374899436847, 'auc_mean': 0.40730715170573667, 'auc_weighted': 0.2785734705546027}, 'dlts': {'accuracy': [0.7857142857142857, 0.8928571428571429, 0.9107142857142857, 0.9464285714285714, 0.8035714285714286], 'accuracy_mean': 0.8678571428571429, 'auc': [0.3787878787878788, 0.45333333333333337, 0.596078431372549, 0.5031446540880503, 0.5272727272727273], 'auc_mean': 0.4917234049709077}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [tensor([[0.4928, 0.2319, 0.2753],\n",
      "        [0.5303, 0.2508, 0.2189],\n",
      "        [0.4144, 0.2803, 0.3053],\n",
      "        [0.3925, 0.2747, 0.3328],\n",
      "        [0.4872, 0.2733, 0.2395],\n",
      "        [0.4702, 0.2521, 0.2777],\n",
      "        [0.3898, 0.3001, 0.3101],\n",
      "        [0.3643, 0.2833, 0.3524],\n",
      "        [0.4864, 0.2568, 0.2568],\n",
      "        [0.3655, 0.2734, 0.3611],\n",
      "        [0.5298, 0.2470, 0.2232],\n",
      "        [0.3401, 0.2716, 0.3883],\n",
      "        [0.3427, 0.2930, 0.3643],\n",
      "        [0.4350, 0.2887, 0.2763],\n",
      "        [0.3368, 0.2814, 0.3818],\n",
      "        [0.4386, 0.2749, 0.2865],\n",
      "        [0.4060, 0.2973, 0.2968],\n",
      "        [0.3363, 0.3012, 0.3625],\n",
      "        [0.3841, 0.3016, 0.3144],\n",
      "        [0.5705, 0.2226, 0.2069],\n",
      "        [0.4979, 0.2666, 0.2355],\n",
      "        [0.4752, 0.2688, 0.2560],\n",
      "        [0.4001, 0.2978, 0.3021],\n",
      "        [0.4026, 0.2707, 0.3267],\n",
      "        [0.4826, 0.2752, 0.2422],\n",
      "        [0.2786, 0.3556, 0.3658],\n",
      "        [0.3835, 0.3177, 0.2988],\n",
      "        [0.4045, 0.3013, 0.2942],\n",
      "        [0.4442, 0.2993, 0.2565],\n",
      "        [0.3674, 0.3110, 0.3216],\n",
      "        [0.4131, 0.2597, 0.3271],\n",
      "        [0.4812, 0.2870, 0.2319],\n",
      "        [0.4235, 0.2640, 0.3124],\n",
      "        [0.3322, 0.3176, 0.3502],\n",
      "        [0.4424, 0.2965, 0.2611],\n",
      "        [0.4303, 0.2759, 0.2938],\n",
      "        [0.4860, 0.2546, 0.2594],\n",
      "        [0.4281, 0.2855, 0.2864],\n",
      "        [0.4240, 0.2817, 0.2943],\n",
      "        [0.4831, 0.2656, 0.2513],\n",
      "        [0.4250, 0.2763, 0.2987],\n",
      "        [0.3865, 0.2891, 0.3244],\n",
      "        [0.3322, 0.2784, 0.3894],\n",
      "        [0.4064, 0.2838, 0.3098],\n",
      "        [0.5044, 0.2630, 0.2326],\n",
      "        [0.4888, 0.2539, 0.2573],\n",
      "        [0.3979, 0.3056, 0.2965],\n",
      "        [0.4826, 0.2640, 0.2534],\n",
      "        [0.3919, 0.2980, 0.3101],\n",
      "        [0.4472, 0.2979, 0.2549],\n",
      "        [0.4478, 0.2858, 0.2664],\n",
      "        [0.5304, 0.2357, 0.2339],\n",
      "        [0.4181, 0.2636, 0.3183],\n",
      "        [0.3901, 0.2943, 0.3156],\n",
      "        [0.4788, 0.2775, 0.2437],\n",
      "        [0.4827, 0.2710, 0.2463]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[0.7979, 0.0554, 0.1466],\n",
      "        [0.6822, 0.1005, 0.2173],\n",
      "        [0.6443, 0.1390, 0.2167],\n",
      "        [0.5662, 0.1572, 0.2767],\n",
      "        [0.6397, 0.1471, 0.2133],\n",
      "        [0.6451, 0.1425, 0.2124],\n",
      "        [0.4279, 0.1882, 0.3839],\n",
      "        [0.5975, 0.1425, 0.2600],\n",
      "        [0.6782, 0.1357, 0.1861],\n",
      "        [0.5413, 0.1629, 0.2959],\n",
      "        [0.7719, 0.0933, 0.1347],\n",
      "        [0.5458, 0.1679, 0.2863],\n",
      "        [0.2633, 0.0663, 0.6704],\n",
      "        [0.7040, 0.0986, 0.1974],\n",
      "        [0.4337, 0.1468, 0.4195],\n",
      "        [0.5802, 0.1331, 0.2866],\n",
      "        [0.5084, 0.1661, 0.3254],\n",
      "        [0.4898, 0.1788, 0.3315],\n",
      "        [0.5576, 0.1719, 0.2705],\n",
      "        [0.7796, 0.0585, 0.1619],\n",
      "        [0.6076, 0.1543, 0.2381],\n",
      "        [0.7182, 0.1119, 0.1699],\n",
      "        [0.6642, 0.1245, 0.2113],\n",
      "        [0.5788, 0.1512, 0.2700],\n",
      "        [0.6987, 0.1073, 0.1940],\n",
      "        [0.3482, 0.1572, 0.4946],\n",
      "        [0.5903, 0.1606, 0.2491],\n",
      "        [0.4993, 0.1613, 0.3395],\n",
      "        [0.6287, 0.1521, 0.2192],\n",
      "        [0.5134, 0.1434, 0.3432],\n",
      "        [0.6125, 0.1405, 0.2470],\n",
      "        [0.5992, 0.1133, 0.2875],\n",
      "        [0.6211, 0.1493, 0.2296],\n",
      "        [0.3494, 0.1715, 0.4791],\n",
      "        [0.5842, 0.1571, 0.2587],\n",
      "        [0.5275, 0.1727, 0.2998],\n",
      "        [0.6810, 0.1340, 0.1850],\n",
      "        [0.7834, 0.0763, 0.1402],\n",
      "        [0.5400, 0.1729, 0.2870],\n",
      "        [0.6424, 0.1461, 0.2116],\n",
      "        [0.6505, 0.1238, 0.2257],\n",
      "        [0.5458, 0.1474, 0.3069],\n",
      "        [0.4742, 0.1783, 0.3475],\n",
      "        [0.5502, 0.1511, 0.2987],\n",
      "        [0.6662, 0.1404, 0.1934],\n",
      "        [0.7151, 0.1158, 0.1690],\n",
      "        [0.6094, 0.1490, 0.2416],\n",
      "        [0.6977, 0.1293, 0.1730],\n",
      "        [0.5479, 0.1267, 0.3254],\n",
      "        [0.6236, 0.1069, 0.2695],\n",
      "        [0.6310, 0.1523, 0.2167],\n",
      "        [0.7851, 0.0874, 0.1275],\n",
      "        [0.6132, 0.1225, 0.2643],\n",
      "        [0.5403, 0.1623, 0.2974],\n",
      "        [0.6041, 0.1464, 0.2495],\n",
      "        [0.6524, 0.1408, 0.2068]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[0.1121, 0.3126, 0.1462, 0.1595, 0.1226, 0.1469],\n",
      "        [0.1428, 0.2464, 0.1610, 0.1752, 0.1282, 0.1464],\n",
      "        [0.1345, 0.2503, 0.1576, 0.1635, 0.1379, 0.1562],\n",
      "        [0.1364, 0.2462, 0.1542, 0.1642, 0.1413, 0.1576],\n",
      "        [0.1401, 0.2246, 0.1690, 0.1670, 0.1429, 0.1563],\n",
      "        [0.1407, 0.2270, 0.1672, 0.1637, 0.1411, 0.1603],\n",
      "        [0.1364, 0.2445, 0.1611, 0.1605, 0.1479, 0.1497],\n",
      "        [0.1312, 0.2530, 0.1500, 0.1633, 0.1489, 0.1536],\n",
      "        [0.1448, 0.2130, 0.1624, 0.1681, 0.1458, 0.1659],\n",
      "        [0.1361, 0.2490, 0.1564, 0.1653, 0.1386, 0.1546],\n",
      "        [0.1426, 0.2193, 0.1658, 0.1740, 0.1432, 0.1550],\n",
      "        [0.1473, 0.2234, 0.1685, 0.1672, 0.1439, 0.1497],\n",
      "        [0.1059, 0.3631, 0.1274, 0.1497, 0.1162, 0.1378],\n",
      "        [0.1298, 0.2551, 0.1650, 0.1666, 0.1424, 0.1411],\n",
      "        [0.1262, 0.2939, 0.1469, 0.1570, 0.1311, 0.1449],\n",
      "        [0.1289, 0.2723, 0.1564, 0.1570, 0.1400, 0.1454],\n",
      "        [0.1373, 0.2425, 0.1619, 0.1666, 0.1423, 0.1495],\n",
      "        [0.1419, 0.2172, 0.1692, 0.1643, 0.1522, 0.1552],\n",
      "        [0.1410, 0.2356, 0.1602, 0.1592, 0.1434, 0.1606],\n",
      "        [0.1042, 0.3300, 0.1579, 0.1438, 0.1210, 0.1432],\n",
      "        [0.1417, 0.2273, 0.1595, 0.1701, 0.1475, 0.1539],\n",
      "        [0.1408, 0.2198, 0.1640, 0.1716, 0.1522, 0.1517],\n",
      "        [0.1390, 0.2203, 0.1693, 0.1712, 0.1517, 0.1485],\n",
      "        [0.1320, 0.2580, 0.1534, 0.1598, 0.1418, 0.1550],\n",
      "        [0.1337, 0.2533, 0.1582, 0.1606, 0.1408, 0.1533],\n",
      "        [0.1328, 0.2512, 0.1617, 0.1556, 0.1477, 0.1511],\n",
      "        [0.1417, 0.2110, 0.1765, 0.1668, 0.1516, 0.1524],\n",
      "        [0.1387, 0.2481, 0.1636, 0.1531, 0.1444, 0.1521],\n",
      "        [0.1365, 0.2161, 0.1653, 0.1677, 0.1458, 0.1687],\n",
      "        [0.1295, 0.2556, 0.1601, 0.1681, 0.1410, 0.1457],\n",
      "        [0.1499, 0.2362, 0.1584, 0.1653, 0.1391, 0.1512],\n",
      "        [0.1437, 0.2523, 0.1533, 0.1746, 0.1350, 0.1412],\n",
      "        [0.1421, 0.2364, 0.1560, 0.1652, 0.1471, 0.1532],\n",
      "        [0.1383, 0.2460, 0.1704, 0.1503, 0.1456, 0.1494],\n",
      "        [0.1419, 0.2394, 0.1626, 0.1629, 0.1435, 0.1496],\n",
      "        [0.1462, 0.2361, 0.1605, 0.1628, 0.1423, 0.1521],\n",
      "        [0.1444, 0.2147, 0.1605, 0.1674, 0.1463, 0.1667],\n",
      "        [0.1377, 0.2352, 0.1642, 0.1729, 0.1347, 0.1554],\n",
      "        [0.1452, 0.2165, 0.1626, 0.1632, 0.1506, 0.1619],\n",
      "        [0.1398, 0.2298, 0.1612, 0.1652, 0.1442, 0.1598],\n",
      "        [0.1326, 0.2620, 0.1518, 0.1600, 0.1435, 0.1502],\n",
      "        [0.1339, 0.2685, 0.1490, 0.1560, 0.1358, 0.1568],\n",
      "        [0.1480, 0.2212, 0.1631, 0.1646, 0.1495, 0.1536],\n",
      "        [0.1287, 0.2460, 0.1615, 0.1665, 0.1481, 0.1493],\n",
      "        [0.1422, 0.2160, 0.1636, 0.1624, 0.1485, 0.1672],\n",
      "        [0.1373, 0.2386, 0.1692, 0.1605, 0.1407, 0.1537],\n",
      "        [0.1448, 0.2127, 0.1773, 0.1714, 0.1483, 0.1457],\n",
      "        [0.1444, 0.2065, 0.1702, 0.1763, 0.1394, 0.1632],\n",
      "        [0.1401, 0.2456, 0.1594, 0.1665, 0.1403, 0.1481],\n",
      "        [0.1247, 0.2757, 0.1553, 0.1547, 0.1355, 0.1541],\n",
      "        [0.1393, 0.2109, 0.1662, 0.1685, 0.1544, 0.1608],\n",
      "        [0.1422, 0.2224, 0.1611, 0.1716, 0.1446, 0.1581],\n",
      "        [0.1330, 0.2455, 0.1681, 0.1663, 0.1324, 0.1549],\n",
      "        [0.1446, 0.2249, 0.1648, 0.1683, 0.1464, 0.1510],\n",
      "        [0.1371, 0.2274, 0.1625, 0.1684, 0.1474, 0.1572],\n",
      "        [0.1430, 0.2061, 0.1736, 0.1750, 0.1403, 0.1619]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[0.0550, 0.0977, 0.0906, 0.0665, 0.1340],\n",
      "        [0.0999, 0.1756, 0.1110, 0.1184, 0.1546],\n",
      "        [0.1588, 0.2925, 0.2006, 0.1579, 0.2237],\n",
      "        [0.2030, 0.2361, 0.2077, 0.1718, 0.2516],\n",
      "        [0.1577, 0.2670, 0.2164, 0.1633, 0.2336],\n",
      "        [0.1529, 0.2555, 0.2389, 0.1961, 0.2437],\n",
      "        [0.1837, 0.2138, 0.1948, 0.1638, 0.2107],\n",
      "        [0.1829, 0.2386, 0.1915, 0.1573, 0.2469],\n",
      "        [0.1713, 0.2719, 0.2461, 0.1973, 0.2685],\n",
      "        [0.1895, 0.2727, 0.2093, 0.1774, 0.2266],\n",
      "        [0.1411, 0.2116, 0.1770, 0.1691, 0.2436],\n",
      "        [0.1878, 0.1943, 0.1998, 0.2087, 0.2293],\n",
      "        [0.0523, 0.0844, 0.1163, 0.0537, 0.1024],\n",
      "        [0.0988, 0.1967, 0.1285, 0.1340, 0.1829],\n",
      "        [0.1092, 0.1800, 0.1402, 0.0815, 0.1477],\n",
      "        [0.1456, 0.2042, 0.1637, 0.1455, 0.2069],\n",
      "        [0.1911, 0.2762, 0.2189, 0.1943, 0.2536],\n",
      "        [0.2047, 0.2302, 0.2043, 0.1822, 0.2495],\n",
      "        [0.2165, 0.2681, 0.2106, 0.1682, 0.2498],\n",
      "        [0.0340, 0.1007, 0.0862, 0.0461, 0.1150],\n",
      "        [0.1731, 0.2764, 0.2083, 0.1832, 0.2384],\n",
      "        [0.1617, 0.2239, 0.1838, 0.1739, 0.2454],\n",
      "        [0.1727, 0.2137, 0.1609, 0.1695, 0.2431],\n",
      "        [0.1923, 0.2269, 0.1915, 0.1655, 0.2411],\n",
      "        [0.1346, 0.2065, 0.1470, 0.1338, 0.2037],\n",
      "        [0.1955, 0.1976, 0.1367, 0.1488, 0.2086],\n",
      "        [0.1860, 0.2204, 0.1953, 0.1761, 0.2534],\n",
      "        [0.1639, 0.2478, 0.1666, 0.1579, 0.2273],\n",
      "        [0.2056, 0.2633, 0.1925, 0.1723, 0.2923],\n",
      "        [0.1223, 0.1385, 0.1405, 0.1388, 0.2161],\n",
      "        [0.1517, 0.2237, 0.1999, 0.1777, 0.2240],\n",
      "        [0.0877, 0.1555, 0.1236, 0.1087, 0.1852],\n",
      "        [0.2062, 0.2646, 0.2149, 0.1792, 0.2572],\n",
      "        [0.1792, 0.2212, 0.1749, 0.1561, 0.2140],\n",
      "        [0.1683, 0.2501, 0.1887, 0.1595, 0.2346],\n",
      "        [0.1716, 0.2659, 0.2262, 0.1832, 0.2246],\n",
      "        [0.1706, 0.2738, 0.2457, 0.1974, 0.2656],\n",
      "        [0.0953, 0.1853, 0.1412, 0.1027, 0.2002],\n",
      "        [0.1960, 0.2916, 0.2410, 0.1916, 0.2517],\n",
      "        [0.1611, 0.2893, 0.2291, 0.1742, 0.2316],\n",
      "        [0.1492, 0.2557, 0.1771, 0.1515, 0.2202],\n",
      "        [0.2061, 0.2339, 0.1829, 0.1298, 0.2081],\n",
      "        [0.1906, 0.2156, 0.2096, 0.2109, 0.2456],\n",
      "        [0.1569, 0.2550, 0.1728, 0.1851, 0.2428],\n",
      "        [0.1696, 0.2905, 0.2248, 0.1881, 0.2493],\n",
      "        [0.1209, 0.2213, 0.2016, 0.1597, 0.2317],\n",
      "        [0.1846, 0.2070, 0.1824, 0.1886, 0.2581],\n",
      "        [0.1963, 0.2549, 0.2154, 0.1969, 0.2926],\n",
      "        [0.1460, 0.1910, 0.1549, 0.1277, 0.1819],\n",
      "        [0.0954, 0.1683, 0.1073, 0.1228, 0.2028],\n",
      "        [0.1647, 0.2374, 0.2110, 0.1880, 0.2819],\n",
      "        [0.1409, 0.2227, 0.1757, 0.1700, 0.2400],\n",
      "        [0.0927, 0.1861, 0.1447, 0.1028, 0.1765],\n",
      "        [0.2020, 0.2305, 0.2045, 0.1784, 0.2224],\n",
      "        [0.1571, 0.2985, 0.2049, 0.1892, 0.2379],\n",
      "        [0.1915, 0.2542, 0.1956, 0.2024, 0.2848]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)], '5%': [tensor([[0.3005, 0.1298, 0.1502],\n",
      "        [0.4309, 0.1446, 0.1252],\n",
      "        [0.3745, 0.2289, 0.2403],\n",
      "        [0.3489, 0.2356, 0.2991],\n",
      "        [0.4409, 0.2038, 0.1797],\n",
      "        [0.4169, 0.1981, 0.1914],\n",
      "        [0.3423, 0.2142, 0.2452],\n",
      "        [0.3448, 0.2035, 0.2709],\n",
      "        [0.4367, 0.1954, 0.2073],\n",
      "        [0.3539, 0.2188, 0.2901],\n",
      "        [0.4231, 0.2065, 0.1895],\n",
      "        [0.2919, 0.2282, 0.2745],\n",
      "        [0.2401, 0.1469, 0.1767],\n",
      "        [0.4010, 0.2036, 0.1725],\n",
      "        [0.2982, 0.1819, 0.2251],\n",
      "        [0.3906, 0.1710, 0.1504],\n",
      "        [0.3404, 0.2535, 0.2401],\n",
      "        [0.2803, 0.2405, 0.2962],\n",
      "        [0.3479, 0.2483, 0.2456],\n",
      "        [0.4936, 0.0608, 0.0879],\n",
      "        [0.4627, 0.2009, 0.1874],\n",
      "        [0.3905, 0.2140, 0.2224],\n",
      "        [0.3401, 0.2549, 0.2342],\n",
      "        [0.3365, 0.2184, 0.2404],\n",
      "        [0.4276, 0.2205, 0.1985],\n",
      "        [0.2441, 0.2783, 0.3016],\n",
      "        [0.3265, 0.2579, 0.2241],\n",
      "        [0.3241, 0.2483, 0.2230],\n",
      "        [0.4197, 0.2368, 0.2055],\n",
      "        [0.3328, 0.2167, 0.2156],\n",
      "        [0.3927, 0.2211, 0.2735],\n",
      "        [0.3708, 0.1888, 0.1453],\n",
      "        [0.3784, 0.2149, 0.2631],\n",
      "        [0.3057, 0.2414, 0.2746],\n",
      "        [0.3928, 0.2296, 0.1907],\n",
      "        [0.3614, 0.2244, 0.2536],\n",
      "        [0.4405, 0.2160, 0.2125],\n",
      "        [0.3406, 0.2072, 0.1951],\n",
      "        [0.3643, 0.2411, 0.2353],\n",
      "        [0.4544, 0.2073, 0.1952],\n",
      "        [0.3639, 0.2382, 0.2160],\n",
      "        [0.3468, 0.2456, 0.2226],\n",
      "        [0.2927, 0.2174, 0.3301],\n",
      "        [0.3336, 0.1995, 0.1994],\n",
      "        [0.4529, 0.2239, 0.1824],\n",
      "        [0.4107, 0.1765, 0.1801],\n",
      "        [0.3477, 0.2241, 0.2205],\n",
      "        [0.4407, 0.2009, 0.2122],\n",
      "        [0.3748, 0.2342, 0.2046],\n",
      "        [0.3978, 0.2049, 0.1632],\n",
      "        [0.4191, 0.2344, 0.2248],\n",
      "        [0.4634, 0.1787, 0.1685],\n",
      "        [0.3749, 0.2035, 0.1963],\n",
      "        [0.3333, 0.2209, 0.2367],\n",
      "        [0.4379, 0.2104, 0.1752],\n",
      "        [0.4660, 0.2350, 0.2103]], device='cuda:0'), tensor([[0.5330, 0.0061, 0.0237],\n",
      "        [0.5598, 0.0237, 0.0825],\n",
      "        [0.6434, 0.0631, 0.1146],\n",
      "        [0.5007, 0.0880, 0.1869],\n",
      "        [0.6026, 0.0752, 0.1096],\n",
      "        [0.5854, 0.0529, 0.1075],\n",
      "        [0.4455, 0.1027, 0.2503],\n",
      "        [0.5618, 0.0577, 0.1255],\n",
      "        [0.5829, 0.0676, 0.1109],\n",
      "        [0.5308, 0.0792, 0.1619],\n",
      "        [0.7172, 0.0449, 0.0796],\n",
      "        [0.4648, 0.0700, 0.1575],\n",
      "        [0.1323, 0.0059, 0.1158],\n",
      "        [0.4925, 0.0216, 0.0845],\n",
      "        [0.3969, 0.0582, 0.1268],\n",
      "        [0.6017, 0.0296, 0.1132],\n",
      "        [0.4532, 0.0860, 0.1929],\n",
      "        [0.4304, 0.1151, 0.2521],\n",
      "        [0.5245, 0.0915, 0.1853],\n",
      "        [0.6447, 0.0118, 0.0350],\n",
      "        [0.5581, 0.0743, 0.1568],\n",
      "        [0.6307, 0.0416, 0.0943],\n",
      "        [0.5713, 0.0542, 0.1044],\n",
      "        [0.4461, 0.0606, 0.1396],\n",
      "        [0.6702, 0.0623, 0.1268],\n",
      "        [0.3318, 0.0881, 0.3204],\n",
      "        [0.5581, 0.1059, 0.1591],\n",
      "        [0.4256, 0.0704, 0.2466],\n",
      "        [0.5940, 0.0832, 0.1338],\n",
      "        [0.4479, 0.0683, 0.1769],\n",
      "        [0.5364, 0.0722, 0.1287],\n",
      "        [0.4714, 0.0272, 0.0938],\n",
      "        [0.5075, 0.0880, 0.1548],\n",
      "        [0.3422, 0.0987, 0.3207],\n",
      "        [0.5004, 0.0638, 0.1536],\n",
      "        [0.5141, 0.0964, 0.1961],\n",
      "        [0.6154, 0.0523, 0.0919],\n",
      "        [0.7022, 0.0165, 0.0376],\n",
      "        [0.4722, 0.1014, 0.2101],\n",
      "        [0.6553, 0.0692, 0.1069],\n",
      "        [0.5992, 0.0439, 0.1047],\n",
      "        [0.4706, 0.0757, 0.1882],\n",
      "        [0.3875, 0.0890, 0.2209],\n",
      "        [0.5527, 0.0719, 0.1684],\n",
      "        [0.6458, 0.0717, 0.0994],\n",
      "        [0.6763, 0.0350, 0.0771],\n",
      "        [0.5281, 0.0751, 0.1191],\n",
      "        [0.6542, 0.0487, 0.0826],\n",
      "        [0.5064, 0.0509, 0.1607],\n",
      "        [0.5624, 0.0400, 0.1054],\n",
      "        [0.5850, 0.0938, 0.1571],\n",
      "        [0.6758, 0.0368, 0.0776],\n",
      "        [0.5272, 0.0302, 0.1324],\n",
      "        [0.4952, 0.0722, 0.1783],\n",
      "        [0.5510, 0.0797, 0.1564],\n",
      "        [0.6150, 0.0666, 0.1208]], device='cuda:0'), tensor([[0.0602, 0.2466, 0.0787, 0.0951, 0.0648, 0.1017],\n",
      "        [0.1007, 0.2225, 0.1182, 0.1239, 0.0919, 0.1209],\n",
      "        [0.1149, 0.2535, 0.1318, 0.1394, 0.1167, 0.1200],\n",
      "        [0.1137, 0.2371, 0.1292, 0.1267, 0.1014, 0.1317],\n",
      "        [0.1174, 0.2012, 0.1464, 0.1496, 0.1202, 0.1411],\n",
      "        [0.1158, 0.1757, 0.1409, 0.1349, 0.1166, 0.1377],\n",
      "        [0.1157, 0.2269, 0.1325, 0.1417, 0.1180, 0.1234],\n",
      "        [0.1071, 0.2306, 0.1173, 0.1358, 0.1162, 0.1196],\n",
      "        [0.1283, 0.1878, 0.1455, 0.1491, 0.1224, 0.1426],\n",
      "        [0.1102, 0.2424, 0.1324, 0.1428, 0.1088, 0.1211],\n",
      "        [0.1204, 0.1736, 0.1507, 0.1403, 0.1154, 0.1246],\n",
      "        [0.1187, 0.2103, 0.1356, 0.1500, 0.1152, 0.1222],\n",
      "        [0.0344, 0.2711, 0.0391, 0.0489, 0.0357, 0.0516],\n",
      "        [0.0952, 0.2267, 0.1337, 0.1316, 0.0944, 0.1120],\n",
      "        [0.0921, 0.2451, 0.1119, 0.1313, 0.0993, 0.1044],\n",
      "        [0.0879, 0.2675, 0.1108, 0.1018, 0.0929, 0.0889],\n",
      "        [0.1095, 0.2022, 0.1307, 0.1282, 0.1216, 0.1365],\n",
      "        [0.1224, 0.1943, 0.1540, 0.1424, 0.1374, 0.1308],\n",
      "        [0.1172, 0.2075, 0.1304, 0.1277, 0.1213, 0.1430],\n",
      "        [0.0674, 0.2393, 0.0938, 0.0917, 0.0596, 0.0959],\n",
      "        [0.1095, 0.2091, 0.1408, 0.1472, 0.1100, 0.1238],\n",
      "        [0.1193, 0.1941, 0.1329, 0.1375, 0.1267, 0.1225],\n",
      "        [0.1200, 0.2101, 0.1418, 0.1444, 0.1255, 0.1293],\n",
      "        [0.1028, 0.2261, 0.1161, 0.1305, 0.1167, 0.1223],\n",
      "        [0.1047, 0.2040, 0.1222, 0.1250, 0.1112, 0.1300],\n",
      "        [0.1040, 0.2137, 0.1281, 0.1331, 0.1211, 0.1320],\n",
      "        [0.1259, 0.1944, 0.1419, 0.1463, 0.1336, 0.1359],\n",
      "        [0.1010, 0.2306, 0.1316, 0.1111, 0.1010, 0.1208],\n",
      "        [0.1178, 0.2074, 0.1356, 0.1453, 0.1202, 0.1381],\n",
      "        [0.0934, 0.2156, 0.1328, 0.1369, 0.1045, 0.1076],\n",
      "        [0.1248, 0.2202, 0.1279, 0.1401, 0.1236, 0.1302],\n",
      "        [0.1035, 0.2217, 0.1129, 0.1188, 0.0999, 0.1140],\n",
      "        [0.1226, 0.2100, 0.1289, 0.1479, 0.1198, 0.1347],\n",
      "        [0.1037, 0.2278, 0.1341, 0.1184, 0.1225, 0.1214],\n",
      "        [0.1163, 0.2204, 0.1440, 0.1358, 0.1177, 0.1228],\n",
      "        [0.1222, 0.2162, 0.1335, 0.1314, 0.1093, 0.1350],\n",
      "        [0.1213, 0.1915, 0.1339, 0.1396, 0.1219, 0.1335],\n",
      "        [0.1102, 0.1928, 0.1335, 0.1384, 0.0990, 0.1244],\n",
      "        [0.1217, 0.1807, 0.1415, 0.1455, 0.1221, 0.1396],\n",
      "        [0.1169, 0.2331, 0.1457, 0.1426, 0.1233, 0.1355],\n",
      "        [0.1045, 0.2327, 0.1356, 0.1361, 0.1086, 0.1235],\n",
      "        [0.1077, 0.2319, 0.1182, 0.1353, 0.1131, 0.1176],\n",
      "        [0.1192, 0.2176, 0.1337, 0.1283, 0.1273, 0.1290],\n",
      "        [0.1068, 0.2363, 0.1384, 0.1372, 0.1179, 0.1184],\n",
      "        [0.1205, 0.2050, 0.1468, 0.1355, 0.1261, 0.1346],\n",
      "        [0.1022, 0.2066, 0.1437, 0.1379, 0.1134, 0.1210],\n",
      "        [0.1290, 0.1941, 0.1500, 0.1563, 0.1225, 0.1257],\n",
      "        [0.1282, 0.1840, 0.1324, 0.1558, 0.1144, 0.1347],\n",
      "        [0.1055, 0.2238, 0.1450, 0.1330, 0.1141, 0.1166],\n",
      "        [0.0818, 0.2082, 0.1171, 0.1111, 0.0918, 0.1028],\n",
      "        [0.1217, 0.2021, 0.1410, 0.1369, 0.1333, 0.1351],\n",
      "        [0.1153, 0.1898, 0.1460, 0.1501, 0.1123, 0.1284],\n",
      "        [0.0961, 0.2243, 0.1314, 0.1375, 0.1008, 0.1238],\n",
      "        [0.1165, 0.2039, 0.1341, 0.1397, 0.1220, 0.1299],\n",
      "        [0.1196, 0.2190, 0.1316, 0.1511, 0.1197, 0.1248],\n",
      "        [0.1230, 0.2000, 0.1445, 0.1519, 0.1155, 0.1454]], device='cuda:0'), tensor([[0.0054, 0.0170, 0.0124, 0.0041, 0.0239],\n",
      "        [0.0177, 0.0456, 0.0254, 0.0375, 0.0567],\n",
      "        [0.0681, 0.1683, 0.1000, 0.0631, 0.1280],\n",
      "        [0.0925, 0.1484, 0.0860, 0.0669, 0.1427],\n",
      "        [0.0766, 0.1348, 0.0932, 0.0702, 0.1249],\n",
      "        [0.0562, 0.1349, 0.0813, 0.0707, 0.1287],\n",
      "        [0.0771, 0.0876, 0.0900, 0.0765, 0.1011],\n",
      "        [0.0787, 0.1336, 0.0883, 0.0560, 0.1236],\n",
      "        [0.0829, 0.1839, 0.1446, 0.1007, 0.1652],\n",
      "        [0.0904, 0.1732, 0.1262, 0.0754, 0.1237],\n",
      "        [0.0705, 0.1350, 0.0970, 0.0864, 0.1633],\n",
      "        [0.0809, 0.0798, 0.0873, 0.0733, 0.1388],\n",
      "        [0.0041, 0.0083, 0.0194, 0.0031, 0.0090],\n",
      "        [0.0233, 0.0572, 0.0331, 0.0384, 0.0730],\n",
      "        [0.0242, 0.0766, 0.0448, 0.0200, 0.0366],\n",
      "        [0.0220, 0.0771, 0.0396, 0.0369, 0.0682],\n",
      "        [0.0800, 0.1757, 0.1087, 0.0904, 0.1363],\n",
      "        [0.0856, 0.1331, 0.1053, 0.0966, 0.1245],\n",
      "        [0.1212, 0.1358, 0.1104, 0.0706, 0.1235],\n",
      "        [0.0023, 0.0178, 0.0107, 0.0048, 0.0163],\n",
      "        [0.0844, 0.1499, 0.1016, 0.0809, 0.1372],\n",
      "        [0.0631, 0.1071, 0.0807, 0.0950, 0.1355],\n",
      "        [0.0766, 0.1191, 0.0806, 0.0800, 0.1153],\n",
      "        [0.0854, 0.1167, 0.0890, 0.0637, 0.1556],\n",
      "        [0.0518, 0.1011, 0.0671, 0.0505, 0.1150],\n",
      "        [0.0687, 0.0963, 0.0569, 0.0364, 0.0861],\n",
      "        [0.1125, 0.1441, 0.1182, 0.0961, 0.1586],\n",
      "        [0.0522, 0.1239, 0.0569, 0.0536, 0.1049],\n",
      "        [0.1015, 0.1733, 0.1032, 0.0813, 0.1848],\n",
      "        [0.0340, 0.0541, 0.0416, 0.0347, 0.0672],\n",
      "        [0.0787, 0.1268, 0.1121, 0.0834, 0.1348],\n",
      "        [0.0222, 0.0603, 0.0379, 0.0227, 0.0550],\n",
      "        [0.0977, 0.1350, 0.1120, 0.0850, 0.1390],\n",
      "        [0.0628, 0.1076, 0.0751, 0.0627, 0.1048],\n",
      "        [0.0699, 0.1330, 0.0833, 0.0639, 0.1065],\n",
      "        [0.0815, 0.1599, 0.1271, 0.0781, 0.1125],\n",
      "        [0.0786, 0.1662, 0.0938, 0.0954, 0.1423],\n",
      "        [0.0306, 0.0821, 0.0458, 0.0243, 0.0762],\n",
      "        [0.1225, 0.1880, 0.1336, 0.0951, 0.1642],\n",
      "        [0.0813, 0.1958, 0.1098, 0.1045, 0.1345],\n",
      "        [0.0524, 0.0977, 0.0617, 0.0500, 0.0872],\n",
      "        [0.0836, 0.1172, 0.0863, 0.0454, 0.1019],\n",
      "        [0.0776, 0.0969, 0.0963, 0.0734, 0.1249],\n",
      "        [0.0500, 0.1291, 0.0838, 0.0691, 0.1293],\n",
      "        [0.0911, 0.1865, 0.1194, 0.1034, 0.1502],\n",
      "        [0.0338, 0.1036, 0.0830, 0.0537, 0.1015],\n",
      "        [0.0752, 0.1171, 0.0925, 0.0981, 0.1277],\n",
      "        [0.0892, 0.1412, 0.0689, 0.1009, 0.1749],\n",
      "        [0.0464, 0.0763, 0.0780, 0.0452, 0.0770],\n",
      "        [0.0220, 0.0470, 0.0240, 0.0325, 0.0576],\n",
      "        [0.0824, 0.1671, 0.1247, 0.1118, 0.1995],\n",
      "        [0.0768, 0.1144, 0.0768, 0.1005, 0.1279],\n",
      "        [0.0120, 0.0723, 0.0326, 0.0152, 0.0337],\n",
      "        [0.1029, 0.1055, 0.0909, 0.0829, 0.1286],\n",
      "        [0.0656, 0.1962, 0.0869, 0.0782, 0.1277],\n",
      "        [0.0869, 0.1192, 0.0611, 0.0751, 0.1575]], device='cuda:0')], '95%': [tensor([[0.6480, 0.2901, 0.4367],\n",
      "        [0.7398, 0.2814, 0.2909],\n",
      "        [0.5251, 0.3076, 0.3363],\n",
      "        [0.4293, 0.2943, 0.3843],\n",
      "        [0.6392, 0.3370, 0.2697],\n",
      "        [0.6002, 0.2906, 0.3041],\n",
      "        [0.4827, 0.3623, 0.3575],\n",
      "        [0.5170, 0.2903, 0.4223],\n",
      "        [0.5967, 0.2795, 0.2996],\n",
      "        [0.4611, 0.3227, 0.3848],\n",
      "        [0.5998, 0.3047, 0.2839],\n",
      "        [0.4457, 0.3491, 0.3968],\n",
      "        [0.6270, 0.4046, 0.4482],\n",
      "        [0.6196, 0.2916, 0.3189],\n",
      "        [0.5461, 0.3075, 0.4340],\n",
      "        [0.6523, 0.2842, 0.3460],\n",
      "        [0.4843, 0.3287, 0.3828],\n",
      "        [0.4288, 0.3319, 0.4444],\n",
      "        [0.4856, 0.3317, 0.3583],\n",
      "        [0.8483, 0.2784, 0.2387],\n",
      "        [0.6007, 0.2853, 0.2673],\n",
      "        [0.5498, 0.3058, 0.3080],\n",
      "        [0.4751, 0.3189, 0.3458],\n",
      "        [0.4947, 0.2953, 0.3828],\n",
      "        [0.5530, 0.3283, 0.2834],\n",
      "        [0.3789, 0.3761, 0.4237],\n",
      "        [0.4944, 0.3679, 0.3298],\n",
      "        [0.4988, 0.3546, 0.3768],\n",
      "        [0.5571, 0.3266, 0.2808],\n",
      "        [0.5102, 0.3532, 0.3704],\n",
      "        [0.4900, 0.2835, 0.3492],\n",
      "        [0.6670, 0.3504, 0.3063],\n",
      "        [0.5012, 0.2925, 0.3358],\n",
      "        [0.4824, 0.3495, 0.3748],\n",
      "        [0.5328, 0.3481, 0.2836],\n",
      "        [0.4858, 0.2775, 0.3714],\n",
      "        [0.5817, 0.2686, 0.2952],\n",
      "        [0.5913, 0.3308, 0.3318],\n",
      "        [0.4989, 0.3157, 0.3407],\n",
      "        [0.5909, 0.2866, 0.2644],\n",
      "        [0.5291, 0.3073, 0.3472],\n",
      "        [0.5081, 0.3019, 0.3683],\n",
      "        [0.4060, 0.2939, 0.4562],\n",
      "        [0.6006, 0.3425, 0.3655],\n",
      "        [0.5834, 0.3063, 0.2750],\n",
      "        [0.6229, 0.2944, 0.3206],\n",
      "        [0.5539, 0.3470, 0.3360],\n",
      "        [0.5651, 0.3059, 0.3037],\n",
      "        [0.5338, 0.3520, 0.3295],\n",
      "        [0.6128, 0.3237, 0.2829],\n",
      "        [0.5135, 0.3073, 0.2833],\n",
      "        [0.6586, 0.2784, 0.2628],\n",
      "        [0.5976, 0.3021, 0.3505],\n",
      "        [0.5376, 0.3109, 0.3580],\n",
      "        [0.5974, 0.3087, 0.2745],\n",
      "        [0.5300, 0.2882, 0.2806]], device='cuda:0'), tensor([[0.9688, 0.0905, 0.3661],\n",
      "        [0.8892, 0.1416, 0.3186],\n",
      "        [0.8080, 0.1262, 0.2327],\n",
      "        [0.7376, 0.1568, 0.3288],\n",
      "        [0.8098, 0.1631, 0.2431],\n",
      "        [0.8356, 0.1677, 0.2558],\n",
      "        [0.6378, 0.1833, 0.4370],\n",
      "        [0.8103, 0.1193, 0.2948],\n",
      "        [0.8140, 0.1679, 0.2515],\n",
      "        [0.7424, 0.1466, 0.3209],\n",
      "        [0.8733, 0.1104, 0.1930],\n",
      "        [0.7692, 0.1628, 0.3777],\n",
      "        [0.8618, 0.1266, 0.8470],\n",
      "        [0.8789, 0.1112, 0.3427],\n",
      "        [0.8057, 0.1392, 0.4738],\n",
      "        [0.8585, 0.1106, 0.3174],\n",
      "        [0.7132, 0.1571, 0.4286],\n",
      "        [0.6000, 0.1726, 0.4446],\n",
      "        [0.7210, 0.1790, 0.2976],\n",
      "        [0.9475, 0.0800, 0.2899],\n",
      "        [0.7681, 0.1603, 0.2938],\n",
      "        [0.8633, 0.1326, 0.2254],\n",
      "        [0.8275, 0.1468, 0.2967],\n",
      "        [0.7954, 0.1572, 0.3840],\n",
      "        [0.8046, 0.1222, 0.2307],\n",
      "        [0.5291, 0.1718, 0.5619],\n",
      "        [0.7304, 0.1696, 0.2980],\n",
      "        [0.6636, 0.1611, 0.4790],\n",
      "        [0.7799, 0.1521, 0.2790],\n",
      "        [0.7092, 0.1338, 0.4476],\n",
      "        [0.7938, 0.1333, 0.3316],\n",
      "        [0.8763, 0.1514, 0.4417],\n",
      "        [0.7572, 0.1874, 0.3028],\n",
      "        [0.5108, 0.1706, 0.5444],\n",
      "        [0.7647, 0.2094, 0.2868],\n",
      "        [0.6941, 0.1843, 0.3368],\n",
      "        [0.8333, 0.1553, 0.2287],\n",
      "        [0.9495, 0.1079, 0.1856],\n",
      "        [0.6477, 0.1739, 0.3752],\n",
      "        [0.8179, 0.1328, 0.2111],\n",
      "        [0.8485, 0.1315, 0.2814],\n",
      "        [0.7046, 0.1646, 0.3911],\n",
      "        [0.6720, 0.1519, 0.4567],\n",
      "        [0.7545, 0.1342, 0.3317],\n",
      "        [0.8292, 0.1451, 0.2111],\n",
      "        [0.8879, 0.1282, 0.1896],\n",
      "        [0.8012, 0.1514, 0.3241],\n",
      "        [0.8641, 0.1308, 0.2139],\n",
      "        [0.7674, 0.1558, 0.3412],\n",
      "        [0.8450, 0.1143, 0.3805],\n",
      "        [0.7327, 0.1711, 0.2457],\n",
      "        [0.8857, 0.1207, 0.1996],\n",
      "        [0.8134, 0.1587, 0.3604],\n",
      "        [0.7098, 0.1517, 0.3558],\n",
      "        [0.7704, 0.1431, 0.2904],\n",
      "        [0.8126, 0.1405, 0.2432]], device='cuda:0'), tensor([[0.1379, 0.5245, 0.1742, 0.2031, 0.1326, 0.1878],\n",
      "        [0.1540, 0.4113, 0.1785, 0.1789, 0.1420, 0.1627],\n",
      "        [0.1489, 0.3406, 0.1699, 0.1880, 0.1520, 0.1636],\n",
      "        [0.1442, 0.3498, 0.1650, 0.1835, 0.1481, 0.1735],\n",
      "        [0.1429, 0.2879, 0.1906, 0.1856, 0.1519, 0.1677],\n",
      "        [0.1534, 0.3135, 0.1803, 0.1894, 0.1626, 0.1925],\n",
      "        [0.1418, 0.3314, 0.1715, 0.1876, 0.1502, 0.1664],\n",
      "        [0.1475, 0.3485, 0.1694, 0.2091, 0.1528, 0.1707],\n",
      "        [0.1545, 0.2578, 0.1934, 0.1936, 0.1580, 0.1762],\n",
      "        [0.1566, 0.3307, 0.1778, 0.1708, 0.1414, 0.1724],\n",
      "        [0.1606, 0.3073, 0.2041, 0.1929, 0.1484, 0.1779],\n",
      "        [0.1529, 0.3613, 0.1839, 0.1846, 0.1534, 0.1687],\n",
      "        [0.1304, 0.7724, 0.1829, 0.1710, 0.1247, 0.1521],\n",
      "        [0.1284, 0.3910, 0.1864, 0.1918, 0.1444, 0.1796],\n",
      "        [0.1332, 0.4143, 0.1808, 0.1967, 0.1353, 0.1646],\n",
      "        [0.1263, 0.4531, 0.1923, 0.1755, 0.1418, 0.1747],\n",
      "        [0.1488, 0.2928, 0.1851, 0.1948, 0.1512, 0.1688],\n",
      "        [0.1746, 0.2636, 0.1888, 0.1784, 0.1717, 0.1613],\n",
      "        [0.1552, 0.3041, 0.1871, 0.1642, 0.1510, 0.1736],\n",
      "        [0.1463, 0.5820, 0.2084, 0.1658, 0.1387, 0.1721],\n",
      "        [0.1480, 0.2912, 0.1781, 0.1904, 0.1664, 0.1709],\n",
      "        [0.1459, 0.3233, 0.1870, 0.1957, 0.1736, 0.1621],\n",
      "        [0.1427, 0.2747, 0.1774, 0.1958, 0.1640, 0.1740],\n",
      "        [0.1441, 0.3857, 0.1734, 0.2031, 0.1521, 0.1561],\n",
      "        [0.1424, 0.3349, 0.1872, 0.1821, 0.1642, 0.1846],\n",
      "        [0.1420, 0.3283, 0.1823, 0.1791, 0.1660, 0.1686],\n",
      "        [0.1492, 0.2824, 0.1988, 0.1831, 0.1573, 0.1727],\n",
      "        [0.1549, 0.4065, 0.2000, 0.1746, 0.1517, 0.1633],\n",
      "        [0.1331, 0.3015, 0.1860, 0.1858, 0.1508, 0.1772],\n",
      "        [0.1550, 0.4172, 0.1976, 0.1862, 0.1561, 0.1687],\n",
      "        [0.1529, 0.2976, 0.1768, 0.1979, 0.1613, 0.1668],\n",
      "        [0.1433, 0.3721, 0.1740, 0.2114, 0.1423, 0.1737],\n",
      "        [0.1577, 0.2972, 0.1896, 0.1845, 0.1671, 0.1684],\n",
      "        [0.1496, 0.3120, 0.1850, 0.1775, 0.1611, 0.1711],\n",
      "        [0.1507, 0.3357, 0.1702, 0.1714, 0.1641, 0.1770],\n",
      "        [0.1597, 0.3112, 0.1776, 0.1709, 0.1524, 0.1747],\n",
      "        [0.1581, 0.3055, 0.1961, 0.1796, 0.1637, 0.1800],\n",
      "        [0.1483, 0.3375, 0.1957, 0.2035, 0.1476, 0.1785],\n",
      "        [0.1542, 0.2826, 0.1840, 0.1840, 0.1538, 0.1888],\n",
      "        [0.1469, 0.2720, 0.1814, 0.1976, 0.1489, 0.1754],\n",
      "        [0.1355, 0.3546, 0.1798, 0.1634, 0.1585, 0.1675],\n",
      "        [0.1425, 0.3753, 0.1620, 0.1835, 0.1443, 0.1740],\n",
      "        [0.1570, 0.2939, 0.1753, 0.1962, 0.1623, 0.1695],\n",
      "        [0.1408, 0.3346, 0.2020, 0.1851, 0.1603, 0.1866],\n",
      "        [0.1540, 0.2625, 0.1798, 0.1874, 0.1629, 0.1817],\n",
      "        [0.1470, 0.3221, 0.2046, 0.1881, 0.1471, 0.1601],\n",
      "        [0.1542, 0.2557, 0.2057, 0.2077, 0.1590, 0.1598],\n",
      "        [0.1617, 0.2492, 0.2028, 0.2145, 0.1565, 0.1804],\n",
      "        [0.1438, 0.3484, 0.1855, 0.1907, 0.1495, 0.1590],\n",
      "        [0.1452, 0.4306, 0.1738, 0.2109, 0.1593, 0.1601],\n",
      "        [0.1521, 0.2653, 0.1867, 0.1867, 0.1624, 0.1818],\n",
      "        [0.1631, 0.2924, 0.1846, 0.1961, 0.1611, 0.1846],\n",
      "        [0.1427, 0.3642, 0.1947, 0.1786, 0.1410, 0.1744],\n",
      "        [0.1416, 0.3414, 0.1952, 0.1965, 0.1565, 0.1726],\n",
      "        [0.1624, 0.3036, 0.1653, 0.2074, 0.1559, 0.1691],\n",
      "        [0.1518, 0.2839, 0.1966, 0.1835, 0.1415, 0.1888]], device='cuda:0'), tensor([[0.0979, 0.0975, 0.1154, 0.1174, 0.2113],\n",
      "        [0.1297, 0.2321, 0.1422, 0.1274, 0.1635],\n",
      "        [0.1465, 0.3118, 0.1684, 0.1927, 0.2480],\n",
      "        [0.1944, 0.2293, 0.2053, 0.1477, 0.2319],\n",
      "        [0.1485, 0.2743, 0.2348, 0.1771, 0.2731],\n",
      "        [0.1925, 0.3152, 0.2421, 0.1995, 0.2842],\n",
      "        [0.1771, 0.2364, 0.1916, 0.1629, 0.2170],\n",
      "        [0.1895, 0.2359, 0.1570, 0.1518, 0.2475],\n",
      "        [0.1993, 0.3123, 0.2546, 0.2055, 0.3128],\n",
      "        [0.1745, 0.2857, 0.2235, 0.1747, 0.2503],\n",
      "        [0.1591, 0.2202, 0.2093, 0.1527, 0.2326],\n",
      "        [0.1617, 0.2016, 0.2041, 0.1782, 0.2595],\n",
      "        [0.1106, 0.1220, 0.1349, 0.1010, 0.2063],\n",
      "        [0.1013, 0.2153, 0.1649, 0.1022, 0.1753],\n",
      "        [0.1725, 0.1735, 0.1282, 0.1005, 0.1769],\n",
      "        [0.1237, 0.1907, 0.1214, 0.1059, 0.2009],\n",
      "        [0.1819, 0.2756, 0.1974, 0.1811, 0.2304],\n",
      "        [0.2129, 0.2539, 0.1945, 0.1927, 0.2579],\n",
      "        [0.2114, 0.2819, 0.1993, 0.1716, 0.2374],\n",
      "        [0.0887, 0.1427, 0.1054, 0.0785, 0.2113],\n",
      "        [0.1447, 0.3056, 0.2011, 0.1848, 0.2891],\n",
      "        [0.1570, 0.2494, 0.2031, 0.1716, 0.2429],\n",
      "        [0.1926, 0.2109, 0.1700, 0.1862, 0.2608],\n",
      "        [0.1896, 0.2315, 0.1704, 0.1565, 0.2353],\n",
      "        [0.1304, 0.1892, 0.2054, 0.1363, 0.2032],\n",
      "        [0.1912, 0.2225, 0.1606, 0.1480, 0.2692],\n",
      "        [0.1868, 0.2641, 0.2106, 0.2016, 0.3085],\n",
      "        [0.1277, 0.2251, 0.1916, 0.1298, 0.1925],\n",
      "        [0.1796, 0.2774, 0.1677, 0.1742, 0.2893],\n",
      "        [0.1278, 0.2389, 0.1886, 0.1427, 0.2452],\n",
      "        [0.1426, 0.2173, 0.1674, 0.1760, 0.2438],\n",
      "        [0.0968, 0.1567, 0.1141, 0.1133, 0.1628],\n",
      "        [0.1987, 0.3158, 0.2217, 0.1868, 0.2645],\n",
      "        [0.1952, 0.2125, 0.1992, 0.1653, 0.2267],\n",
      "        [0.2020, 0.2593, 0.2225, 0.1947, 0.2626],\n",
      "        [0.1824, 0.2887, 0.2643, 0.2092, 0.2700],\n",
      "        [0.1845, 0.2868, 0.2443, 0.2325, 0.3026],\n",
      "        [0.0932, 0.1691, 0.1322, 0.1104, 0.2128],\n",
      "        [0.1938, 0.2854, 0.2639, 0.1779, 0.2665],\n",
      "        [0.1832, 0.2770, 0.2143, 0.1775, 0.2308],\n",
      "        [0.1395, 0.2401, 0.1678, 0.1677, 0.2510],\n",
      "        [0.1698, 0.2420, 0.1976, 0.1506, 0.2201],\n",
      "        [0.1616, 0.1886, 0.1872, 0.1999, 0.2329],\n",
      "        [0.1028, 0.2823, 0.1627, 0.1695, 0.2355],\n",
      "        [0.1906, 0.2971, 0.2263, 0.2076, 0.3204],\n",
      "        [0.1064, 0.2109, 0.1930, 0.1261, 0.2346],\n",
      "        [0.1770, 0.2349, 0.1765, 0.2108, 0.2423],\n",
      "        [0.1913, 0.2575, 0.1935, 0.1881, 0.2771],\n",
      "        [0.2017, 0.1842, 0.1678, 0.1711, 0.2373],\n",
      "        [0.1224, 0.2123, 0.1657, 0.1145, 0.2348],\n",
      "        [0.1725, 0.2693, 0.2121, 0.1684, 0.2721],\n",
      "        [0.1901, 0.2552, 0.2030, 0.2061, 0.3094],\n",
      "        [0.1776, 0.2438, 0.2175, 0.1541, 0.2346],\n",
      "        [0.1813, 0.2498, 0.1840, 0.1788, 0.2371],\n",
      "        [0.1618, 0.2869, 0.1831, 0.1796, 0.2709],\n",
      "        [0.1616, 0.2260, 0.1878, 0.1901, 0.2606]], device='cuda:0')], 'order': ['pd', 'nd', 'mod', 'dlt']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.30952380952380953,\n",
       "  'auc_micro': 0.6172164119066773,\n",
       "  'auc_mean': 0.5387440920327916,\n",
       "  'auc_weighted': 0.5826149504786146},\n",
       " 'nd': {'accuracy': 0.2962962962962963,\n",
       "  'auc_micro': 0.16138374899436847,\n",
       "  'auc_mean': 0.40730715170573667,\n",
       "  'auc_weighted': 0.2785734705546027},\n",
       " 'mod': {'accuracy': 0.2962962962962963,\n",
       "  'auc_micro': 0.16138374899436847,\n",
       "  'auc_mean': 0.40730715170573667,\n",
       "  'auc_weighted': 0.2785734705546027},\n",
       " 'dlts': {'accuracy': [0.7857142857142857,\n",
       "   0.8928571428571429,\n",
       "   0.9107142857142857,\n",
       "   0.9464285714285714,\n",
       "   0.8035714285714286],\n",
       "  'accuracy_mean': 0.8678571428571429,\n",
       "  'auc': [0.3787878787878788,\n",
       "   0.45333333333333337,\n",
       "   0.596078431372549,\n",
       "   0.5031446540880503,\n",
       "   0.5272727272727273],\n",
       "  'auc_mean': 0.4917234049709077}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        \n",
    "def train_state(model=None,\n",
    "                model_args={},\n",
    "                state=1,\n",
    "                split=.7,\n",
    "                lr=.001,\n",
    "                epochs=1000,\n",
    "                patience=10,\n",
    "                weights=None,\n",
    "                save_path='../data/models/',\n",
    "                use_default_split=True,\n",
    "                use_bagging_split=False,\n",
    "                resample_training=False,#use bootstraping on training data after splitting\n",
    "                n_validation_trainsteps=2,\n",
    "                verbose=True,\n",
    "                balanced=True,\n",
    "                sqrt_balance_weights=False,\n",
    "                use_smote=False,\n",
    "                smote_cols = None,\n",
    "                file_suffix=''):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "\n",
    "    if use_smote:\n",
    "        if smote_cols is None:\n",
    "            smote_cols = Const.outcomes\n",
    "            if state == 1:\n",
    "                smote_cols = Const.primary_disease_states\n",
    "            elif state == 2:\n",
    "                smote_cols = Const.primary_disease_states2\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids,smote_columns=[Const.decisions[state-1]])\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "    \n",
    "    #only train on people with  IC for state 1 since other people can't have any outcomes otherwise\n",
    "    require = None\n",
    "    if state == 1:\n",
    "        require = Const.decisions[0] #we don't expect a state update if there is no treatment\n",
    "        valid_ids = dataset.get_input_state(require=require).index.values\n",
    "        train_ids = [t for t in train_ids if t in valid_ids]\n",
    "        test_ids = [t for t in test_ids if t in valid_ids]\n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids,require=require)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids,require=require)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids,require=require)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids,require=require)\n",
    "    \n",
    "    model_args = {k:v for k,v in model_args.items() if 'attention' not in k and 'embed_size' not in k}\n",
    "    if state < 3:\n",
    "        if model is None:\n",
    "                model = BayesianOutcomeSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "        lfunc = state_loss\n",
    "        if weights is None:\n",
    "            weights = [1,1,.1,1]\n",
    "    else:\n",
    "        if model is None:\n",
    "                model = BayesianEndpointSimulator(xtrain.shape[1],**model_args)\n",
    "        if weights is None:\n",
    "            weights = [1,1,1,1]\n",
    "        lfunc = outcome_loss\n",
    "    print(model.passthrough)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.set_device(device)\n",
    "    \n",
    "    balance_weights=None\n",
    "    if balanced:\n",
    "        if state < 3:\n",
    "            balance_weights = [w.to(device) for w in get_weights(ytrain)]\n",
    "            if sqrt_balance_weights:\n",
    "                balance_weights = [torch.sqrt(w) for w in balance_weights]\n",
    "        else:\n",
    "            print('I dont do balancing on the outputs because Idk how that would work')\n",
    "    \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    save_file = save_path + 'model_' + model.identifier + '_split' + str(split) + '_resample' + str(resample_training) +  '_hash' + hashcode + file_suffix + '.tar'\n",
    "    xtrain = df_to_torch(xtrain).to(device)\n",
    "    \n",
    "    xtest = df_to_torch(xtest).to(device)\n",
    "    ytrain = [df_to_torch(t).to(device) for t in ytrain]\n",
    "    ytest= [df_to_torch(t).to(device) for t in ytest]\n",
    "    \n",
    "    model.fit_normalizer(xtrain)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    last_epoch = False\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(xtrain_sample,n_samples=1)\n",
    "        loss = lfunc(ytrain,ypred,weights=weights,subweights=balance_weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(xtest,n_samples=1)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights,subweights=balance_weights)\n",
    "        if state < 3:\n",
    "            val_metrics = state_metrics(ytest,yval)\n",
    "        else:\n",
    "            val_metrics = outcome_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if verbose:\n",
    "            print('val loss',val_loss.item())\n",
    "            print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    #train one step on validation data\n",
    "    for i in range(n_validation_trainsteps):\n",
    "        model.train()\n",
    "        yval = model(xtest,n_samples=1)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        val_loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model.state_dict(),save_file)\n",
    "    \n",
    "    model.eval()\n",
    "    print(model(xtest))\n",
    "    return model,  best_val_loss, best_loss_metrics\n",
    "\n",
    "from Models import *\n",
    "t1_args = {'hidden_layers': [500,500],\n",
    "   'dropout': 0.5,\n",
    "   'input_dropout': 0.5}\n",
    "tmodel_balanced = train_state(model_args=t1_args,state=1,lr=.0001,weights=[1,1,.1,1])\n",
    "tmodel_balanced[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ac5af9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "epoch 0 train loss 2.8485398292541504\n",
      "val loss 2.7995493412017822\n",
      "______________\n",
      "epoch 1 train loss 2.734757900238037\n",
      "val loss 2.7321619987487793\n",
      "______________\n",
      "epoch 2 train loss 2.668363571166992\n",
      "val loss 2.6781983375549316\n",
      "______________\n",
      "epoch 3 train loss 2.594677448272705\n",
      "val loss 2.6337931156158447\n",
      "______________\n",
      "epoch 4 train loss 2.5526328086853027\n",
      "val loss 2.6012423038482666\n",
      "______________\n",
      "epoch 5 train loss 2.498991012573242\n",
      "val loss 2.5778346061706543\n",
      "______________\n",
      "epoch 6 train loss 2.494217872619629\n",
      "val loss 2.562265634536743\n",
      "______________\n",
      "epoch 7 train loss 2.4240756034851074\n",
      "val loss 2.552873373031616\n",
      "______________\n",
      "epoch 8 train loss 2.420686960220337\n",
      "val loss 2.5482935905456543\n",
      "______________\n",
      "epoch 9 train loss 2.4513015747070312\n",
      "val loss 2.546400547027588\n",
      "______________\n",
      "epoch 10 train loss 2.3852906227111816\n",
      "val loss 2.5439209938049316\n",
      "______________\n",
      "epoch 11 train loss 2.316455841064453\n",
      "val loss 2.5416195392608643\n",
      "______________\n",
      "epoch 12 train loss 2.4168808460235596\n",
      "val loss 2.538494348526001\n",
      "______________\n",
      "epoch 13 train loss 2.3045248985290527\n",
      "val loss 2.5347797870635986\n",
      "______________\n",
      "epoch 14 train loss 2.2862987518310547\n",
      "val loss 2.53155255317688\n",
      "______________\n",
      "epoch 15 train loss 2.3339955806732178\n",
      "val loss 2.5279836654663086\n",
      "______________\n",
      "epoch 16 train loss 2.311998128890991\n",
      "val loss 2.5250871181488037\n",
      "______________\n",
      "epoch 17 train loss 2.225553274154663\n",
      "val loss 2.5233817100524902\n",
      "______________\n",
      "epoch 18 train loss 2.27370023727417\n",
      "val loss 2.5229952335357666\n",
      "______________\n",
      "epoch 19 train loss 2.203350782394409\n",
      "val loss 2.5256354808807373\n",
      "______________\n",
      "epoch 20 train loss 2.154737710952759\n",
      "val loss 2.529263496398926\n",
      "______________\n",
      "epoch 21 train loss 2.1485421657562256\n",
      "val loss 2.5322558879852295\n",
      "______________\n",
      "epoch 22 train loss 2.134906768798828\n",
      "val loss 2.536778450012207\n",
      "______________\n",
      "epoch 23 train loss 2.1186888217926025\n",
      "val loss 2.5430238246917725\n",
      "______________\n",
      "epoch 24 train loss 2.1177783012390137\n",
      "val loss 2.5524420738220215\n",
      "______________\n",
      "epoch 25 train loss 2.1055214405059814\n",
      "val loss 2.564225435256958\n",
      "______________\n",
      "epoch 26 train loss 2.095073938369751\n",
      "val loss 2.5782101154327393\n",
      "______________\n",
      "epoch 27 train loss 2.060316324234009\n",
      "val loss 2.58909010887146\n",
      "______________\n",
      "epoch 28 train loss 2.068495035171509\n",
      "val loss 2.5916836261749268\n",
      "______________\n",
      "epoch 29 train loss 2.0092058181762695\n",
      "val loss 2.5915231704711914\n",
      "______________\n",
      "best loss 2.5229952335357666 {'pd': {'accuracy': 0.41793330976788035, 'auc_micro': 0.7947998503554059, 'auc_mean': 0.5737713836763664, 'auc_weighted': 0.6698207964863278}, 'nd': {'accuracy': 0.47960618846694797, 'auc_micro': 0.5587706855791962, 'auc_mean': 0.6462857946486413, 'auc_weighted': 0.5455822973985921}, 'mod': {'accuracy': 0.47960618846694797, 'auc_micro': 0.5587706855791962, 'auc_mean': 0.6462857946486413, 'auc_weighted': 0.5455822973985921}, 'dlts': {'accuracy': [0.9523809523809523, 0.9659863945578231, 0.9659863945578231, 0.9795918367346939, 0.9183673469387755], 'accuracy_mean': 0.9564625850340136, 'auc': [0.6, 0.643661971830986, 0.46197183098591554, 0.7430555555555556, 0.575925925925926], 'auc_mean': 0.6049230568596766}}\n",
      "{'predictions': [tensor([[0.5846, 0.1448, 0.2707],\n",
      "        [0.9044, 0.0751, 0.0205],\n",
      "        [0.5014, 0.3635, 0.1352],\n",
      "        [0.5458, 0.3258, 0.1284],\n",
      "        [0.5788, 0.3249, 0.0964],\n",
      "        [0.6553, 0.1878, 0.1569],\n",
      "        [0.7902, 0.1859, 0.0239],\n",
      "        [0.6067, 0.2275, 0.1658],\n",
      "        [0.9607, 0.0254, 0.0139],\n",
      "        [0.6015, 0.2273, 0.1712],\n",
      "        [0.7848, 0.1271, 0.0882],\n",
      "        [0.3051, 0.1990, 0.4958],\n",
      "        [0.6466, 0.2185, 0.1350],\n",
      "        [0.6240, 0.1786, 0.1974],\n",
      "        [0.5047, 0.3530, 0.1423],\n",
      "        [0.5091, 0.2477, 0.2431],\n",
      "        [0.8116, 0.1689, 0.0195],\n",
      "        [0.8260, 0.1389, 0.0351],\n",
      "        [0.5948, 0.2069, 0.1983],\n",
      "        [0.7948, 0.1790, 0.0262],\n",
      "        [0.7285, 0.2509, 0.0206],\n",
      "        [0.4552, 0.2874, 0.2574],\n",
      "        [0.5795, 0.3233, 0.0973],\n",
      "        [0.4169, 0.4772, 0.1059],\n",
      "        [0.9362, 0.0531, 0.0107],\n",
      "        [0.4323, 0.1884, 0.3793],\n",
      "        [0.6927, 0.1282, 0.1790],\n",
      "        [0.7121, 0.2221, 0.0658],\n",
      "        [0.6385, 0.1952, 0.1663],\n",
      "        [0.6539, 0.1787, 0.1674],\n",
      "        [0.6700, 0.2134, 0.1166],\n",
      "        [0.7615, 0.2023, 0.0362],\n",
      "        [0.5441, 0.2263, 0.2296],\n",
      "        [0.5382, 0.3407, 0.1211],\n",
      "        [0.5270, 0.1265, 0.3465],\n",
      "        [0.6542, 0.2142, 0.1317],\n",
      "        [0.8286, 0.1455, 0.0260],\n",
      "        [0.3016, 0.2504, 0.4480],\n",
      "        [0.6033, 0.3657, 0.0311],\n",
      "        [0.6605, 0.1828, 0.1566],\n",
      "        [0.5258, 0.3694, 0.1049],\n",
      "        [0.7119, 0.2126, 0.0755],\n",
      "        [0.4365, 0.4325, 0.1310],\n",
      "        [0.8571, 0.0989, 0.0440],\n",
      "        [0.7129, 0.1917, 0.0954],\n",
      "        [0.7811, 0.1167, 0.1022],\n",
      "        [0.4110, 0.3984, 0.1906],\n",
      "        [0.6675, 0.2303, 0.1022],\n",
      "        [0.6063, 0.2862, 0.1075],\n",
      "        [0.5199, 0.2069, 0.2731],\n",
      "        [0.9403, 0.0486, 0.0111],\n",
      "        [0.4869, 0.3764, 0.1367],\n",
      "        [0.8215, 0.0975, 0.0810],\n",
      "        [0.5017, 0.2903, 0.2080],\n",
      "        [0.5951, 0.2129, 0.1920],\n",
      "        [0.6287, 0.2986, 0.0728],\n",
      "        [0.6291, 0.3023, 0.0685],\n",
      "        [0.9278, 0.0514, 0.0207],\n",
      "        [0.9397, 0.0548, 0.0055],\n",
      "        [0.6774, 0.2563, 0.0664],\n",
      "        [0.4978, 0.2491, 0.2532],\n",
      "        [0.7972, 0.1628, 0.0401],\n",
      "        [0.4846, 0.4130, 0.1024],\n",
      "        [0.6631, 0.2219, 0.1150],\n",
      "        [0.8984, 0.0779, 0.0237],\n",
      "        [0.5974, 0.2450, 0.1576],\n",
      "        [0.5150, 0.3220, 0.1630],\n",
      "        [0.7385, 0.2198, 0.0417],\n",
      "        [0.5957, 0.2574, 0.1470],\n",
      "        [0.4885, 0.3298, 0.1816],\n",
      "        [0.7488, 0.2269, 0.0243],\n",
      "        [0.4607, 0.3921, 0.1472],\n",
      "        [0.5210, 0.2371, 0.2418],\n",
      "        [0.5869, 0.1976, 0.2155],\n",
      "        [0.5638, 0.3076, 0.1286],\n",
      "        [0.9047, 0.0790, 0.0163],\n",
      "        [0.4885, 0.3928, 0.1187],\n",
      "        [0.5946, 0.3550, 0.0504],\n",
      "        [0.8518, 0.1236, 0.0246],\n",
      "        [0.6194, 0.2205, 0.1601],\n",
      "        [0.6685, 0.2023, 0.1292],\n",
      "        [0.4246, 0.1813, 0.3941],\n",
      "        [0.4371, 0.3646, 0.1983],\n",
      "        [0.6524, 0.2700, 0.0776],\n",
      "        [0.7856, 0.1362, 0.0783],\n",
      "        [0.6633, 0.1955, 0.1413],\n",
      "        [0.6226, 0.2949, 0.0825],\n",
      "        [0.6299, 0.2796, 0.0905],\n",
      "        [0.7207, 0.1620, 0.1173],\n",
      "        [0.4665, 0.2101, 0.3233],\n",
      "        [0.5321, 0.3001, 0.1678],\n",
      "        [0.6720, 0.1910, 0.1370],\n",
      "        [0.4682, 0.4502, 0.0816],\n",
      "        [0.7473, 0.1687, 0.0840],\n",
      "        [0.5965, 0.3254, 0.0781],\n",
      "        [0.8278, 0.1456, 0.0266],\n",
      "        [0.6517, 0.2469, 0.1013],\n",
      "        [0.8263, 0.1536, 0.0200],\n",
      "        [0.8011, 0.1157, 0.0831],\n",
      "        [0.5948, 0.3228, 0.0824],\n",
      "        [0.8415, 0.1260, 0.0325],\n",
      "        [0.8711, 0.1015, 0.0274],\n",
      "        [0.8439, 0.1247, 0.0313],\n",
      "        [0.7766, 0.2052, 0.0182],\n",
      "        [0.4143, 0.1961, 0.3896],\n",
      "        [0.8380, 0.1133, 0.0487],\n",
      "        [0.8656, 0.1024, 0.0320],\n",
      "        [0.8869, 0.0510, 0.0621],\n",
      "        [0.8411, 0.1106, 0.0482],\n",
      "        [0.3637, 0.2159, 0.4203],\n",
      "        [0.5530, 0.2967, 0.1503],\n",
      "        [0.3902, 0.2773, 0.3325],\n",
      "        [0.6003, 0.2435, 0.1562],\n",
      "        [0.7134, 0.1036, 0.1830],\n",
      "        [0.8819, 0.0932, 0.0249],\n",
      "        [0.3835, 0.2728, 0.3437],\n",
      "        [0.6418, 0.2153, 0.1429],\n",
      "        [0.6305, 0.2296, 0.1399],\n",
      "        [0.7730, 0.2014, 0.0256],\n",
      "        [0.9120, 0.0768, 0.0112],\n",
      "        [0.5958, 0.2245, 0.1797],\n",
      "        [0.6263, 0.2226, 0.1511],\n",
      "        [0.5674, 0.3180, 0.1147],\n",
      "        [0.4657, 0.2974, 0.2369],\n",
      "        [0.5494, 0.3535, 0.0971],\n",
      "        [0.5531, 0.2229, 0.2240],\n",
      "        [0.5764, 0.3748, 0.0487],\n",
      "        [0.8928, 0.0731, 0.0342],\n",
      "        [0.8821, 0.1022, 0.0157],\n",
      "        [0.5945, 0.2305, 0.1749],\n",
      "        [0.7055, 0.2231, 0.0714],\n",
      "        [0.5681, 0.2307, 0.2012],\n",
      "        [0.6176, 0.2527, 0.1297],\n",
      "        [0.4024, 0.3833, 0.2143],\n",
      "        [0.5663, 0.2749, 0.1589],\n",
      "        [0.4137, 0.4075, 0.1788],\n",
      "        [0.5614, 0.3353, 0.1034],\n",
      "        [0.9500, 0.0424, 0.0076],\n",
      "        [0.5896, 0.3408, 0.0695],\n",
      "        [0.5252, 0.3656, 0.1092],\n",
      "        [0.7139, 0.2190, 0.0671],\n",
      "        [0.5657, 0.2882, 0.1461],\n",
      "        [0.8751, 0.1206, 0.0043],\n",
      "        [0.7723, 0.1757, 0.0520],\n",
      "        [0.5739, 0.3687, 0.0573],\n",
      "        [0.8240, 0.1230, 0.0529],\n",
      "        [0.6999, 0.2189, 0.0812]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[0.8474, 0.0923, 0.0603],\n",
      "        [0.8255, 0.0890, 0.0856],\n",
      "        [0.5268, 0.1956, 0.2775],\n",
      "        [0.5716, 0.1978, 0.2306],\n",
      "        [0.4878, 0.2329, 0.2793],\n",
      "        [0.4991, 0.2959, 0.2050],\n",
      "        [0.4125, 0.1672, 0.4204],\n",
      "        [0.4884, 0.3286, 0.1830],\n",
      "        [0.8389, 0.1340, 0.0271],\n",
      "        [0.4462, 0.3218, 0.2320],\n",
      "        [0.5917, 0.2058, 0.2025],\n",
      "        [0.6692, 0.2107, 0.1201],\n",
      "        [0.4281, 0.3185, 0.2534],\n",
      "        [0.4960, 0.3095, 0.1945],\n",
      "        [0.5212, 0.2180, 0.2608],\n",
      "        [0.5780, 0.2743, 0.1477],\n",
      "        [0.7514, 0.1083, 0.1403],\n",
      "        [0.3851, 0.1791, 0.4358],\n",
      "        [0.4508, 0.3226, 0.2266],\n",
      "        [0.3534, 0.1198, 0.5267],\n",
      "        [0.0306, 0.0084, 0.9610],\n",
      "        [0.5461, 0.2792, 0.1747],\n",
      "        [0.4919, 0.2339, 0.2742],\n",
      "        [0.7455, 0.1610, 0.0935],\n",
      "        [0.8207, 0.1336, 0.0457],\n",
      "        [0.6844, 0.1974, 0.1181],\n",
      "        [0.8021, 0.1415, 0.0564],\n",
      "        [0.7582, 0.1457, 0.0961],\n",
      "        [0.4373, 0.2348, 0.3279],\n",
      "        [0.5101, 0.3061, 0.1838],\n",
      "        [0.4814, 0.3009, 0.2177],\n",
      "        [0.2327, 0.1064, 0.6609],\n",
      "        [0.4688, 0.3220, 0.2092],\n",
      "        [0.5278, 0.2361, 0.2361],\n",
      "        [0.5702, 0.2295, 0.2003],\n",
      "        [0.6691, 0.1168, 0.2141],\n",
      "        [0.6183, 0.2060, 0.1757],\n",
      "        [0.5298, 0.2579, 0.2123],\n",
      "        [0.3903, 0.1765, 0.4332],\n",
      "        [0.4832, 0.3078, 0.2091],\n",
      "        [0.4964, 0.2659, 0.2377],\n",
      "        [0.8263, 0.1213, 0.0524],\n",
      "        [0.6558, 0.1871, 0.1571],\n",
      "        [0.9173, 0.0631, 0.0196],\n",
      "        [0.4932, 0.3276, 0.1792],\n",
      "        [0.6367, 0.2073, 0.1560],\n",
      "        [0.4876, 0.1928, 0.3196],\n",
      "        [0.5282, 0.3565, 0.1153],\n",
      "        [0.4236, 0.2356, 0.3408],\n",
      "        [0.4912, 0.2840, 0.2248],\n",
      "        [0.6539, 0.1519, 0.1942],\n",
      "        [0.4503, 0.2530, 0.2967],\n",
      "        [0.7659, 0.0798, 0.1543],\n",
      "        [0.4681, 0.3048, 0.2272],\n",
      "        [0.4739, 0.3042, 0.2219],\n",
      "        [0.4535, 0.2210, 0.3256],\n",
      "        [0.5761, 0.2519, 0.1720],\n",
      "        [0.5864, 0.1966, 0.2170],\n",
      "        [0.8715, 0.0880, 0.0406],\n",
      "        [0.3944, 0.2599, 0.3456],\n",
      "        [0.4597, 0.3196, 0.2208],\n",
      "        [0.2645, 0.1224, 0.6131],\n",
      "        [0.4725, 0.2747, 0.2528],\n",
      "        [0.4839, 0.3140, 0.2021],\n",
      "        [0.7995, 0.1512, 0.0493],\n",
      "        [0.4725, 0.3262, 0.2013],\n",
      "        [0.5412, 0.3006, 0.1581],\n",
      "        [0.3664, 0.2206, 0.4129],\n",
      "        [0.4139, 0.2155, 0.3706],\n",
      "        [0.5937, 0.2275, 0.1788],\n",
      "        [0.1511, 0.0912, 0.7576],\n",
      "        [0.5141, 0.2237, 0.2622],\n",
      "        [0.4867, 0.3185, 0.1947],\n",
      "        [0.5368, 0.2362, 0.2270],\n",
      "        [0.3690, 0.1870, 0.4440],\n",
      "        [0.6437, 0.1439, 0.2124],\n",
      "        [0.6020, 0.2333, 0.1647],\n",
      "        [0.2528, 0.1762, 0.5710],\n",
      "        [0.6314, 0.1236, 0.2450],\n",
      "        [0.4769, 0.2709, 0.2521],\n",
      "        [0.5276, 0.3141, 0.1584],\n",
      "        [0.6567, 0.2132, 0.1301],\n",
      "        [0.4170, 0.2463, 0.3367],\n",
      "        [0.4995, 0.3194, 0.1810],\n",
      "        [0.8216, 0.1142, 0.0641],\n",
      "        [0.4842, 0.3342, 0.1816],\n",
      "        [0.5755, 0.2176, 0.2068],\n",
      "        [0.4889, 0.3784, 0.1327],\n",
      "        [0.5466, 0.3131, 0.1403],\n",
      "        [0.7780, 0.1425, 0.0795],\n",
      "        [0.5299, 0.2830, 0.1871],\n",
      "        [0.4769, 0.3361, 0.1870],\n",
      "        [0.3870, 0.2539, 0.3590],\n",
      "        [0.4656, 0.3335, 0.2010],\n",
      "        [0.4959, 0.2259, 0.2783],\n",
      "        [0.6514, 0.1364, 0.2122],\n",
      "        [0.4514, 0.2225, 0.3260],\n",
      "        [0.6046, 0.1354, 0.2601],\n",
      "        [0.5156, 0.1955, 0.2889],\n",
      "        [0.5934, 0.1685, 0.2381],\n",
      "        [0.6314, 0.1753, 0.1933],\n",
      "        [0.3913, 0.1399, 0.4688],\n",
      "        [0.5274, 0.1555, 0.3171],\n",
      "        [0.6131, 0.1254, 0.2615],\n",
      "        [0.5470, 0.2841, 0.1688],\n",
      "        [0.5206, 0.1480, 0.3314],\n",
      "        [0.3681, 0.1802, 0.4517],\n",
      "        [0.5838, 0.1308, 0.2854],\n",
      "        [0.4371, 0.2738, 0.2891],\n",
      "        [0.5625, 0.2593, 0.1782],\n",
      "        [0.3751, 0.1936, 0.4313],\n",
      "        [0.5213, 0.3078, 0.1709],\n",
      "        [0.4109, 0.3204, 0.2687],\n",
      "        [0.8687, 0.0833, 0.0479],\n",
      "        [0.4477, 0.1439, 0.4085],\n",
      "        [0.6228, 0.2360, 0.1412],\n",
      "        [0.4710, 0.3323, 0.1967],\n",
      "        [0.4497, 0.3146, 0.2357],\n",
      "        [0.6071, 0.2012, 0.1917],\n",
      "        [0.6065, 0.1349, 0.2587],\n",
      "        [0.6653, 0.1913, 0.1434],\n",
      "        [0.5765, 0.1913, 0.2321],\n",
      "        [0.4160, 0.2447, 0.3393],\n",
      "        [0.5128, 0.3047, 0.1826],\n",
      "        [0.4586, 0.2573, 0.2841],\n",
      "        [0.4638, 0.3230, 0.2132],\n",
      "        [0.3900, 0.2623, 0.3477],\n",
      "        [0.6453, 0.2511, 0.1035],\n",
      "        [0.3945, 0.1090, 0.4965],\n",
      "        [0.5164, 0.3395, 0.1441],\n",
      "        [0.6258, 0.2227, 0.1516],\n",
      "        [0.4658, 0.3007, 0.2335],\n",
      "        [0.4307, 0.2010, 0.3683],\n",
      "        [0.4764, 0.2582, 0.2654],\n",
      "        [0.4714, 0.3081, 0.2205],\n",
      "        [0.6016, 0.1967, 0.2017],\n",
      "        [0.4815, 0.2163, 0.3022],\n",
      "        [0.7102, 0.1635, 0.1264],\n",
      "        [0.4242, 0.2834, 0.2924],\n",
      "        [0.4851, 0.2333, 0.2816],\n",
      "        [0.4288, 0.2338, 0.3374],\n",
      "        [0.5130, 0.2158, 0.2712],\n",
      "        [0.7445, 0.1266, 0.1289],\n",
      "        [0.6213, 0.2079, 0.1708],\n",
      "        [0.3586, 0.2128, 0.4286],\n",
      "        [0.4356, 0.1254, 0.4390],\n",
      "        [0.5228, 0.2652, 0.2120]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[0.3284, 0.3111, 0.1653, 0.1952],\n",
      "        [0.1965, 0.6172, 0.0870, 0.0994],\n",
      "        [0.2333, 0.4328, 0.1540, 0.1799],\n",
      "        [0.2426, 0.3835, 0.1831, 0.1908],\n",
      "        [0.2613, 0.3495, 0.1920, 0.1972],\n",
      "        [0.2976, 0.2959, 0.2082, 0.1983],\n",
      "        [0.2629, 0.4517, 0.1388, 0.1466],\n",
      "        [0.2990, 0.2900, 0.2053, 0.2057],\n",
      "        [0.3728, 0.3803, 0.1214, 0.1256],\n",
      "        [0.3270, 0.2945, 0.1856, 0.1929],\n",
      "        [0.3121, 0.3534, 0.1634, 0.1711],\n",
      "        [0.2902, 0.3192, 0.1907, 0.1999],\n",
      "        [0.2953, 0.3047, 0.1975, 0.2025],\n",
      "        [0.3369, 0.2829, 0.1922, 0.1881],\n",
      "        [0.2449, 0.3622, 0.1946, 0.1983],\n",
      "        [0.3280, 0.2753, 0.1953, 0.2015],\n",
      "        [0.2610, 0.4852, 0.1213, 0.1325],\n",
      "        [0.2847, 0.3723, 0.1742, 0.1689],\n",
      "        [0.3057, 0.2866, 0.2072, 0.2005],\n",
      "        [0.2573, 0.4734, 0.1209, 0.1484],\n",
      "        [0.2893, 0.5076, 0.1006, 0.1025],\n",
      "        [0.2889, 0.2934, 0.2057, 0.2121],\n",
      "        [0.2576, 0.3603, 0.1874, 0.1947],\n",
      "        [0.2562, 0.4214, 0.1529, 0.1696],\n",
      "        [0.4030, 0.3910, 0.1012, 0.1047],\n",
      "        [0.2941, 0.3473, 0.1645, 0.1941],\n",
      "        [0.3701, 0.3917, 0.1130, 0.1252],\n",
      "        [0.2475, 0.4357, 0.1429, 0.1740],\n",
      "        [0.3023, 0.3317, 0.1832, 0.1827],\n",
      "        [0.3315, 0.2796, 0.1980, 0.1909],\n",
      "        [0.2935, 0.3029, 0.2048, 0.1987],\n",
      "        [0.2722, 0.4419, 0.1311, 0.1548],\n",
      "        [0.3016, 0.2806, 0.2093, 0.2085],\n",
      "        [0.2678, 0.3474, 0.1874, 0.1973],\n",
      "        [0.3669, 0.2714, 0.1868, 0.1749],\n",
      "        [0.2587, 0.3905, 0.1691, 0.1817],\n",
      "        [0.2528, 0.4283, 0.1424, 0.1765],\n",
      "        [0.2828, 0.3106, 0.1998, 0.2068],\n",
      "        [0.2430, 0.4770, 0.1262, 0.1539],\n",
      "        [0.3325, 0.2874, 0.1925, 0.1875],\n",
      "        [0.2607, 0.3331, 0.1979, 0.2083],\n",
      "        [0.2638, 0.4387, 0.1388, 0.1588],\n",
      "        [0.2391, 0.3872, 0.1799, 0.1938],\n",
      "        [0.2617, 0.4817, 0.1189, 0.1376],\n",
      "        [0.2996, 0.2955, 0.2059, 0.1990],\n",
      "        [0.3088, 0.3315, 0.1899, 0.1698],\n",
      "        [0.2563, 0.3764, 0.1788, 0.1885],\n",
      "        [0.3044, 0.3255, 0.1762, 0.1940],\n",
      "        [0.2726, 0.3439, 0.1850, 0.1985],\n",
      "        [0.2895, 0.2996, 0.2075, 0.2034],\n",
      "        [0.2495, 0.4920, 0.1260, 0.1325],\n",
      "        [0.2571, 0.3332, 0.1991, 0.2106],\n",
      "        [0.3364, 0.3774, 0.1365, 0.1497],\n",
      "        [0.2864, 0.3012, 0.2013, 0.2111],\n",
      "        [0.2900, 0.2961, 0.2121, 0.2018],\n",
      "        [0.2474, 0.4085, 0.1678, 0.1762],\n",
      "        [0.2586, 0.3449, 0.1892, 0.2073],\n",
      "        [0.3013, 0.3890, 0.1502, 0.1595],\n",
      "        [0.2252, 0.5452, 0.1073, 0.1223],\n",
      "        [0.2736, 0.3476, 0.1853, 0.1935],\n",
      "        [0.2967, 0.2855, 0.2074, 0.2104],\n",
      "        [0.2813, 0.3952, 0.1641, 0.1595],\n",
      "        [0.2571, 0.3623, 0.1812, 0.1994],\n",
      "        [0.3031, 0.3145, 0.1928, 0.1896],\n",
      "        [0.3597, 0.4151, 0.1059, 0.1193],\n",
      "        [0.3023, 0.2864, 0.2049, 0.2064],\n",
      "        [0.2752, 0.3117, 0.2020, 0.2111],\n",
      "        [0.2922, 0.3844, 0.1494, 0.1740],\n",
      "        [0.2689, 0.3556, 0.1832, 0.1923],\n",
      "        [0.2732, 0.3396, 0.1822, 0.2051],\n",
      "        [0.2516, 0.4545, 0.1428, 0.1511],\n",
      "        [0.2642, 0.3407, 0.1945, 0.2006],\n",
      "        [0.2984, 0.2801, 0.2086, 0.2129],\n",
      "        [0.3337, 0.2862, 0.1901, 0.1900],\n",
      "        [0.2608, 0.3761, 0.1779, 0.1852],\n",
      "        [0.3249, 0.4116, 0.1276, 0.1359],\n",
      "        [0.2251, 0.4357, 0.1560, 0.1832],\n",
      "        [0.2414, 0.4318, 0.1554, 0.1714],\n",
      "        [0.2575, 0.4554, 0.1408, 0.1462],\n",
      "        [0.2820, 0.3571, 0.1777, 0.1832],\n",
      "        [0.3222, 0.2865, 0.1952, 0.1961],\n",
      "        [0.2982, 0.3160, 0.1842, 0.2016],\n",
      "        [0.2714, 0.3440, 0.1846, 0.2000],\n",
      "        [0.2586, 0.3759, 0.1740, 0.1916],\n",
      "        [0.3469, 0.3516, 0.1424, 0.1592],\n",
      "        [0.3084, 0.2876, 0.2045, 0.1995],\n",
      "        [0.2645, 0.3607, 0.1861, 0.1888],\n",
      "        [0.2674, 0.3571, 0.1761, 0.1994],\n",
      "        [0.3498, 0.2663, 0.1921, 0.1917],\n",
      "        [0.2867, 0.3333, 0.1897, 0.1903],\n",
      "        [0.2755, 0.3281, 0.1958, 0.2006],\n",
      "        [0.3098, 0.2887, 0.2038, 0.1978],\n",
      "        [0.2480, 0.3709, 0.1807, 0.2004],\n",
      "        [0.3053, 0.3009, 0.2038, 0.1900],\n",
      "        [0.2789, 0.3824, 0.1598, 0.1789],\n",
      "        [0.2101, 0.5244, 0.1183, 0.1472],\n",
      "        [0.2878, 0.3737, 0.1533, 0.1852],\n",
      "        [0.2522, 0.5046, 0.1176, 0.1255],\n",
      "        [0.3459, 0.3128, 0.1688, 0.1726],\n",
      "        [0.2310, 0.4543, 0.1459, 0.1688],\n",
      "        [0.2917, 0.4013, 0.1498, 0.1572],\n",
      "        [0.3460, 0.3510, 0.1511, 0.1519],\n",
      "        [0.2979, 0.3779, 0.1533, 0.1708],\n",
      "        [0.3102, 0.4302, 0.1238, 0.1358],\n",
      "        [0.3196, 0.2801, 0.1972, 0.2030],\n",
      "        [0.3153, 0.3734, 0.1522, 0.1592],\n",
      "        [0.3343, 0.3393, 0.1657, 0.1608],\n",
      "        [0.3884, 0.3347, 0.1383, 0.1386],\n",
      "        [0.3566, 0.3058, 0.1708, 0.1669],\n",
      "        [0.2786, 0.3088, 0.1950, 0.2176],\n",
      "        [0.2740, 0.3630, 0.1684, 0.1946],\n",
      "        [0.2883, 0.2863, 0.2056, 0.2197],\n",
      "        [0.2882, 0.3100, 0.1980, 0.2038],\n",
      "        [0.2765, 0.4092, 0.1471, 0.1672],\n",
      "        [0.2821, 0.4148, 0.1484, 0.1547],\n",
      "        [0.2741, 0.3134, 0.2058, 0.2067],\n",
      "        [0.3079, 0.2835, 0.2064, 0.2022],\n",
      "        [0.2941, 0.3040, 0.1955, 0.2064],\n",
      "        [0.2399, 0.4487, 0.1373, 0.1742],\n",
      "        [0.2635, 0.4577, 0.1288, 0.1500],\n",
      "        [0.2750, 0.3562, 0.1672, 0.2015],\n",
      "        [0.2874, 0.3416, 0.1800, 0.1910],\n",
      "        [0.2690, 0.3391, 0.1923, 0.1996],\n",
      "        [0.2812, 0.2962, 0.2053, 0.2173],\n",
      "        [0.2649, 0.3575, 0.1797, 0.1979],\n",
      "        [0.3025, 0.2813, 0.2092, 0.2069],\n",
      "        [0.2358, 0.4372, 0.1486, 0.1784],\n",
      "        [0.3224, 0.3194, 0.1879, 0.1703],\n",
      "        [0.2908, 0.4337, 0.1319, 0.1435],\n",
      "        [0.3229, 0.2852, 0.1920, 0.1999],\n",
      "        [0.3144, 0.3360, 0.1706, 0.1789],\n",
      "        [0.2850, 0.3018, 0.2097, 0.2035],\n",
      "        [0.2784, 0.3623, 0.1762, 0.1830],\n",
      "        [0.2600, 0.3480, 0.1872, 0.2048],\n",
      "        [0.2889, 0.3129, 0.1952, 0.2030],\n",
      "        [0.2556, 0.3574, 0.1860, 0.2010],\n",
      "        [0.2425, 0.3798, 0.1850, 0.1927],\n",
      "        [0.3020, 0.4526, 0.1177, 0.1276],\n",
      "        [0.2585, 0.3689, 0.1779, 0.1947],\n",
      "        [0.2593, 0.3441, 0.1936, 0.2029],\n",
      "        [0.2666, 0.3722, 0.1809, 0.1803],\n",
      "        [0.2478, 0.3692, 0.1913, 0.1917],\n",
      "        [0.1790, 0.6449, 0.0818, 0.0942],\n",
      "        [0.2835, 0.3685, 0.1721, 0.1758],\n",
      "        [0.2465, 0.4102, 0.1650, 0.1783],\n",
      "        [0.2986, 0.3939, 0.1533, 0.1542],\n",
      "        [0.2881, 0.3477, 0.1724, 0.1918]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0162, 0.0014, 0.0038, 0.0046, 0.0100],\n",
      "        [0.0567, 0.0102, 0.0235, 0.0318, 0.0433],\n",
      "        [0.0712, 0.0266, 0.0494, 0.0560, 0.0525],\n",
      "        [0.0875, 0.0433, 0.0610, 0.0759, 0.0872],\n",
      "        [0.0661, 0.0459, 0.0733, 0.0824, 0.0665],\n",
      "        [0.0311, 0.0064, 0.0151, 0.0142, 0.0253],\n",
      "        [0.0817, 0.0491, 0.0866, 0.0920, 0.0752],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0506, 0.0201, 0.0378, 0.0389, 0.0345],\n",
      "        [0.0522, 0.0198, 0.0469, 0.0454, 0.0438],\n",
      "        [0.0640, 0.0420, 0.0685, 0.0773, 0.0736],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0981, 0.0423, 0.0678, 0.0831, 0.0802],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0111, 0.0017, 0.0048, 0.0076, 0.0062],\n",
      "        [0.0602, 0.0245, 0.0372, 0.0423, 0.0528],\n",
      "        [0.0730, 0.0443, 0.0769, 0.0818, 0.0739],\n",
      "        [0.0333, 0.0056, 0.0145, 0.0188, 0.0214],\n",
      "        [0.0141, 0.0015, 0.0046, 0.0062, 0.0057],\n",
      "        [0.0716, 0.0366, 0.0697, 0.0785, 0.0695],\n",
      "        [0.0967, 0.0438, 0.0744, 0.0803, 0.0871],\n",
      "        [0.0335, 0.0072, 0.0178, 0.0237, 0.0215],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0662, 0.0203, 0.0409, 0.0416, 0.0456],\n",
      "        [0.0073, 0.0018, 0.0039, 0.0046, 0.0053],\n",
      "        [0.0506, 0.0077, 0.0221, 0.0230, 0.0259],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0824, 0.0459, 0.0810, 0.0820, 0.0855],\n",
      "        [0.0426, 0.0085, 0.0176, 0.0257, 0.0267],\n",
      "        [0.0824, 0.0511, 0.0860, 0.0936, 0.0803],\n",
      "        [0.0996, 0.0468, 0.0672, 0.0969, 0.0881],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0549, 0.0114, 0.0308, 0.0318, 0.0385],\n",
      "        [0.0568, 0.0136, 0.0268, 0.0246, 0.0342],\n",
      "        [0.1175, 0.0582, 0.1079, 0.1196, 0.0932],\n",
      "        [0.0417, 0.0063, 0.0109, 0.0198, 0.0247],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0895, 0.0423, 0.0699, 0.0821, 0.0928],\n",
      "        [0.0152, 0.0023, 0.0061, 0.0104, 0.0138],\n",
      "        [0.0845, 0.0254, 0.0454, 0.0584, 0.0604],\n",
      "        [0.0148, 0.0013, 0.0063, 0.0044, 0.0131],\n",
      "        [0.0561, 0.0357, 0.0607, 0.0659, 0.0630],\n",
      "        [0.0425, 0.0256, 0.0410, 0.0387, 0.0325],\n",
      "        [0.0843, 0.0381, 0.0609, 0.0799, 0.0705],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0931, 0.0512, 0.0735, 0.0875, 0.0957],\n",
      "        [0.0797, 0.0532, 0.0834, 0.0953, 0.0764],\n",
      "        [0.0338, 0.0068, 0.0137, 0.0108, 0.0208],\n",
      "        [0.1171, 0.0615, 0.0884, 0.1077, 0.1124],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0803, 0.0430, 0.0755, 0.0851, 0.0714],\n",
      "        [0.0760, 0.0509, 0.0843, 0.0903, 0.0731],\n",
      "        [0.0788, 0.0225, 0.0362, 0.0428, 0.0498],\n",
      "        [0.0709, 0.0292, 0.0515, 0.0606, 0.0689],\n",
      "        [0.0320, 0.0082, 0.0206, 0.0171, 0.0206],\n",
      "        [0.0125, 0.0014, 0.0029, 0.0032, 0.0082],\n",
      "        [0.0673, 0.0349, 0.0555, 0.0652, 0.0773],\n",
      "        [0.0880, 0.0516, 0.0882, 0.0975, 0.0804],\n",
      "        [0.0581, 0.0218, 0.0358, 0.0351, 0.0534],\n",
      "        [0.0927, 0.0352, 0.0708, 0.0792, 0.0824],\n",
      "        [0.0536, 0.0271, 0.0465, 0.0602, 0.0570],\n",
      "        [0.0051, 0.0012, 0.0024, 0.0033, 0.0039],\n",
      "        [0.0709, 0.0397, 0.0745, 0.0792, 0.0671],\n",
      "        [0.0932, 0.0461, 0.0884, 0.0971, 0.0872],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0934, 0.0518, 0.0780, 0.0907, 0.0846],\n",
      "        [0.1071, 0.0331, 0.0750, 0.0749, 0.0872],\n",
      "        [0.0403, 0.0092, 0.0146, 0.0211, 0.0326],\n",
      "        [0.0921, 0.0434, 0.0681, 0.0831, 0.0876],\n",
      "        [0.0848, 0.0522, 0.0878, 0.0970, 0.0811],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0650, 0.0270, 0.0471, 0.0527, 0.0590],\n",
      "        [0.0237, 0.0051, 0.0113, 0.0101, 0.0192],\n",
      "        [0.0499, 0.0159, 0.0255, 0.0420, 0.0303],\n",
      "        [0.0686, 0.0225, 0.0313, 0.0449, 0.0579],\n",
      "        [0.0325, 0.0061, 0.0117, 0.0130, 0.0178],\n",
      "        [0.0773, 0.0366, 0.0603, 0.0589, 0.0638],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0797, 0.0264, 0.0658, 0.0661, 0.0668],\n",
      "        [0.1051, 0.0423, 0.0658, 0.0873, 0.0922],\n",
      "        [0.0824, 0.0402, 0.0552, 0.0710, 0.0900],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0707, 0.0449, 0.0790, 0.0828, 0.0706],\n",
      "        [0.0849, 0.0318, 0.0555, 0.0635, 0.0755],\n",
      "        [0.0660, 0.0344, 0.0491, 0.0664, 0.0726],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0872, 0.0283, 0.0640, 0.0661, 0.0656],\n",
      "        [0.0664, 0.0307, 0.0690, 0.0697, 0.0710],\n",
      "        [0.0688, 0.0438, 0.0775, 0.0805, 0.0696],\n",
      "        [0.0868, 0.0341, 0.0529, 0.0701, 0.0840],\n",
      "        [0.0507, 0.0324, 0.0559, 0.0582, 0.0599],\n",
      "        [0.0477, 0.0188, 0.0354, 0.0404, 0.0485],\n",
      "        [0.0271, 0.0037, 0.0103, 0.0122, 0.0153],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0215, 0.0045, 0.0099, 0.0088, 0.0160],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0539, 0.0121, 0.0226, 0.0291, 0.0251],\n",
      "        [0.0434, 0.0123, 0.0272, 0.0241, 0.0344],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0618, 0.0121, 0.0284, 0.0282, 0.0375],\n",
      "        [0.0171, 0.0022, 0.0054, 0.0065, 0.0114],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0893, 0.0466, 0.0962, 0.0988, 0.0722],\n",
      "        [0.0871, 0.0260, 0.0456, 0.0539, 0.0664],\n",
      "        [0.0960, 0.0525, 0.0912, 0.1004, 0.0832],\n",
      "        [0.0698, 0.0433, 0.0734, 0.0821, 0.0740],\n",
      "        [0.0418, 0.0077, 0.0228, 0.0179, 0.0183],\n",
      "        [0.0405, 0.0138, 0.0233, 0.0249, 0.0301],\n",
      "        [0.0900, 0.0418, 0.0844, 0.0955, 0.0769],\n",
      "        [0.0686, 0.0414, 0.0755, 0.0792, 0.0689],\n",
      "        [0.0656, 0.0418, 0.0678, 0.0797, 0.0729],\n",
      "        [0.0504, 0.0086, 0.0165, 0.0190, 0.0439],\n",
      "        [0.0297, 0.0052, 0.0117, 0.0142, 0.0179],\n",
      "        [0.1005, 0.0271, 0.0700, 0.0626, 0.0750],\n",
      "        [0.0836, 0.0309, 0.0666, 0.0648, 0.0812],\n",
      "        [0.0996, 0.0517, 0.0775, 0.0884, 0.0986],\n",
      "        [0.0877, 0.0488, 0.0810, 0.0946, 0.0802],\n",
      "        [0.1037, 0.0415, 0.0658, 0.0799, 0.0882],\n",
      "        [0.0810, 0.0502, 0.0846, 0.0917, 0.0796],\n",
      "        [0.0595, 0.0196, 0.0265, 0.0456, 0.0472],\n",
      "        [0.0227, 0.0150, 0.0264, 0.0272, 0.0251],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0457, 0.0201, 0.0377, 0.0403, 0.0486],\n",
      "        [0.0776, 0.0482, 0.0830, 0.0867, 0.0708],\n",
      "        [0.1000, 0.0312, 0.0508, 0.0562, 0.0728],\n",
      "        [0.1150, 0.0488, 0.0855, 0.1093, 0.0942],\n",
      "        [0.0743, 0.0342, 0.0642, 0.0720, 0.0774],\n",
      "        [0.1055, 0.0413, 0.0776, 0.0869, 0.0845],\n",
      "        [0.0828, 0.0378, 0.0596, 0.0753, 0.0729],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0747, 0.0304, 0.0567, 0.0647, 0.0842],\n",
      "        [0.0952, 0.0462, 0.0667, 0.0842, 0.0896],\n",
      "        [0.0589, 0.0294, 0.0516, 0.0553, 0.0629],\n",
      "        [0.0851, 0.0370, 0.0649, 0.0719, 0.0664],\n",
      "        [0.0020, 0.0002, 0.0010, 0.0011, 0.0016],\n",
      "        [0.0553, 0.0206, 0.0369, 0.0350, 0.0428],\n",
      "        [0.0757, 0.0221, 0.0307, 0.0498, 0.0560],\n",
      "        [0.0589, 0.0161, 0.0401, 0.0313, 0.0529],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)], '5%': [tensor([[6.3186e-01, 5.2301e-02, 1.4021e-02],\n",
      "        [8.3261e-01, 2.0203e-03, 1.2048e-04],\n",
      "        [4.3949e-01, 1.1798e-01, 1.4673e-02],\n",
      "        [4.5441e-01, 1.9368e-01, 5.4290e-02],\n",
      "        [5.1919e-01, 2.1289e-01, 2.8341e-02],\n",
      "        [5.7457e-01, 8.9096e-02, 4.5089e-02],\n",
      "        [6.9682e-01, 3.1755e-02, 9.3554e-04],\n",
      "        [5.2842e-01, 1.2513e-01, 6.7061e-02],\n",
      "        [8.7891e-01, 8.6106e-04, 1.3729e-04],\n",
      "        [5.5297e-01, 1.3578e-01, 7.3956e-02],\n",
      "        [5.8389e-01, 3.1209e-02, 6.1268e-03],\n",
      "        [2.4334e-01, 3.4222e-02, 1.1965e-02],\n",
      "        [4.9514e-01, 1.1230e-01, 5.8856e-02],\n",
      "        [6.3844e-01, 8.2726e-02, 5.7653e-02],\n",
      "        [4.7521e-01, 2.3624e-01, 4.2637e-02],\n",
      "        [3.0736e-01, 1.4089e-01, 1.2688e-01],\n",
      "        [4.3176e-01, 5.0766e-03, 1.8772e-04],\n",
      "        [6.9109e-01, 3.2114e-02, 7.4648e-03],\n",
      "        [5.4722e-01, 1.2137e-01, 7.1701e-02],\n",
      "        [8.0444e-01, 2.2329e-02, 1.3189e-03],\n",
      "        [5.0811e-01, 2.8269e-02, 1.1641e-03],\n",
      "        [3.2578e-01, 1.8127e-01, 8.3423e-02],\n",
      "        [5.4841e-01, 1.8065e-01, 3.5210e-02],\n",
      "        [1.7191e-01, 1.8159e-01, 9.8053e-03],\n",
      "        [7.4675e-01, 4.5447e-04, 5.9092e-05],\n",
      "        [2.9862e-01, 4.4518e-02, 1.8440e-02],\n",
      "        [1.6328e-01, 2.0350e-03, 3.9671e-04],\n",
      "        [4.8783e-01, 2.4796e-02, 6.5250e-03],\n",
      "        [6.1884e-01, 9.7443e-02, 5.0875e-02],\n",
      "        [5.5626e-01, 7.0408e-02, 6.5802e-02],\n",
      "        [5.2846e-01, 1.0285e-01, 4.8019e-02],\n",
      "        [6.3909e-01, 6.5672e-02, 1.2137e-03],\n",
      "        [4.4723e-01, 1.3856e-01, 9.1329e-02],\n",
      "        [5.0873e-01, 1.9440e-01, 2.2048e-02],\n",
      "        [1.5273e-01, 2.3984e-02, 3.0259e-02],\n",
      "        [5.0559e-01, 2.3929e-02, 1.3872e-02],\n",
      "        [8.3456e-01, 3.7035e-02, 3.5267e-03],\n",
      "        [2.3366e-01, 1.3051e-01, 1.1384e-01],\n",
      "        [4.5966e-01, 5.1182e-02, 1.3547e-03],\n",
      "        [5.4120e-01, 8.9766e-02, 4.9361e-02],\n",
      "        [3.8655e-01, 2.1636e-01, 5.0990e-02],\n",
      "        [3.5491e-01, 1.5470e-02, 1.2542e-03],\n",
      "        [3.8783e-01, 2.6472e-01, 4.0293e-02],\n",
      "        [8.4459e-01, 3.8677e-03, 2.4745e-04],\n",
      "        [5.8321e-01, 9.9463e-02, 3.4231e-02],\n",
      "        [7.5109e-01, 1.9027e-02, 1.4057e-02],\n",
      "        [2.3746e-01, 2.3782e-01, 4.0637e-02],\n",
      "        [6.5262e-01, 7.4081e-02, 2.0248e-02],\n",
      "        [5.4817e-01, 1.4187e-01, 4.0473e-02],\n",
      "        [4.1780e-01, 1.2182e-01, 1.1530e-01],\n",
      "        [8.3482e-01, 1.6240e-03, 1.5253e-04],\n",
      "        [4.5440e-01, 2.8386e-01, 7.2557e-02],\n",
      "        [6.6665e-01, 1.1061e-02, 7.1623e-03],\n",
      "        [4.4925e-01, 1.9769e-01, 8.9359e-02],\n",
      "        [5.6040e-01, 1.1685e-01, 6.5365e-02],\n",
      "        [5.9249e-01, 5.4790e-02, 1.1024e-02],\n",
      "        [5.1153e-01, 1.2566e-01, 2.5443e-02],\n",
      "        [8.3552e-01, 7.1277e-03, 6.6380e-04],\n",
      "        [6.8858e-01, 4.4209e-03, 9.7215e-05],\n",
      "        [5.7472e-01, 1.1508e-01, 1.9006e-02],\n",
      "        [4.8592e-01, 1.6415e-01, 1.2140e-01],\n",
      "        [7.5570e-01, 5.6460e-02, 1.1496e-02],\n",
      "        [5.0886e-01, 2.0444e-01, 2.7568e-02],\n",
      "        [6.1165e-01, 1.0425e-01, 3.6093e-02],\n",
      "        [4.8636e-01, 1.0301e-03, 9.0004e-05],\n",
      "        [5.6352e-01, 1.2459e-01, 5.2922e-02],\n",
      "        [5.2782e-01, 1.7303e-01, 6.5102e-02],\n",
      "        [6.3702e-01, 1.0122e-01, 1.0938e-02],\n",
      "        [6.1429e-01, 1.4112e-01, 4.5600e-02],\n",
      "        [4.8272e-01, 1.4385e-01, 5.1650e-02],\n",
      "        [6.7889e-01, 7.6126e-02, 3.7371e-03],\n",
      "        [3.9089e-01, 2.0928e-01, 5.8076e-02],\n",
      "        [3.6452e-01, 1.4914e-01, 1.1707e-01],\n",
      "        [4.8445e-01, 1.0108e-01, 4.2120e-02],\n",
      "        [4.0990e-01, 1.0959e-01, 2.3216e-02],\n",
      "        [8.4191e-01, 1.1521e-02, 1.2354e-03],\n",
      "        [5.1306e-01, 1.3582e-01, 2.8891e-02],\n",
      "        [5.6845e-01, 1.2203e-01, 1.4019e-02],\n",
      "        [7.8624e-01, 1.4871e-02, 1.5865e-03],\n",
      "        [4.0242e-01, 7.2782e-02, 2.7821e-02],\n",
      "        [5.2445e-01, 1.0195e-01, 3.8253e-02],\n",
      "        [5.1230e-01, 7.4021e-02, 1.2555e-01],\n",
      "        [2.9254e-01, 1.9916e-01, 5.9106e-02],\n",
      "        [6.0286e-01, 1.1539e-01, 1.7921e-02],\n",
      "        [6.3000e-01, 2.1635e-02, 4.3433e-03],\n",
      "        [6.4674e-01, 9.0751e-02, 4.4527e-02],\n",
      "        [5.9243e-01, 6.3350e-02, 1.8372e-02],\n",
      "        [5.7962e-01, 1.1138e-01, 1.0890e-02],\n",
      "        [5.8906e-01, 3.4666e-02, 2.1569e-02],\n",
      "        [3.0075e-01, 9.0355e-02, 6.2991e-02],\n",
      "        [5.0845e-01, 1.5965e-01, 5.1279e-02],\n",
      "        [5.6189e-01, 6.6562e-02, 3.1559e-02],\n",
      "        [3.6516e-01, 3.3188e-01, 3.8281e-02],\n",
      "        [6.3024e-01, 7.6743e-02, 1.6344e-02],\n",
      "        [4.9810e-01, 1.1861e-01, 9.7475e-03],\n",
      "        [7.1982e-01, 1.0099e-02, 7.7464e-04],\n",
      "        [4.6160e-01, 7.4173e-02, 1.8618e-02],\n",
      "        [6.5779e-01, 1.8156e-02, 8.9181e-04],\n",
      "        [7.3770e-01, 2.7899e-02, 1.8495e-02],\n",
      "        [5.2994e-01, 6.4171e-02, 9.4719e-03],\n",
      "        [6.9107e-01, 2.5859e-02, 5.6083e-03],\n",
      "        [8.3159e-01, 1.1611e-02, 2.4998e-03],\n",
      "        [6.6170e-01, 3.9532e-02, 4.9001e-03],\n",
      "        [7.7980e-01, 3.6143e-02, 1.6841e-03],\n",
      "        [3.5531e-01, 1.3251e-01, 1.7815e-01],\n",
      "        [6.8776e-01, 1.9209e-02, 4.2874e-03],\n",
      "        [7.5678e-01, 2.3624e-02, 7.1274e-03],\n",
      "        [8.8824e-01, 9.7573e-03, 1.1551e-02],\n",
      "        [7.1777e-01, 4.5862e-02, 8.0873e-03],\n",
      "        [2.8642e-01, 9.1846e-02, 1.0377e-01],\n",
      "        [4.6640e-01, 1.2278e-01, 2.4190e-02],\n",
      "        [3.8061e-01, 2.0132e-01, 1.4988e-01],\n",
      "        [5.1829e-01, 1.4171e-01, 5.3093e-02],\n",
      "        [5.2009e-01, 9.6189e-03, 4.1914e-03],\n",
      "        [8.1356e-01, 2.3949e-02, 1.4954e-03],\n",
      "        [3.4672e-01, 1.2664e-01, 1.1499e-01],\n",
      "        [5.7431e-01, 1.0382e-01, 5.1220e-02],\n",
      "        [5.8752e-01, 1.0692e-01, 4.6366e-02],\n",
      "        [5.9337e-01, 3.3091e-02, 2.4222e-03],\n",
      "        [7.8944e-01, 4.0854e-03, 3.0717e-04],\n",
      "        [4.5421e-01, 8.6041e-02, 3.5675e-02],\n",
      "        [5.5726e-01, 9.2692e-02, 5.6227e-02],\n",
      "        [5.2004e-01, 1.9211e-01, 5.7377e-02],\n",
      "        [3.8920e-01, 1.8076e-01, 1.0738e-01],\n",
      "        [5.3583e-01, 1.4517e-01, 2.6616e-02],\n",
      "        [5.1506e-01, 1.1197e-01, 6.4998e-02],\n",
      "        [4.8517e-01, 2.1639e-01, 1.3143e-02],\n",
      "        [7.3104e-01, 1.0480e-02, 4.7223e-03],\n",
      "        [8.3173e-01, 1.0095e-02, 9.3553e-04],\n",
      "        [5.4432e-01, 1.0994e-01, 6.6483e-02],\n",
      "        [6.2740e-01, 9.6426e-02, 8.4379e-03],\n",
      "        [5.2601e-01, 1.4243e-01, 7.2252e-02],\n",
      "        [4.5510e-01, 1.2646e-01, 2.9672e-02],\n",
      "        [3.5795e-01, 2.3318e-01, 8.8650e-02],\n",
      "        [4.0964e-01, 1.6514e-01, 6.8063e-02],\n",
      "        [2.9302e-01, 2.3295e-01, 6.4016e-02],\n",
      "        [5.0282e-01, 1.9522e-01, 4.4615e-02],\n",
      "        [9.0980e-01, 2.2908e-03, 1.1687e-04],\n",
      "        [4.8926e-01, 1.3775e-01, 2.7842e-02],\n",
      "        [4.7292e-01, 2.3323e-01, 3.7525e-02],\n",
      "        [6.7827e-01, 1.1348e-01, 2.8885e-02],\n",
      "        [4.9811e-01, 1.4422e-01, 4.3534e-02],\n",
      "        [4.2780e-01, 1.5562e-03, 3.7836e-05],\n",
      "        [6.5331e-01, 1.5550e-02, 2.7201e-03],\n",
      "        [4.5254e-01, 2.1717e-01, 1.3990e-02],\n",
      "        [7.6143e-01, 2.6180e-02, 1.3752e-02],\n",
      "        [6.7039e-01, 6.5257e-02, 2.5555e-02]], device='cuda:0'), tensor([[6.6214e-01, 3.8554e-02, 2.0798e-02],\n",
      "        [4.5639e-01, 2.5162e-03, 3.2771e-03],\n",
      "        [4.5918e-01, 9.0867e-02, 1.0201e-01],\n",
      "        [4.4988e-01, 1.0492e-01, 1.1292e-01],\n",
      "        [4.2229e-01, 1.4365e-01, 1.5242e-01],\n",
      "        [4.2235e-01, 1.5877e-01, 1.0667e-01],\n",
      "        [2.1875e-01, 3.2126e-02, 1.0130e-01],\n",
      "        [4.3204e-01, 2.4284e-01, 1.0672e-01],\n",
      "        [5.2932e-01, 1.2894e-02, 2.9509e-03],\n",
      "        [3.7710e-01, 2.0726e-01, 9.2987e-02],\n",
      "        [4.4188e-01, 5.5144e-02, 4.5414e-02],\n",
      "        [5.5519e-01, 7.3307e-02, 2.9744e-02],\n",
      "        [3.6717e-01, 2.1829e-01, 1.3268e-01],\n",
      "        [4.0702e-01, 1.8156e-01, 1.1364e-01],\n",
      "        [3.7746e-01, 1.1341e-01, 1.3909e-01],\n",
      "        [5.4588e-01, 1.6259e-01, 6.0551e-02],\n",
      "        [3.3594e-01, 1.1238e-02, 1.2969e-02],\n",
      "        [2.2988e-01, 7.6879e-02, 2.0278e-01],\n",
      "        [3.6796e-01, 2.0382e-01, 1.3400e-01],\n",
      "        [4.1217e-02, 3.6711e-03, 5.0742e-02],\n",
      "        [3.4035e-03, 2.1140e-04, 6.2728e-01],\n",
      "        [4.5404e-01, 1.4155e-01, 8.7979e-02],\n",
      "        [3.8003e-01, 1.4994e-01, 1.2350e-01],\n",
      "        [6.1228e-01, 3.7688e-02, 8.7098e-03],\n",
      "        [5.0823e-01, 4.9782e-03, 2.2743e-03],\n",
      "        [5.2250e-01, 6.3626e-02, 3.1401e-02],\n",
      "        [5.2355e-01, 7.9246e-03, 8.5686e-04],\n",
      "        [6.3538e-01, 2.4809e-02, 8.9712e-03],\n",
      "        [3.5576e-01, 1.1313e-01, 1.9756e-01],\n",
      "        [4.5677e-01, 1.9712e-01, 9.2837e-02],\n",
      "        [3.7674e-01, 2.0872e-01, 1.2135e-01],\n",
      "        [1.6390e-02, 8.6959e-03, 3.0132e-01],\n",
      "        [4.6747e-01, 2.0528e-01, 9.9006e-02],\n",
      "        [4.2891e-01, 1.7633e-01, 9.9853e-02],\n",
      "        [5.2734e-01, 1.0356e-01, 6.3873e-02],\n",
      "        [5.9300e-01, 4.0297e-02, 6.8138e-02],\n",
      "        [4.8444e-01, 1.2000e-01, 3.7345e-02],\n",
      "        [5.0879e-01, 1.9565e-01, 1.1208e-01],\n",
      "        [3.6570e-01, 3.7147e-02, 1.0138e-01],\n",
      "        [3.8310e-01, 2.1365e-01, 1.3759e-01],\n",
      "        [4.4233e-01, 1.5749e-01, 1.2820e-01],\n",
      "        [5.2087e-01, 2.7998e-02, 8.1925e-03],\n",
      "        [5.6103e-01, 5.8904e-02, 4.7581e-02],\n",
      "        [6.2514e-01, 9.1449e-03, 1.7015e-03],\n",
      "        [4.2973e-01, 2.0621e-01, 9.2975e-02],\n",
      "        [4.5732e-01, 4.7947e-02, 1.7248e-02],\n",
      "        [4.2787e-01, 7.7608e-02, 1.6903e-01],\n",
      "        [5.0621e-01, 1.8430e-01, 3.8209e-02],\n",
      "        [3.6105e-01, 1.7605e-01, 2.1386e-01],\n",
      "        [3.8378e-01, 1.5531e-01, 1.4106e-01],\n",
      "        [5.1214e-01, 1.1553e-02, 7.7195e-03],\n",
      "        [4.1626e-01, 1.6326e-01, 1.6894e-01],\n",
      "        [7.0104e-01, 2.3675e-02, 1.9921e-02],\n",
      "        [3.8402e-01, 2.1013e-01, 1.2989e-01],\n",
      "        [3.8451e-01, 2.3526e-01, 1.0351e-01],\n",
      "        [3.7145e-01, 9.4252e-02, 6.2183e-02],\n",
      "        [4.5671e-01, 1.2021e-01, 5.9074e-02],\n",
      "        [3.6411e-01, 4.2641e-02, 4.5030e-02],\n",
      "        [5.9418e-01, 2.5906e-02, 4.0159e-03],\n",
      "        [3.3888e-01, 1.4906e-01, 2.0995e-01],\n",
      "        [3.9009e-01, 2.4108e-01, 1.2710e-01],\n",
      "        [1.2895e-01, 4.1774e-02, 2.0880e-01],\n",
      "        [3.6675e-01, 1.3314e-01, 1.0580e-01],\n",
      "        [3.9339e-01, 1.5765e-01, 6.5270e-02],\n",
      "        [4.5069e-01, 9.8931e-03, 2.6784e-03],\n",
      "        [4.5797e-01, 1.8994e-01, 7.3766e-02],\n",
      "        [5.0658e-01, 2.0615e-01, 6.9491e-02],\n",
      "        [2.0932e-01, 6.9481e-02, 2.1964e-01],\n",
      "        [3.1459e-01, 1.4835e-01, 2.2794e-01],\n",
      "        [4.5445e-01, 1.2407e-01, 7.2118e-02],\n",
      "        [5.1045e-02, 1.7176e-02, 3.7896e-01],\n",
      "        [4.4207e-01, 1.5080e-01, 1.4890e-01],\n",
      "        [4.7743e-01, 2.0394e-01, 8.6558e-02],\n",
      "        [4.9021e-01, 9.1297e-02, 7.0200e-02],\n",
      "        [3.1673e-01, 7.5825e-02, 2.0354e-01],\n",
      "        [4.1649e-01, 3.0837e-02, 5.2725e-02],\n",
      "        [5.3097e-01, 8.7982e-02, 3.9884e-02],\n",
      "        [2.4199e-01, 8.2358e-02, 2.1751e-01],\n",
      "        [6.2326e-01, 3.7854e-02, 2.2907e-02],\n",
      "        [4.1303e-01, 1.6461e-01, 1.0828e-01],\n",
      "        [4.6842e-01, 1.9982e-01, 8.1974e-02],\n",
      "        [4.8932e-01, 9.9175e-02, 3.9461e-02],\n",
      "        [3.6989e-01, 1.4780e-01, 1.9889e-01],\n",
      "        [4.0561e-01, 1.8017e-01, 6.4988e-02],\n",
      "        [7.6377e-01, 1.2866e-02, 8.1223e-03],\n",
      "        [4.0961e-01, 1.7528e-01, 9.9190e-02],\n",
      "        [5.0411e-01, 9.7058e-02, 5.1165e-02],\n",
      "        [4.2423e-01, 1.8334e-01, 4.3971e-02],\n",
      "        [4.6879e-01, 1.7640e-01, 5.3464e-02],\n",
      "        [5.9963e-01, 3.8370e-02, 1.9365e-02],\n",
      "        [4.2606e-01, 1.6996e-01, 1.4194e-01],\n",
      "        [4.0982e-01, 1.9777e-01, 1.0580e-01],\n",
      "        [3.7532e-01, 1.6378e-01, 1.7194e-01],\n",
      "        [3.7149e-01, 1.8258e-01, 1.0202e-01],\n",
      "        [4.5666e-01, 7.4726e-02, 7.9312e-02],\n",
      "        [2.4958e-01, 1.6139e-02, 1.1547e-02],\n",
      "        [3.3137e-01, 9.7035e-02, 2.0498e-01],\n",
      "        [2.5576e-01, 3.2857e-02, 3.9546e-02],\n",
      "        [3.6140e-01, 8.2042e-02, 1.1295e-01],\n",
      "        [3.6736e-01, 3.7904e-02, 3.0581e-02],\n",
      "        [5.0849e-01, 7.6167e-02, 4.6800e-02],\n",
      "        [2.7188e-01, 4.2172e-02, 1.2151e-01],\n",
      "        [3.7399e-01, 4.8491e-02, 8.1154e-02],\n",
      "        [5.3767e-01, 1.2635e-02, 8.3079e-03],\n",
      "        [5.1673e-01, 1.8146e-01, 8.3905e-02],\n",
      "        [4.1946e-01, 3.9285e-02, 5.0668e-02],\n",
      "        [2.5489e-01, 8.4823e-02, 2.1606e-01],\n",
      "        [3.3469e-01, 2.1607e-02, 2.3649e-02],\n",
      "        [3.6230e-01, 1.4559e-01, 1.2490e-01],\n",
      "        [5.1085e-01, 1.6114e-01, 4.8410e-02],\n",
      "        [3.0955e-01, 8.9850e-02, 1.5537e-01],\n",
      "        [3.9464e-01, 1.7731e-01, 7.8707e-02],\n",
      "        [3.5515e-01, 2.2615e-01, 1.7587e-01],\n",
      "        [5.9071e-01, 2.7195e-02, 1.3069e-02],\n",
      "        [3.0402e-01, 3.6806e-02, 6.8831e-02],\n",
      "        [4.8098e-01, 8.6089e-02, 3.3965e-02],\n",
      "        [4.1790e-01, 2.0999e-01, 1.0274e-01],\n",
      "        [3.9440e-01, 1.8850e-01, 1.2928e-01],\n",
      "        [3.9390e-01, 4.6107e-02, 2.9455e-02],\n",
      "        [5.1576e-01, 2.1138e-02, 1.5941e-02],\n",
      "        [6.4712e-01, 7.0576e-02, 4.9312e-02],\n",
      "        [3.6074e-01, 7.4034e-02, 7.0586e-02],\n",
      "        [3.7965e-01, 1.5859e-01, 2.0062e-01],\n",
      "        [4.9758e-01, 1.9261e-01, 1.1211e-01],\n",
      "        [4.4929e-01, 1.4523e-01, 1.4184e-01],\n",
      "        [3.9739e-01, 2.0563e-01, 9.9666e-02],\n",
      "        [2.8796e-01, 1.0855e-01, 1.0113e-01],\n",
      "        [4.1862e-01, 6.2274e-02, 1.6173e-02],\n",
      "        [2.5611e-01, 1.9195e-02, 1.0578e-01],\n",
      "        [4.5040e-01, 2.0930e-01, 9.0645e-02],\n",
      "        [4.8373e-01, 1.0376e-01, 6.1882e-02],\n",
      "        [4.1769e-01, 1.8489e-01, 1.0484e-01],\n",
      "        [3.1635e-01, 1.1828e-01, 1.3163e-01],\n",
      "        [3.7240e-01, 1.5795e-01, 1.5641e-01],\n",
      "        [3.8089e-01, 1.8366e-01, 1.4040e-01],\n",
      "        [5.5413e-01, 1.0541e-01, 9.1517e-02],\n",
      "        [4.3632e-01, 1.2564e-01, 1.7097e-01],\n",
      "        [4.3037e-01, 8.4810e-03, 3.5324e-03],\n",
      "        [4.2052e-01, 1.6330e-01, 1.3894e-01],\n",
      "        [4.4245e-01, 1.5022e-01, 1.9933e-01],\n",
      "        [3.7465e-01, 1.4366e-01, 1.3975e-01],\n",
      "        [3.8057e-01, 1.0857e-01, 1.5093e-01],\n",
      "        [3.8307e-01, 1.3614e-02, 2.8293e-03],\n",
      "        [4.6528e-01, 6.0878e-02, 2.2263e-02],\n",
      "        [2.2862e-01, 9.0659e-02, 1.5522e-01],\n",
      "        [2.9927e-01, 6.1623e-02, 1.3383e-01],\n",
      "        [4.3052e-01, 1.1357e-01, 9.4717e-02]], device='cuda:0'), tensor([[0.2416, 0.2333, 0.1082, 0.1149],\n",
      "        [0.0601, 0.3833, 0.0335, 0.0460],\n",
      "        [0.1024, 0.3950, 0.0629, 0.0872],\n",
      "        [0.2111, 0.3256, 0.1163, 0.1257],\n",
      "        [0.1982, 0.3164, 0.1254, 0.1441],\n",
      "        [0.2539, 0.2171, 0.1573, 0.1610],\n",
      "        [0.1167, 0.3043, 0.0565, 0.0702],\n",
      "        [0.2382, 0.2460, 0.1507, 0.1595],\n",
      "        [0.1779, 0.2558, 0.0331, 0.0305],\n",
      "        [0.2607, 0.2363, 0.1237, 0.1382],\n",
      "        [0.1772, 0.2928, 0.0649, 0.1163],\n",
      "        [0.2031, 0.2917, 0.0960, 0.0928],\n",
      "        [0.2015, 0.2660, 0.1389, 0.1435],\n",
      "        [0.2502, 0.2650, 0.1413, 0.1359],\n",
      "        [0.1820, 0.3319, 0.1559, 0.1600],\n",
      "        [0.2802, 0.2529, 0.1318, 0.1531],\n",
      "        [0.0396, 0.3692, 0.0176, 0.0158],\n",
      "        [0.1996, 0.2773, 0.1090, 0.1164],\n",
      "        [0.2526, 0.2464, 0.1553, 0.1491],\n",
      "        [0.1663, 0.3472, 0.0468, 0.0474],\n",
      "        [0.1261, 0.3902, 0.0283, 0.0284],\n",
      "        [0.2267, 0.2420, 0.1627, 0.1530],\n",
      "        [0.1936, 0.3093, 0.1458, 0.1479],\n",
      "        [0.1322, 0.3639, 0.0681, 0.0730],\n",
      "        [0.2284, 0.0787, 0.0119, 0.0147],\n",
      "        [0.1333, 0.3204, 0.0744, 0.0992],\n",
      "        [0.1153, 0.2525, 0.0274, 0.0271],\n",
      "        [0.1437, 0.2757, 0.0450, 0.0924],\n",
      "        [0.2174, 0.3070, 0.1272, 0.1301],\n",
      "        [0.2588, 0.2396, 0.1409, 0.1528],\n",
      "        [0.2232, 0.2634, 0.1416, 0.1432],\n",
      "        [0.1177, 0.3706, 0.0367, 0.0561],\n",
      "        [0.2579, 0.2303, 0.1503, 0.1656],\n",
      "        [0.2102, 0.2949, 0.1409, 0.1471],\n",
      "        [0.3033, 0.2186, 0.1131, 0.1065],\n",
      "        [0.1735, 0.2827, 0.0842, 0.0927],\n",
      "        [0.1588, 0.3510, 0.0839, 0.0820],\n",
      "        [0.2350, 0.2500, 0.1573, 0.1488],\n",
      "        [0.0961, 0.3589, 0.0441, 0.0565],\n",
      "        [0.3141, 0.2248, 0.1355, 0.1370],\n",
      "        [0.2301, 0.2594, 0.1572, 0.1611],\n",
      "        [0.1815, 0.2770, 0.0506, 0.0471],\n",
      "        [0.1836, 0.3185, 0.1119, 0.1314],\n",
      "        [0.0980, 0.2980, 0.0378, 0.0301],\n",
      "        [0.2683, 0.2273, 0.1567, 0.1716],\n",
      "        [0.1692, 0.2731, 0.0784, 0.0754],\n",
      "        [0.2412, 0.3219, 0.1221, 0.1505],\n",
      "        [0.2378, 0.2497, 0.1216, 0.1266],\n",
      "        [0.2218, 0.2891, 0.1423, 0.1533],\n",
      "        [0.2397, 0.2707, 0.1549, 0.1474],\n",
      "        [0.1572, 0.3768, 0.0414, 0.0490],\n",
      "        [0.2030, 0.2869, 0.1435, 0.1731],\n",
      "        [0.1756, 0.3784, 0.0643, 0.0726],\n",
      "        [0.2214, 0.2579, 0.1434, 0.1709],\n",
      "        [0.2608, 0.2564, 0.1632, 0.1541],\n",
      "        [0.1802, 0.3200, 0.0935, 0.0990],\n",
      "        [0.2055, 0.2748, 0.1436, 0.1449],\n",
      "        [0.1293, 0.2686, 0.0813, 0.0937],\n",
      "        [0.0509, 0.3322, 0.0213, 0.0240],\n",
      "        [0.2288, 0.2867, 0.1462, 0.1572],\n",
      "        [0.2365, 0.2698, 0.1502, 0.1772],\n",
      "        [0.1917, 0.2941, 0.1002, 0.0986],\n",
      "        [0.1810, 0.3184, 0.1198, 0.1200],\n",
      "        [0.2374, 0.2696, 0.1186, 0.1406],\n",
      "        [0.1904, 0.2373, 0.0107, 0.0127],\n",
      "        [0.2191, 0.2449, 0.1523, 0.1502],\n",
      "        [0.2074, 0.2589, 0.1442, 0.1566],\n",
      "        [0.2198, 0.2557, 0.0974, 0.1180],\n",
      "        [0.2167, 0.2765, 0.1379, 0.1369],\n",
      "        [0.2218, 0.2985, 0.1233, 0.1379],\n",
      "        [0.1722, 0.3785, 0.0663, 0.0757],\n",
      "        [0.1932, 0.3384, 0.1495, 0.1437],\n",
      "        [0.2300, 0.2319, 0.1621, 0.1733],\n",
      "        [0.2491, 0.2442, 0.1350, 0.1424],\n",
      "        [0.1692, 0.2949, 0.1021, 0.1047],\n",
      "        [0.2066, 0.3499, 0.0727, 0.0736],\n",
      "        [0.1944, 0.3367, 0.0744, 0.0740],\n",
      "        [0.1835, 0.3278, 0.1057, 0.1254],\n",
      "        [0.1750, 0.3180, 0.0393, 0.0527],\n",
      "        [0.2338, 0.3142, 0.1135, 0.1108],\n",
      "        [0.2625, 0.2217, 0.1369, 0.1293],\n",
      "        [0.2249, 0.2522, 0.1040, 0.1458],\n",
      "        [0.2111, 0.3222, 0.1187, 0.1445],\n",
      "        [0.1936, 0.3160, 0.1092, 0.1148],\n",
      "        [0.2195, 0.2474, 0.0556, 0.0696],\n",
      "        [0.2702, 0.2734, 0.1390, 0.1534],\n",
      "        [0.1914, 0.3342, 0.1293, 0.1242],\n",
      "        [0.1997, 0.2745, 0.1061, 0.1068],\n",
      "        [0.2979, 0.2277, 0.1499, 0.1441],\n",
      "        [0.2061, 0.2763, 0.1178, 0.1164],\n",
      "        [0.2310, 0.2898, 0.1449, 0.1540],\n",
      "        [0.2161, 0.2350, 0.1458, 0.1352],\n",
      "        [0.1860, 0.3109, 0.1319, 0.1481],\n",
      "        [0.2202, 0.2524, 0.1200, 0.1317],\n",
      "        [0.1600, 0.3297, 0.0741, 0.0703],\n",
      "        [0.0850, 0.3481, 0.0335, 0.0434],\n",
      "        [0.2096, 0.2951, 0.0884, 0.1070],\n",
      "        [0.1236, 0.3654, 0.0417, 0.0574],\n",
      "        [0.2063, 0.2320, 0.1004, 0.1040],\n",
      "        [0.1495, 0.3740, 0.0532, 0.0642],\n",
      "        [0.1803, 0.2712, 0.0834, 0.0970],\n",
      "        [0.2511, 0.3162, 0.0896, 0.0963],\n",
      "        [0.1693, 0.2741, 0.0892, 0.1111],\n",
      "        [0.1422, 0.3256, 0.0528, 0.0621],\n",
      "        [0.2400, 0.2515, 0.1413, 0.1356],\n",
      "        [0.2111, 0.2829, 0.0755, 0.0811],\n",
      "        [0.2410, 0.2782, 0.1074, 0.1151],\n",
      "        [0.2102, 0.2606, 0.0466, 0.0483],\n",
      "        [0.2245, 0.2324, 0.1056, 0.1024],\n",
      "        [0.2341, 0.2531, 0.1394, 0.1577],\n",
      "        [0.1984, 0.2940, 0.0869, 0.1098],\n",
      "        [0.2284, 0.2719, 0.1565, 0.1656],\n",
      "        [0.2146, 0.2871, 0.1606, 0.1466],\n",
      "        [0.2100, 0.3184, 0.0664, 0.0873],\n",
      "        [0.2347, 0.2412, 0.0768, 0.0909],\n",
      "        [0.2204, 0.2473, 0.1320, 0.1464],\n",
      "        [0.2281, 0.2431, 0.1485, 0.1414],\n",
      "        [0.2269, 0.2540, 0.1308, 0.1623],\n",
      "        [0.1944, 0.3431, 0.1009, 0.1070],\n",
      "        [0.1317, 0.4564, 0.0381, 0.0343],\n",
      "        [0.1952, 0.2539, 0.1220, 0.1444],\n",
      "        [0.2320, 0.3084, 0.1186, 0.1343],\n",
      "        [0.2380, 0.2838, 0.1534, 0.1585],\n",
      "        [0.2172, 0.2511, 0.1599, 0.1618],\n",
      "        [0.1544, 0.2819, 0.1255, 0.1298],\n",
      "        [0.2195, 0.2579, 0.1483, 0.1481],\n",
      "        [0.1707, 0.3367, 0.0981, 0.1086],\n",
      "        [0.2037, 0.2008, 0.0955, 0.1008],\n",
      "        [0.1417, 0.2957, 0.0349, 0.0335],\n",
      "        [0.2352, 0.2176, 0.1588, 0.1496],\n",
      "        [0.1909, 0.3036, 0.0971, 0.1093],\n",
      "        [0.2576, 0.2580, 0.1651, 0.1514],\n",
      "        [0.2072, 0.3036, 0.1248, 0.1147],\n",
      "        [0.1977, 0.3003, 0.1412, 0.1561],\n",
      "        [0.2075, 0.2586, 0.1225, 0.1569],\n",
      "        [0.2097, 0.2756, 0.1429, 0.1411],\n",
      "        [0.1981, 0.3023, 0.1396, 0.1557],\n",
      "        [0.0788, 0.2922, 0.0362, 0.0392],\n",
      "        [0.1936, 0.3033, 0.1188, 0.1430],\n",
      "        [0.2091, 0.2815, 0.1505, 0.1491],\n",
      "        [0.2062, 0.3440, 0.1310, 0.1250],\n",
      "        [0.1915, 0.3068, 0.1438, 0.1314],\n",
      "        [0.0257, 0.3803, 0.0151, 0.0225],\n",
      "        [0.2272, 0.2998, 0.1036, 0.1184],\n",
      "        [0.1749, 0.2798, 0.1186, 0.1174],\n",
      "        [0.2234, 0.2969, 0.0930, 0.1127],\n",
      "        [0.2277, 0.2972, 0.1183, 0.1191]], device='cuda:0'), tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.2493e-05, 1.8990e-06, 1.5519e-05, 7.3699e-06, 9.3073e-05],\n",
      "        [7.4940e-03, 5.2146e-04, 1.9241e-03, 3.0494e-03, 3.3006e-03],\n",
      "        [2.2942e-02, 5.8091e-03, 1.4270e-02, 2.3766e-02, 1.9719e-02],\n",
      "        [2.3592e-02, 7.7359e-03, 1.1014e-02, 1.1544e-02, 1.9797e-02],\n",
      "        [2.6259e-02, 9.0129e-03, 2.4310e-02, 2.0691e-02, 1.4897e-02],\n",
      "        [1.5588e-03, 7.3762e-05, 8.3204e-04, 5.5649e-04, 2.1789e-03],\n",
      "        [2.9414e-02, 1.3801e-02, 2.2908e-02, 3.2348e-02, 3.5966e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0518e-02, 1.1065e-03, 3.2633e-03, 2.4126e-03, 3.6427e-03],\n",
      "        [2.9253e-03, 5.2470e-04, 2.0034e-03, 3.9382e-03, 3.2564e-03],\n",
      "        [1.7620e-02, 8.9447e-03, 1.6505e-02, 1.9392e-02, 2.8079e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.2426e-02, 1.3468e-02, 1.9981e-02, 2.4246e-02, 2.9711e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.6198e-04, 1.5965e-06, 3.7494e-05, 8.9163e-05, 4.0540e-05],\n",
      "        [1.0136e-02, 5.8181e-03, 7.1622e-03, 9.3836e-03, 1.2599e-02],\n",
      "        [2.2955e-02, 9.2928e-03, 2.2655e-02, 2.9569e-02, 1.3733e-02],\n",
      "        [1.0605e-03, 3.0502e-05, 5.2512e-04, 4.7184e-04, 1.6636e-04],\n",
      "        [7.2896e-04, 1.4892e-05, 1.4109e-04, 1.0268e-04, 1.0672e-04],\n",
      "        [3.5717e-02, 1.4779e-02, 1.4157e-02, 2.7188e-02, 3.4020e-02],\n",
      "        [3.3929e-02, 8.5055e-03, 1.2876e-02, 2.6079e-02, 2.8555e-02],\n",
      "        [2.2202e-03, 1.6081e-04, 4.5727e-04, 8.9601e-04, 1.5593e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0559e-03, 1.3989e-03, 4.9929e-03, 6.2188e-03, 5.5076e-03],\n",
      "        [4.0129e-05, 9.6959e-07, 3.7164e-06, 1.3699e-05, 1.5385e-05],\n",
      "        [9.0357e-03, 1.3884e-04, 1.5623e-03, 1.0006e-03, 2.1540e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.3972e-02, 1.0046e-02, 2.0259e-02, 2.0077e-02, 2.9148e-02],\n",
      "        [2.0361e-03, 1.6352e-04, 7.4225e-04, 9.9627e-04, 1.2314e-03],\n",
      "        [2.4060e-02, 1.3652e-02, 2.9408e-02, 3.4494e-02, 2.1168e-02],\n",
      "        [3.4189e-02, 6.1718e-03, 1.1071e-02, 2.4232e-02, 2.5094e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.5072e-03, 6.5414e-04, 4.3332e-03, 2.8264e-03, 4.5174e-03],\n",
      "        [5.8198e-03, 1.1002e-03, 3.5579e-03, 2.9548e-03, 2.2063e-03],\n",
      "        [2.5133e-02, 1.1304e-02, 2.8171e-02, 2.6890e-02, 1.5222e-02],\n",
      "        [7.3960e-03, 2.0403e-04, 3.0462e-04, 4.7470e-04, 7.6338e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.1088e-02, 9.6150e-03, 1.4396e-02, 2.5415e-02, 3.4659e-02],\n",
      "        [2.6766e-04, 7.9001e-06, 5.5813e-05, 1.1352e-04, 2.0717e-04],\n",
      "        [2.4910e-02, 2.9573e-03, 6.9665e-03, 1.3028e-02, 1.3942e-02],\n",
      "        [2.0836e-04, 9.8772e-06, 3.8587e-05, 3.1513e-05, 2.5351e-04],\n",
      "        [1.9205e-02, 6.8189e-03, 1.7726e-02, 1.2186e-02, 2.0262e-02],\n",
      "        [2.8473e-03, 1.5581e-03, 1.9761e-03, 1.9555e-03, 3.1417e-03],\n",
      "        [2.4953e-02, 4.4725e-03, 9.6924e-03, 1.2359e-02, 1.0948e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.2830e-02, 7.6187e-03, 2.4237e-02, 1.8090e-02, 2.7031e-02],\n",
      "        [2.5960e-02, 1.6084e-02, 2.5926e-02, 3.4901e-02, 2.7040e-02],\n",
      "        [1.3517e-03, 1.0971e-04, 2.5544e-04, 2.1244e-04, 1.2164e-03],\n",
      "        [4.2513e-02, 1.3387e-02, 2.8833e-02, 4.3722e-02, 3.9075e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.5142e-02, 1.5834e-02, 4.0402e-02, 3.0712e-02, 2.6537e-02],\n",
      "        [2.2119e-02, 9.5938e-03, 2.4934e-02, 2.3306e-02, 2.2093e-02],\n",
      "        [1.6763e-02, 2.5550e-03, 4.3735e-03, 3.5832e-03, 5.4862e-03],\n",
      "        [1.9837e-02, 4.9900e-03, 1.7709e-02, 1.5710e-02, 1.6158e-02],\n",
      "        [2.8053e-03, 1.3840e-04, 8.0296e-04, 7.4325e-04, 9.1457e-04],\n",
      "        [2.7437e-04, 1.4700e-05, 8.0283e-05, 1.4572e-04, 3.9356e-04],\n",
      "        [1.7629e-02, 1.0133e-02, 1.5048e-02, 1.7589e-02, 2.3337e-02],\n",
      "        [3.4180e-02, 1.8901e-02, 3.2066e-02, 2.9599e-02, 3.4845e-02],\n",
      "        [9.5549e-03, 2.7406e-03, 7.7070e-03, 4.7046e-03, 1.3388e-02],\n",
      "        [1.9492e-02, 4.8756e-03, 8.9840e-03, 1.3996e-02, 1.5504e-02],\n",
      "        [1.3151e-02, 2.1743e-03, 8.3459e-03, 1.3551e-02, 1.3647e-02],\n",
      "        [1.4902e-05, 9.7937e-07, 8.2369e-06, 4.1584e-06, 2.0655e-05],\n",
      "        [1.5018e-02, 7.0486e-03, 1.9181e-02, 2.0167e-02, 1.5032e-02],\n",
      "        [2.1005e-02, 1.2737e-02, 2.6842e-02, 2.5978e-02, 2.4355e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0231e-02, 1.0409e-02, 2.8479e-02, 2.9947e-02, 2.7698e-02],\n",
      "        [2.9204e-02, 4.0480e-03, 1.3032e-02, 2.2268e-02, 2.1477e-02],\n",
      "        [3.0907e-03, 5.6667e-04, 8.4418e-04, 1.8448e-03, 4.0304e-03],\n",
      "        [3.0502e-02, 9.1109e-03, 1.9764e-02, 2.7674e-02, 2.1956e-02],\n",
      "        [2.6160e-02, 9.2415e-03, 2.7466e-02, 2.6966e-02, 2.7915e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0557e-02, 3.6670e-03, 6.9356e-03, 6.7834e-03, 1.4702e-02],\n",
      "        [1.7620e-03, 1.5874e-04, 4.9066e-04, 7.9337e-04, 1.1894e-03],\n",
      "        [6.1150e-03, 5.6536e-04, 2.8671e-03, 3.3463e-03, 1.7560e-03],\n",
      "        [1.2106e-02, 3.4604e-03, 3.4690e-03, 9.4854e-03, 1.3132e-02],\n",
      "        [2.2935e-03, 2.5104e-04, 6.0154e-04, 1.1906e-03, 1.5828e-03],\n",
      "        [1.8872e-02, 5.1284e-03, 1.2593e-02, 1.1738e-02, 1.4960e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.1924e-02, 4.5103e-03, 1.5042e-02, 1.7848e-02, 9.6192e-03],\n",
      "        [1.5592e-02, 6.7033e-03, 1.0555e-02, 1.7435e-02, 2.6734e-02],\n",
      "        [1.1358e-02, 5.7463e-03, 9.5784e-03, 9.0004e-03, 2.2038e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0344e-02, 1.2821e-02, 2.4781e-02, 2.4456e-02, 3.2631e-02],\n",
      "        [2.1331e-02, 5.5075e-03, 1.1870e-02, 1.5724e-02, 2.0858e-02],\n",
      "        [7.7134e-03, 4.0922e-03, 5.0728e-03, 8.9223e-03, 9.8913e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4615e-02, 2.6751e-03, 6.7222e-03, 1.2701e-02, 1.2649e-02],\n",
      "        [1.9968e-02, 6.7633e-03, 1.8786e-02, 2.2251e-02, 3.0390e-02],\n",
      "        [1.9791e-02, 5.6916e-03, 1.7492e-02, 2.0279e-02, 1.5857e-02],\n",
      "        [2.5481e-02, 5.2633e-03, 1.1318e-02, 1.6692e-02, 2.3871e-02],\n",
      "        [1.5748e-02, 6.7783e-03, 1.6557e-02, 1.3530e-02, 2.2847e-02],\n",
      "        [4.7888e-03, 8.3831e-04, 2.0119e-03, 3.2009e-03, 4.3625e-03],\n",
      "        [6.1240e-04, 2.6108e-05, 3.5641e-04, 1.1263e-04, 2.5718e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.5301e-04, 5.0260e-05, 2.2897e-04, 1.3994e-04, 4.1035e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3164e-03, 3.8052e-04, 1.2989e-03, 2.1278e-03, 1.3408e-03],\n",
      "        [1.2490e-02, 8.6207e-04, 3.8889e-03, 2.4755e-03, 3.6620e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.7905e-03, 9.5367e-04, 2.1780e-03, 2.9788e-03, 6.0639e-03],\n",
      "        [7.8238e-04, 3.2292e-05, 1.0562e-04, 1.3666e-04, 2.8334e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.9102e-02, 8.2558e-03, 1.8993e-02, 1.9977e-02, 8.8066e-03],\n",
      "        [1.2063e-02, 1.7873e-03, 3.4397e-03, 7.1859e-03, 7.4597e-03],\n",
      "        [3.0096e-02, 1.2452e-02, 2.3792e-02, 3.0671e-02, 2.1035e-02],\n",
      "        [2.4475e-02, 1.1914e-02, 1.7762e-02, 3.0428e-02, 2.3861e-02],\n",
      "        [4.7611e-03, 2.3202e-04, 1.3272e-03, 1.0809e-03, 1.8593e-03],\n",
      "        [4.4569e-03, 6.7123e-04, 1.3498e-03, 1.7540e-03, 2.9316e-03],\n",
      "        [1.7276e-02, 4.9565e-03, 1.7355e-02, 1.6347e-02, 2.1566e-02],\n",
      "        [1.6321e-02, 9.4954e-03, 2.1854e-02, 2.1040e-02, 1.6539e-02],\n",
      "        [2.0745e-02, 1.1515e-02, 1.6547e-02, 2.5364e-02, 2.2564e-02],\n",
      "        [9.0083e-03, 3.5392e-04, 1.0839e-03, 1.7034e-03, 6.9398e-03],\n",
      "        [1.3211e-03, 6.1745e-05, 2.7091e-04, 4.3888e-04, 7.2022e-04],\n",
      "        [2.1577e-02, 2.4321e-03, 1.3802e-02, 9.1324e-03, 1.5602e-02],\n",
      "        [2.6249e-02, 6.8907e-03, 1.9183e-02, 1.8556e-02, 2.0030e-02],\n",
      "        [5.4913e-02, 1.6038e-02, 2.7490e-02, 4.0428e-02, 3.8447e-02],\n",
      "        [2.6117e-02, 1.0212e-02, 2.6302e-02, 1.6234e-02, 2.3988e-02],\n",
      "        [3.0162e-02, 7.7727e-03, 1.5644e-02, 2.0040e-02, 3.0653e-02],\n",
      "        [3.6242e-02, 1.2845e-02, 2.7476e-02, 3.6343e-02, 3.3502e-02],\n",
      "        [1.4867e-02, 1.7961e-03, 2.5187e-03, 9.7446e-03, 8.8461e-03],\n",
      "        [2.7080e-03, 6.6046e-04, 1.8582e-03, 1.7894e-03, 1.7875e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8132e-03, 1.2676e-03, 6.1515e-03, 5.6528e-03, 8.9692e-03],\n",
      "        [3.3829e-02, 1.3381e-02, 2.6515e-02, 2.7106e-02, 2.1197e-02],\n",
      "        [2.8267e-02, 5.4071e-03, 1.3174e-02, 1.3244e-02, 1.7214e-02],\n",
      "        [2.1142e-02, 9.1663e-03, 2.2955e-02, 2.3061e-02, 3.3148e-02],\n",
      "        [2.9896e-02, 7.8966e-03, 2.3762e-02, 2.1009e-02, 2.3758e-02],\n",
      "        [3.5320e-02, 8.3045e-03, 1.8570e-02, 2.5045e-02, 1.6765e-02],\n",
      "        [2.4038e-02, 1.1001e-02, 1.2277e-02, 1.9103e-02, 2.4406e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7908e-02, 6.3715e-03, 1.6691e-02, 1.9594e-02, 2.1517e-02],\n",
      "        [3.7572e-02, 8.9715e-03, 2.0596e-02, 2.4393e-02, 2.2808e-02],\n",
      "        [2.0493e-02, 6.8091e-03, 1.7644e-02, 1.5137e-02, 3.0381e-02],\n",
      "        [2.8372e-02, 9.6539e-03, 1.4146e-02, 1.9875e-02, 1.8435e-02],\n",
      "        [1.8695e-05, 1.5606e-07, 3.0534e-06, 4.2000e-06, 3.0453e-06],\n",
      "        [4.9320e-03, 1.3500e-03, 1.9516e-03, 3.1398e-03, 3.0482e-03],\n",
      "        [1.9120e-02, 3.4550e-03, 4.4041e-03, 1.1713e-02, 1.2165e-02],\n",
      "        [1.5529e-02, 2.0752e-03, 8.3203e-03, 4.4767e-03, 1.1335e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')], '95%': [tensor([[0.9052, 0.1832, 0.2512],\n",
      "        [0.9977, 0.1340, 0.0357],\n",
      "        [0.8534, 0.3932, 0.2294],\n",
      "        [0.7530, 0.3930, 0.1877],\n",
      "        [0.7462, 0.3871, 0.1482],\n",
      "        [0.8638, 0.2039, 0.2409],\n",
      "        [0.9674, 0.2814, 0.0417],\n",
      "        [0.7508, 0.2641, 0.2342],\n",
      "        [0.9989, 0.0634, 0.0378],\n",
      "        [0.7758, 0.3079, 0.2033],\n",
      "        [0.9621, 0.2558, 0.1578],\n",
      "        [0.9401, 0.3093, 0.5704],\n",
      "        [0.8158, 0.3957, 0.1665],\n",
      "        [0.8536, 0.2263, 0.2141],\n",
      "        [0.6597, 0.4335, 0.1533],\n",
      "        [0.7124, 0.3394, 0.4813],\n",
      "        [0.9944, 0.5029, 0.1011],\n",
      "        [0.9596, 0.2338, 0.0725],\n",
      "        [0.7913, 0.2348, 0.2432],\n",
      "        [0.9761, 0.1918, 0.0218],\n",
      "        [0.9688, 0.4775, 0.0171],\n",
      "        [0.7089, 0.3432, 0.4310],\n",
      "        [0.7716, 0.3845, 0.0862],\n",
      "        [0.8126, 0.7541, 0.1319],\n",
      "        [0.9993, 0.1911, 0.0750],\n",
      "        [0.9093, 0.3948, 0.4528],\n",
      "        [0.9968, 0.2574, 0.7071],\n",
      "        [0.9509, 0.3335, 0.0691],\n",
      "        [0.8671, 0.2100, 0.2127],\n",
      "        [0.8614, 0.2350, 0.2368],\n",
      "        [0.8332, 0.2689, 0.1742],\n",
      "        [0.9301, 0.2745, 0.0869],\n",
      "        [0.7547, 0.2564, 0.3133],\n",
      "        [0.7592, 0.3710, 0.1729],\n",
      "        [0.9353, 0.1308, 0.7988],\n",
      "        [0.9651, 0.3172, 0.1947],\n",
      "        [0.9592, 0.1500, 0.0200],\n",
      "        [0.5845, 0.4085, 0.5936],\n",
      "        [0.9438, 0.5061, 0.0368],\n",
      "        [0.8632, 0.2469, 0.2203],\n",
      "        [0.7149, 0.4984, 0.1445],\n",
      "        [0.9801, 0.4407, 0.1665],\n",
      "        [0.6559, 0.5508, 0.1440],\n",
      "        [0.9949, 0.0864, 0.0898],\n",
      "        [0.8425, 0.2596, 0.1516],\n",
      "        [0.9608, 0.1411, 0.1054],\n",
      "        [0.6956, 0.5641, 0.2872],\n",
      "        [0.9060, 0.2178, 0.1570],\n",
      "        [0.8032, 0.3490, 0.1534],\n",
      "        [0.7410, 0.3083, 0.3585],\n",
      "        [0.9982, 0.1528, 0.0127],\n",
      "        [0.6732, 0.4057, 0.1623],\n",
      "        [0.9762, 0.2144, 0.1039],\n",
      "        [0.7050, 0.3483, 0.2213],\n",
      "        [0.7897, 0.2863, 0.1924],\n",
      "        [0.9347, 0.3582, 0.0859],\n",
      "        [0.8489, 0.3903, 0.1019],\n",
      "        [0.9923, 0.1080, 0.0357],\n",
      "        [0.9953, 0.2836, 0.0239],\n",
      "        [0.8472, 0.3549, 0.0806],\n",
      "        [0.6555, 0.2996, 0.2974],\n",
      "        [0.9324, 0.2091, 0.0459],\n",
      "        [0.7459, 0.4127, 0.1085],\n",
      "        [0.8632, 0.2281, 0.1299],\n",
      "        [0.9988, 0.3281, 0.2314],\n",
      "        [0.8223, 0.2662, 0.1993],\n",
      "        [0.7548, 0.3155, 0.1496],\n",
      "        [0.8888, 0.3284, 0.0516],\n",
      "        [0.8085, 0.2671, 0.1608],\n",
      "        [0.7077, 0.4127, 0.2371],\n",
      "        [0.9178, 0.3150, 0.0322],\n",
      "        [0.7030, 0.5070, 0.1741],\n",
      "        [0.7300, 0.2865, 0.3995],\n",
      "        [0.8259, 0.2419, 0.3171],\n",
      "        [0.8652, 0.3516, 0.2279],\n",
      "        [0.9858, 0.1310, 0.0194],\n",
      "        [0.8006, 0.4477, 0.0951],\n",
      "        [0.8657, 0.4106, 0.0445],\n",
      "        [0.9822, 0.1666, 0.0309],\n",
      "        [0.8375, 0.2025, 0.4865],\n",
      "        [0.8497, 0.2915, 0.1808],\n",
      "        [0.6970, 0.2340, 0.3806],\n",
      "        [0.6478, 0.4173, 0.4393],\n",
      "        [0.8583, 0.3529, 0.0747],\n",
      "        [0.9740, 0.2342, 0.1171],\n",
      "        [0.8373, 0.2459, 0.1510],\n",
      "        [0.9073, 0.3324, 0.0753],\n",
      "        [0.8795, 0.3596, 0.0810],\n",
      "        [0.9449, 0.2759, 0.1680],\n",
      "        [0.7419, 0.2588, 0.5029],\n",
      "        [0.7654, 0.3103, 0.2004],\n",
      "        [0.8991, 0.3046, 0.1550],\n",
      "        [0.6177, 0.5605, 0.0721],\n",
      "        [0.9069, 0.2286, 0.1241],\n",
      "        [0.8606, 0.4632, 0.0789],\n",
      "        [0.9884, 0.2204, 0.0327],\n",
      "        [0.9059, 0.4089, 0.1514],\n",
      "        [0.9796, 0.2950, 0.0300],\n",
      "        [0.9540, 0.1580, 0.1242],\n",
      "        [0.9215, 0.4239, 0.1088],\n",
      "        [0.9648, 0.2335, 0.0718],\n",
      "        [0.9869, 0.1409, 0.0283],\n",
      "        [0.9517, 0.3147, 0.0683],\n",
      "        [0.9610, 0.2143, 0.0300],\n",
      "        [0.6785, 0.2767, 0.5130],\n",
      "        [0.9746, 0.2285, 0.1070],\n",
      "        [0.9695, 0.1779, 0.0578],\n",
      "        [0.9725, 0.0537, 0.0654],\n",
      "        [0.9400, 0.1848, 0.0769],\n",
      "        [0.7615, 0.2772, 0.4849],\n",
      "        [0.8122, 0.3555, 0.2593],\n",
      "        [0.5852, 0.4091, 0.4127],\n",
      "        [0.7745, 0.3285, 0.1552],\n",
      "        [0.9851, 0.1453, 0.3000],\n",
      "        [0.9747, 0.1396, 0.0399],\n",
      "        [0.6336, 0.4138, 0.4298],\n",
      "        [0.8280, 0.2683, 0.1653],\n",
      "        [0.8459, 0.2958, 0.1511],\n",
      "        [0.9654, 0.4029, 0.0274],\n",
      "        [0.9957, 0.2005, 0.0192],\n",
      "        [0.8471, 0.3726, 0.2310],\n",
      "        [0.7895, 0.3031, 0.1847],\n",
      "        [0.7194, 0.3522, 0.1322],\n",
      "        [0.6510, 0.3729, 0.3111],\n",
      "        [0.8271, 0.3890, 0.1193],\n",
      "        [0.7914, 0.2818, 0.2449],\n",
      "        [0.7670, 0.4801, 0.0726],\n",
      "        [0.9845, 0.1914, 0.0890],\n",
      "        [0.9866, 0.1560, 0.0276],\n",
      "        [0.7966, 0.2986, 0.1795],\n",
      "        [0.8952, 0.3049, 0.0792],\n",
      "        [0.7706, 0.3008, 0.1934],\n",
      "        [0.8237, 0.3286, 0.3004],\n",
      "        [0.6283, 0.4104, 0.3414],\n",
      "        [0.7454, 0.4124, 0.1920],\n",
      "        [0.6648, 0.5370, 0.2018],\n",
      "        [0.7735, 0.4161, 0.1241],\n",
      "        [0.9976, 0.0752, 0.0167],\n",
      "        [0.8044, 0.4711, 0.0876],\n",
      "        [0.6971, 0.4305, 0.1444],\n",
      "        [0.8532, 0.2499, 0.0791],\n",
      "        [0.8117, 0.3744, 0.1980],\n",
      "        [0.9984, 0.5178, 0.0505],\n",
      "        [0.9821, 0.2864, 0.0754],\n",
      "        [0.7588, 0.4972, 0.0526],\n",
      "        [0.9517, 0.1685, 0.0700],\n",
      "        [0.9022, 0.2359, 0.1085]], device='cuda:0'), tensor([[0.9406, 0.2045, 0.1311],\n",
      "        [0.9921, 0.1619, 0.4048],\n",
      "        [0.7796, 0.2206, 0.3700],\n",
      "        [0.7128, 0.2813, 0.3807],\n",
      "        [0.6876, 0.2742, 0.3713],\n",
      "        [0.6943, 0.3468, 0.2989],\n",
      "        [0.8791, 0.2956, 0.6262],\n",
      "        [0.6477, 0.3736, 0.2489],\n",
      "        [0.9832, 0.3045, 0.1676],\n",
      "        [0.6954, 0.3717, 0.3010],\n",
      "        [0.9092, 0.2856, 0.3666],\n",
      "        [0.8991, 0.3065, 0.1755],\n",
      "        [0.5564, 0.3444, 0.3627],\n",
      "        [0.6923, 0.3820, 0.2814],\n",
      "        [0.7211, 0.2495, 0.3835],\n",
      "        [0.7481, 0.3135, 0.1434],\n",
      "        [0.9762, 0.2502, 0.4579],\n",
      "        [0.6610, 0.2360, 0.6547],\n",
      "        [0.5895, 0.3855, 0.2968],\n",
      "        [0.8237, 0.1756, 0.9549],\n",
      "        [0.2570, 0.0357, 0.9964],\n",
      "        [0.7505, 0.3135, 0.2503],\n",
      "        [0.6984, 0.3002, 0.3539],\n",
      "        [0.9564, 0.2508, 0.1485],\n",
      "        [0.9850, 0.4060, 0.0999],\n",
      "        [0.9027, 0.2658, 0.2340],\n",
      "        [0.9918, 0.2946, 0.1702],\n",
      "        [0.9417, 0.1892, 0.2269],\n",
      "        [0.6124, 0.3228, 0.4091],\n",
      "        [0.6639, 0.3279, 0.2688],\n",
      "        [0.6341, 0.4594, 0.3011],\n",
      "        [0.5140, 0.2134, 0.9748],\n",
      "        [0.6809, 0.3265, 0.2670],\n",
      "        [0.7084, 0.2588, 0.3509],\n",
      "        [0.7627, 0.2539, 0.2191],\n",
      "        [0.8881, 0.2261, 0.2481],\n",
      "        [0.8032, 0.3277, 0.3186],\n",
      "        [0.6487, 0.2933, 0.2344],\n",
      "        [0.8195, 0.2814, 0.4771],\n",
      "        [0.6113, 0.3982, 0.2808],\n",
      "        [0.7147, 0.3272, 0.3069],\n",
      "        [0.9491, 0.3162, 0.1737],\n",
      "        [0.8500, 0.2657, 0.2061],\n",
      "        [0.9790, 0.2140, 0.0617],\n",
      "        [0.6783, 0.3662, 0.2249],\n",
      "        [0.9183, 0.2318, 0.3294],\n",
      "        [0.7022, 0.2437, 0.3953],\n",
      "        [0.7582, 0.3282, 0.1845],\n",
      "        [0.5890, 0.2770, 0.4252],\n",
      "        [0.6381, 0.3112, 0.3554],\n",
      "        [0.9771, 0.2402, 0.3243],\n",
      "        [0.6342, 0.3183, 0.3161],\n",
      "        [0.9520, 0.0823, 0.2428],\n",
      "        [0.6156, 0.3691, 0.3528],\n",
      "        [0.6515, 0.3699, 0.2901],\n",
      "        [0.7749, 0.2379, 0.4835],\n",
      "        [0.8217, 0.3175, 0.2653],\n",
      "        [0.8586, 0.2189, 0.3386],\n",
      "        [0.9560, 0.1919, 0.1937],\n",
      "        [0.5344, 0.3659, 0.4357],\n",
      "        [0.6080, 0.3673, 0.3295],\n",
      "        [0.6274, 0.2174, 0.8434],\n",
      "        [0.7185, 0.3197, 0.3559],\n",
      "        [0.7070, 0.3164, 0.2971],\n",
      "        [0.9614, 0.3606, 0.2025],\n",
      "        [0.7082, 0.3432, 0.2336],\n",
      "        [0.7033, 0.3587, 0.2329],\n",
      "        [0.5749, 0.2761, 0.6915],\n",
      "        [0.5903, 0.2525, 0.4782],\n",
      "        [0.7713, 0.3250, 0.1857],\n",
      "        [0.4421, 0.1874, 0.9303],\n",
      "        [0.7174, 0.2458, 0.3657],\n",
      "        [0.7015, 0.3382, 0.2103],\n",
      "        [0.7846, 0.2357, 0.3104],\n",
      "        [0.6788, 0.2763, 0.5026],\n",
      "        [0.8857, 0.1758, 0.4642],\n",
      "        [0.8494, 0.3066, 0.2122],\n",
      "        [0.5101, 0.2882, 0.6201],\n",
      "        [0.9373, 0.1522, 0.2899],\n",
      "        [0.7092, 0.3022, 0.3019],\n",
      "        [0.6387, 0.3456, 0.2007],\n",
      "        [0.8496, 0.3373, 0.2362],\n",
      "        [0.6138, 0.2650, 0.3837],\n",
      "        [0.7456, 0.4396, 0.2203],\n",
      "        [0.9740, 0.1726, 0.1015],\n",
      "        [0.6246, 0.3886, 0.2339],\n",
      "        [0.8339, 0.3050, 0.2897],\n",
      "        [0.7033, 0.4878, 0.1836],\n",
      "        [0.7675, 0.4185, 0.1726],\n",
      "        [0.9404, 0.2405, 0.1771],\n",
      "        [0.6198, 0.3770, 0.2748],\n",
      "        [0.6437, 0.3508, 0.2310],\n",
      "        [0.6295, 0.2596, 0.4022],\n",
      "        [0.6684, 0.4041, 0.3049],\n",
      "        [0.8137, 0.2153, 0.3854],\n",
      "        [0.9404, 0.1517, 0.6772],\n",
      "        [0.6293, 0.2709, 0.4633],\n",
      "        [0.8689, 0.1955, 0.6588],\n",
      "        [0.7168, 0.2859, 0.5515],\n",
      "        [0.8838, 0.2158, 0.4594],\n",
      "        [0.8605, 0.2056, 0.2605],\n",
      "        [0.7173, 0.2278, 0.5775],\n",
      "        [0.8231, 0.2254, 0.4677],\n",
      "        [0.9330, 0.2371, 0.3827],\n",
      "        [0.7231, 0.3072, 0.1968],\n",
      "        [0.8915, 0.1942, 0.3972],\n",
      "        [0.6461, 0.2062, 0.6120],\n",
      "        [0.9048, 0.2234, 0.5430],\n",
      "        [0.6750, 0.3615, 0.4039],\n",
      "        [0.7966, 0.3462, 0.2250],\n",
      "        [0.7297, 0.2436, 0.5540],\n",
      "        [0.7385, 0.3674, 0.3159],\n",
      "        [0.5264, 0.3910, 0.3445],\n",
      "        [0.9596, 0.1397, 0.2597],\n",
      "        [0.8440, 0.2034, 0.5595],\n",
      "        [0.8785, 0.2703, 0.2014],\n",
      "        [0.6700, 0.3371, 0.2587],\n",
      "        [0.6143, 0.3308, 0.3404],\n",
      "        [0.8310, 0.3218, 0.4624],\n",
      "        [0.9642, 0.1711, 0.3265],\n",
      "        [0.8693, 0.2290, 0.1614],\n",
      "        [0.8639, 0.2126, 0.4297],\n",
      "        [0.5640, 0.3101, 0.4020],\n",
      "        [0.6713, 0.3694, 0.2284],\n",
      "        [0.6699, 0.2837, 0.3450],\n",
      "        [0.6602, 0.3385, 0.2456],\n",
      "        [0.6784, 0.3091, 0.4928],\n",
      "        [0.9169, 0.3522, 0.2091],\n",
      "        [0.7774, 0.1485, 0.7106],\n",
      "        [0.6867, 0.4171, 0.2394],\n",
      "        [0.8344, 0.2899, 0.2129],\n",
      "        [0.6710, 0.3515, 0.3030],\n",
      "        [0.6987, 0.2357, 0.4934],\n",
      "        [0.6773, 0.2745, 0.3697],\n",
      "        [0.6184, 0.4582, 0.2917],\n",
      "        [0.7888, 0.2277, 0.2723],\n",
      "        [0.5827, 0.2940, 0.3589],\n",
      "        [0.9864, 0.1940, 0.3968],\n",
      "        [0.6373, 0.3004, 0.3724],\n",
      "        [0.6487, 0.2801, 0.3569],\n",
      "        [0.6351, 0.3078, 0.3365],\n",
      "        [0.7108, 0.2632, 0.3619],\n",
      "        [0.9578, 0.2997, 0.3232],\n",
      "        [0.9124, 0.3138, 0.2607],\n",
      "        [0.6187, 0.2571, 0.6525],\n",
      "        [0.7363, 0.1457, 0.5986],\n",
      "        [0.7699, 0.3100, 0.2688]], device='cuda:0'), tensor([[0.5030, 0.5110, 0.1979, 0.1934],\n",
      "        [0.4050, 0.8332, 0.1189, 0.1387],\n",
      "        [0.2910, 0.7214, 0.1844, 0.1974],\n",
      "        [0.3272, 0.5333, 0.2001, 0.2018],\n",
      "        [0.3155, 0.4811, 0.1991, 0.2241],\n",
      "        [0.3852, 0.3608, 0.2511, 0.2478],\n",
      "        [0.3967, 0.7338, 0.1443, 0.1704],\n",
      "        [0.3352, 0.3901, 0.2388, 0.2623],\n",
      "        [0.5729, 0.5299, 0.1655, 0.1539],\n",
      "        [0.4608, 0.4019, 0.2038, 0.1927],\n",
      "        [0.3650, 0.5832, 0.1988, 0.1884],\n",
      "        [0.4043, 0.5625, 0.1885, 0.1922],\n",
      "        [0.3609, 0.4409, 0.2372, 0.2522],\n",
      "        [0.4065, 0.3861, 0.2233, 0.2121],\n",
      "        [0.2739, 0.4769, 0.2056, 0.2307],\n",
      "        [0.4106, 0.3473, 0.2166, 0.2133],\n",
      "        [0.3219, 0.9171, 0.1999, 0.2048],\n",
      "        [0.4070, 0.5621, 0.2059, 0.1841],\n",
      "        [0.3681, 0.4077, 0.2215, 0.2202],\n",
      "        [0.3461, 0.6842, 0.1676, 0.1862],\n",
      "        [0.4930, 0.7728, 0.1411, 0.1264],\n",
      "        [0.3564, 0.4254, 0.2512, 0.2311],\n",
      "        [0.2974, 0.4856, 0.2234, 0.2126],\n",
      "        [0.3030, 0.6944, 0.1896, 0.1781],\n",
      "        [0.8727, 0.6132, 0.1999, 0.2067],\n",
      "        [0.3483, 0.7056, 0.2176, 0.2320],\n",
      "        [0.6300, 0.8048, 0.1801, 0.2245],\n",
      "        [0.5551, 0.6613, 0.1567, 0.1851],\n",
      "        [0.3375, 0.4779, 0.2030, 0.1950],\n",
      "        [0.4226, 0.3672, 0.2351, 0.2365],\n",
      "        [0.3567, 0.4115, 0.2270, 0.2131],\n",
      "        [0.3926, 0.7889, 0.1656, 0.1666],\n",
      "        [0.3603, 0.3896, 0.2413, 0.2382],\n",
      "        [0.3792, 0.4076, 0.2120, 0.2378],\n",
      "        [0.5262, 0.3562, 0.2083, 0.1921],\n",
      "        [0.3997, 0.5724, 0.1686, 0.2165],\n",
      "        [0.3793, 0.6215, 0.1381, 0.1827],\n",
      "        [0.3669, 0.3926, 0.2385, 0.2407],\n",
      "        [0.2890, 0.7900, 0.1590, 0.2169],\n",
      "        [0.4908, 0.3465, 0.1972, 0.2083],\n",
      "        [0.3242, 0.4265, 0.2417, 0.2700],\n",
      "        [0.4992, 0.6507, 0.1523, 0.1625],\n",
      "        [0.3360, 0.5463, 0.2094, 0.2048],\n",
      "        [0.4929, 0.8141, 0.1620, 0.2102],\n",
      "        [0.3685, 0.3556, 0.2267, 0.2434],\n",
      "        [0.3828, 0.6652, 0.2063, 0.2110],\n",
      "        [0.3256, 0.4745, 0.1927, 0.1933],\n",
      "        [0.4285, 0.4168, 0.1972, 0.2410],\n",
      "        [0.3129, 0.4126, 0.2123, 0.2359],\n",
      "        [0.3365, 0.4214, 0.2223, 0.2236],\n",
      "        [0.4681, 0.7045, 0.1690, 0.1554],\n",
      "        [0.2977, 0.4239, 0.2019, 0.2420],\n",
      "        [0.3865, 0.6130, 0.1239, 0.1691],\n",
      "        [0.3194, 0.4196, 0.2469, 0.2275],\n",
      "        [0.3327, 0.3828, 0.2397, 0.2176],\n",
      "        [0.3721, 0.5912, 0.2022, 0.1944],\n",
      "        [0.3303, 0.4890, 0.2220, 0.2288],\n",
      "        [0.4053, 0.6567, 0.1707, 0.1673],\n",
      "        [0.3706, 0.9006, 0.1445, 0.1560],\n",
      "        [0.3219, 0.4347, 0.2017, 0.2337],\n",
      "        [0.3378, 0.3579, 0.2335, 0.2321],\n",
      "        [0.4175, 0.5924, 0.1676, 0.1781],\n",
      "        [0.3071, 0.5664, 0.2158, 0.2060],\n",
      "        [0.3949, 0.4220, 0.2276, 0.2226],\n",
      "        [0.6438, 0.7666, 0.2112, 0.2134],\n",
      "        [0.3541, 0.3984, 0.2483, 0.2597],\n",
      "        [0.3307, 0.4482, 0.2284, 0.2405],\n",
      "        [0.4247, 0.4628, 0.1845, 0.1881],\n",
      "        [0.3623, 0.4613, 0.2032, 0.2042],\n",
      "        [0.3730, 0.4824, 0.1833, 0.2140],\n",
      "        [0.3333, 0.6059, 0.1527, 0.1843],\n",
      "        [0.2889, 0.4970, 0.2216, 0.1959],\n",
      "        [0.3549, 0.3682, 0.2392, 0.2483],\n",
      "        [0.4036, 0.4089, 0.2215, 0.1993],\n",
      "        [0.3259, 0.5669, 0.1812, 0.2024],\n",
      "        [0.4680, 0.5985, 0.1357, 0.1767],\n",
      "        [0.3488, 0.6318, 0.1672, 0.2027],\n",
      "        [0.3465, 0.5593, 0.1600, 0.2274],\n",
      "        [0.4728, 0.6516, 0.1597, 0.1679],\n",
      "        [0.3644, 0.5326, 0.1884, 0.1969],\n",
      "        [0.4485, 0.4198, 0.2130, 0.2248],\n",
      "        [0.3742, 0.4488, 0.2000, 0.2374],\n",
      "        [0.3467, 0.4093, 0.1962, 0.2425],\n",
      "        [0.3491, 0.5251, 0.1983, 0.2009],\n",
      "        [0.5512, 0.5510, 0.1790, 0.1842],\n",
      "        [0.3742, 0.3780, 0.2147, 0.2022],\n",
      "        [0.2997, 0.5401, 0.1985, 0.2312],\n",
      "        [0.4186, 0.4936, 0.1808, 0.2083],\n",
      "        [0.4511, 0.3524, 0.2216, 0.2013],\n",
      "        [0.4269, 0.5043, 0.1928, 0.2330],\n",
      "        [0.3309, 0.4278, 0.2089, 0.2228],\n",
      "        [0.4074, 0.4050, 0.2193, 0.2227],\n",
      "        [0.2902, 0.5255, 0.2127, 0.2388],\n",
      "        [0.3603, 0.4475, 0.1998, 0.2782],\n",
      "        [0.4784, 0.6201, 0.1920, 0.1941],\n",
      "        [0.3642, 0.8081, 0.1569, 0.1514],\n",
      "        [0.3847, 0.5923, 0.1738, 0.1954],\n",
      "        [0.4168, 0.7281, 0.1452, 0.1457],\n",
      "        [0.4455, 0.5337, 0.1693, 0.2087],\n",
      "        [0.3696, 0.7087, 0.1702, 0.1860],\n",
      "        [0.5134, 0.4996, 0.1859, 0.2079],\n",
      "        [0.4610, 0.5082, 0.1733, 0.1693],\n",
      "        [0.4933, 0.5617, 0.2042, 0.2303],\n",
      "        [0.4634, 0.6812, 0.1665, 0.1643],\n",
      "        [0.3778, 0.4017, 0.2153, 0.2408],\n",
      "        [0.4232, 0.6075, 0.1795, 0.1896],\n",
      "        [0.4597, 0.4791, 0.1731, 0.1702],\n",
      "        [0.5349, 0.5735, 0.1542, 0.1653],\n",
      "        [0.4573, 0.4931, 0.1952, 0.2035],\n",
      "        [0.3449, 0.4215, 0.2134, 0.2342],\n",
      "        [0.4409, 0.5741, 0.1576, 0.1896],\n",
      "        [0.3193, 0.4170, 0.2330, 0.2367],\n",
      "        [0.3351, 0.4197, 0.2239, 0.2253],\n",
      "        [0.4040, 0.6167, 0.1758, 0.1951],\n",
      "        [0.4094, 0.5344, 0.1892, 0.2041],\n",
      "        [0.3396, 0.4224, 0.2442, 0.2322],\n",
      "        [0.3816, 0.4123, 0.2470, 0.2393],\n",
      "        [0.4089, 0.4310, 0.2066, 0.2201],\n",
      "        [0.3637, 0.5633, 0.1514, 0.1810],\n",
      "        [0.2832, 0.7610, 0.1609, 0.1600],\n",
      "        [0.3646, 0.4905, 0.2179, 0.2277],\n",
      "        [0.3627, 0.4327, 0.2233, 0.2148],\n",
      "        [0.3372, 0.4254, 0.2259, 0.2164],\n",
      "        [0.3456, 0.3705, 0.2465, 0.2512],\n",
      "        [0.3406, 0.5903, 0.2030, 0.2380],\n",
      "        [0.3393, 0.4262, 0.2139, 0.2343],\n",
      "        [0.2961, 0.6353, 0.1907, 0.2031],\n",
      "        [0.4722, 0.5171, 0.2339, 0.2152],\n",
      "        [0.5671, 0.7184, 0.1484, 0.1566],\n",
      "        [0.3887, 0.3925, 0.2303, 0.2037],\n",
      "        [0.3833, 0.5157, 0.2159, 0.2002],\n",
      "        [0.4024, 0.3269, 0.2344, 0.2436],\n",
      "        [0.3621, 0.5158, 0.1988, 0.1846],\n",
      "        [0.3000, 0.4665, 0.2125, 0.2309],\n",
      "        [0.3406, 0.4429, 0.2240, 0.2304],\n",
      "        [0.3489, 0.4471, 0.1936, 0.2440],\n",
      "        [0.3133, 0.4630, 0.2288, 0.2215],\n",
      "        [0.4556, 0.8029, 0.1377, 0.1557],\n",
      "        [0.3307, 0.5006, 0.2038, 0.2346],\n",
      "        [0.3276, 0.4301, 0.2145, 0.2270],\n",
      "        [0.3228, 0.5125, 0.1882, 0.2036],\n",
      "        [0.3192, 0.4743, 0.2132, 0.2171],\n",
      "        [0.3538, 0.9405, 0.1505, 0.1989],\n",
      "        [0.4147, 0.4978, 0.2069, 0.2022],\n",
      "        [0.3404, 0.5840, 0.2035, 0.2023],\n",
      "        [0.3862, 0.5041, 0.1616, 0.1831],\n",
      "        [0.3975, 0.4524, 0.1831, 0.2211]], device='cuda:0'), tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0375, 0.0035, 0.0134, 0.0106, 0.0169],\n",
      "        [0.0709, 0.0211, 0.0441, 0.0440, 0.0453],\n",
      "        [0.0955, 0.0353, 0.0593, 0.0662, 0.0607],\n",
      "        [0.1035, 0.0659, 0.0782, 0.1076, 0.1171],\n",
      "        [0.0838, 0.0477, 0.0849, 0.1051, 0.1006],\n",
      "        [0.0622, 0.0140, 0.0324, 0.0290, 0.0278],\n",
      "        [0.0893, 0.0667, 0.1113, 0.1211, 0.0827],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0654, 0.0584, 0.0745, 0.0682, 0.0476],\n",
      "        [0.0362, 0.0160, 0.0361, 0.0601, 0.0313],\n",
      "        [0.0710, 0.0562, 0.0807, 0.1027, 0.0890],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1251, 0.0413, 0.0819, 0.0859, 0.0950],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0914, 0.0300, 0.0579, 0.0820, 0.0685],\n",
      "        [0.0579, 0.0215, 0.0316, 0.0292, 0.0558],\n",
      "        [0.0998, 0.0503, 0.0775, 0.0828, 0.0816],\n",
      "        [0.0403, 0.0039, 0.0133, 0.0089, 0.0233],\n",
      "        [0.0121, 0.0005, 0.0023, 0.0056, 0.0033],\n",
      "        [0.1041, 0.0437, 0.1159, 0.0913, 0.0935],\n",
      "        [0.1117, 0.0371, 0.0729, 0.0734, 0.0915],\n",
      "        [0.0275, 0.0106, 0.0200, 0.0317, 0.0289],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0565, 0.0182, 0.0394, 0.0462, 0.0403],\n",
      "        [0.0779, 0.0267, 0.0622, 0.0566, 0.0516],\n",
      "        [0.0606, 0.0135, 0.0315, 0.0429, 0.0411],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0795, 0.0446, 0.0762, 0.0923, 0.0965],\n",
      "        [0.0679, 0.0178, 0.0246, 0.0546, 0.0630],\n",
      "        [0.0789, 0.0331, 0.0626, 0.0896, 0.0794],\n",
      "        [0.1346, 0.0569, 0.0757, 0.1213, 0.0910],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0642, 0.0232, 0.0464, 0.0479, 0.0486],\n",
      "        [0.0467, 0.0078, 0.0187, 0.0233, 0.0304],\n",
      "        [0.0866, 0.0486, 0.0712, 0.0775, 0.0922],\n",
      "        [0.0379, 0.0145, 0.0148, 0.0212, 0.0201],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1101, 0.0422, 0.0694, 0.0742, 0.0966],\n",
      "        [0.0403, 0.0138, 0.0246, 0.0371, 0.0302],\n",
      "        [0.0881, 0.0253, 0.0453, 0.0566, 0.0732],\n",
      "        [0.0236, 0.0019, 0.0125, 0.0085, 0.0148],\n",
      "        [0.0936, 0.0486, 0.0761, 0.0738, 0.0644],\n",
      "        [0.0573, 0.0214, 0.0454, 0.0317, 0.0442],\n",
      "        [0.0793, 0.0200, 0.0535, 0.0476, 0.0528],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1029, 0.0647, 0.0927, 0.0982, 0.1147],\n",
      "        [0.0796, 0.0394, 0.1054, 0.1028, 0.0719],\n",
      "        [0.0256, 0.0027, 0.0105, 0.0066, 0.0181],\n",
      "        [0.1123, 0.0591, 0.0933, 0.1066, 0.1265],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1229, 0.0614, 0.0993, 0.1030, 0.0893],\n",
      "        [0.0731, 0.0548, 0.0881, 0.0851, 0.0947],\n",
      "        [0.0568, 0.0111, 0.0306, 0.0525, 0.0375],\n",
      "        [0.0786, 0.0269, 0.0651, 0.0831, 0.0744],\n",
      "        [0.0309, 0.0085, 0.0249, 0.0136, 0.0378],\n",
      "        [0.0406, 0.0061, 0.0103, 0.0176, 0.0176],\n",
      "        [0.0822, 0.0337, 0.0783, 0.0978, 0.0752],\n",
      "        [0.1098, 0.0648, 0.1052, 0.0984, 0.0944],\n",
      "        [0.0464, 0.0254, 0.0362, 0.0391, 0.0592],\n",
      "        [0.0735, 0.0265, 0.0671, 0.0648, 0.0613],\n",
      "        [0.0531, 0.0345, 0.0548, 0.0598, 0.0576],\n",
      "        [0.0793, 0.0399, 0.0491, 0.0623, 0.0788],\n",
      "        [0.0966, 0.0356, 0.0732, 0.0851, 0.0603],\n",
      "        [0.1283, 0.0444, 0.0957, 0.0835, 0.1019],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0993, 0.0509, 0.0856, 0.0754, 0.0683],\n",
      "        [0.0861, 0.0331, 0.0776, 0.0686, 0.0811],\n",
      "        [0.0380, 0.0070, 0.0135, 0.0196, 0.0312],\n",
      "        [0.0842, 0.0495, 0.0611, 0.0793, 0.0815],\n",
      "        [0.0987, 0.0416, 0.0708, 0.0882, 0.1045],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0552, 0.0295, 0.0387, 0.0461, 0.0557],\n",
      "        [0.0328, 0.0059, 0.0201, 0.0131, 0.0289],\n",
      "        [0.0519, 0.0119, 0.0183, 0.0299, 0.0330],\n",
      "        [0.0514, 0.0186, 0.0270, 0.0345, 0.0390],\n",
      "        [0.0525, 0.0037, 0.0116, 0.0098, 0.0200],\n",
      "        [0.0556, 0.0196, 0.0381, 0.0356, 0.0494],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0680, 0.0244, 0.0521, 0.0513, 0.0644],\n",
      "        [0.0717, 0.0270, 0.0496, 0.0616, 0.0583],\n",
      "        [0.0726, 0.0292, 0.0555, 0.0796, 0.0680],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0614, 0.0426, 0.0662, 0.0757, 0.0767],\n",
      "        [0.0837, 0.0194, 0.0489, 0.0585, 0.0826],\n",
      "        [0.0432, 0.0167, 0.0279, 0.0379, 0.0369],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0883, 0.0306, 0.0567, 0.0716, 0.0743],\n",
      "        [0.0919, 0.0415, 0.0712, 0.0891, 0.0850],\n",
      "        [0.0498, 0.0259, 0.0503, 0.0666, 0.0575],\n",
      "        [0.0824, 0.0234, 0.0644, 0.0799, 0.0782],\n",
      "        [0.0662, 0.0258, 0.0514, 0.0548, 0.0693],\n",
      "        [0.0493, 0.0193, 0.0459, 0.0472, 0.0442],\n",
      "        [0.0103, 0.0012, 0.0035, 0.0050, 0.0048],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0167, 0.0048, 0.0108, 0.0192, 0.0307],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0654, 0.0237, 0.0470, 0.0549, 0.0604],\n",
      "        [0.0791, 0.0201, 0.0372, 0.0279, 0.0349],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0447, 0.0101, 0.0266, 0.0211, 0.0542],\n",
      "        [0.0097, 0.0019, 0.0045, 0.0071, 0.0137],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0832, 0.0400, 0.0826, 0.0917, 0.0894],\n",
      "        [0.0597, 0.0204, 0.0328, 0.0399, 0.0448],\n",
      "        [0.1001, 0.0437, 0.0702, 0.0912, 0.0883],\n",
      "        [0.0837, 0.0389, 0.0866, 0.1099, 0.0799],\n",
      "        [0.0366, 0.0062, 0.0163, 0.0193, 0.0215],\n",
      "        [0.0564, 0.0246, 0.0271, 0.0526, 0.0589],\n",
      "        [0.0825, 0.0367, 0.0773, 0.0858, 0.0608],\n",
      "        [0.0670, 0.0294, 0.0715, 0.0785, 0.0536],\n",
      "        [0.0676, 0.0425, 0.0650, 0.0737, 0.0691],\n",
      "        [0.0296, 0.0056, 0.0115, 0.0190, 0.0308],\n",
      "        [0.0283, 0.0058, 0.0101, 0.0137, 0.0275],\n",
      "        [0.0755, 0.0233, 0.0490, 0.0543, 0.0518],\n",
      "        [0.0771, 0.0278, 0.0731, 0.0793, 0.0999],\n",
      "        [0.1106, 0.0495, 0.0961, 0.0813, 0.0795],\n",
      "        [0.0947, 0.0473, 0.0917, 0.1048, 0.0837],\n",
      "        [0.0873, 0.0348, 0.0500, 0.0962, 0.0705],\n",
      "        [0.0860, 0.0528, 0.0791, 0.1135, 0.0785],\n",
      "        [0.0823, 0.0202, 0.0292, 0.0408, 0.0515],\n",
      "        [0.0439, 0.0203, 0.0410, 0.0559, 0.0419],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0650, 0.0292, 0.0449, 0.0652, 0.0688],\n",
      "        [0.1025, 0.0484, 0.0867, 0.0970, 0.0907],\n",
      "        [0.0832, 0.0283, 0.0481, 0.0714, 0.0762],\n",
      "        [0.0983, 0.0437, 0.0591, 0.0906, 0.0786],\n",
      "        [0.1015, 0.0391, 0.0721, 0.1092, 0.0805],\n",
      "        [0.1040, 0.0320, 0.0643, 0.0964, 0.0684],\n",
      "        [0.1191, 0.0418, 0.0879, 0.1033, 0.0997],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1093, 0.0182, 0.0539, 0.0675, 0.0730],\n",
      "        [0.0948, 0.0606, 0.0643, 0.1035, 0.0971],\n",
      "        [0.0754, 0.0299, 0.0540, 0.0678, 0.0745],\n",
      "        [0.0896, 0.0477, 0.0729, 0.0823, 0.0974],\n",
      "        [0.0397, 0.0113, 0.0343, 0.0518, 0.0534],\n",
      "        [0.0753, 0.0144, 0.0417, 0.0639, 0.0509],\n",
      "        [0.0648, 0.0195, 0.0361, 0.0498, 0.0556],\n",
      "        [0.0502, 0.0110, 0.0337, 0.0263, 0.0442],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')], 'order': ['pd', 'nd', 'mod', 'dlt']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.41793330976788035,\n",
       "  'auc_micro': 0.7947998503554059,\n",
       "  'auc_mean': 0.5737713836763664,\n",
       "  'auc_weighted': 0.6698207964863278},\n",
       " 'nd': {'accuracy': 0.47960618846694797,\n",
       "  'auc_micro': 0.5587706855791962,\n",
       "  'auc_mean': 0.6462857946486413,\n",
       "  'auc_weighted': 0.5455822973985921},\n",
       " 'mod': {'accuracy': 0.47960618846694797,\n",
       "  'auc_micro': 0.5587706855791962,\n",
       "  'auc_mean': 0.6462857946486413,\n",
       "  'auc_weighted': 0.5455822973985921},\n",
       " 'dlts': {'accuracy': [0.9523809523809523,\n",
       "   0.9659863945578231,\n",
       "   0.9659863945578231,\n",
       "   0.9795918367346939,\n",
       "   0.9183673469387755],\n",
       "  'accuracy_mean': 0.9564625850340136,\n",
       "  'auc': [0.6,\n",
       "   0.643661971830986,\n",
       "   0.46197183098591554,\n",
       "   0.7430555555555556,\n",
       "   0.575925925925926],\n",
       "  'auc_mean': 0.6049230568596766}}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel2_balanced = train_state(model_args=t1_args,state=2,lr=.001,weights=[1,1,.1,1],use_smote=False)\n",
    "tmodel2_balanced[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c5caf99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "epoch 0 train loss 3.080742359161377\n",
      "val loss 3.062634229660034\n",
      "______________\n",
      "epoch 1 train loss 3.059621810913086\n",
      "val loss 3.0490384101867676\n",
      "______________\n",
      "epoch 2 train loss 3.0407726764678955\n",
      "val loss 3.0357325077056885\n",
      "______________\n",
      "epoch 3 train loss 3.0215752124786377\n",
      "val loss 3.0225942134857178\n",
      "______________\n",
      "epoch 4 train loss 3.007042646408081\n",
      "val loss 3.0095856189727783\n",
      "______________\n",
      "epoch 5 train loss 2.9928855895996094\n",
      "val loss 2.9967219829559326\n",
      "______________\n",
      "epoch 6 train loss 2.973318576812744\n",
      "val loss 2.983933210372925\n",
      "______________\n",
      "epoch 7 train loss 2.959923505783081\n",
      "val loss 2.9712271690368652\n",
      "______________\n",
      "epoch 8 train loss 2.9284117221832275\n",
      "val loss 2.9585702419281006\n",
      "______________\n",
      "epoch 9 train loss 2.928635358810425\n",
      "val loss 2.945906162261963\n",
      "______________\n",
      "epoch 10 train loss 2.90486741065979\n",
      "val loss 2.9332542419433594\n",
      "______________\n",
      "epoch 11 train loss 2.8958935737609863\n",
      "val loss 2.9205875396728516\n",
      "______________\n",
      "epoch 12 train loss 2.8821587562561035\n",
      "val loss 2.907845973968506\n",
      "______________\n",
      "epoch 13 train loss 2.856055736541748\n",
      "val loss 2.895002841949463\n",
      "______________\n",
      "epoch 14 train loss 2.858839273452759\n",
      "val loss 2.882051467895508\n",
      "______________\n",
      "epoch 15 train loss 2.8338658809661865\n",
      "val loss 2.8689653873443604\n",
      "______________\n",
      "epoch 16 train loss 2.811462640762329\n",
      "val loss 2.8557889461517334\n",
      "______________\n",
      "epoch 17 train loss 2.791501760482788\n",
      "val loss 2.8425135612487793\n",
      "______________\n",
      "epoch 18 train loss 2.776923418045044\n",
      "val loss 2.829068660736084\n",
      "______________\n",
      "epoch 19 train loss 2.759554862976074\n",
      "val loss 2.8154897689819336\n",
      "______________\n",
      "epoch 20 train loss 2.752922773361206\n",
      "val loss 2.8017961978912354\n",
      "______________\n",
      "epoch 21 train loss 2.7362213134765625\n",
      "val loss 2.7880001068115234\n",
      "______________\n",
      "epoch 22 train loss 2.7111380100250244\n",
      "val loss 2.7740652561187744\n",
      "______________\n",
      "epoch 23 train loss 2.690995693206787\n",
      "val loss 2.7600162029266357\n",
      "______________\n",
      "epoch 24 train loss 2.690778970718384\n",
      "val loss 2.745866537094116\n",
      "______________\n",
      "epoch 25 train loss 2.6674599647521973\n",
      "val loss 2.7316861152648926\n",
      "______________\n",
      "epoch 26 train loss 2.640577554702759\n",
      "val loss 2.717491626739502\n",
      "______________\n",
      "epoch 27 train loss 2.628518581390381\n",
      "val loss 2.7032744884490967\n",
      "______________\n",
      "epoch 28 train loss 2.6188583374023438\n",
      "val loss 2.689149856567383\n",
      "______________\n",
      "epoch 29 train loss 2.610483407974243\n",
      "val loss 2.675076723098755\n",
      "______________\n",
      "epoch 30 train loss 2.593459367752075\n",
      "val loss 2.661163091659546\n",
      "______________\n",
      "epoch 31 train loss 2.574779748916626\n",
      "val loss 2.647413492202759\n",
      "______________\n",
      "epoch 32 train loss 2.55672025680542\n",
      "val loss 2.633755683898926\n",
      "______________\n",
      "epoch 33 train loss 2.5187530517578125\n",
      "val loss 2.6202645301818848\n",
      "______________\n",
      "epoch 34 train loss 2.5115602016448975\n",
      "val loss 2.606959581375122\n",
      "______________\n",
      "epoch 35 train loss 2.520688056945801\n",
      "val loss 2.593942642211914\n",
      "______________\n",
      "epoch 36 train loss 2.4944067001342773\n",
      "val loss 2.5811612606048584\n",
      "______________\n",
      "epoch 37 train loss 2.490054130554199\n",
      "val loss 2.568671464920044\n",
      "______________\n",
      "epoch 38 train loss 2.448214530944824\n",
      "val loss 2.556459426879883\n",
      "______________\n",
      "epoch 39 train loss 2.451932430267334\n",
      "val loss 2.544585943222046\n",
      "______________\n",
      "epoch 40 train loss 2.456806182861328\n",
      "val loss 2.5331456661224365\n",
      "______________\n",
      "epoch 41 train loss 2.4417171478271484\n",
      "val loss 2.5221102237701416\n",
      "______________\n",
      "epoch 42 train loss 2.4257805347442627\n",
      "val loss 2.511464834213257\n",
      "______________\n",
      "epoch 43 train loss 2.422300338745117\n",
      "val loss 2.501214027404785\n",
      "______________\n",
      "epoch 44 train loss 2.403536558151245\n",
      "val loss 2.4912984371185303\n",
      "______________\n",
      "epoch 45 train loss 2.403799057006836\n",
      "val loss 2.4818034172058105\n",
      "______________\n",
      "epoch 46 train loss 2.3860485553741455\n",
      "val loss 2.472698211669922\n",
      "______________\n",
      "epoch 47 train loss 2.382662057876587\n",
      "val loss 2.463968276977539\n",
      "______________\n",
      "epoch 48 train loss 2.37371563911438\n",
      "val loss 2.4556398391723633\n",
      "______________\n",
      "epoch 49 train loss 2.3720760345458984\n",
      "val loss 2.4477062225341797\n",
      "______________\n",
      "epoch 50 train loss 2.37802791595459\n",
      "val loss 2.4400947093963623\n",
      "______________\n",
      "epoch 51 train loss 2.3448872566223145\n",
      "val loss 2.432860851287842\n",
      "______________\n",
      "epoch 52 train loss 2.3806920051574707\n",
      "val loss 2.42607045173645\n",
      "______________\n",
      "epoch 53 train loss 2.334782838821411\n",
      "val loss 2.4196341037750244\n",
      "______________\n",
      "epoch 54 train loss 2.3367981910705566\n",
      "val loss 2.413545846939087\n",
      "______________\n",
      "epoch 55 train loss 2.339597702026367\n",
      "val loss 2.4077107906341553\n",
      "______________\n",
      "epoch 56 train loss 2.320903778076172\n",
      "val loss 2.402172565460205\n",
      "______________\n",
      "epoch 57 train loss 2.29960298538208\n",
      "val loss 2.39686918258667\n",
      "______________\n",
      "epoch 58 train loss 2.34356689453125\n",
      "val loss 2.3918449878692627\n",
      "______________\n",
      "epoch 59 train loss 2.323773145675659\n",
      "val loss 2.3871114253997803\n",
      "______________\n",
      "epoch 60 train loss 2.299365282058716\n",
      "val loss 2.3826375007629395\n",
      "______________\n",
      "epoch 61 train loss 2.2827634811401367\n",
      "val loss 2.3784055709838867\n",
      "______________\n",
      "epoch 62 train loss 2.338505506515503\n",
      "val loss 2.3745181560516357\n",
      "______________\n",
      "epoch 63 train loss 2.3045122623443604\n",
      "val loss 2.370818614959717\n",
      "______________\n",
      "epoch 64 train loss 2.311075448989868\n",
      "val loss 2.3672733306884766\n",
      "______________\n",
      "epoch 65 train loss 2.3048336505889893\n",
      "val loss 2.3638675212860107\n",
      "______________\n",
      "epoch 66 train loss 2.2730705738067627\n",
      "val loss 2.360560894012451\n",
      "______________\n",
      "epoch 67 train loss 2.2992143630981445\n",
      "val loss 2.3573989868164062\n",
      "______________\n",
      "epoch 68 train loss 2.285804271697998\n",
      "val loss 2.3543646335601807\n",
      "______________\n",
      "epoch 69 train loss 2.2874388694763184\n",
      "val loss 2.3514418601989746\n",
      "______________\n",
      "epoch 70 train loss 2.277606725692749\n",
      "val loss 2.3487091064453125\n",
      "______________\n",
      "epoch 71 train loss 2.285086154937744\n",
      "val loss 2.3460776805877686\n",
      "______________\n",
      "epoch 72 train loss 2.2786569595336914\n",
      "val loss 2.3435819149017334\n",
      "______________\n",
      "epoch 73 train loss 2.276165723800659\n",
      "val loss 2.3412177562713623\n",
      "______________\n",
      "epoch 74 train loss 2.2714715003967285\n",
      "val loss 2.3389110565185547\n",
      "______________\n",
      "epoch 75 train loss 2.2446842193603516\n",
      "val loss 2.3366172313690186\n",
      "______________\n",
      "epoch 76 train loss 2.2507541179656982\n",
      "val loss 2.334359645843506\n",
      "______________\n",
      "epoch 77 train loss 2.253986120223999\n",
      "val loss 2.332138776779175\n",
      "______________\n",
      "epoch 78 train loss 2.233491897583008\n",
      "val loss 2.3299214839935303\n",
      "______________\n",
      "epoch 79 train loss 2.2659096717834473\n",
      "val loss 2.3276572227478027\n",
      "______________\n",
      "epoch 80 train loss 2.2390897274017334\n",
      "val loss 2.3254473209381104\n",
      "______________\n",
      "epoch 81 train loss 2.285855770111084\n",
      "val loss 2.3233144283294678\n",
      "______________\n",
      "epoch 82 train loss 2.2389538288116455\n",
      "val loss 2.3212804794311523\n",
      "______________\n",
      "epoch 83 train loss 2.254084348678589\n",
      "val loss 2.319308042526245\n",
      "______________\n",
      "epoch 84 train loss 2.2354917526245117\n",
      "val loss 2.3174359798431396\n",
      "______________\n",
      "epoch 85 train loss 2.216179370880127\n",
      "val loss 2.315566062927246\n",
      "______________\n",
      "epoch 86 train loss 2.249286413192749\n",
      "val loss 2.313868522644043\n",
      "______________\n",
      "epoch 87 train loss 2.2430546283721924\n",
      "val loss 2.3122527599334717\n",
      "______________\n",
      "epoch 88 train loss 2.227630615234375\n",
      "val loss 2.3107364177703857\n",
      "______________\n",
      "epoch 89 train loss 2.232016086578369\n",
      "val loss 2.3092257976531982\n",
      "______________\n",
      "epoch 90 train loss 2.243452310562134\n",
      "val loss 2.3077714443206787\n",
      "______________\n",
      "epoch 91 train loss 2.2117693424224854\n",
      "val loss 2.306328773498535\n",
      "______________\n",
      "epoch 92 train loss 2.242072343826294\n",
      "val loss 2.304871082305908\n",
      "______________\n",
      "epoch 93 train loss 2.221526622772217\n",
      "val loss 2.303412675857544\n",
      "______________\n",
      "epoch 94 train loss 2.2332375049591064\n",
      "val loss 2.3020517826080322\n",
      "______________\n",
      "epoch 95 train loss 2.221426248550415\n",
      "val loss 2.3007237911224365\n",
      "______________\n",
      "epoch 96 train loss 2.2289507389068604\n",
      "val loss 2.2994120121002197\n",
      "______________\n",
      "epoch 97 train loss 2.250605583190918\n",
      "val loss 2.2981443405151367\n",
      "______________\n",
      "epoch 98 train loss 2.2303881645202637\n",
      "val loss 2.296921968460083\n",
      "______________\n",
      "epoch 99 train loss 2.220357894897461\n",
      "val loss 2.2956783771514893\n",
      "______________\n",
      "epoch 100 train loss 2.2149622440338135\n",
      "val loss 2.294431447982788\n",
      "______________\n",
      "epoch 101 train loss 2.231201648712158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.293219566345215\n",
      "______________\n",
      "epoch 102 train loss 2.189260959625244\n",
      "val loss 2.2920243740081787\n",
      "______________\n",
      "epoch 103 train loss 2.1899211406707764\n",
      "val loss 2.2908382415771484\n",
      "______________\n",
      "epoch 104 train loss 2.2092297077178955\n",
      "val loss 2.2895472049713135\n",
      "______________\n",
      "epoch 105 train loss 2.2053143978118896\n",
      "val loss 2.28823184967041\n",
      "______________\n",
      "epoch 106 train loss 2.184675455093384\n",
      "val loss 2.2869784832000732\n",
      "______________\n",
      "epoch 107 train loss 2.2011818885803223\n",
      "val loss 2.2856807708740234\n",
      "______________\n",
      "epoch 108 train loss 2.2003800868988037\n",
      "val loss 2.2844505310058594\n",
      "______________\n",
      "epoch 109 train loss 2.1822431087493896\n",
      "val loss 2.283299684524536\n",
      "______________\n",
      "epoch 110 train loss 2.191084861755371\n",
      "val loss 2.282125473022461\n",
      "______________\n",
      "epoch 111 train loss 2.1893560886383057\n",
      "val loss 2.281020164489746\n",
      "______________\n",
      "epoch 112 train loss 2.195972442626953\n",
      "val loss 2.2799110412597656\n",
      "______________\n",
      "epoch 113 train loss 2.184896945953369\n",
      "val loss 2.278775930404663\n",
      "______________\n",
      "epoch 114 train loss 2.2184505462646484\n",
      "val loss 2.2777676582336426\n",
      "______________\n",
      "epoch 115 train loss 2.2017159461975098\n",
      "val loss 2.2768688201904297\n",
      "______________\n",
      "epoch 116 train loss 2.182711124420166\n",
      "val loss 2.2760589122772217\n",
      "______________\n",
      "epoch 117 train loss 2.1766345500946045\n",
      "val loss 2.275282382965088\n",
      "______________\n",
      "epoch 118 train loss 2.200504779815674\n",
      "val loss 2.2745442390441895\n",
      "______________\n",
      "epoch 119 train loss 2.2165141105651855\n",
      "val loss 2.2737815380096436\n",
      "______________\n",
      "epoch 120 train loss 2.1493980884552\n",
      "val loss 2.273048162460327\n",
      "______________\n",
      "epoch 121 train loss 2.1773159503936768\n",
      "val loss 2.272327184677124\n",
      "______________\n",
      "epoch 122 train loss 2.2095117568969727\n",
      "val loss 2.271646022796631\n",
      "______________\n",
      "epoch 123 train loss 2.171005964279175\n",
      "val loss 2.271009683609009\n",
      "______________\n",
      "epoch 124 train loss 2.1654012203216553\n",
      "val loss 2.270423173904419\n",
      "______________\n",
      "epoch 125 train loss 2.1716785430908203\n",
      "val loss 2.269798994064331\n",
      "______________\n",
      "epoch 126 train loss 2.189237117767334\n",
      "val loss 2.2690987586975098\n",
      "______________\n",
      "epoch 127 train loss 2.1497325897216797\n",
      "val loss 2.268367052078247\n",
      "______________\n",
      "epoch 128 train loss 2.2033584117889404\n",
      "val loss 2.2676496505737305\n",
      "______________\n",
      "epoch 129 train loss 2.1657421588897705\n",
      "val loss 2.266899824142456\n",
      "______________\n",
      "epoch 130 train loss 2.148041248321533\n",
      "val loss 2.2660653591156006\n",
      "______________\n",
      "epoch 131 train loss 2.154452323913574\n",
      "val loss 2.2652575969696045\n",
      "______________\n",
      "epoch 132 train loss 2.1611216068267822\n",
      "val loss 2.264394998550415\n",
      "______________\n",
      "epoch 133 train loss 2.14595103263855\n",
      "val loss 2.2634592056274414\n",
      "______________\n",
      "epoch 134 train loss 2.1718125343322754\n",
      "val loss 2.2624661922454834\n",
      "______________\n",
      "epoch 135 train loss 2.172792673110962\n",
      "val loss 2.2616121768951416\n",
      "______________\n",
      "epoch 136 train loss 2.14250111579895\n",
      "val loss 2.2607669830322266\n",
      "______________\n",
      "epoch 137 train loss 2.166231155395508\n",
      "val loss 2.259955406188965\n",
      "______________\n",
      "epoch 138 train loss 2.1559484004974365\n",
      "val loss 2.2591474056243896\n",
      "______________\n",
      "epoch 139 train loss 2.142557382583618\n",
      "val loss 2.258347749710083\n",
      "______________\n",
      "epoch 140 train loss 2.1665492057800293\n",
      "val loss 2.2577037811279297\n",
      "______________\n",
      "epoch 141 train loss 2.1775126457214355\n",
      "val loss 2.2570555210113525\n",
      "______________\n",
      "epoch 142 train loss 2.1696956157684326\n",
      "val loss 2.2564480304718018\n",
      "______________\n",
      "epoch 143 train loss 2.1373202800750732\n",
      "val loss 2.2557778358459473\n",
      "______________\n",
      "epoch 144 train loss 2.166948080062866\n",
      "val loss 2.2551393508911133\n",
      "______________\n",
      "epoch 145 train loss 2.1271069049835205\n",
      "val loss 2.254413604736328\n",
      "______________\n",
      "epoch 146 train loss 2.1653683185577393\n",
      "val loss 2.2537283897399902\n",
      "______________\n",
      "epoch 147 train loss 2.1165006160736084\n",
      "val loss 2.2530908584594727\n",
      "______________\n",
      "epoch 148 train loss 2.124521017074585\n",
      "val loss 2.2524566650390625\n",
      "______________\n",
      "epoch 149 train loss 2.1835663318634033\n",
      "val loss 2.251814603805542\n",
      "______________\n",
      "epoch 150 train loss 2.1509549617767334\n",
      "val loss 2.2511379718780518\n",
      "______________\n",
      "epoch 151 train loss 2.1929147243499756\n",
      "val loss 2.2505483627319336\n",
      "______________\n",
      "epoch 152 train loss 2.132249355316162\n",
      "val loss 2.249941110610962\n",
      "______________\n",
      "epoch 153 train loss 2.165255546569824\n",
      "val loss 2.2493233680725098\n",
      "______________\n",
      "epoch 154 train loss 2.137716770172119\n",
      "val loss 2.2486987113952637\n",
      "______________\n",
      "epoch 155 train loss 2.1607964038848877\n",
      "val loss 2.2479095458984375\n",
      "______________\n",
      "epoch 156 train loss 2.1320650577545166\n",
      "val loss 2.2471325397491455\n",
      "______________\n",
      "epoch 157 train loss 2.1397035121917725\n",
      "val loss 2.2463748455047607\n",
      "______________\n",
      "epoch 158 train loss 2.176279067993164\n",
      "val loss 2.245717763900757\n",
      "______________\n",
      "epoch 159 train loss 2.121192693710327\n",
      "val loss 2.2450244426727295\n",
      "______________\n",
      "epoch 160 train loss 2.158780097961426\n",
      "val loss 2.2442808151245117\n",
      "______________\n",
      "epoch 161 train loss 2.1410584449768066\n",
      "val loss 2.243567705154419\n",
      "______________\n",
      "epoch 162 train loss 2.1326146125793457\n",
      "val loss 2.2430355548858643\n",
      "______________\n",
      "epoch 163 train loss 2.1134068965911865\n",
      "val loss 2.2425379753112793\n",
      "______________\n",
      "epoch 164 train loss 2.1533737182617188\n",
      "val loss 2.241990804672241\n",
      "______________\n",
      "epoch 165 train loss 2.1482162475585938\n",
      "val loss 2.2414677143096924\n",
      "______________\n",
      "epoch 166 train loss 2.1058766841888428\n",
      "val loss 2.2410199642181396\n",
      "______________\n",
      "epoch 167 train loss 2.1220927238464355\n",
      "val loss 2.240795373916626\n",
      "______________\n",
      "epoch 168 train loss 2.1487858295440674\n",
      "val loss 2.2404696941375732\n",
      "______________\n",
      "epoch 169 train loss 2.1001038551330566\n",
      "val loss 2.2400736808776855\n",
      "______________\n",
      "epoch 170 train loss 2.118616819381714\n",
      "val loss 2.239619731903076\n",
      "______________\n",
      "epoch 171 train loss 2.142402172088623\n",
      "val loss 2.2391726970672607\n",
      "______________\n",
      "epoch 172 train loss 2.110596179962158\n",
      "val loss 2.238687753677368\n",
      "______________\n",
      "epoch 173 train loss 2.126084566116333\n",
      "val loss 2.2381324768066406\n",
      "______________\n",
      "epoch 174 train loss 2.115335702896118\n",
      "val loss 2.237567663192749\n",
      "______________\n",
      "epoch 175 train loss 2.146721839904785\n",
      "val loss 2.237030506134033\n",
      "______________\n",
      "epoch 176 train loss 2.128640651702881\n",
      "val loss 2.2364165782928467\n",
      "______________\n",
      "epoch 177 train loss 2.1433629989624023\n",
      "val loss 2.2357566356658936\n",
      "______________\n",
      "epoch 178 train loss 2.107254981994629\n",
      "val loss 2.234973907470703\n",
      "______________\n",
      "epoch 179 train loss 2.1560699939727783\n",
      "val loss 2.234198808670044\n",
      "______________\n",
      "epoch 180 train loss 2.1393229961395264\n",
      "val loss 2.2335994243621826\n",
      "______________\n",
      "epoch 181 train loss 2.1031339168548584\n",
      "val loss 2.233104705810547\n",
      "______________\n",
      "epoch 182 train loss 2.1521382331848145\n",
      "val loss 2.2326183319091797\n",
      "______________\n",
      "epoch 183 train loss 2.0958452224731445\n",
      "val loss 2.232081651687622\n",
      "______________\n",
      "epoch 184 train loss 2.1534342765808105\n",
      "val loss 2.2315070629119873\n",
      "______________\n",
      "epoch 185 train loss 2.1203854084014893\n",
      "val loss 2.231010675430298\n",
      "______________\n",
      "epoch 186 train loss 2.116382598876953\n",
      "val loss 2.230619192123413\n",
      "______________\n",
      "epoch 187 train loss 2.117356061935425\n",
      "val loss 2.2302331924438477\n",
      "______________\n",
      "epoch 188 train loss 2.105715036392212\n",
      "val loss 2.2299094200134277\n",
      "______________\n",
      "epoch 189 train loss 2.1225600242614746\n",
      "val loss 2.2295448780059814\n",
      "______________\n",
      "epoch 190 train loss 2.0958821773529053\n",
      "val loss 2.2292490005493164\n",
      "______________\n",
      "epoch 191 train loss 2.141828775405884\n",
      "val loss 2.2289164066314697\n",
      "______________\n",
      "epoch 192 train loss 2.1454970836639404\n",
      "val loss 2.228665351867676\n",
      "______________\n",
      "epoch 193 train loss 2.1022987365722656\n",
      "val loss 2.228480577468872\n",
      "______________\n",
      "epoch 194 train loss 2.13012957572937\n",
      "val loss 2.2282767295837402\n",
      "______________\n",
      "epoch 195 train loss 2.1069822311401367\n",
      "val loss 2.2281603813171387\n",
      "______________\n",
      "epoch 196 train loss 2.093153715133667\n",
      "val loss 2.2280566692352295\n",
      "______________\n",
      "epoch 197 train loss 2.095127582550049\n",
      "val loss 2.227935791015625\n",
      "______________\n",
      "epoch 198 train loss 2.10237979888916\n",
      "val loss 2.2277748584747314\n",
      "______________\n",
      "epoch 199 train loss 2.1086065769195557\n",
      "val loss 2.2276008129119873\n",
      "______________\n",
      "epoch 200 train loss 2.1148855686187744\n",
      "val loss 2.2273941040039062\n",
      "______________\n",
      "epoch 201 train loss 2.1387417316436768\n",
      "val loss 2.227179527282715\n",
      "______________\n",
      "epoch 202 train loss 2.1314589977264404\n",
      "val loss 2.2269814014434814\n",
      "______________\n",
      "epoch 203 train loss 2.0873193740844727\n",
      "val loss 2.2267191410064697\n",
      "______________\n",
      "epoch 204 train loss 2.1220109462738037\n",
      "val loss 2.226447105407715\n",
      "______________\n",
      "epoch 205 train loss 2.1080307960510254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.2261974811553955\n",
      "______________\n",
      "epoch 206 train loss 2.0954039096832275\n",
      "val loss 2.225830554962158\n",
      "______________\n",
      "epoch 207 train loss 2.0876553058624268\n",
      "val loss 2.225322723388672\n",
      "______________\n",
      "epoch 208 train loss 2.1119985580444336\n",
      "val loss 2.22475528717041\n",
      "______________\n",
      "epoch 209 train loss 2.1173601150512695\n",
      "val loss 2.224304437637329\n",
      "______________\n",
      "epoch 210 train loss 2.103910446166992\n",
      "val loss 2.223879337310791\n",
      "______________\n",
      "epoch 211 train loss 2.1145710945129395\n",
      "val loss 2.2234411239624023\n",
      "______________\n",
      "epoch 212 train loss 2.0841360092163086\n",
      "val loss 2.222980260848999\n",
      "______________\n",
      "epoch 213 train loss 2.1102545261383057\n",
      "val loss 2.22263240814209\n",
      "______________\n",
      "epoch 214 train loss 2.0676887035369873\n",
      "val loss 2.2222442626953125\n",
      "______________\n",
      "epoch 215 train loss 2.089869737625122\n",
      "val loss 2.2219674587249756\n",
      "______________\n",
      "epoch 216 train loss 2.1048479080200195\n",
      "val loss 2.2216296195983887\n",
      "______________\n",
      "epoch 217 train loss 2.097607374191284\n",
      "val loss 2.2212982177734375\n",
      "______________\n",
      "epoch 218 train loss 2.1292712688446045\n",
      "val loss 2.2209115028381348\n",
      "______________\n",
      "epoch 219 train loss 2.0826151371002197\n",
      "val loss 2.2205746173858643\n",
      "______________\n",
      "epoch 220 train loss 2.1062705516815186\n",
      "val loss 2.220189332962036\n",
      "______________\n",
      "epoch 221 train loss 2.1024298667907715\n",
      "val loss 2.2199349403381348\n",
      "______________\n",
      "epoch 222 train loss 2.076153039932251\n",
      "val loss 2.2198052406311035\n",
      "______________\n",
      "epoch 223 train loss 2.075333595275879\n",
      "val loss 2.219649076461792\n",
      "______________\n",
      "epoch 224 train loss 2.1073286533355713\n",
      "val loss 2.219454765319824\n",
      "______________\n",
      "epoch 225 train loss 2.0806307792663574\n",
      "val loss 2.219256639480591\n",
      "______________\n",
      "epoch 226 train loss 2.078967571258545\n",
      "val loss 2.2190356254577637\n",
      "______________\n",
      "epoch 227 train loss 2.1110928058624268\n",
      "val loss 2.218885898590088\n",
      "______________\n",
      "epoch 228 train loss 2.0984482765197754\n",
      "val loss 2.218808174133301\n",
      "______________\n",
      "epoch 229 train loss 2.110593795776367\n",
      "val loss 2.2187063694000244\n",
      "______________\n",
      "epoch 230 train loss 2.0680882930755615\n",
      "val loss 2.2187044620513916\n",
      "______________\n",
      "epoch 231 train loss 2.1012730598449707\n",
      "val loss 2.2187559604644775\n",
      "______________\n",
      "epoch 232 train loss 2.0626754760742188\n",
      "val loss 2.2187530994415283\n",
      "______________\n",
      "epoch 233 train loss 2.083726644515991\n",
      "val loss 2.2187700271606445\n",
      "______________\n",
      "epoch 234 train loss 2.0938563346862793\n",
      "val loss 2.2187836170196533\n",
      "______________\n",
      "epoch 235 train loss 2.1148903369903564\n",
      "val loss 2.2189667224884033\n",
      "______________\n",
      "epoch 236 train loss 2.0955142974853516\n",
      "val loss 2.2190330028533936\n",
      "______________\n",
      "epoch 237 train loss 2.0971226692199707\n",
      "val loss 2.2189908027648926\n",
      "______________\n",
      "epoch 238 train loss 2.079944372177124\n",
      "val loss 2.218998670578003\n",
      "______________\n",
      "epoch 239 train loss 2.086897611618042\n",
      "val loss 2.2189953327178955\n",
      "______________\n",
      "epoch 240 train loss 2.0992767810821533\n",
      "val loss 2.2189881801605225\n",
      "______________\n",
      "epoch 241 train loss 2.09199595451355\n",
      "val loss 2.2189927101135254\n",
      "______________\n",
      "best loss 2.2187044620513916 {'pd': {'accuracy': 0.47523809523809524, 'auc_micro': 0.8189863234111021, 'auc_mean': 0.6351170218637215, 'auc_weighted': 0.715185731430196}, 'nd': {'accuracy': 0.3333333333333333, 'auc_micro': 0.8571198712791633, 'auc_mean': 0.48717421860110544, 'auc_weighted': 0.5525586049170954}, 'mod': {'accuracy': 0.3333333333333333, 'auc_micro': 0.8571198712791633, 'auc_mean': 0.48717421860110544, 'auc_weighted': 0.5525586049170954}, 'dlts': {'accuracy': [0.7857142857142857, 0.8928571428571429, 0.9107142857142857, 0.9464285714285714, 0.8035714285714286], 'accuracy_mean': 0.8678571428571429, 'auc': [0.5643939393939393, 0.42666666666666664, 0.4431372549019608, 0.5723270440251572, 0.6323232323232323], 'auc_mean': 0.5277696274621912}}\n",
      "{'predictions': [tensor([[9.3988e-01, 5.9272e-02, 8.4541e-04],\n",
      "        [6.4758e-01, 3.4076e-01, 1.1656e-02],\n",
      "        [5.9006e-01, 3.8479e-01, 2.5148e-02],\n",
      "        [8.1444e-01, 1.6375e-01, 2.1807e-02],\n",
      "        [7.2435e-01, 2.5914e-01, 1.6511e-02],\n",
      "        [9.3864e-01, 5.2869e-02, 8.4873e-03],\n",
      "        [3.4033e-01, 6.4235e-01, 1.7317e-02],\n",
      "        [5.6175e-01, 4.1420e-01, 2.4043e-02],\n",
      "        [8.8863e-01, 9.6602e-02, 1.4767e-02],\n",
      "        [7.5416e-01, 2.2808e-01, 1.7760e-02],\n",
      "        [7.6681e-01, 2.1596e-01, 1.7237e-02],\n",
      "        [6.4599e-01, 3.3759e-01, 1.6414e-02],\n",
      "        [1.8793e-01, 8.1052e-01, 1.5558e-03],\n",
      "        [8.6762e-02, 9.0837e-01, 4.8715e-03],\n",
      "        [1.4123e-01, 8.5219e-01, 6.5796e-03],\n",
      "        [7.8799e-01, 2.0369e-01, 8.3182e-03],\n",
      "        [3.6580e-01, 6.1280e-01, 2.1395e-02],\n",
      "        [1.2609e-01, 8.5833e-01, 1.5585e-02],\n",
      "        [4.8684e-01, 4.7818e-01, 3.4984e-02],\n",
      "        [5.3761e-01, 4.6074e-01, 1.6541e-03],\n",
      "        [8.2852e-01, 1.5034e-01, 2.1133e-02],\n",
      "        [4.3046e-01, 5.4833e-01, 2.1206e-02],\n",
      "        [1.3801e-01, 8.4911e-01, 1.2882e-02],\n",
      "        [8.3516e-01, 1.4346e-01, 2.1376e-02],\n",
      "        [4.5767e-01, 5.2786e-01, 1.4474e-02],\n",
      "        [8.6534e-03, 9.8927e-01, 2.0789e-03],\n",
      "        [1.1483e-01, 8.7161e-01, 1.3556e-02],\n",
      "        [1.9710e-01, 7.8690e-01, 1.5996e-02],\n",
      "        [4.8118e-01, 4.9578e-01, 2.3046e-02],\n",
      "        [1.1867e-01, 8.7664e-01, 4.6950e-03],\n",
      "        [8.0616e-01, 1.7812e-01, 1.5719e-02],\n",
      "        [6.1122e-02, 9.3578e-01, 3.0944e-03],\n",
      "        [8.9878e-01, 8.4604e-02, 1.6611e-02],\n",
      "        [6.2310e-02, 9.3001e-01, 7.6761e-03],\n",
      "        [3.7231e-01, 6.1035e-01, 1.7339e-02],\n",
      "        [8.2550e-01, 1.6094e-01, 1.3560e-02],\n",
      "        [8.9300e-01, 9.2479e-02, 1.4517e-02],\n",
      "        [7.6269e-02, 9.1899e-01, 4.7406e-03],\n",
      "        [7.4111e-01, 2.3656e-01, 2.2337e-02],\n",
      "        [8.0159e-01, 1.8180e-01, 1.6612e-02],\n",
      "        [6.3892e-01, 3.3980e-01, 2.1284e-02],\n",
      "        [7.0327e-01, 2.8034e-01, 1.6391e-02],\n",
      "        [1.8338e-01, 8.0198e-01, 1.4641e-02],\n",
      "        [4.4252e-01, 5.3518e-01, 2.2294e-02],\n",
      "        [8.2429e-01, 1.5796e-01, 1.7753e-02],\n",
      "        [8.8286e-01, 1.0856e-01, 8.5853e-03],\n",
      "        [1.5911e-01, 8.2600e-01, 1.4889e-02],\n",
      "        [8.5571e-01, 1.2781e-01, 1.6481e-02],\n",
      "        [2.0745e-01, 7.8258e-01, 9.9721e-03],\n",
      "        [6.5036e-01, 3.4194e-01, 7.7028e-03],\n",
      "        [6.1413e-01, 3.6509e-01, 2.0773e-02],\n",
      "        [8.2811e-01, 1.5528e-01, 1.6611e-02],\n",
      "        [7.2675e-01, 2.6516e-01, 8.0871e-03],\n",
      "        [3.9492e-01, 5.8505e-01, 2.0028e-02],\n",
      "        [5.7882e-01, 3.9772e-01, 2.3464e-02],\n",
      "        [6.9767e-01, 2.8013e-01, 2.2202e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[1.1151e-04, 9.9978e-01, 1.0903e-04],\n",
      "        [2.5433e-03, 9.9502e-01, 2.4389e-03],\n",
      "        [6.5673e-03, 9.8702e-01, 6.4152e-03],\n",
      "        [8.6675e-03, 9.8280e-01, 8.5285e-03],\n",
      "        [6.7235e-03, 9.8661e-01, 6.6624e-03],\n",
      "        [4.9388e-03, 9.9029e-01, 4.7715e-03],\n",
      "        [5.4027e-03, 9.8925e-01, 5.3500e-03],\n",
      "        [6.2107e-03, 9.8771e-01, 6.0760e-03],\n",
      "        [1.0244e-02, 9.7982e-01, 9.9368e-03],\n",
      "        [5.4966e-03, 9.8909e-01, 5.4174e-03],\n",
      "        [7.0699e-03, 9.8619e-01, 6.7401e-03],\n",
      "        [6.0258e-03, 9.8817e-01, 5.8081e-03],\n",
      "        [1.0830e-04, 9.9979e-01, 1.0626e-04],\n",
      "        [1.2123e-03, 9.9765e-01, 1.1416e-03],\n",
      "        [1.6311e-03, 9.9673e-01, 1.6343e-03],\n",
      "        [1.9915e-03, 9.9609e-01, 1.9218e-03],\n",
      "        [5.1764e-03, 9.8985e-01, 4.9740e-03],\n",
      "        [1.0717e-02, 9.7905e-01, 1.0234e-02],\n",
      "        [1.3420e-02, 9.7341e-01, 1.3172e-02],\n",
      "        [8.7103e-05, 9.9983e-01, 8.3449e-05],\n",
      "        [1.2985e-02, 9.7424e-01, 1.2776e-02],\n",
      "        [7.3345e-03, 9.8579e-01, 6.8741e-03],\n",
      "        [6.3003e-03, 9.8777e-01, 5.9282e-03],\n",
      "        [7.2159e-03, 9.8576e-01, 7.0250e-03],\n",
      "        [3.3275e-03, 9.9338e-01, 3.2907e-03],\n",
      "        [2.3040e-03, 9.9550e-01, 2.1936e-03],\n",
      "        [8.9800e-03, 9.8257e-01, 8.4549e-03],\n",
      "        [5.6299e-03, 9.8906e-01, 5.3151e-03],\n",
      "        [6.0891e-03, 9.8804e-01, 5.8731e-03],\n",
      "        [1.7970e-03, 9.9649e-01, 1.7161e-03],\n",
      "        [8.5472e-03, 9.8309e-01, 8.3581e-03],\n",
      "        [1.2219e-03, 9.9759e-01, 1.1845e-03],\n",
      "        [9.9881e-03, 9.8023e-01, 9.7783e-03],\n",
      "        [4.2633e-03, 9.9164e-01, 4.0994e-03],\n",
      "        [5.8488e-03, 9.8834e-01, 5.8148e-03],\n",
      "        [7.6076e-03, 9.8459e-01, 7.8018e-03],\n",
      "        [1.0215e-02, 9.7987e-01, 9.9129e-03],\n",
      "        [1.7928e-03, 9.9648e-01, 1.7296e-03],\n",
      "        [8.9380e-03, 9.8218e-01, 8.8850e-03],\n",
      "        [8.0024e-03, 9.8400e-01, 8.0000e-03],\n",
      "        [5.9382e-03, 9.8827e-01, 5.7942e-03],\n",
      "        [3.8827e-03, 9.9224e-01, 3.8765e-03],\n",
      "        [8.1676e-03, 9.8390e-01, 7.9289e-03],\n",
      "        [4.0810e-03, 9.9210e-01, 3.8212e-03],\n",
      "        [8.6672e-03, 9.8289e-01, 8.4445e-03],\n",
      "        [3.3633e-03, 9.9340e-01, 3.2405e-03],\n",
      "        [8.0402e-03, 9.8438e-01, 7.5796e-03],\n",
      "        [9.5480e-03, 9.8112e-01, 9.3355e-03],\n",
      "        [4.5128e-03, 9.9113e-01, 4.3602e-03],\n",
      "        [1.4749e-03, 9.9712e-01, 1.4052e-03],\n",
      "        [7.6930e-03, 9.8492e-01, 7.3898e-03],\n",
      "        [8.0471e-03, 9.8432e-01, 7.6321e-03],\n",
      "        [2.3037e-03, 9.9535e-01, 2.3444e-03],\n",
      "        [5.9526e-03, 9.8841e-01, 5.6376e-03],\n",
      "        [8.0183e-03, 9.8438e-01, 7.5991e-03],\n",
      "        [7.1334e-03, 9.8591e-01, 6.9561e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[9.9883e-01, 2.3301e-04, 2.3272e-04, 2.3307e-04, 2.3129e-04, 2.3530e-04],\n",
      "        [9.7814e-01, 4.3420e-03, 4.3803e-03, 4.4019e-03, 4.2643e-03, 4.4719e-03],\n",
      "        [9.3759e-01, 1.2409e-02, 1.2536e-02, 1.2639e-02, 1.1985e-02, 1.2842e-02],\n",
      "        [9.4360e-01, 1.1293e-02, 1.1311e-02, 1.1474e-02, 1.0724e-02, 1.1595e-02],\n",
      "        [9.4883e-01, 1.0230e-02, 1.0258e-02, 1.0205e-02, 9.8913e-03, 1.0583e-02],\n",
      "        [9.5435e-01, 9.1913e-03, 9.0992e-03, 9.1677e-03, 8.8019e-03, 9.3891e-03],\n",
      "        [9.6046e-01, 7.8499e-03, 7.9178e-03, 7.9521e-03, 7.6500e-03, 8.1684e-03],\n",
      "        [9.5327e-01, 9.4925e-03, 9.3250e-03, 9.4504e-03, 8.9584e-03, 9.5028e-03],\n",
      "        [9.3128e-01, 1.3772e-02, 1.3676e-02, 1.3883e-02, 1.3310e-02, 1.4079e-02],\n",
      "        [9.5234e-01, 9.5362e-03, 9.5669e-03, 9.5649e-03, 9.1424e-03, 9.8521e-03],\n",
      "        [9.5897e-01, 8.2441e-03, 8.1677e-03, 8.2977e-03, 7.9061e-03, 8.4178e-03],\n",
      "        [9.6690e-01, 6.5606e-03, 6.5284e-03, 6.6430e-03, 6.4682e-03, 6.8961e-03],\n",
      "        [9.9873e-01, 2.5239e-04, 2.5315e-04, 2.5436e-04, 2.5086e-04, 2.5569e-04],\n",
      "        [9.8923e-01, 2.1377e-03, 2.1504e-03, 2.1666e-03, 2.1232e-03, 2.1881e-03],\n",
      "        [9.8685e-01, 2.6132e-03, 2.6598e-03, 2.6606e-03, 2.5588e-03, 2.6626e-03],\n",
      "        [9.8119e-01, 3.7761e-03, 3.7667e-03, 3.7555e-03, 3.6593e-03, 3.8491e-03],\n",
      "        [9.4314e-01, 1.1264e-02, 1.1475e-02, 1.1487e-02, 1.0997e-02, 1.1638e-02],\n",
      "        [9.4953e-01, 9.9839e-03, 1.0056e-02, 1.0118e-02, 9.8170e-03, 1.0495e-02],\n",
      "        [9.1415e-01, 1.7195e-02, 1.7066e-02, 1.7690e-02, 1.6244e-02, 1.7660e-02],\n",
      "        [9.9895e-01, 2.0911e-04, 2.0904e-04, 2.0984e-04, 2.0774e-04, 2.1084e-04],\n",
      "        [9.0021e-01, 1.9819e-02, 2.0159e-02, 2.0046e-02, 1.9254e-02, 2.0517e-02],\n",
      "        [9.5732e-01, 8.5097e-03, 8.5049e-03, 8.6490e-03, 8.2225e-03, 8.7980e-03],\n",
      "        [9.6749e-01, 6.4676e-03, 6.4560e-03, 6.5699e-03, 6.3101e-03, 6.7026e-03],\n",
      "        [9.4121e-01, 1.1828e-02, 1.1716e-02, 1.1934e-02, 1.1170e-02, 1.2139e-02],\n",
      "        [9.7111e-01, 5.7010e-03, 5.8347e-03, 5.8158e-03, 5.6395e-03, 5.8955e-03],\n",
      "        [9.8194e-01, 3.5799e-03, 3.6272e-03, 3.6478e-03, 3.5240e-03, 3.6843e-03],\n",
      "        [9.5086e-01, 9.7547e-03, 9.7402e-03, 9.8980e-03, 9.5644e-03, 1.0182e-02],\n",
      "        [9.5240e-01, 9.3729e-03, 9.6354e-03, 9.5542e-03, 9.2524e-03, 9.7888e-03],\n",
      "        [9.4237e-01, 1.1461e-02, 1.1658e-02, 1.1794e-02, 1.1038e-02, 1.1678e-02],\n",
      "        [9.9026e-01, 1.9431e-03, 1.9338e-03, 1.9519e-03, 1.9116e-03, 1.9977e-03],\n",
      "        [9.5944e-01, 8.1055e-03, 8.1429e-03, 8.1706e-03, 7.8448e-03, 8.2991e-03],\n",
      "        [9.9231e-01, 1.5361e-03, 1.5348e-03, 1.5518e-03, 1.5067e-03, 1.5578e-03],\n",
      "        [9.3025e-01, 1.4020e-02, 1.3955e-02, 1.4102e-02, 1.3358e-02, 1.4310e-02],\n",
      "        [9.7277e-01, 5.3696e-03, 5.5001e-03, 5.4810e-03, 5.3091e-03, 5.5680e-03],\n",
      "        [9.5894e-01, 8.0939e-03, 8.2830e-03, 8.2897e-03, 8.0023e-03, 8.3913e-03],\n",
      "        [9.4952e-01, 1.0087e-02, 1.0119e-02, 1.0053e-02, 9.7757e-03, 1.0446e-02],\n",
      "        [9.3127e-01, 1.3764e-02, 1.3683e-02, 1.3880e-02, 1.3307e-02, 1.4095e-02],\n",
      "        [9.9015e-01, 1.9632e-03, 1.9681e-03, 1.9877e-03, 1.9373e-03, 1.9941e-03],\n",
      "        [9.3300e-01, 1.3388e-02, 1.3526e-02, 1.3520e-02, 1.2863e-02, 1.3704e-02],\n",
      "        [9.3770e-01, 1.2463e-02, 1.2508e-02, 1.2396e-02, 1.2016e-02, 1.2917e-02],\n",
      "        [9.4953e-01, 1.0066e-02, 1.0185e-02, 1.0154e-02, 9.7525e-03, 1.0311e-02],\n",
      "        [9.6796e-01, 6.4002e-03, 6.4888e-03, 6.3529e-03, 6.1575e-03, 6.6355e-03],\n",
      "        [9.5942e-01, 8.0564e-03, 8.0268e-03, 8.2260e-03, 7.9063e-03, 8.3642e-03],\n",
      "        [9.5534e-01, 8.8408e-03, 9.0509e-03, 9.0335e-03, 8.6130e-03, 9.1170e-03],\n",
      "        [9.3020e-01, 1.3969e-02, 1.4013e-02, 1.4072e-02, 1.3419e-02, 1.4328e-02],\n",
      "        [9.7044e-01, 5.8814e-03, 5.8984e-03, 5.9413e-03, 5.7333e-03, 6.1056e-03],\n",
      "        [9.6124e-01, 7.7388e-03, 7.6803e-03, 7.8253e-03, 7.5432e-03, 7.9764e-03],\n",
      "        [9.3422e-01, 1.3140e-02, 1.3038e-02, 1.3276e-02, 1.2762e-02, 1.3570e-02],\n",
      "        [9.7335e-01, 5.2764e-03, 5.3075e-03, 5.3882e-03, 5.1549e-03, 5.5205e-03],\n",
      "        [9.9119e-01, 1.7574e-03, 1.7550e-03, 1.7741e-03, 1.7267e-03, 1.8015e-03],\n",
      "        [9.4613e-01, 1.0758e-02, 1.0743e-02, 1.0894e-02, 1.0401e-02, 1.1073e-02],\n",
      "        [9.5129e-01, 9.7757e-03, 9.7059e-03, 9.8493e-03, 9.3622e-03, 1.0021e-02],\n",
      "        [9.8235e-01, 3.5177e-03, 3.5173e-03, 3.5573e-03, 3.4584e-03, 3.6004e-03],\n",
      "        [9.5723e-01, 8.5428e-03, 8.5442e-03, 8.5111e-03, 8.3603e-03, 8.8160e-03],\n",
      "        [9.2001e-01, 1.5787e-02, 1.6277e-02, 1.6194e-02, 1.5432e-02, 1.6305e-02],\n",
      "        [9.4821e-01, 1.0416e-02, 1.0306e-02, 1.0539e-02, 9.8924e-03, 1.0639e-02]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor([[0.0463, 0.0940, 0.1377, 0.1357, 0.2116],\n",
      "        [0.1140, 0.1561, 0.1098, 0.1317, 0.1404],\n",
      "        [0.1588, 0.4216, 0.2290, 0.1181, 0.2170],\n",
      "        [0.2455, 0.1954, 0.1603, 0.1686, 0.1821],\n",
      "        [0.1213, 0.2836, 0.1616, 0.0695, 0.1854],\n",
      "        [0.1332, 0.2268, 0.2493, 0.2141, 0.2351],\n",
      "        [0.1966, 0.2087, 0.2242, 0.0790, 0.1657],\n",
      "        [0.2287, 0.2322, 0.1523, 0.1432, 0.3401],\n",
      "        [0.1422, 0.2440, 0.1819, 0.1612, 0.2445],\n",
      "        [0.1793, 0.3034, 0.1896, 0.1244, 0.1869],\n",
      "        [0.1434, 0.1581, 0.1016, 0.1700, 0.2436],\n",
      "        [0.1772, 0.0757, 0.1176, 0.2178, 0.1752],\n",
      "        [0.1100, 0.0561, 0.3298, 0.0388, 0.1621],\n",
      "        [0.1548, 0.1573, 0.1039, 0.1743, 0.2223],\n",
      "        [0.0883, 0.2208, 0.1871, 0.0369, 0.1061],\n",
      "        [0.1020, 0.2001, 0.1882, 0.1038, 0.2408],\n",
      "        [0.1629, 0.3706, 0.2321, 0.1731, 0.2631],\n",
      "        [0.1825, 0.1479, 0.1144, 0.0993, 0.2193],\n",
      "        [0.2432, 0.2763, 0.1891, 0.1097, 0.2452],\n",
      "        [0.0174, 0.1864, 0.3135, 0.0486, 0.1505],\n",
      "        [0.1912, 0.2875, 0.2059, 0.1242, 0.2270],\n",
      "        [0.1441, 0.1470, 0.1097, 0.1544, 0.2239],\n",
      "        [0.1752, 0.1087, 0.0827, 0.1476, 0.2152],\n",
      "        [0.3326, 0.2299, 0.2021, 0.2025, 0.2120],\n",
      "        [0.1307, 0.1849, 0.1147, 0.0648, 0.1291],\n",
      "        [0.2192, 0.1682, 0.2190, 0.0691, 0.1901],\n",
      "        [0.1934, 0.1268, 0.0989, 0.1105, 0.2468],\n",
      "        [0.1418, 0.2683, 0.2189, 0.1083, 0.2048],\n",
      "        [0.2417, 0.2637, 0.1275, 0.1153, 0.3863],\n",
      "        [0.0930, 0.0742, 0.0816, 0.0815, 0.2295],\n",
      "        [0.1431, 0.1435, 0.1120, 0.1160, 0.1543],\n",
      "        [0.0617, 0.1369, 0.1116, 0.0719, 0.1982],\n",
      "        [0.2539, 0.2554, 0.1712, 0.1655, 0.2130],\n",
      "        [0.1107, 0.2104, 0.2096, 0.0877, 0.1437],\n",
      "        [0.1412, 0.1924, 0.1403, 0.0516, 0.1443],\n",
      "        [0.1255, 0.2276, 0.1799, 0.0634, 0.1085],\n",
      "        [0.1403, 0.2467, 0.1854, 0.1602, 0.2398],\n",
      "        [0.0944, 0.1047, 0.0767, 0.0936, 0.2093],\n",
      "        [0.1447, 0.3214, 0.2380, 0.1082, 0.2080],\n",
      "        [0.1177, 0.3131, 0.1877, 0.0721, 0.1726],\n",
      "        [0.1898, 0.3192, 0.1585, 0.1339, 0.2422],\n",
      "        [0.2699, 0.2408, 0.1612, 0.0628, 0.1158],\n",
      "        [0.1739, 0.1140, 0.1132, 0.1419, 0.2006],\n",
      "        [0.2592, 0.2949, 0.2604, 0.2609, 0.3312],\n",
      "        [0.1528, 0.3012, 0.2070, 0.1152, 0.2242],\n",
      "        [0.1040, 0.1472, 0.1721, 0.1243, 0.2128],\n",
      "        [0.1976, 0.1026, 0.0883, 0.1603, 0.2468],\n",
      "        [0.1722, 0.1959, 0.1058, 0.1870, 0.2794],\n",
      "        [0.1329, 0.1175, 0.1594, 0.0612, 0.1093],\n",
      "        [0.0600, 0.1455, 0.0862, 0.1476, 0.2258],\n",
      "        [0.1388, 0.2012, 0.1516, 0.1321, 0.3269],\n",
      "        [0.1454, 0.1744, 0.1204, 0.1839, 0.2272],\n",
      "        [0.0814, 0.1658, 0.1122, 0.0652, 0.1101],\n",
      "        [0.2688, 0.1595, 0.1366, 0.1368, 0.1762],\n",
      "        [0.1658, 0.3975, 0.2623, 0.1333, 0.2199],\n",
      "        [0.1895, 0.2055, 0.1175, 0.2078, 0.2268]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)], '5%': [tensor([[1.7024e-01, 7.3962e-03, 1.0261e-05],\n",
      "        [3.0573e-01, 1.2811e-01, 1.7560e-03],\n",
      "        [3.0176e-01, 1.0258e-01, 2.3222e-03],\n",
      "        [6.2111e-01, 5.1785e-02, 2.0628e-03],\n",
      "        [5.4236e-01, 1.2204e-01, 2.9000e-03],\n",
      "        [8.1119e-01, 7.6928e-03, 7.6273e-04],\n",
      "        [1.6733e-01, 1.3048e-01, 1.9248e-03],\n",
      "        [3.2199e-01, 7.5653e-02, 3.5231e-03],\n",
      "        [6.0023e-01, 2.8174e-02, 3.4455e-03],\n",
      "        [4.5113e-01, 1.4380e-01, 4.1822e-03],\n",
      "        [4.1396e-01, 1.0087e-01, 3.1185e-03],\n",
      "        [1.6494e-01, 3.8771e-02, 1.4680e-03],\n",
      "        [3.6566e-03, 1.2583e-01, 2.5726e-05],\n",
      "        [2.1996e-03, 7.2265e-01, 6.0026e-05],\n",
      "        [1.6957e-02, 6.0543e-01, 2.4240e-04],\n",
      "        [2.0184e-01, 3.5592e-03, 6.4745e-05],\n",
      "        [1.1863e-01, 3.9690e-01, 1.7695e-03],\n",
      "        [2.5267e-02, 3.0838e-01, 1.1380e-03],\n",
      "        [1.8067e-01, 2.2158e-01, 6.0994e-03],\n",
      "        [1.8398e-02, 3.3560e-02, 6.8735e-06],\n",
      "        [4.5105e-01, 5.0275e-02, 3.2769e-03],\n",
      "        [1.2011e-01, 2.2239e-01, 5.2320e-03],\n",
      "        [4.6658e-02, 3.3195e-01, 2.0829e-03],\n",
      "        [4.7512e-01, 7.5473e-02, 4.0458e-03],\n",
      "        [8.3710e-02, 1.6058e-01, 1.6621e-03],\n",
      "        [3.5141e-04, 8.5824e-01, 3.2575e-05],\n",
      "        [2.3971e-02, 5.2182e-01, 7.3689e-04],\n",
      "        [5.3013e-03, 5.7167e-01, 4.7786e-04],\n",
      "        [3.9966e-01, 1.8403e-01, 3.1424e-03],\n",
      "        [4.2423e-02, 2.9643e-01, 2.2137e-04],\n",
      "        [4.9674e-01, 4.9896e-02, 2.7246e-03],\n",
      "        [2.3566e-03, 5.6956e-01, 1.2418e-04],\n",
      "        [6.6271e-01, 1.3431e-02, 2.2131e-03],\n",
      "        [2.8451e-03, 5.8161e-01, 3.2124e-04],\n",
      "        [6.5550e-02, 1.0447e-01, 1.3053e-03],\n",
      "        [4.6885e-01, 7.9549e-02, 1.8733e-03],\n",
      "        [7.9493e-01, 6.0544e-02, 5.7544e-03],\n",
      "        [9.9612e-03, 3.5833e-01, 2.6065e-04],\n",
      "        [4.7410e-01, 1.1660e-01, 4.7409e-03],\n",
      "        [4.7057e-01, 3.1053e-02, 1.6809e-03],\n",
      "        [2.6572e-01, 3.0955e-01, 4.4443e-03],\n",
      "        [3.8946e-01, 1.4349e-01, 2.4025e-03],\n",
      "        [1.3635e-02, 2.5503e-01, 1.0907e-03],\n",
      "        [1.9322e-01, 2.2063e-01, 2.9031e-03],\n",
      "        [6.7654e-01, 5.2439e-02, 4.2782e-03],\n",
      "        [5.3831e-01, 2.5588e-02, 5.5556e-04],\n",
      "        [3.4906e-02, 4.4672e-01, 1.0450e-03],\n",
      "        [5.9806e-01, 3.7582e-02, 2.6194e-03],\n",
      "        [7.2850e-02, 4.0381e-01, 1.4450e-03],\n",
      "        [2.9562e-02, 6.7187e-03, 1.3683e-04],\n",
      "        [4.2686e-01, 1.2755e-01, 2.0138e-03],\n",
      "        [5.3820e-01, 6.7635e-02, 2.8636e-03],\n",
      "        [3.2204e-01, 1.1572e-01, 4.7509e-04],\n",
      "        [7.5723e-02, 2.1457e-01, 1.9855e-03],\n",
      "        [2.2359e-01, 1.0969e-01, 3.7190e-03],\n",
      "        [4.0051e-01, 4.9754e-02, 2.7651e-03]], device='cuda:0'), tensor([[1.1474e-07, 9.9898e-01, 1.1403e-07],\n",
      "        [9.9448e-05, 9.8952e-01, 9.4457e-05],\n",
      "        [1.5024e-04, 9.9227e-01, 1.5152e-04],\n",
      "        [6.6531e-04, 9.9132e-01, 6.7826e-04],\n",
      "        [7.2348e-04, 9.7900e-01, 7.1294e-04],\n",
      "        [3.3572e-04, 9.8812e-01, 3.2108e-04],\n",
      "        [2.9189e-04, 9.8903e-01, 2.9027e-04],\n",
      "        [4.6583e-04, 9.8394e-01, 4.6738e-04],\n",
      "        [1.5995e-03, 9.6896e-01, 1.6099e-03],\n",
      "        [3.4506e-04, 9.9506e-01, 3.2470e-04],\n",
      "        [4.3829e-04, 9.8769e-01, 4.4431e-04],\n",
      "        [4.0226e-04, 9.9451e-01, 3.8836e-04],\n",
      "        [1.0318e-07, 9.9906e-01, 1.0292e-07],\n",
      "        [1.4462e-05, 9.9683e-01, 1.4384e-05],\n",
      "        [1.6198e-05, 9.9848e-01, 1.6120e-05],\n",
      "        [2.6372e-05, 9.9542e-01, 2.5818e-05],\n",
      "        [1.3922e-04, 9.9178e-01, 1.3775e-04],\n",
      "        [8.5574e-04, 9.8207e-01, 8.9981e-04],\n",
      "        [9.0318e-04, 9.8770e-01, 8.1923e-04],\n",
      "        [1.1979e-07, 9.9960e-01, 1.1871e-07],\n",
      "        [1.0653e-03, 9.7551e-01, 1.0190e-03],\n",
      "        [5.5437e-04, 9.8912e-01, 5.2779e-04],\n",
      "        [6.5685e-04, 9.8982e-01, 6.3754e-04],\n",
      "        [5.3769e-04, 9.8101e-01, 4.8687e-04],\n",
      "        [1.2478e-04, 9.9427e-01, 1.1823e-04],\n",
      "        [2.2774e-05, 9.9367e-01, 2.1288e-05],\n",
      "        [4.3709e-04, 9.8463e-01, 4.3428e-04],\n",
      "        [1.3344e-04, 9.9730e-01, 1.2770e-04],\n",
      "        [6.7957e-04, 9.8220e-01, 6.6740e-04],\n",
      "        [1.7271e-05, 9.9354e-01, 1.7083e-05],\n",
      "        [7.4968e-04, 9.8586e-01, 7.2485e-04],\n",
      "        [1.5897e-05, 9.9695e-01, 1.5448e-05],\n",
      "        [9.4412e-04, 9.7943e-01, 9.4502e-04],\n",
      "        [1.4504e-04, 9.9757e-01, 1.3880e-04],\n",
      "        [3.8994e-04, 9.8246e-01, 3.9056e-04],\n",
      "        [4.4776e-04, 9.8579e-01, 4.4416e-04],\n",
      "        [2.8070e-03, 9.7836e-01, 2.6971e-03],\n",
      "        [6.9729e-05, 9.9468e-01, 6.8099e-05],\n",
      "        [7.1402e-04, 9.6960e-01, 7.0359e-04],\n",
      "        [6.8044e-04, 9.8334e-01, 6.9296e-04],\n",
      "        [3.1593e-04, 9.9246e-01, 3.0084e-04],\n",
      "        [9.2510e-05, 9.9497e-01, 9.3847e-05],\n",
      "        [6.1665e-04, 9.9368e-01, 5.8396e-04],\n",
      "        [1.2409e-04, 9.9448e-01, 1.2014e-04],\n",
      "        [1.5458e-03, 9.7774e-01, 1.4427e-03],\n",
      "        [1.0575e-04, 9.9198e-01, 1.0115e-04],\n",
      "        [4.5055e-04, 9.9109e-01, 4.4917e-04],\n",
      "        [1.0719e-03, 9.8029e-01, 1.0220e-03],\n",
      "        [3.4888e-04, 9.9591e-01, 3.5196e-04],\n",
      "        [4.0554e-05, 9.9551e-01, 3.8985e-05],\n",
      "        [3.9354e-04, 9.9048e-01, 4.0342e-04],\n",
      "        [1.0465e-03, 9.9278e-01, 1.0010e-03],\n",
      "        [4.4867e-05, 9.9061e-01, 4.4635e-05],\n",
      "        [2.1621e-04, 9.8135e-01, 2.1293e-04],\n",
      "        [5.7944e-04, 9.8563e-01, 5.8911e-04],\n",
      "        [9.1054e-04, 9.8707e-01, 8.6468e-04]], device='cuda:0'), tensor([[9.9480e-01, 4.2877e-07, 4.2979e-07, 4.2883e-07, 4.2873e-07, 4.3007e-07],\n",
      "        [9.5222e-01, 3.2808e-04, 3.3340e-04, 3.2641e-04, 3.2349e-04, 3.3340e-04],\n",
      "        [9.5555e-01, 9.6298e-04, 9.8233e-04, 9.6018e-04, 9.4936e-04, 9.6204e-04],\n",
      "        [9.3312e-01, 1.0292e-03, 1.0266e-03, 1.0425e-03, 9.8936e-04, 1.0540e-03],\n",
      "        [9.3439e-01, 1.1026e-03, 1.1338e-03, 1.1171e-03, 1.0894e-03, 1.2142e-03],\n",
      "        [9.3304e-01, 9.4788e-04, 9.3151e-04, 1.0117e-03, 9.2927e-04, 1.0095e-03],\n",
      "        [9.5915e-01, 4.9592e-04, 5.1550e-04, 4.9842e-04, 4.8711e-04, 5.0337e-04],\n",
      "        [9.6622e-01, 5.7876e-04, 5.6455e-04, 5.7623e-04, 5.5314e-04, 5.6596e-04],\n",
      "        [9.2081e-01, 2.6509e-03, 2.6133e-03, 2.6401e-03, 2.5861e-03, 2.6967e-03],\n",
      "        [9.6801e-01, 1.3691e-03, 1.3220e-03, 1.3495e-03, 1.2988e-03, 1.4138e-03],\n",
      "        [9.7495e-01, 7.5963e-04, 7.6639e-04, 7.7823e-04, 7.6252e-04, 7.6960e-04],\n",
      "        [9.8257e-01, 3.2405e-04, 3.2664e-04, 3.3139e-04, 3.2747e-04, 3.3440e-04],\n",
      "        [9.9601e-01, 7.2218e-07, 7.2255e-07, 7.2164e-07, 7.2173e-07, 7.2442e-07],\n",
      "        [9.8348e-01, 2.4787e-05, 2.4812e-05, 2.4865e-05, 2.4859e-05, 2.4864e-05],\n",
      "        [9.9250e-01, 5.5538e-05, 5.5572e-05, 5.5577e-05, 5.5453e-05, 5.5536e-05],\n",
      "        [9.8506e-01, 1.0049e-04, 1.0260e-04, 1.0289e-04, 9.9836e-05, 1.0124e-04],\n",
      "        [9.6394e-01, 4.8315e-04, 4.8882e-04, 4.8465e-04, 4.8171e-04, 4.8962e-04],\n",
      "        [9.5284e-01, 9.8054e-04, 9.6622e-04, 9.8510e-04, 9.8705e-04, 9.6649e-04],\n",
      "        [9.2218e-01, 1.5127e-03, 1.5395e-03, 1.5406e-03, 1.5008e-03, 1.5509e-03],\n",
      "        [9.9842e-01, 4.5408e-07, 4.5517e-07, 4.5440e-07, 4.5406e-07, 4.5531e-07],\n",
      "        [8.9294e-01, 2.8937e-03, 2.7763e-03, 2.6991e-03, 2.8248e-03, 2.8261e-03],\n",
      "        [9.6355e-01, 1.1342e-03, 1.1711e-03, 1.1426e-03, 1.1313e-03, 1.1526e-03],\n",
      "        [9.7004e-01, 4.3246e-04, 4.3032e-04, 4.1997e-04, 4.1382e-04, 4.3117e-04],\n",
      "        [9.2633e-01, 1.1637e-03, 1.1124e-03, 1.0941e-03, 1.1182e-03, 1.1450e-03],\n",
      "        [9.7686e-01, 2.3600e-04, 2.3750e-04, 2.3553e-04, 2.3619e-04, 2.4144e-04],\n",
      "        [9.8229e-01, 1.4804e-04, 1.5023e-04, 1.4771e-04, 1.4617e-04, 1.4804e-04],\n",
      "        [9.6000e-01, 5.4748e-04, 5.4861e-04, 5.4910e-04, 5.4280e-04, 5.5216e-04],\n",
      "        [9.8042e-01, 3.9356e-04, 4.0488e-04, 3.9283e-04, 3.9548e-04, 4.0773e-04],\n",
      "        [9.2171e-01, 8.4647e-04, 8.6162e-04, 8.7568e-04, 8.3812e-04, 8.4916e-04],\n",
      "        [9.7355e-01, 4.8244e-05, 4.8083e-05, 4.8042e-05, 4.7757e-05, 4.9824e-05],\n",
      "        [9.4802e-01, 5.8630e-04, 5.7980e-04, 5.7698e-04, 5.7388e-04, 6.0676e-04],\n",
      "        [9.8700e-01, 1.8362e-05, 1.8401e-05, 1.8444e-05, 1.8301e-05, 1.8428e-05],\n",
      "        [9.3392e-01, 1.7626e-03, 1.7409e-03, 1.8314e-03, 1.6969e-03, 1.7140e-03],\n",
      "        [9.8720e-01, 2.4998e-04, 2.4758e-04, 2.5058e-04, 2.4535e-04, 2.5241e-04],\n",
      "        [9.2863e-01, 4.5171e-04, 4.5222e-04, 4.7311e-04, 4.5034e-04, 4.5745e-04],\n",
      "        [9.5976e-01, 9.5959e-04, 9.9231e-04, 9.6452e-04, 9.5043e-04, 9.6977e-04],\n",
      "        [9.1669e-01, 3.4454e-03, 3.3550e-03, 3.5154e-03, 3.3551e-03, 3.4399e-03],\n",
      "        [9.7655e-01, 8.6256e-05, 8.5474e-05, 8.5088e-05, 8.4557e-05, 8.7517e-05],\n",
      "        [8.8724e-01, 1.4788e-03, 1.4899e-03, 1.5142e-03, 1.4543e-03, 1.5673e-03],\n",
      "        [9.2409e-01, 1.4182e-03, 1.4047e-03, 1.4005e-03, 1.3686e-03, 1.4265e-03],\n",
      "        [9.6293e-01, 7.6117e-04, 7.6161e-04, 7.8741e-04, 7.3965e-04, 7.6358e-04],\n",
      "        [9.7868e-01, 1.6058e-04, 1.6279e-04, 1.6035e-04, 1.5984e-04, 1.6485e-04],\n",
      "        [9.7224e-01, 5.7616e-04, 5.6717e-04, 5.8435e-04, 5.6923e-04, 5.8396e-04],\n",
      "        [9.6412e-01, 3.4950e-04, 3.4229e-04, 3.4516e-04, 3.4041e-04, 3.4957e-04],\n",
      "        [9.0885e-01, 3.0105e-03, 2.7668e-03, 2.8271e-03, 2.6692e-03, 2.8513e-03],\n",
      "        [9.6605e-01, 3.0876e-04, 3.1229e-04, 3.1716e-04, 3.0809e-04, 3.1737e-04],\n",
      "        [9.7332e-01, 5.3635e-04, 5.4227e-04, 5.5021e-04, 5.2651e-04, 6.0058e-04],\n",
      "        [9.2888e-01, 6.8659e-04, 6.8434e-04, 6.7903e-04, 6.7707e-04, 7.0063e-04],\n",
      "        [9.8408e-01, 2.7929e-04, 2.7846e-04, 2.8247e-04, 2.7669e-04, 2.8192e-04],\n",
      "        [9.8380e-01, 7.2928e-05, 7.3158e-05, 7.2857e-05, 7.2875e-05, 7.3936e-05],\n",
      "        [9.5520e-01, 1.1588e-03, 1.1607e-03, 1.1884e-03, 1.1484e-03, 1.1981e-03],\n",
      "        [9.6191e-01, 2.0098e-03, 2.0891e-03, 2.1481e-03, 2.0800e-03, 2.0799e-03],\n",
      "        [9.6424e-01, 8.2923e-05, 8.3426e-05, 8.5219e-05, 8.2968e-05, 8.3712e-05],\n",
      "        [9.4410e-01, 5.2234e-04, 5.2402e-04, 5.1933e-04, 5.1653e-04, 5.2383e-04],\n",
      "        [9.3527e-01, 2.2142e-03, 2.1684e-03, 2.2219e-03, 2.1376e-03, 2.2163e-03],\n",
      "        [9.5739e-01, 1.9576e-03, 1.9160e-03, 1.9865e-03, 1.9042e-03, 2.0110e-03]],\n",
      "       device='cuda:0'), tensor([[0.0054, 0.0158, 0.0126, 0.0136, 0.0339],\n",
      "        [0.0305, 0.0866, 0.0364, 0.0439, 0.0449],\n",
      "        [0.0397, 0.2099, 0.0797, 0.0266, 0.0741],\n",
      "        [0.1075, 0.0682, 0.0714, 0.0600, 0.0878],\n",
      "        [0.0325, 0.1478, 0.0751, 0.0136, 0.0629],\n",
      "        [0.0463, 0.1137, 0.1108, 0.1051, 0.0982],\n",
      "        [0.0691, 0.0830, 0.0811, 0.0203, 0.0606],\n",
      "        [0.0932, 0.1024, 0.0688, 0.0404, 0.1450],\n",
      "        [0.0754, 0.1223, 0.0917, 0.0740, 0.1368],\n",
      "        [0.0697, 0.1259, 0.0915, 0.0373, 0.0780],\n",
      "        [0.0540, 0.0719, 0.0303, 0.0442, 0.0906],\n",
      "        [0.0525, 0.0194, 0.0504, 0.0511, 0.0825],\n",
      "        [0.0047, 0.0047, 0.0426, 0.0028, 0.0254],\n",
      "        [0.0201, 0.0484, 0.0291, 0.0316, 0.0523],\n",
      "        [0.0128, 0.0631, 0.0680, 0.0040, 0.0140],\n",
      "        [0.0204, 0.0399, 0.0386, 0.0272, 0.0798],\n",
      "        [0.0361, 0.1608, 0.0529, 0.0449, 0.1480],\n",
      "        [0.0546, 0.0444, 0.0534, 0.0312, 0.1025],\n",
      "        [0.0977, 0.1373, 0.0807, 0.0423, 0.1311],\n",
      "        [0.0014, 0.0107, 0.0634, 0.0036, 0.0096],\n",
      "        [0.0821, 0.1562, 0.0996, 0.0468, 0.1057],\n",
      "        [0.0767, 0.0899, 0.0475, 0.0726, 0.1237],\n",
      "        [0.0562, 0.0604, 0.0327, 0.0482, 0.1161],\n",
      "        [0.1071, 0.1097, 0.0609, 0.0455, 0.0870],\n",
      "        [0.0314, 0.0635, 0.0512, 0.0131, 0.0319],\n",
      "        [0.0479, 0.0389, 0.0480, 0.0125, 0.0651],\n",
      "        [0.0635, 0.0604, 0.0427, 0.0370, 0.1209],\n",
      "        [0.0244, 0.0963, 0.0591, 0.0277, 0.0613],\n",
      "        [0.1026, 0.1442, 0.0415, 0.0292, 0.1339],\n",
      "        [0.0166, 0.0136, 0.0109, 0.0142, 0.0975],\n",
      "        [0.0417, 0.0654, 0.0566, 0.0499, 0.0908],\n",
      "        [0.0131, 0.0404, 0.0267, 0.0153, 0.0995],\n",
      "        [0.1218, 0.1506, 0.0777, 0.0680, 0.0928],\n",
      "        [0.0250, 0.0790, 0.0733, 0.0221, 0.0545],\n",
      "        [0.0453, 0.1036, 0.0430, 0.0122, 0.1052],\n",
      "        [0.0351, 0.1374, 0.0872, 0.0193, 0.0516],\n",
      "        [0.0643, 0.1472, 0.0979, 0.0516, 0.1256],\n",
      "        [0.0174, 0.0367, 0.0314, 0.0319, 0.0871],\n",
      "        [0.0882, 0.1963, 0.0947, 0.0271, 0.0748],\n",
      "        [0.0439, 0.2004, 0.0620, 0.0150, 0.0825],\n",
      "        [0.0597, 0.1655, 0.0604, 0.0471, 0.0690],\n",
      "        [0.0670, 0.1207, 0.0598, 0.0088, 0.0303],\n",
      "        [0.0563, 0.0370, 0.0264, 0.0463, 0.0497],\n",
      "        [0.0936, 0.0734, 0.0961, 0.0669, 0.1474],\n",
      "        [0.0806, 0.1625, 0.1110, 0.0567, 0.1079],\n",
      "        [0.0337, 0.0399, 0.0404, 0.0338, 0.0851],\n",
      "        [0.0716, 0.0343, 0.0217, 0.0405, 0.1183],\n",
      "        [0.0794, 0.0674, 0.0365, 0.1056, 0.1890],\n",
      "        [0.0438, 0.0441, 0.0621, 0.0158, 0.0370],\n",
      "        [0.0139, 0.0353, 0.0236, 0.0605, 0.0716],\n",
      "        [0.0641, 0.0894, 0.0632, 0.0293, 0.1108],\n",
      "        [0.0613, 0.1139, 0.0447, 0.0519, 0.1373],\n",
      "        [0.0125, 0.0825, 0.0327, 0.0074, 0.0273],\n",
      "        [0.1042, 0.0444, 0.0608, 0.0371, 0.0559],\n",
      "        [0.0706, 0.2175, 0.1123, 0.0405, 0.0994],\n",
      "        [0.1002, 0.0813, 0.0552, 0.0868, 0.0981]], device='cuda:0')], '95%': [tensor([[0.9921, 0.8294, 0.0030],\n",
      "        [0.8685, 0.6910, 0.0161],\n",
      "        [0.8885, 0.6889, 0.0116],\n",
      "        [0.9462, 0.3663, 0.0149],\n",
      "        [0.8713, 0.4440, 0.0170],\n",
      "        [0.9918, 0.1726, 0.0143],\n",
      "        [0.8675, 0.8293, 0.0155],\n",
      "        [0.9140, 0.6745, 0.0250],\n",
      "        [0.9696, 0.3426, 0.0350],\n",
      "        [0.8515, 0.5348, 0.0144],\n",
      "        [0.8909, 0.5788, 0.0110],\n",
      "        [0.9592, 0.8311, 0.0102],\n",
      "        [0.8741, 0.9963, 0.0048],\n",
      "        [0.2728, 0.9976, 0.0047],\n",
      "        [0.3921, 0.9827, 0.0046],\n",
      "        [0.9964, 0.7899, 0.0086],\n",
      "        [0.5987, 0.8750, 0.0103],\n",
      "        [0.6801, 0.9737, 0.0229],\n",
      "        [0.7738, 0.8013, 0.0210],\n",
      "        [0.9664, 0.9815, 0.0013],\n",
      "        [0.9464, 0.5409, 0.0296],\n",
      "        [0.7713, 0.8741, 0.0126],\n",
      "        [0.6551, 0.9512, 0.0136],\n",
      "        [0.9144, 0.4922, 0.0265],\n",
      "        [0.8327, 0.9140, 0.0108],\n",
      "        [0.1326, 0.9996, 0.0087],\n",
      "        [0.4707, 0.9753, 0.0175],\n",
      "        [0.4197, 0.9939, 0.0064],\n",
      "        [0.7963, 0.5957, 0.0257],\n",
      "        [0.7032, 0.9543, 0.0068],\n",
      "        [0.9419, 0.4955, 0.0126],\n",
      "        [0.4293, 0.9975, 0.0065],\n",
      "        [0.9839, 0.3207, 0.0156],\n",
      "        [0.4091, 0.9970, 0.0071],\n",
      "        [0.8888, 0.9329, 0.0218],\n",
      "        [0.9159, 0.5260, 0.0163],\n",
      "        [0.9320, 0.1939, 0.0204],\n",
      "        [0.6306, 0.9899, 0.0132],\n",
      "        [0.8791, 0.5152, 0.0310],\n",
      "        [0.9672, 0.5000, 0.0265],\n",
      "        [0.6820, 0.7192, 0.0151],\n",
      "        [0.8539, 0.5969, 0.0136],\n",
      "        [0.7376, 0.9849, 0.0099],\n",
      "        [0.7753, 0.7979, 0.0162],\n",
      "        [0.9436, 0.3008, 0.0257],\n",
      "        [0.9724, 0.4530, 0.0119],\n",
      "        [0.5491, 0.9640, 0.0118],\n",
      "        [0.9597, 0.3815, 0.0239],\n",
      "        [0.5724, 0.9240, 0.0119],\n",
      "        [0.9931, 0.9687, 0.0057],\n",
      "        [0.8636, 0.5572, 0.0211],\n",
      "        [0.9297, 0.4459, 0.0159],\n",
      "        [0.8832, 0.6774, 0.0130],\n",
      "        [0.7829, 0.9207, 0.0219],\n",
      "        [0.8857, 0.7608, 0.0169],\n",
      "        [0.9418, 0.5930, 0.0223]], device='cuda:0'), tensor([[5.1860e-04, 1.0000e+00, 4.9997e-04],\n",
      "        [5.1390e-03, 9.9981e-01, 5.3459e-03],\n",
      "        [3.9452e-03, 9.9970e-01, 3.7870e-03],\n",
      "        [4.4152e-03, 9.9866e-01, 4.2601e-03],\n",
      "        [1.0141e-02, 9.9855e-01, 1.0862e-02],\n",
      "        [5.7201e-03, 9.9933e-01, 6.1590e-03],\n",
      "        [5.6818e-03, 9.9941e-01, 5.2904e-03],\n",
      "        [8.0692e-03, 9.9907e-01, 7.9866e-03],\n",
      "        [1.5439e-02, 9.9673e-01, 1.5596e-02],\n",
      "        [2.5004e-03, 9.9933e-01, 2.4352e-03],\n",
      "        [6.2544e-03, 9.9912e-01, 6.0536e-03],\n",
      "        [2.7696e-03, 9.9921e-01, 2.7972e-03],\n",
      "        [4.7693e-04, 1.0000e+00, 4.5927e-04],\n",
      "        [1.5865e-03, 9.9997e-01, 1.5805e-03],\n",
      "        [7.5676e-04, 9.9997e-01, 7.5843e-04],\n",
      "        [2.4973e-03, 9.9995e-01, 2.0779e-03],\n",
      "        [4.1418e-03, 9.9972e-01, 4.0745e-03],\n",
      "        [9.1911e-03, 9.9824e-01, 8.7371e-03],\n",
      "        [6.4304e-03, 9.9828e-01, 6.0435e-03],\n",
      "        [2.0816e-04, 1.0000e+00, 1.9619e-04],\n",
      "        [1.2230e-02, 9.9792e-01, 1.2261e-02],\n",
      "        [5.5499e-03, 9.9892e-01, 5.4180e-03],\n",
      "        [5.1838e-03, 9.9870e-01, 4.9924e-03],\n",
      "        [9.8374e-03, 9.9898e-01, 8.9605e-03],\n",
      "        [2.9641e-03, 9.9976e-01, 2.7645e-03],\n",
      "        [3.2922e-03, 9.9996e-01, 3.0367e-03],\n",
      "        [7.7476e-03, 9.9913e-01, 7.6233e-03],\n",
      "        [1.3666e-03, 9.9974e-01, 1.3288e-03],\n",
      "        [8.8639e-03, 9.9865e-01, 8.9395e-03],\n",
      "        [3.3666e-03, 9.9997e-01, 3.1396e-03],\n",
      "        [7.2443e-03, 9.9853e-01, 6.8916e-03],\n",
      "        [1.5204e-03, 9.9997e-01, 1.5296e-03],\n",
      "        [1.0806e-02, 9.9811e-01, 9.7631e-03],\n",
      "        [1.2671e-03, 9.9971e-01, 1.2012e-03],\n",
      "        [8.4848e-03, 9.9921e-01, 9.0585e-03],\n",
      "        [7.1734e-03, 9.9911e-01, 7.0380e-03],\n",
      "        [1.0723e-02, 9.9450e-01, 1.0916e-02],\n",
      "        [2.7190e-03, 9.9986e-01, 2.5761e-03],\n",
      "        [1.5369e-02, 9.9858e-01, 1.5239e-02],\n",
      "        [8.3285e-03, 9.9863e-01, 8.3305e-03],\n",
      "        [3.9150e-03, 9.9938e-01, 3.6228e-03],\n",
      "        [2.4878e-03, 9.9981e-01, 2.5787e-03],\n",
      "        [3.2280e-03, 9.9880e-01, 3.0964e-03],\n",
      "        [2.7397e-03, 9.9976e-01, 2.7782e-03],\n",
      "        [1.1890e-02, 9.9701e-01, 1.0897e-02],\n",
      "        [4.0184e-03, 9.9979e-01, 4.0025e-03],\n",
      "        [4.5310e-03, 9.9910e-01, 4.3796e-03],\n",
      "        [9.9174e-03, 9.9789e-01, 9.7969e-03],\n",
      "        [2.0902e-03, 9.9930e-01, 2.0043e-03],\n",
      "        [2.2611e-03, 9.9992e-01, 2.2253e-03],\n",
      "        [4.8284e-03, 9.9920e-01, 4.6965e-03],\n",
      "        [3.6318e-03, 9.9795e-01, 3.5596e-03],\n",
      "        [4.7671e-03, 9.9991e-01, 4.6241e-03],\n",
      "        [9.1141e-03, 9.9957e-01, 9.5349e-03],\n",
      "        [7.3851e-03, 9.9883e-01, 6.9851e-03],\n",
      "        [6.3852e-03, 9.9822e-01, 6.5493e-03]], device='cuda:0'), tensor([[1.0000e+00, 1.0228e-03, 1.0266e-03, 1.0440e-03, 1.0152e-03, 1.0920e-03],\n",
      "        [9.9836e-01, 9.2062e-03, 9.6224e-03, 9.2523e-03, 9.3048e-03, 1.0398e-02],\n",
      "        [9.9520e-01, 8.9887e-03, 9.0332e-03, 8.7084e-03, 8.6912e-03, 8.9965e-03],\n",
      "        [9.9478e-01, 1.2770e-02, 1.3385e-02, 1.2853e-02, 1.3001e-02, 1.3626e-02],\n",
      "        [9.9434e-01, 1.3917e-02, 1.3251e-02, 1.2755e-02, 1.2847e-02, 1.2822e-02],\n",
      "        [9.9516e-01, 1.3638e-02, 1.3168e-02, 1.3625e-02, 1.2604e-02, 1.3930e-02],\n",
      "        [9.9750e-01, 7.9952e-03, 8.3498e-03, 8.2234e-03, 7.8605e-03, 8.4208e-03],\n",
      "        [9.9716e-01, 6.9891e-03, 6.7119e-03, 6.5058e-03, 6.7761e-03, 6.7970e-03],\n",
      "        [9.8684e-01, 1.5517e-02, 1.5098e-02, 1.5243e-02, 1.5788e-02, 1.7545e-02],\n",
      "        [9.9325e-01, 6.7440e-03, 6.1389e-03, 6.4731e-03, 6.1500e-03, 6.4838e-03],\n",
      "        [9.9616e-01, 5.0337e-03, 4.9071e-03, 5.0357e-03, 4.9097e-03, 5.1682e-03],\n",
      "        [9.9836e-01, 3.4180e-03, 3.4958e-03, 3.5059e-03, 3.3821e-03, 3.6274e-03],\n",
      "        [1.0000e+00, 8.0356e-04, 7.9630e-04, 8.0230e-04, 7.8196e-04, 8.0917e-04],\n",
      "        [9.9988e-01, 3.3748e-03, 3.2573e-03, 3.3407e-03, 3.1816e-03, 3.3204e-03],\n",
      "        [9.9972e-01, 1.4634e-03, 1.4695e-03, 1.4853e-03, 1.4519e-03, 1.6311e-03],\n",
      "        [9.9949e-01, 2.9550e-03, 3.0462e-03, 2.9649e-03, 2.9376e-03, 3.0357e-03],\n",
      "        [9.9757e-01, 7.2916e-03, 7.1210e-03, 7.2909e-03, 6.9062e-03, 7.4459e-03],\n",
      "        [9.9511e-01, 1.0079e-02, 9.0987e-03, 9.5449e-03, 9.0461e-03, 9.3871e-03],\n",
      "        [9.9236e-01, 1.6532e-02, 1.4552e-02, 1.6264e-02, 1.5381e-02, 1.5089e-02],\n",
      "        [1.0000e+00, 3.1328e-04, 3.1604e-04, 3.1860e-04, 3.1177e-04, 3.2503e-04],\n",
      "        [9.8598e-01, 2.2053e-02, 2.1095e-02, 2.0578e-02, 2.0930e-02, 2.2407e-02],\n",
      "        [9.9427e-01, 7.3566e-03, 7.1935e-03, 7.3981e-03, 7.3779e-03, 7.1284e-03],\n",
      "        [9.9787e-01, 5.9347e-03, 5.9875e-03, 5.8618e-03, 5.7689e-03, 6.4026e-03],\n",
      "        [9.9437e-01, 1.4991e-02, 1.4497e-02, 1.4855e-02, 1.4390e-02, 1.4821e-02],\n",
      "        [9.9881e-01, 4.6162e-03, 4.6257e-03, 4.6442e-03, 4.4635e-03, 4.7799e-03],\n",
      "        [9.9926e-01, 3.5763e-03, 3.4898e-03, 3.6794e-03, 3.4180e-03, 3.5475e-03],\n",
      "        [9.9726e-01, 7.9499e-03, 8.0079e-03, 8.2898e-03, 8.0206e-03, 8.1024e-03],\n",
      "        [9.9801e-01, 3.8081e-03, 3.9544e-03, 4.0076e-03, 3.8030e-03, 4.0090e-03],\n",
      "        [9.9573e-01, 1.5374e-02, 1.4942e-02, 1.6848e-02, 1.5013e-02, 1.6111e-02],\n",
      "        [9.9976e-01, 5.2705e-03, 5.1349e-03, 5.3688e-03, 5.1396e-03, 5.5353e-03],\n",
      "        [9.9708e-01, 1.0092e-02, 1.0793e-02, 1.0486e-02, 1.0249e-02, 1.0357e-02],\n",
      "        [9.9991e-01, 2.6095e-03, 2.5378e-03, 2.6506e-03, 2.5155e-03, 2.6899e-03],\n",
      "        [9.9125e-01, 1.3545e-02, 1.2964e-02, 1.3596e-02, 1.2411e-02, 1.3565e-02],\n",
      "        [9.9875e-01, 2.5145e-03, 2.6000e-03, 2.5856e-03, 2.5348e-03, 2.6224e-03],\n",
      "        [9.9772e-01, 1.3961e-02, 1.4909e-02, 1.3969e-02, 1.3546e-02, 1.5228e-02],\n",
      "        [9.9515e-01, 8.1449e-03, 7.8741e-03, 8.0770e-03, 7.7659e-03, 8.3839e-03],\n",
      "        [9.8289e-01, 1.6451e-02, 1.6518e-02, 1.7392e-02, 1.6376e-02, 1.6466e-02],\n",
      "        [9.9957e-01, 4.6277e-03, 4.5936e-03, 4.5101e-03, 4.5503e-03, 4.8411e-03],\n",
      "        [9.9250e-01, 2.4170e-02, 2.1730e-02, 2.2724e-02, 2.2397e-02, 2.1740e-02],\n",
      "        [9.9298e-01, 1.4965e-02, 1.5202e-02, 1.5474e-02, 1.4608e-02, 1.5654e-02],\n",
      "        [9.9619e-01, 7.3836e-03, 7.3080e-03, 7.6552e-03, 7.1354e-03, 7.5896e-03],\n",
      "        [9.9919e-01, 4.2229e-03, 4.1948e-03, 4.1666e-03, 4.2274e-03, 4.5693e-03],\n",
      "        [9.9712e-01, 5.4507e-03, 5.4662e-03, 5.8617e-03, 5.2315e-03, 5.7451e-03],\n",
      "        [9.9827e-01, 6.9708e-03, 7.0626e-03, 7.3256e-03, 6.9707e-03, 7.3308e-03],\n",
      "        [9.8583e-01, 1.8871e-02, 1.7783e-02, 1.8001e-02, 1.7055e-02, 1.9166e-02],\n",
      "        [9.9844e-01, 6.7715e-03, 6.6731e-03, 6.8985e-03, 6.5753e-03, 7.0319e-03],\n",
      "        [9.9724e-01, 5.3164e-03, 5.3245e-03, 5.3328e-03, 5.3117e-03, 5.3985e-03],\n",
      "        [9.9657e-01, 1.4232e-02, 1.3745e-02, 1.4578e-02, 1.3935e-02, 1.4631e-02],\n",
      "        [9.9860e-01, 3.1726e-03, 3.1664e-03, 3.1064e-03, 3.0542e-03, 3.3417e-03],\n",
      "        [9.9963e-01, 3.4318e-03, 3.1380e-03, 3.3071e-03, 3.2024e-03, 3.1243e-03],\n",
      "        [9.9415e-01, 8.6525e-03, 9.0897e-03, 8.6981e-03, 8.5820e-03, 9.7740e-03],\n",
      "        [9.8966e-01, 7.4514e-03, 7.7641e-03, 7.5526e-03, 7.4798e-03, 7.9896e-03],\n",
      "        [9.9958e-01, 7.0353e-03, 7.0601e-03, 6.9584e-03, 7.4758e-03, 7.2328e-03],\n",
      "        [9.9739e-01, 1.1302e-02, 1.0631e-02, 1.2371e-02, 1.0571e-02, 1.1030e-02],\n",
      "        [9.8897e-01, 1.3414e-02, 1.2399e-02, 1.2927e-02, 1.2529e-02, 1.3460e-02],\n",
      "        [9.9022e-01, 8.4010e-03, 8.4412e-03, 9.6345e-03, 7.9293e-03, 8.5194e-03]],\n",
      "       device='cuda:0'), tensor([[0.1164, 0.1549, 0.2315, 0.1943, 0.3410],\n",
      "        [0.1408, 0.2927, 0.1875, 0.1597, 0.1835],\n",
      "        [0.1679, 0.4958, 0.2357, 0.1378, 0.2944],\n",
      "        [0.2456, 0.2030, 0.2033, 0.3000, 0.2271],\n",
      "        [0.1485, 0.3453, 0.2442, 0.1343, 0.2633],\n",
      "        [0.1921, 0.3659, 0.3736, 0.3360, 0.2584],\n",
      "        [0.2040, 0.2419, 0.2993, 0.1246, 0.2353],\n",
      "        [0.3094, 0.3194, 0.1836, 0.2301, 0.4058],\n",
      "        [0.2066, 0.2393, 0.2175, 0.2343, 0.3005],\n",
      "        [0.1812, 0.3804, 0.2444, 0.2365, 0.2878],\n",
      "        [0.1260, 0.2054, 0.2120, 0.1850, 0.2412],\n",
      "        [0.1993, 0.1036, 0.1383, 0.3105, 0.1871],\n",
      "        [0.3252, 0.1105, 0.5281, 0.1279, 0.2794],\n",
      "        [0.1690, 0.2204, 0.1640, 0.3347, 0.2581],\n",
      "        [0.1145, 0.2423, 0.2619, 0.0265, 0.1325],\n",
      "        [0.0922, 0.2892, 0.2505, 0.1100, 0.2835],\n",
      "        [0.1983, 0.3708, 0.2117, 0.2418, 0.3544],\n",
      "        [0.2036, 0.2040, 0.1184, 0.1350, 0.2636],\n",
      "        [0.2224, 0.3582, 0.2044, 0.1383, 0.2684],\n",
      "        [0.0506, 0.2324, 0.4769, 0.0902, 0.2026],\n",
      "        [0.1921, 0.3368, 0.3578, 0.1782, 0.2399],\n",
      "        [0.1736, 0.1592, 0.1314, 0.2253, 0.2967],\n",
      "        [0.1794, 0.2091, 0.1143, 0.2712, 0.2866],\n",
      "        [0.3800, 0.3184, 0.2760, 0.2178, 0.1880],\n",
      "        [0.1155, 0.2427, 0.1856, 0.0913, 0.1541],\n",
      "        [0.2603, 0.1771, 0.2071, 0.0700, 0.2026],\n",
      "        [0.2064, 0.2116, 0.1289, 0.1071, 0.2447],\n",
      "        [0.1441, 0.2726, 0.2538, 0.1289, 0.2248],\n",
      "        [0.2453, 0.2704, 0.1415, 0.1346, 0.4124],\n",
      "        [0.1681, 0.1607, 0.0919, 0.1414, 0.3283],\n",
      "        [0.1679, 0.2364, 0.1736, 0.1536, 0.2128],\n",
      "        [0.1161, 0.2175, 0.1656, 0.0833, 0.2134],\n",
      "        [0.2741, 0.3145, 0.1487, 0.1985, 0.2414],\n",
      "        [0.1242, 0.2317, 0.1829, 0.1488, 0.1821],\n",
      "        [0.1637, 0.2641, 0.1948, 0.0965, 0.1996],\n",
      "        [0.1729, 0.2772, 0.2469, 0.0910, 0.1327],\n",
      "        [0.2067, 0.3243, 0.2122, 0.2268, 0.3483],\n",
      "        [0.1236, 0.2010, 0.1196, 0.1840, 0.3660],\n",
      "        [0.1688, 0.3553, 0.2788, 0.1704, 0.2308],\n",
      "        [0.2241, 0.3944, 0.2206, 0.0986, 0.2109],\n",
      "        [0.1915, 0.3761, 0.1982, 0.1677, 0.2353],\n",
      "        [0.3421, 0.3270, 0.2047, 0.0888, 0.1638],\n",
      "        [0.2223, 0.1493, 0.1500, 0.1701, 0.2661],\n",
      "        [0.3001, 0.4125, 0.3220, 0.2326, 0.3950],\n",
      "        [0.1767, 0.2923, 0.2547, 0.1960, 0.2642],\n",
      "        [0.1647, 0.2188, 0.2253, 0.2438, 0.2631],\n",
      "        [0.2075, 0.1697, 0.0851, 0.2155, 0.3057],\n",
      "        [0.2409, 0.2584, 0.1461, 0.2962, 0.3590],\n",
      "        [0.1278, 0.1477, 0.2185, 0.0671, 0.1432],\n",
      "        [0.0923, 0.2332, 0.1311, 0.2015, 0.2646],\n",
      "        [0.1584, 0.2415, 0.2062, 0.1972, 0.4292],\n",
      "        [0.1682, 0.2617, 0.1508, 0.2082, 0.3509],\n",
      "        [0.1599, 0.1987, 0.1528, 0.1490, 0.1960],\n",
      "        [0.3136, 0.2283, 0.1788, 0.1700, 0.2790],\n",
      "        [0.2108, 0.4178, 0.2793, 0.1867, 0.2727],\n",
      "        [0.2583, 0.2787, 0.1524, 0.2550, 0.2654]], device='cuda:0')], 'order': ['pd', 'nd', 'mod', 'dlt']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2187044620513916"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel1 = train_state(model_args=t1_args,state=1,lr=.0001,weights=[1,1,.1,1],balanced=False)\n",
    "tmodel1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "710a716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "epoch 0 train loss 2.884871006011963\n",
      "val loss 2.7672245502471924\n",
      "______________\n",
      "epoch 1 train loss 2.7081034183502197\n",
      "val loss 2.628927230834961\n",
      "______________\n",
      "epoch 2 train loss 2.5365307331085205\n",
      "val loss 2.4884705543518066\n",
      "______________\n",
      "epoch 3 train loss 2.3873772621154785\n",
      "val loss 2.3543004989624023\n",
      "______________\n",
      "epoch 4 train loss 2.2397007942199707\n",
      "val loss 2.237830638885498\n",
      "______________\n",
      "epoch 5 train loss 2.143876791000366\n",
      "val loss 2.1452903747558594\n",
      "______________\n",
      "epoch 6 train loss 2.0588982105255127\n",
      "val loss 2.0769734382629395\n",
      "______________\n",
      "epoch 7 train loss 2.015490770339966\n",
      "val loss 2.0324482917785645\n",
      "______________\n",
      "epoch 8 train loss 2.0037107467651367\n",
      "val loss 2.0080528259277344\n",
      "______________\n",
      "epoch 9 train loss 1.987803339958191\n",
      "val loss 1.9981358051300049\n",
      "______________\n",
      "epoch 10 train loss 2.0021519660949707\n",
      "val loss 1.9972429275512695\n",
      "______________\n",
      "epoch 11 train loss 1.9991101026535034\n",
      "val loss 2.001216173171997\n",
      "______________\n",
      "epoch 12 train loss 1.98967707157135\n",
      "val loss 2.0075316429138184\n",
      "______________\n",
      "epoch 13 train loss 1.989128828048706\n",
      "val loss 2.0088090896606445\n",
      "______________\n",
      "epoch 14 train loss 1.9702463150024414\n",
      "val loss 2.0029547214508057\n",
      "______________\n",
      "epoch 15 train loss 1.992693543434143\n",
      "val loss 1.9961094856262207\n",
      "______________\n",
      "epoch 16 train loss 1.9594669342041016\n",
      "val loss 1.989800214767456\n",
      "______________\n",
      "epoch 17 train loss 1.941843867301941\n",
      "val loss 1.985084891319275\n",
      "______________\n",
      "epoch 18 train loss 1.9604592323303223\n",
      "val loss 1.9855464696884155\n",
      "______________\n",
      "epoch 19 train loss 1.9219005107879639\n",
      "val loss 1.9910345077514648\n",
      "______________\n",
      "epoch 20 train loss 1.929269552230835\n",
      "val loss 1.9996790885925293\n",
      "______________\n",
      "epoch 21 train loss 1.9035239219665527\n",
      "val loss 2.013258695602417\n",
      "______________\n",
      "epoch 22 train loss 1.9024171829223633\n",
      "val loss 2.024449586868286\n",
      "______________\n",
      "epoch 23 train loss 1.9033069610595703\n",
      "val loss 2.029784917831421\n",
      "______________\n",
      "epoch 24 train loss 1.9490878582000732\n",
      "val loss 2.0300827026367188\n",
      "______________\n",
      "epoch 25 train loss 1.8878982067108154\n",
      "val loss 2.0242919921875\n",
      "______________\n",
      "epoch 26 train loss 1.9026321172714233\n",
      "val loss 2.0151424407958984\n",
      "______________\n",
      "epoch 27 train loss 1.8896501064300537\n",
      "val loss 2.006190299987793\n",
      "______________\n",
      "epoch 28 train loss 1.8925628662109375\n",
      "val loss 1.9987858533859253\n",
      "______________\n",
      "best loss 1.985084891319275 {'pd': {'accuracy': 0.3333333333333333, 'auc_micro': 0.9091844369622148, 'auc_mean': 0.7637496207870599, 'auc_weighted': 0.6764454721144771}, 'nd': {'accuracy': 0.3605972086984745, 'auc_micro': 0.7578723404255319, 'auc_mean': 0.5144727637975773, 'auc_weighted': 0.5495057525091257}, 'mod': {'accuracy': 0.3605972086984745, 'auc_micro': 0.7578723404255319, 'auc_mean': 0.5144727637975773, 'auc_weighted': 0.5495057525091257}, 'dlts': {'accuracy': [0.9523809523809523, 0.9659863945578231, 0.9659863945578231, 0.9795918367346939, 0.9183673469387755], 'accuracy_mean': 0.9564625850340136, 'auc': [0.8357142857142856, 0.6380281690140845, 0.5140845070422535, 0.6921296296296295, 0.6234567901234568], 'auc_mean': 0.660682676304742}}\n",
      "{'predictions': [tensor([[9.9994e-01, 3.1886e-05, 3.1894e-05],\n",
      "        [1.0000e+00, 1.4605e-06, 1.4607e-06],\n",
      "        [9.9991e-01, 4.5601e-05, 4.5610e-05],\n",
      "        [9.9893e-01, 5.3441e-04, 5.3511e-04],\n",
      "        [9.9915e-01, 4.2545e-04, 4.2589e-04],\n",
      "        [9.9930e-01, 3.4901e-04, 3.4957e-04],\n",
      "        [9.9991e-01, 4.4663e-05, 4.4681e-05],\n",
      "        [9.9949e-01, 2.5487e-04, 2.5520e-04],\n",
      "        [1.0000e+00, 2.0632e-07, 2.0634e-07],\n",
      "        [9.9939e-01, 3.0474e-04, 3.0493e-04],\n",
      "        [9.9994e-01, 2.8092e-05, 2.8102e-05],\n",
      "        [9.9999e-01, 7.4503e-06, 7.4530e-06],\n",
      "        [9.9902e-01, 4.8842e-04, 4.8925e-04],\n",
      "        [9.9965e-01, 1.7673e-04, 1.7693e-04],\n",
      "        [9.9814e-01, 9.2822e-04, 9.2896e-04],\n",
      "        [9.9922e-01, 3.9209e-04, 3.9263e-04],\n",
      "        [1.0000e+00, 7.4294e-07, 7.4299e-07],\n",
      "        [9.9927e-01, 3.6655e-04, 3.6722e-04],\n",
      "        [9.9952e-01, 2.3996e-04, 2.4018e-04],\n",
      "        [9.9993e-01, 3.7090e-05, 3.7107e-05],\n",
      "        [9.9998e-01, 9.6945e-06, 9.6948e-06],\n",
      "        [9.9921e-01, 3.9691e-04, 3.9756e-04],\n",
      "        [9.9763e-01, 1.1860e-03, 1.1889e-03],\n",
      "        [9.9998e-01, 9.2996e-06, 9.3004e-06],\n",
      "        [1.0000e+00, 5.8048e-09, 5.8049e-09],\n",
      "        [9.9978e-01, 1.1191e-04, 1.1207e-04],\n",
      "        [1.0000e+00, 7.8178e-09, 7.8178e-09],\n",
      "        [9.9982e-01, 8.7941e-05, 8.7946e-05],\n",
      "        [9.9864e-01, 6.8070e-04, 6.8216e-04],\n",
      "        [9.9929e-01, 3.5467e-04, 3.5507e-04],\n",
      "        [9.9957e-01, 2.1263e-04, 2.1281e-04],\n",
      "        [9.9966e-01, 1.6784e-04, 1.6787e-04],\n",
      "        [9.9918e-01, 4.0875e-04, 4.0917e-04],\n",
      "        [9.9922e-01, 3.9112e-04, 3.9187e-04],\n",
      "        [9.9989e-01, 5.5250e-05, 5.5280e-05],\n",
      "        [9.9995e-01, 2.5945e-05, 2.5950e-05],\n",
      "        [9.9947e-01, 2.6635e-04, 2.6663e-04],\n",
      "        [9.9942e-01, 2.9090e-04, 2.9119e-04],\n",
      "        [9.9996e-01, 1.7895e-05, 1.7899e-05],\n",
      "        [9.9957e-01, 2.1594e-04, 2.1621e-04],\n",
      "        [9.9935e-01, 3.2411e-04, 3.2418e-04],\n",
      "        [1.0000e+00, 9.4443e-07, 9.4452e-07],\n",
      "        [9.9942e-01, 2.9253e-04, 2.9248e-04],\n",
      "        [1.0000e+00, 4.5040e-08, 4.5043e-08],\n",
      "        [9.9956e-01, 2.2122e-04, 2.2146e-04],\n",
      "        [9.9995e-01, 2.7269e-05, 2.7275e-05],\n",
      "        [9.9853e-01, 7.3291e-04, 7.3394e-04],\n",
      "        [9.9967e-01, 1.6630e-04, 1.6634e-04],\n",
      "        [9.9852e-01, 7.4178e-04, 7.4287e-04],\n",
      "        [9.9869e-01, 6.5268e-04, 6.5402e-04],\n",
      "        [9.9999e-01, 6.3537e-06, 6.3569e-06],\n",
      "        [9.9873e-01, 6.3520e-04, 6.3565e-04],\n",
      "        [9.9991e-01, 4.6602e-05, 4.6644e-05],\n",
      "        [9.9937e-01, 3.1683e-04, 3.1716e-04],\n",
      "        [9.9925e-01, 3.7463e-04, 3.7521e-04],\n",
      "        [9.9881e-01, 5.9504e-04, 5.9571e-04],\n",
      "        [9.9945e-01, 2.7573e-04, 2.7578e-04],\n",
      "        [9.9998e-01, 1.2241e-05, 1.2246e-05],\n",
      "        [1.0000e+00, 1.0185e-06, 1.0185e-06],\n",
      "        [9.9924e-01, 3.8152e-04, 3.8193e-04],\n",
      "        [9.9921e-01, 3.9395e-04, 3.9432e-04],\n",
      "        [9.9923e-01, 3.8353e-04, 3.8404e-04],\n",
      "        [9.9676e-01, 1.6170e-03, 1.6190e-03],\n",
      "        [9.9975e-01, 1.2265e-04, 1.2277e-04],\n",
      "        [1.0000e+00, 7.5622e-09, 7.5623e-09],\n",
      "        [9.9969e-01, 1.5256e-04, 1.5265e-04],\n",
      "        [9.9798e-01, 1.0076e-03, 1.0093e-03],\n",
      "        [9.9759e-01, 1.2058e-03, 1.2043e-03],\n",
      "        [9.9791e-01, 1.0450e-03, 1.0470e-03],\n",
      "        [9.9832e-01, 8.4115e-04, 8.4094e-04],\n",
      "        [9.9979e-01, 1.0629e-04, 1.0632e-04],\n",
      "        [9.9903e-01, 4.8659e-04, 4.8736e-04],\n",
      "        [9.9909e-01, 4.5474e-04, 4.5520e-04],\n",
      "        [9.9938e-01, 3.1150e-04, 3.1203e-04],\n",
      "        [9.9978e-01, 1.0861e-04, 1.0866e-04],\n",
      "        [9.9995e-01, 2.4421e-05, 2.4441e-05],\n",
      "        [9.9981e-01, 9.3623e-05, 9.3689e-05],\n",
      "        [9.9727e-01, 1.3650e-03, 1.3651e-03],\n",
      "        [9.9997e-01, 1.5102e-05, 1.5105e-05],\n",
      "        [9.9931e-01, 3.4511e-04, 3.4592e-04],\n",
      "        [9.9936e-01, 3.2168e-04, 3.2197e-04],\n",
      "        [9.9920e-01, 3.9740e-04, 3.9774e-04],\n",
      "        [9.9927e-01, 3.6513e-04, 3.6527e-04],\n",
      "        [9.9970e-01, 1.4753e-04, 1.4760e-04],\n",
      "        [9.9989e-01, 5.3778e-05, 5.3818e-05],\n",
      "        [9.9957e-01, 2.1239e-04, 2.1267e-04],\n",
      "        [9.9935e-01, 3.2521e-04, 3.2569e-04],\n",
      "        [9.9985e-01, 7.7032e-05, 7.7073e-05],\n",
      "        [9.9956e-01, 2.1946e-04, 2.1958e-04],\n",
      "        [9.9975e-01, 1.2596e-04, 1.2607e-04],\n",
      "        [9.9894e-01, 5.2876e-04, 5.2959e-04],\n",
      "        [9.9961e-01, 1.9353e-04, 1.9378e-04],\n",
      "        [9.9757e-01, 1.2162e-03, 1.2135e-03],\n",
      "        [9.9972e-01, 1.4121e-04, 1.4135e-04],\n",
      "        [9.9944e-01, 2.8133e-04, 2.8122e-04],\n",
      "        [9.9999e-01, 4.3970e-06, 4.3985e-06],\n",
      "        [9.9790e-01, 1.0496e-03, 1.0481e-03],\n",
      "        [9.9999e-01, 3.2372e-06, 3.2375e-06],\n",
      "        [9.9981e-01, 9.5176e-05, 9.5196e-05],\n",
      "        [9.9996e-01, 2.1443e-05, 2.1448e-05],\n",
      "        [9.9970e-01, 1.4805e-04, 1.4811e-04],\n",
      "        [9.9992e-01, 3.9236e-05, 3.9256e-05],\n",
      "        [9.9987e-01, 6.4420e-05, 6.4457e-05],\n",
      "        [9.9999e-01, 2.5597e-06, 2.5597e-06],\n",
      "        [9.9867e-01, 6.6637e-04, 6.6713e-04],\n",
      "        [9.9984e-01, 7.9313e-05, 7.9334e-05],\n",
      "        [9.9907e-01, 4.6602e-04, 4.6666e-04],\n",
      "        [9.9998e-01, 1.0377e-05, 1.0383e-05],\n",
      "        [9.9978e-01, 1.1067e-04, 1.1079e-04],\n",
      "        [9.9884e-01, 5.7837e-04, 5.7897e-04],\n",
      "        [9.9958e-01, 2.0978e-04, 2.0993e-04],\n",
      "        [9.9896e-01, 5.1776e-04, 5.1800e-04],\n",
      "        [9.9904e-01, 4.8128e-04, 4.8193e-04],\n",
      "        [1.0000e+00, 2.4171e-06, 2.4177e-06],\n",
      "        [9.9990e-01, 5.0573e-05, 5.0595e-05],\n",
      "        [9.9851e-01, 7.4618e-04, 7.4775e-04],\n",
      "        [9.9964e-01, 1.7899e-04, 1.7912e-04],\n",
      "        [9.9901e-01, 4.9605e-04, 4.9687e-04],\n",
      "        [9.9985e-01, 7.3336e-05, 7.3364e-05],\n",
      "        [9.9997e-01, 1.6947e-05, 1.6950e-05],\n",
      "        [9.9924e-01, 3.8139e-04, 3.8154e-04],\n",
      "        [9.9928e-01, 3.6104e-04, 3.6167e-04],\n",
      "        [9.9921e-01, 3.9483e-04, 3.9522e-04],\n",
      "        [9.9893e-01, 5.3376e-04, 5.3429e-04],\n",
      "        [9.9732e-01, 1.3435e-03, 1.3414e-03],\n",
      "        [9.9924e-01, 3.7933e-04, 3.7972e-04],\n",
      "        [9.9856e-01, 7.1881e-04, 7.1765e-04],\n",
      "        [9.9993e-01, 3.2960e-05, 3.2971e-05],\n",
      "        [9.9999e-01, 7.0266e-06, 7.0289e-06],\n",
      "        [9.9918e-01, 4.0966e-04, 4.1008e-04],\n",
      "        [9.9976e-01, 1.2114e-04, 1.2114e-04],\n",
      "        [9.9944e-01, 2.7934e-04, 2.7971e-04],\n",
      "        [9.9912e-01, 4.4115e-04, 4.4151e-04],\n",
      "        [9.9784e-01, 1.0808e-03, 1.0802e-03],\n",
      "        [9.9920e-01, 4.0201e-04, 4.0234e-04],\n",
      "        [9.9875e-01, 6.2317e-04, 6.2417e-04],\n",
      "        [9.9637e-01, 1.8109e-03, 1.8144e-03],\n",
      "        [1.0000e+00, 6.0801e-07, 6.0809e-07],\n",
      "        [9.9720e-01, 1.4017e-03, 1.4019e-03],\n",
      "        [9.9904e-01, 4.7784e-04, 4.7823e-04],\n",
      "        [9.9903e-01, 4.8363e-04, 4.8503e-04],\n",
      "        [9.9815e-01, 9.2183e-04, 9.2422e-04],\n",
      "        [1.0000e+00, 7.7248e-10, 7.7249e-10],\n",
      "        [9.9982e-01, 8.8665e-05, 8.8680e-05],\n",
      "        [9.9819e-01, 9.0516e-04, 9.0401e-04],\n",
      "        [9.9959e-01, 2.0609e-04, 2.0647e-04],\n",
      "        [9.9760e-01, 1.1970e-03, 1.1995e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[9.6241e-01, 3.6172e-02, 1.4148e-03],\n",
      "        [8.6207e-01, 1.3723e-01, 7.0065e-04],\n",
      "        [8.6360e-01, 1.3324e-01, 3.1566e-03],\n",
      "        [7.7330e-01, 2.1590e-01, 1.0800e-02],\n",
      "        [8.1166e-01, 1.7942e-01, 8.9129e-03],\n",
      "        [6.1050e-01, 3.7812e-01, 1.1382e-02],\n",
      "        [7.0264e-01, 2.9320e-01, 4.1635e-03],\n",
      "        [4.7494e-01, 5.1472e-01, 1.0337e-02],\n",
      "        [8.7243e-01, 1.2727e-01, 2.9467e-04],\n",
      "        [5.1146e-01, 4.7821e-01, 1.0327e-02],\n",
      "        [8.5521e-01, 1.4227e-01, 2.5287e-03],\n",
      "        [8.8711e-01, 1.1156e-01, 1.3351e-03],\n",
      "        [5.2439e-01, 4.6322e-01, 1.2390e-02],\n",
      "        [4.9633e-01, 4.9445e-01, 9.2235e-03],\n",
      "        [7.4009e-01, 2.4474e-01, 1.5170e-02],\n",
      "        [7.0210e-01, 2.8693e-01, 1.0967e-02],\n",
      "        [8.2519e-01, 1.7430e-01, 5.0722e-04],\n",
      "        [8.0387e-01, 1.8656e-01, 9.5769e-03],\n",
      "        [4.5136e-01, 5.3931e-01, 9.3301e-03],\n",
      "        [6.9842e-01, 2.9769e-01, 3.8920e-03],\n",
      "        [8.7038e-01, 1.2807e-01, 1.5539e-03],\n",
      "        [6.8199e-01, 3.0717e-01, 1.0834e-02],\n",
      "        [6.9152e-01, 2.9034e-01, 1.8139e-02],\n",
      "        [8.5031e-01, 1.4837e-01, 1.3189e-03],\n",
      "        [6.3419e-01, 3.6575e-01, 6.4514e-05],\n",
      "        [8.7335e-01, 1.2147e-01, 5.1850e-03],\n",
      "        [7.3132e-01, 2.6861e-01, 7.1637e-05],\n",
      "        [7.0768e-01, 2.8650e-01, 5.8264e-03],\n",
      "        [6.1485e-01, 3.6964e-01, 1.5506e-02],\n",
      "        [5.7943e-01, 4.0873e-01, 1.1841e-02],\n",
      "        [4.5101e-01, 5.3981e-01, 9.1763e-03],\n",
      "        [7.3993e-01, 2.5369e-01, 6.3822e-03],\n",
      "        [5.0408e-01, 4.8384e-01, 1.2078e-02],\n",
      "        [7.0133e-01, 2.8763e-01, 1.1037e-02],\n",
      "        [7.9360e-01, 2.0187e-01, 4.5216e-03],\n",
      "        [9.4678e-01, 5.1654e-02, 1.5655e-03],\n",
      "        [7.9218e-01, 1.9936e-01, 8.4579e-03],\n",
      "        [7.8709e-01, 2.0450e-01, 8.4086e-03],\n",
      "        [8.2749e-01, 1.7032e-01, 2.1900e-03],\n",
      "        [5.5244e-01, 4.3811e-01, 9.4554e-03],\n",
      "        [7.1966e-01, 2.7072e-01, 9.6213e-03],\n",
      "        [8.8194e-01, 1.1756e-01, 5.0429e-04],\n",
      "        [8.1875e-01, 1.7293e-01, 8.3164e-03],\n",
      "        [9.8035e-01, 1.9590e-02, 6.0112e-05],\n",
      "        [5.6046e-01, 4.3056e-01, 8.9787e-03],\n",
      "        [8.2733e-01, 1.6952e-01, 3.1466e-03],\n",
      "        [8.6852e-01, 1.2107e-01, 1.0408e-02],\n",
      "        [5.6697e-01, 4.2483e-01, 8.1964e-03],\n",
      "        [6.4402e-01, 3.4083e-01, 1.5149e-02],\n",
      "        [6.2572e-01, 3.5979e-01, 1.4487e-02],\n",
      "        [8.8598e-01, 1.1276e-01, 1.2627e-03],\n",
      "        [7.3776e-01, 2.5010e-01, 1.2144e-02],\n",
      "        [9.6924e-01, 2.9149e-02, 1.6074e-03],\n",
      "        [6.1409e-01, 3.7604e-01, 9.8643e-03],\n",
      "        [5.8039e-01, 4.0784e-01, 1.1774e-02],\n",
      "        [6.1896e-01, 3.6794e-01, 1.3096e-02],\n",
      "        [7.3998e-01, 2.5152e-01, 8.5041e-03],\n",
      "        [8.0470e-01, 1.9324e-01, 2.0548e-03],\n",
      "        [8.8218e-01, 1.1732e-01, 4.9930e-04],\n",
      "        [6.1841e-01, 3.7044e-01, 1.1150e-02],\n",
      "        [5.0065e-01, 4.8751e-01, 1.1845e-02],\n",
      "        [6.9983e-01, 2.8802e-01, 1.2156e-02],\n",
      "        [5.3776e-01, 4.4078e-01, 2.1464e-02],\n",
      "        [4.8240e-01, 5.1069e-01, 6.9140e-03],\n",
      "        [5.8093e-01, 4.1899e-01, 7.3204e-05],\n",
      "        [4.8542e-01, 5.0653e-01, 8.0419e-03],\n",
      "        [4.5166e-01, 5.3030e-01, 1.8040e-02],\n",
      "        [5.6615e-01, 4.1523e-01, 1.8618e-02],\n",
      "        [6.8777e-01, 2.9444e-01, 1.7789e-02],\n",
      "        [5.8098e-01, 4.0262e-01, 1.6398e-02],\n",
      "        [6.8632e-01, 3.0819e-01, 5.4969e-03],\n",
      "        [8.1445e-01, 1.7560e-01, 9.9526e-03],\n",
      "        [5.4545e-01, 4.4180e-01, 1.2746e-02],\n",
      "        [7.1098e-01, 2.7797e-01, 1.1050e-02],\n",
      "        [7.9398e-01, 2.0010e-01, 5.9203e-03],\n",
      "        [7.6900e-01, 2.2799e-01, 3.0155e-03],\n",
      "        [7.6166e-01, 2.3316e-01, 5.1765e-03],\n",
      "        [5.8856e-01, 3.9188e-01, 1.9562e-02],\n",
      "        [8.3316e-01, 1.6478e-01, 2.0659e-03],\n",
      "        [5.8321e-01, 4.0542e-01, 1.1370e-02],\n",
      "        [5.6827e-01, 4.2069e-01, 1.1040e-02],\n",
      "        [7.6860e-01, 2.2149e-01, 9.9112e-03],\n",
      "        [7.4863e-01, 2.4138e-01, 9.9869e-03],\n",
      "        [6.0135e-01, 3.9112e-01, 7.5270e-03],\n",
      "        [8.4928e-01, 1.4728e-01, 3.4363e-03],\n",
      "        [4.4360e-01, 5.4683e-01, 9.5794e-03],\n",
      "        [7.0011e-01, 2.8918e-01, 1.0711e-02],\n",
      "        [4.2793e-01, 5.6577e-01, 6.2988e-03],\n",
      "        [5.2541e-01, 4.6463e-01, 9.9604e-03],\n",
      "        [9.5422e-01, 4.3146e-02, 2.6361e-03],\n",
      "        [4.3444e-01, 5.5166e-01, 1.3894e-02],\n",
      "        [4.2619e-01, 5.6467e-01, 9.1461e-03],\n",
      "        [6.5170e-01, 3.3149e-01, 1.6812e-02],\n",
      "        [4.8694e-01, 5.0579e-01, 7.2723e-03],\n",
      "        [6.6854e-01, 3.2228e-01, 9.1803e-03],\n",
      "        [8.5664e-01, 1.4231e-01, 1.0529e-03],\n",
      "        [6.1991e-01, 3.6215e-01, 1.7942e-02],\n",
      "        [9.0681e-01, 9.2346e-02, 8.4706e-04],\n",
      "        [6.8703e-01, 3.0603e-01, 6.9343e-03],\n",
      "        [9.1068e-01, 8.7710e-02, 1.6122e-03],\n",
      "        [6.7981e-01, 3.1270e-01, 7.4985e-03],\n",
      "        [8.1317e-01, 1.8302e-01, 3.8113e-03],\n",
      "        [8.7575e-01, 1.2063e-01, 3.6257e-03],\n",
      "        [8.3254e-01, 1.6666e-01, 8.0258e-04],\n",
      "        [6.4122e-01, 3.4365e-01, 1.5124e-02],\n",
      "        [9.4039e-01, 5.7000e-02, 2.6138e-03],\n",
      "        [7.2371e-01, 2.6379e-01, 1.2502e-02],\n",
      "        [9.2314e-01, 7.5393e-02, 1.4636e-03],\n",
      "        [5.0913e-01, 4.8347e-01, 7.4084e-03],\n",
      "        [6.4123e-01, 3.4490e-01, 1.3876e-02],\n",
      "        [7.7122e-01, 2.2106e-01, 7.7149e-03],\n",
      "        [5.8511e-01, 4.0144e-01, 1.3450e-02],\n",
      "        [5.0297e-01, 4.8478e-01, 1.2250e-02],\n",
      "        [9.6512e-01, 3.4400e-02, 4.7621e-04],\n",
      "        [9.1582e-01, 8.1741e-02, 2.4391e-03],\n",
      "        [5.9421e-01, 3.8881e-01, 1.6980e-02],\n",
      "        [4.4770e-01, 5.4368e-01, 8.6192e-03],\n",
      "        [5.7123e-01, 4.1634e-01, 1.2421e-02],\n",
      "        [7.5105e-01, 2.4436e-01, 4.5878e-03],\n",
      "        [9.0738e-01, 9.0666e-02, 1.9545e-03],\n",
      "        [7.9406e-01, 1.9625e-01, 9.6880e-03],\n",
      "        [8.7929e-01, 1.1351e-01, 7.1987e-03],\n",
      "        [7.1057e-01, 2.7933e-01, 1.0105e-02],\n",
      "        [6.4515e-01, 3.4236e-01, 1.2495e-02],\n",
      "        [6.4001e-01, 3.4192e-01, 1.8071e-02],\n",
      "        [4.9171e-01, 4.9665e-01, 1.1640e-02],\n",
      "        [5.6993e-01, 4.1614e-01, 1.3929e-02],\n",
      "        [6.7267e-01, 3.2309e-01, 4.2318e-03],\n",
      "        [8.8640e-01, 1.1238e-01, 1.2201e-03],\n",
      "        [5.2032e-01, 4.6721e-01, 1.2475e-02],\n",
      "        [6.7793e-01, 3.1561e-01, 6.4612e-03],\n",
      "        [5.8549e-01, 4.0425e-01, 1.0261e-02],\n",
      "        [8.1301e-01, 1.7709e-01, 9.9018e-03],\n",
      "        [6.5115e-01, 3.3246e-01, 1.6383e-02],\n",
      "        [5.4520e-01, 4.4393e-01, 1.0870e-02],\n",
      "        [7.8147e-01, 2.0560e-01, 1.2931e-02],\n",
      "        [7.1895e-01, 2.6013e-01, 2.0914e-02],\n",
      "        [9.0131e-01, 9.8249e-02, 4.4457e-04],\n",
      "        [4.3982e-01, 5.4078e-01, 1.9398e-02],\n",
      "        [8.2473e-01, 1.6616e-01, 9.1139e-03],\n",
      "        [5.3716e-01, 4.4961e-01, 1.3230e-02],\n",
      "        [6.5695e-01, 3.2698e-01, 1.6066e-02],\n",
      "        [7.8971e-01, 2.1028e-01, 1.6374e-05],\n",
      "        [7.7912e-01, 2.1523e-01, 5.6537e-03],\n",
      "        [5.5856e-01, 4.2480e-01, 1.6639e-02],\n",
      "        [8.6857e-01, 1.2474e-01, 6.6875e-03],\n",
      "        [6.0716e-01, 3.7420e-01, 1.8641e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[7.4436e-03, 9.7951e-01, 6.8007e-03, 6.2432e-03],\n",
      "        [1.6617e-03, 9.9519e-01, 1.5994e-03, 1.5512e-03],\n",
      "        [9.0204e-03, 9.7446e-01, 8.5631e-03, 7.9576e-03],\n",
      "        [2.5477e-02, 9.3042e-01, 2.3175e-02, 2.0929e-02],\n",
      "        [2.4452e-02, 9.3303e-01, 2.2422e-02, 2.0092e-02],\n",
      "        [2.4657e-02, 9.3260e-01, 2.2649e-02, 2.0093e-02],\n",
      "        [1.0543e-02, 9.7056e-01, 9.6802e-03, 9.2177e-03],\n",
      "        [2.4902e-02, 9.3241e-01, 2.2433e-02, 2.0255e-02],\n",
      "        [9.5690e-04, 9.9724e-01, 9.1157e-04, 8.9114e-04],\n",
      "        [2.4299e-02, 9.3484e-01, 2.1422e-02, 1.9440e-02],\n",
      "        [8.0174e-03, 9.7742e-01, 7.5386e-03, 7.0241e-03],\n",
      "        [4.1422e-03, 9.8814e-01, 3.9587e-03, 3.7583e-03],\n",
      "        [2.7682e-02, 9.2399e-01, 2.5594e-02, 2.2731e-02],\n",
      "        [1.9783e-02, 9.4724e-01, 1.7261e-02, 1.5720e-02],\n",
      "        [3.4974e-02, 9.0435e-01, 3.2114e-02, 2.8561e-02],\n",
      "        [2.9021e-02, 9.2128e-01, 2.6286e-02, 2.3411e-02],\n",
      "        [1.2946e-03, 9.9626e-01, 1.2384e-03, 1.2111e-03],\n",
      "        [2.6706e-02, 9.2742e-01, 2.4202e-02, 2.1669e-02],\n",
      "        [2.1612e-02, 9.4030e-01, 2.0011e-02, 1.8076e-02],\n",
      "        [9.8916e-03, 9.7217e-01, 9.2051e-03, 8.7348e-03],\n",
      "        [4.8540e-03, 9.8607e-01, 4.6408e-03, 4.4332e-03],\n",
      "        [2.6527e-02, 9.2659e-01, 2.4845e-02, 2.2037e-02],\n",
      "        [4.2072e-02, 8.8598e-01, 3.8154e-02, 3.3791e-02],\n",
      "        [3.9300e-03, 9.8897e-01, 3.6127e-03, 3.4843e-03],\n",
      "        [1.9885e-04, 9.9942e-01, 1.9312e-04, 1.9169e-04],\n",
      "        [1.6105e-02, 9.5496e-01, 1.5194e-02, 1.3737e-02],\n",
      "        [2.1934e-04, 9.9935e-01, 2.1433e-04, 2.1251e-04],\n",
      "        [1.1226e-02, 9.6848e-01, 1.0524e-02, 9.7704e-03],\n",
      "        [3.4520e-02, 9.0908e-01, 2.9832e-02, 2.6572e-02],\n",
      "        [2.6237e-02, 9.3033e-01, 2.2908e-02, 2.0521e-02],\n",
      "        [2.2718e-02, 9.3787e-01, 2.0629e-02, 1.8786e-02],\n",
      "        [1.8020e-02, 9.5042e-01, 1.6368e-02, 1.5191e-02],\n",
      "        [2.7487e-02, 9.2435e-01, 2.5480e-02, 2.2681e-02],\n",
      "        [2.6089e-02, 9.2930e-01, 2.3327e-02, 2.1281e-02],\n",
      "        [1.1966e-02, 9.6683e-01, 1.1062e-02, 1.0142e-02],\n",
      "        [6.3078e-03, 9.8238e-01, 5.8549e-03, 5.4600e-03],\n",
      "        [2.2593e-02, 9.3883e-01, 2.0234e-02, 1.8341e-02],\n",
      "        [1.9690e-02, 9.4476e-01, 1.8841e-02, 1.6713e-02],\n",
      "        [6.4229e-03, 9.8199e-01, 5.9300e-03, 5.6581e-03],\n",
      "        [2.0121e-02, 9.4631e-01, 1.7597e-02, 1.5977e-02],\n",
      "        [2.4430e-02, 9.3380e-01, 2.1940e-02, 1.9833e-02],\n",
      "        [1.4701e-03, 9.9577e-01, 1.3973e-03, 1.3633e-03],\n",
      "        [2.0449e-02, 9.4395e-01, 1.8590e-02, 1.7011e-02],\n",
      "        [4.0487e-04, 9.9881e-01, 3.9422e-04, 3.8710e-04],\n",
      "        [2.0757e-02, 9.4287e-01, 1.9141e-02, 1.7229e-02],\n",
      "        [8.2729e-03, 9.7692e-01, 7.6703e-03, 7.1417e-03],\n",
      "        [3.0353e-02, 9.1743e-01, 2.7688e-02, 2.4530e-02],\n",
      "        [1.9416e-02, 9.4717e-01, 1.7436e-02, 1.5978e-02],\n",
      "        [3.3231e-02, 9.0934e-01, 3.0534e-02, 2.6895e-02],\n",
      "        [3.0023e-02, 9.1743e-01, 2.8021e-02, 2.4526e-02],\n",
      "        [4.0143e-03, 9.8857e-01, 3.7761e-03, 3.6403e-03],\n",
      "        [2.9649e-02, 9.1926e-01, 2.7030e-02, 2.4060e-02],\n",
      "        [9.1026e-03, 9.7443e-01, 8.5746e-03, 7.8941e-03],\n",
      "        [2.1758e-02, 9.4001e-01, 2.0175e-02, 1.8055e-02],\n",
      "        [2.4901e-02, 9.3217e-01, 2.2752e-02, 2.0178e-02],\n",
      "        [3.0519e-02, 9.1778e-01, 2.7086e-02, 2.4620e-02],\n",
      "        [2.1540e-02, 9.4112e-01, 1.9544e-02, 1.7796e-02],\n",
      "        [5.7236e-03, 9.8374e-01, 5.4255e-03, 5.1093e-03],\n",
      "        [1.6207e-03, 9.9536e-01, 1.5280e-03, 1.4909e-03],\n",
      "        [2.5716e-02, 9.3032e-01, 2.3149e-02, 2.0820e-02],\n",
      "        [2.6342e-02, 9.2754e-01, 2.4384e-02, 2.1737e-02],\n",
      "        [2.7821e-02, 9.2319e-01, 2.5742e-02, 2.3250e-02],\n",
      "        [4.6601e-02, 8.7278e-01, 4.3014e-02, 3.7604e-02],\n",
      "        [1.6395e-02, 9.5472e-01, 1.5021e-02, 1.3861e-02],\n",
      "        [2.0690e-04, 9.9939e-01, 2.0156e-04, 1.9997e-04],\n",
      "        [1.8287e-02, 9.4985e-01, 1.6669e-02, 1.5190e-02],\n",
      "        [4.0563e-02, 8.8849e-01, 3.7725e-02, 3.3225e-02],\n",
      "        [4.5191e-02, 8.8059e-01, 3.8975e-02, 3.5240e-02],\n",
      "        [3.7268e-02, 8.9864e-01, 3.4246e-02, 2.9842e-02],\n",
      "        [3.7972e-02, 8.9513e-01, 3.5641e-02, 3.1253e-02],\n",
      "        [1.3956e-02, 9.6171e-01, 1.2571e-02, 1.1762e-02],\n",
      "        [2.8103e-02, 9.2294e-01, 2.5881e-02, 2.3077e-02],\n",
      "        [2.9052e-02, 9.2008e-01, 2.6968e-02, 2.3904e-02],\n",
      "        [2.9589e-02, 9.2061e-01, 2.6246e-02, 2.3556e-02],\n",
      "        [1.2609e-02, 9.6483e-01, 1.1756e-02, 1.0810e-02],\n",
      "        [8.1395e-03, 9.7714e-01, 7.6042e-03, 7.1173e-03],\n",
      "        [1.3412e-02, 9.6291e-01, 1.2180e-02, 1.1498e-02],\n",
      "        [4.6029e-02, 8.7717e-01, 4.0454e-02, 3.6348e-02],\n",
      "        [6.6598e-03, 9.8111e-01, 6.2434e-03, 5.9875e-03],\n",
      "        [2.6702e-02, 9.2612e-01, 2.4701e-02, 2.2477e-02],\n",
      "        [2.6976e-02, 9.2827e-01, 2.3509e-02, 2.1249e-02],\n",
      "        [2.5433e-02, 9.2947e-01, 2.4098e-02, 2.1003e-02],\n",
      "        [2.3786e-02, 9.3415e-01, 2.2086e-02, 1.9979e-02],\n",
      "        [1.6678e-02, 9.5395e-01, 1.5268e-02, 1.4105e-02],\n",
      "        [1.0671e-02, 9.7025e-01, 9.8880e-03, 9.1870e-03],\n",
      "        [2.3757e-02, 9.3545e-01, 2.1390e-02, 1.9405e-02],\n",
      "        [2.4572e-02, 9.3299e-01, 2.2169e-02, 2.0268e-02],\n",
      "        [1.3952e-02, 9.6185e-01, 1.2494e-02, 1.1699e-02],\n",
      "        [2.5137e-02, 9.3285e-01, 2.2020e-02, 1.9992e-02],\n",
      "        [1.3251e-02, 9.6329e-01, 1.2402e-02, 1.1054e-02],\n",
      "        [3.2650e-02, 9.1024e-01, 3.0124e-02, 2.6981e-02],\n",
      "        [2.2802e-02, 9.3800e-01, 2.0531e-02, 1.8672e-02],\n",
      "        [4.1841e-02, 8.8687e-01, 3.7756e-02, 3.3534e-02],\n",
      "        [1.7099e-02, 9.5286e-01, 1.5715e-02, 1.4328e-02],\n",
      "        [2.0189e-02, 9.4380e-01, 1.8939e-02, 1.7068e-02],\n",
      "        [3.1575e-03, 9.9089e-01, 3.0266e-03, 2.9229e-03],\n",
      "        [4.2181e-02, 8.8928e-01, 3.6256e-02, 3.2279e-02],\n",
      "        [2.3329e-03, 9.9325e-01, 2.2497e-03, 2.1706e-03],\n",
      "        [1.7057e-02, 9.5391e-01, 1.5106e-02, 1.3928e-02],\n",
      "        [6.5844e-03, 9.8148e-01, 6.1221e-03, 5.8178e-03],\n",
      "        [1.6527e-02, 9.5375e-01, 1.5580e-02, 1.4148e-02],\n",
      "        [9.7240e-03, 9.7339e-01, 8.7814e-03, 8.1094e-03],\n",
      "        [1.2010e-02, 9.6675e-01, 1.1050e-02, 1.0189e-02],\n",
      "        [2.3540e-03, 9.9326e-01, 2.2350e-03, 2.1557e-03],\n",
      "        [3.5385e-02, 9.0585e-01, 3.1267e-02, 2.7502e-02],\n",
      "        [1.1563e-02, 9.6797e-01, 1.0642e-02, 9.8273e-03],\n",
      "        [3.2615e-02, 9.1311e-01, 2.8630e-02, 2.5646e-02],\n",
      "        [5.4416e-03, 9.8463e-01, 5.1457e-03, 4.7793e-03],\n",
      "        [1.8517e-02, 9.5089e-01, 1.5843e-02, 1.4752e-02],\n",
      "        [3.1281e-02, 9.1447e-01, 2.8783e-02, 2.5466e-02],\n",
      "        [1.9046e-02, 9.4717e-01, 1.7610e-02, 1.6169e-02],\n",
      "        [3.1000e-02, 9.1517e-01, 2.8568e-02, 2.5260e-02],\n",
      "        [2.7226e-02, 9.2550e-01, 2.5014e-02, 2.2256e-02],\n",
      "        [2.4415e-03, 9.9297e-01, 2.3431e-03, 2.2490e-03],\n",
      "        [9.6964e-03, 9.7266e-01, 9.1561e-03, 8.4873e-03],\n",
      "        [3.7237e-02, 8.9794e-01, 3.4490e-02, 3.0335e-02],\n",
      "        [2.0241e-02, 9.4464e-01, 1.8387e-02, 1.6729e-02],\n",
      "        [2.7959e-02, 9.2324e-01, 2.5877e-02, 2.2929e-02],\n",
      "        [1.5709e-02, 9.5684e-01, 1.4115e-02, 1.3337e-02],\n",
      "        [5.9268e-03, 9.8339e-01, 5.4890e-03, 5.1943e-03],\n",
      "        [2.5251e-02, 9.3077e-01, 2.3315e-02, 2.0666e-02],\n",
      "        [2.2958e-02, 9.3580e-01, 2.2076e-02, 1.9169e-02],\n",
      "        [2.3725e-02, 9.3499e-01, 2.1772e-02, 1.9512e-02],\n",
      "        [2.8193e-02, 9.2236e-01, 2.6317e-02, 2.3134e-02],\n",
      "        [4.3598e-02, 8.8259e-01, 3.9332e-02, 3.4480e-02],\n",
      "        [2.6545e-02, 9.2692e-01, 2.4592e-02, 2.1942e-02],\n",
      "        [3.1790e-02, 9.1440e-01, 2.8175e-02, 2.5638e-02],\n",
      "        [9.2711e-03, 9.7415e-01, 8.5683e-03, 8.0110e-03],\n",
      "        [4.4069e-03, 9.8759e-01, 4.0904e-03, 3.9128e-03],\n",
      "        [3.0316e-02, 9.1831e-01, 2.7176e-02, 2.4202e-02],\n",
      "        [1.5306e-02, 9.5740e-01, 1.4291e-02, 1.3007e-02],\n",
      "        [2.1266e-02, 9.4201e-01, 1.9377e-02, 1.7344e-02],\n",
      "        [2.7276e-02, 9.2442e-01, 2.5490e-02, 2.2814e-02],\n",
      "        [3.5882e-02, 9.0244e-01, 3.2970e-02, 2.8713e-02],\n",
      "        [2.5373e-02, 9.3017e-01, 2.3457e-02, 2.1002e-02],\n",
      "        [3.3185e-02, 9.0976e-01, 3.0097e-02, 2.6957e-02],\n",
      "        [4.5418e-02, 8.7674e-01, 4.1482e-02, 3.6359e-02],\n",
      "        [1.2640e-03, 9.9640e-01, 1.1806e-03, 1.1510e-03],\n",
      "        [4.5898e-02, 8.7506e-01, 4.1887e-02, 3.7160e-02],\n",
      "        [2.5454e-02, 9.3039e-01, 2.3323e-02, 2.0837e-02],\n",
      "        [2.8191e-02, 9.2341e-01, 2.5381e-02, 2.3018e-02],\n",
      "        [3.3705e-02, 9.0837e-01, 3.0633e-02, 2.7294e-02],\n",
      "        [5.4219e-05, 9.9984e-01, 5.2823e-05, 5.2618e-05],\n",
      "        [1.3733e-02, 9.6207e-01, 1.2645e-02, 1.1553e-02],\n",
      "        [4.0622e-02, 8.9171e-01, 3.5350e-02, 3.2321e-02],\n",
      "        [1.9580e-02, 9.4494e-01, 1.8687e-02, 1.6795e-02],\n",
      "        [4.6026e-02, 8.7904e-01, 3.9591e-02, 3.5342e-02]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.3152e-02, 2.1697e-03, 5.7166e-03, 1.0331e-02, 9.6533e-03],\n",
      "        [5.5802e-02, 7.4451e-03, 1.6233e-02, 2.1464e-02, 2.0777e-02],\n",
      "        [7.7184e-02, 2.3729e-02, 4.1398e-02, 5.3161e-02, 4.4604e-02],\n",
      "        [6.7559e-02, 2.4544e-02, 3.7060e-02, 4.7237e-02, 4.6842e-02],\n",
      "        [5.5126e-02, 2.6988e-02, 3.4891e-02, 5.4028e-02, 4.8669e-02],\n",
      "        [3.8152e-02, 9.6490e-03, 2.0562e-02, 2.1126e-02, 2.4232e-02],\n",
      "        [5.3471e-02, 2.5074e-02, 3.1416e-02, 4.5137e-02, 4.7183e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.9869e-02, 8.0184e-03, 1.1998e-02, 2.4192e-02, 2.0857e-02],\n",
      "        [2.1103e-02, 4.4060e-03, 9.6552e-03, 1.2166e-02, 1.4116e-02],\n",
      "        [5.5385e-02, 2.8958e-02, 3.6276e-02, 5.0704e-02, 5.1133e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.2956e-02, 3.4524e-02, 5.0989e-02, 6.4599e-02, 5.8119e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.5120e-03, 1.2505e-03, 3.0153e-03, 6.1159e-03, 5.7084e-03],\n",
      "        [7.4855e-02, 2.9303e-02, 3.6389e-02, 5.7575e-02, 5.7507e-02],\n",
      "        [4.7409e-02, 2.1163e-02, 2.9005e-02, 3.4127e-02, 4.0206e-02],\n",
      "        [4.5377e-02, 7.8698e-03, 1.1919e-02, 3.1859e-02, 2.2018e-02],\n",
      "        [3.5461e-02, 5.2886e-03, 8.9773e-03, 1.6956e-02, 1.1764e-02],\n",
      "        [6.2996e-02, 2.6840e-02, 3.7773e-02, 4.7446e-02, 4.7757e-02],\n",
      "        [9.3884e-02, 4.2198e-02, 5.4787e-02, 7.1093e-02, 6.9432e-02],\n",
      "        [2.7706e-02, 3.6799e-03, 7.1896e-03, 1.0584e-02, 1.0321e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.8613e-02, 1.4895e-02, 2.4908e-02, 4.3013e-02, 4.3059e-02],\n",
      "        [2.5106e-03, 3.7400e-04, 5.1527e-04, 8.8189e-04, 1.1985e-03],\n",
      "        [7.9997e-02, 1.2011e-02, 2.9012e-02, 3.2010e-02, 2.7663e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.2009e-02, 2.0227e-02, 2.8701e-02, 3.6915e-02, 4.4389e-02],\n",
      "        [7.5669e-02, 1.7471e-02, 2.1372e-02, 3.7298e-02, 2.9684e-02],\n",
      "        [5.8457e-02, 2.6874e-02, 3.5707e-02, 4.3569e-02, 4.7983e-02],\n",
      "        [6.2700e-02, 2.5199e-02, 3.6684e-02, 5.0564e-02, 4.7725e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0195e-02, 6.6257e-03, 1.2626e-02, 2.5027e-02, 1.6139e-02],\n",
      "        [8.1089e-02, 2.3459e-02, 3.1215e-02, 4.5638e-02, 4.5342e-02],\n",
      "        [7.3234e-02, 1.9659e-02, 3.5376e-02, 4.5029e-02, 4.1204e-02],\n",
      "        [3.9284e-02, 4.8500e-03, 9.6688e-03, 1.7567e-02, 1.7644e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.6212e-02, 2.1631e-02, 3.4033e-02, 4.6066e-02, 4.4205e-02],\n",
      "        [1.3259e-02, 1.8777e-03, 3.7533e-03, 6.6566e-03, 6.8989e-03],\n",
      "        [7.5423e-02, 1.8638e-02, 3.6573e-02, 4.2844e-02, 3.7689e-02],\n",
      "        [1.1491e-02, 4.9755e-04, 1.6398e-03, 2.6376e-03, 3.3525e-03],\n",
      "        [4.6672e-02, 2.0838e-02, 2.8093e-02, 4.1852e-02, 4.2765e-02],\n",
      "        [4.1667e-02, 1.1722e-02, 1.6049e-02, 2.6476e-02, 2.0791e-02],\n",
      "        [9.0798e-02, 3.1593e-02, 4.8065e-02, 6.0085e-02, 5.8314e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.0992e-02, 3.3297e-02, 4.7034e-02, 5.4154e-02, 6.3025e-02],\n",
      "        [6.2521e-02, 3.4536e-02, 4.2839e-02, 5.9678e-02, 5.3752e-02],\n",
      "        [2.9898e-02, 4.7512e-03, 1.0915e-02, 1.2362e-02, 1.1472e-02],\n",
      "        [7.3209e-02, 2.8331e-02, 4.1586e-02, 5.2567e-02, 5.0723e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0372e-02, 2.2762e-02, 3.1739e-02, 4.3775e-02, 3.9624e-02],\n",
      "        [5.4620e-02, 2.7096e-02, 3.6240e-02, 5.4619e-02, 4.7251e-02],\n",
      "        [8.6169e-02, 3.1683e-02, 4.3626e-02, 4.7307e-02, 5.7806e-02],\n",
      "        [6.4233e-02, 2.1503e-02, 3.1281e-02, 4.4638e-02, 4.4170e-02],\n",
      "        [3.1893e-02, 5.9807e-03, 1.1327e-02, 1.7391e-02, 1.4892e-02],\n",
      "        [2.4355e-02, 2.0616e-03, 3.6070e-03, 6.4893e-03, 6.5430e-03],\n",
      "        [5.7999e-02, 2.3848e-02, 3.4746e-02, 4.5959e-02, 5.1006e-02],\n",
      "        [5.7483e-02, 2.5702e-02, 3.5367e-02, 4.2192e-02, 4.6212e-02],\n",
      "        [8.1815e-02, 3.1002e-02, 4.1596e-02, 4.8920e-02, 5.5688e-02],\n",
      "        [1.1701e-01, 4.0793e-02, 7.1793e-02, 7.6109e-02, 7.8086e-02],\n",
      "        [3.4413e-02, 1.4908e-02, 2.2152e-02, 2.8735e-02, 3.2669e-02],\n",
      "        [2.0492e-03, 3.7243e-04, 4.8061e-04, 8.0049e-04, 1.1217e-03],\n",
      "        [4.5232e-02, 1.7370e-02, 2.5297e-02, 3.3755e-02, 3.6697e-02],\n",
      "        [9.9807e-02, 3.5400e-02, 5.8698e-02, 6.2679e-02, 6.9145e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6994e-02, 4.0739e-02, 5.3248e-02, 6.4831e-02, 7.0899e-02],\n",
      "        [1.2290e-01, 3.3758e-02, 5.8892e-02, 5.9636e-02, 6.4693e-02],\n",
      "        [5.3065e-02, 1.2121e-02, 2.0135e-02, 2.9941e-02, 3.0277e-02],\n",
      "        [7.6884e-02, 2.6310e-02, 4.2431e-02, 4.9752e-02, 5.1934e-02],\n",
      "        [6.2978e-02, 2.8482e-02, 3.7753e-02, 4.7188e-02, 5.0116e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.4718e-02, 1.5524e-02, 2.0746e-02, 3.6673e-02, 3.1264e-02],\n",
      "        [3.8009e-02, 8.3596e-03, 1.4808e-02, 2.1374e-02, 2.5594e-02],\n",
      "        [6.4826e-02, 1.3770e-02, 1.8051e-02, 3.2615e-02, 2.7502e-02],\n",
      "        [1.1255e-01, 4.0967e-02, 5.5071e-02, 7.1440e-02, 7.2476e-02],\n",
      "        [4.1731e-02, 6.3942e-03, 1.0330e-02, 1.4405e-02, 1.7349e-02],\n",
      "        [8.0318e-02, 2.3859e-02, 3.5785e-02, 5.1988e-02, 5.8212e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.9755e-02, 2.6772e-02, 4.1012e-02, 5.3237e-02, 4.3551e-02],\n",
      "        [7.7688e-02, 2.2664e-02, 3.5876e-02, 4.5463e-02, 4.9286e-02],\n",
      "        [5.7522e-02, 1.6851e-02, 2.2731e-02, 3.1182e-02, 3.3722e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.9745e-02, 2.3659e-02, 2.9176e-02, 4.1804e-02, 4.5475e-02],\n",
      "        [7.2030e-02, 2.2205e-02, 3.7714e-02, 4.4591e-02, 4.7972e-02],\n",
      "        [4.3025e-02, 1.4821e-02, 2.0676e-02, 2.9962e-02, 3.2418e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.9631e-02, 1.5156e-02, 2.4882e-02, 4.1588e-02, 2.6686e-02],\n",
      "        [8.3314e-02, 2.7984e-02, 4.7693e-02, 4.6490e-02, 6.6531e-02],\n",
      "        [4.7587e-02, 2.2705e-02, 2.8066e-02, 3.9895e-02, 4.3816e-02],\n",
      "        [9.0622e-02, 3.6874e-02, 5.0532e-02, 6.2585e-02, 6.5984e-02],\n",
      "        [3.7454e-02, 1.6903e-02, 2.3231e-02, 3.3506e-02, 3.5927e-02],\n",
      "        [7.4503e-02, 1.9787e-02, 3.3104e-02, 3.9559e-02, 4.0996e-02],\n",
      "        [3.0140e-02, 2.9328e-03, 7.8713e-03, 1.5089e-02, 9.1796e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.6505e-02, 3.5841e-03, 6.5243e-03, 9.2646e-03, 9.3826e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.8541e-02, 5.6084e-03, 9.3750e-03, 1.9825e-02, 1.4114e-02],\n",
      "        [7.1980e-02, 1.8893e-02, 2.8099e-02, 3.2005e-02, 3.9323e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0907e-02, 1.1009e-02, 1.8492e-02, 2.8720e-02, 3.0683e-02],\n",
      "        [1.9476e-02, 2.3168e-03, 5.4829e-03, 7.3391e-03, 8.5673e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.1153e-02, 3.2480e-02, 4.4106e-02, 5.5356e-02, 5.6526e-02],\n",
      "        [7.5099e-02, 1.5247e-02, 3.2722e-02, 4.1491e-02, 4.3754e-02],\n",
      "        [7.3033e-02, 2.8755e-02, 4.1526e-02, 5.2607e-02, 4.9752e-02],\n",
      "        [5.4971e-02, 2.7858e-02, 3.6478e-02, 4.9386e-02, 4.9308e-02],\n",
      "        [3.5165e-02, 2.9360e-03, 6.3043e-03, 1.0258e-02, 9.9774e-03],\n",
      "        [3.9715e-02, 9.6082e-03, 1.4146e-02, 2.5977e-02, 2.5895e-02],\n",
      "        [1.0533e-01, 3.5994e-02, 5.8495e-02, 6.1784e-02, 7.1417e-02],\n",
      "        [4.6814e-02, 1.8927e-02, 2.6684e-02, 3.5089e-02, 3.9963e-02],\n",
      "        [5.8493e-02, 2.9405e-02, 3.7080e-02, 5.3092e-02, 5.1339e-02],\n",
      "        [6.2075e-02, 1.2058e-02, 1.8436e-02, 3.1044e-02, 3.2442e-02],\n",
      "        [4.0864e-02, 5.6155e-03, 9.7851e-03, 2.2436e-02, 2.3417e-02],\n",
      "        [9.5055e-02, 2.7419e-02, 3.9175e-02, 5.0606e-02, 4.5064e-02],\n",
      "        [8.1336e-02, 2.3008e-02, 3.8161e-02, 4.9887e-02, 4.4100e-02],\n",
      "        [5.8368e-02, 2.2887e-02, 3.4968e-02, 4.1861e-02, 4.3668e-02],\n",
      "        [6.4221e-02, 2.9116e-02, 3.9284e-02, 5.6226e-02, 4.8629e-02],\n",
      "        [1.1164e-01, 4.1473e-02, 5.9238e-02, 7.6519e-02, 7.6589e-02],\n",
      "        [5.6438e-02, 2.5972e-02, 3.4624e-02, 4.1913e-02, 4.6767e-02],\n",
      "        [9.2542e-02, 3.3973e-02, 4.2993e-02, 6.2811e-02, 5.3145e-02],\n",
      "        [3.3937e-02, 1.2157e-02, 1.4124e-02, 2.3353e-02, 2.2924e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.3450e-02, 1.5466e-02, 2.5664e-02, 3.1630e-02, 3.6371e-02],\n",
      "        [4.9797e-02, 2.3442e-02, 3.2677e-02, 4.9072e-02, 4.1025e-02],\n",
      "        [8.8981e-02, 2.6809e-02, 4.2163e-02, 5.4558e-02, 5.5193e-02],\n",
      "        [9.8101e-02, 3.5313e-02, 5.9755e-02, 6.6021e-02, 6.3079e-02],\n",
      "        [5.7901e-02, 2.6158e-02, 3.5112e-02, 4.3339e-02, 4.6187e-02],\n",
      "        [9.9324e-02, 3.2006e-02, 4.9092e-02, 5.8593e-02, 5.8376e-02],\n",
      "        [1.0828e-01, 4.7186e-02, 6.3281e-02, 8.3273e-02, 8.1202e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0783e-01, 3.8768e-02, 6.5169e-02, 6.4303e-02, 8.2238e-02],\n",
      "        [7.0936e-02, 2.5211e-02, 3.8902e-02, 4.9834e-02, 4.6424e-02],\n",
      "        [6.6148e-02, 2.5978e-02, 3.7439e-02, 5.0165e-02, 5.6278e-02],\n",
      "        [8.5610e-02, 3.1868e-02, 5.1192e-02, 6.4456e-02, 5.7836e-02],\n",
      "        [1.4765e-03, 5.6989e-05, 2.5713e-04, 1.9657e-04, 4.6119e-04],\n",
      "        [6.6070e-02, 1.6867e-02, 2.7039e-02, 3.6334e-02, 3.1433e-02],\n",
      "        [9.4048e-02, 3.1786e-02, 4.6677e-02, 6.5061e-02, 6.3910e-02],\n",
      "        [8.4134e-02, 2.1810e-02, 3.4005e-02, 4.4013e-02, 4.0604e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)], '5%': [tensor([[9.9979e-01, 8.7573e-08, 8.7584e-08],\n",
      "        [1.0000e+00, 1.4391e-11, 1.4391e-11],\n",
      "        [9.9991e-01, 1.6537e-08, 1.6536e-08],\n",
      "        [9.9957e-01, 8.6266e-06, 8.6290e-06],\n",
      "        [9.9909e-01, 7.4316e-06, 7.4622e-06],\n",
      "        [9.9927e-01, 1.6719e-05, 1.6644e-05],\n",
      "        [9.9983e-01, 1.8655e-08, 1.8654e-08],\n",
      "        [9.9952e-01, 5.5400e-06, 5.5281e-06],\n",
      "        [9.9999e-01, 2.5661e-13, 2.5661e-13],\n",
      "        [9.9905e-01, 5.1882e-06, 5.1893e-06],\n",
      "        [9.9986e-01, 1.3923e-08, 1.3924e-08],\n",
      "        [9.9982e-01, 5.7883e-09, 5.7881e-09],\n",
      "        [9.9921e-01, 1.8817e-05, 1.8825e-05],\n",
      "        [9.9923e-01, 1.9320e-06, 1.9324e-06],\n",
      "        [9.9888e-01, 2.9151e-05, 2.9190e-05],\n",
      "        [9.9961e-01, 7.7622e-06, 7.7690e-06],\n",
      "        [9.9774e-01, 3.0542e-12, 3.0542e-12],\n",
      "        [9.9944e-01, 7.1111e-06, 7.1474e-06],\n",
      "        [9.9953e-01, 4.3326e-06, 4.3351e-06],\n",
      "        [9.9997e-01, 2.6856e-08, 2.6857e-08],\n",
      "        [9.9999e-01, 3.8734e-09, 3.8736e-09],\n",
      "        [9.9960e-01, 7.1975e-06, 7.1888e-06],\n",
      "        [9.9771e-01, 6.7855e-05, 6.7729e-05],\n",
      "        [9.9988e-01, 1.8704e-09, 1.8704e-09],\n",
      "        [9.9986e-01, 3.6760e-17, 3.6760e-17],\n",
      "        [9.9995e-01, 7.0653e-07, 7.0658e-07],\n",
      "        [9.9999e-01, 5.1182e-15, 5.1182e-15],\n",
      "        [9.9961e-01, 2.5143e-08, 2.5137e-08],\n",
      "        [9.9952e-01, 1.2184e-05, 1.2184e-05],\n",
      "        [9.9930e-01, 1.1415e-05, 1.1447e-05],\n",
      "        [9.9926e-01, 5.6071e-06, 5.6176e-06],\n",
      "        [9.9859e-01, 2.9626e-07, 2.9624e-07],\n",
      "        [9.9936e-01, 4.8342e-06, 4.8390e-06],\n",
      "        [9.9843e-01, 4.5379e-06, 4.5371e-06],\n",
      "        [9.9981e-01, 2.2146e-07, 2.2140e-07],\n",
      "        [9.9998e-01, 5.7566e-08, 5.7566e-08],\n",
      "        [9.9982e-01, 5.0465e-07, 5.0458e-07],\n",
      "        [9.9899e-01, 1.5646e-06, 1.5648e-06],\n",
      "        [9.9999e-01, 6.5014e-09, 6.5021e-09],\n",
      "        [9.9954e-01, 4.6041e-06, 4.6015e-06],\n",
      "        [9.9975e-01, 6.8186e-06, 6.8223e-06],\n",
      "        [9.9993e-01, 4.2666e-13, 4.2666e-13],\n",
      "        [9.9932e-01, 3.7359e-06, 3.7350e-06],\n",
      "        [9.9999e-01, 1.4403e-14, 1.4403e-14],\n",
      "        [9.9934e-01, 2.1293e-05, 2.1308e-05],\n",
      "        [9.9974e-01, 5.1486e-09, 5.1486e-09],\n",
      "        [9.9916e-01, 2.2229e-05, 2.2220e-05],\n",
      "        [9.9966e-01, 3.6703e-07, 3.6698e-07],\n",
      "        [9.9941e-01, 2.3025e-05, 2.3097e-05],\n",
      "        [9.9876e-01, 2.5597e-05, 2.5589e-05],\n",
      "        [9.9999e-01, 1.7347e-09, 1.7348e-09],\n",
      "        [9.9748e-01, 2.1820e-05, 2.1841e-05],\n",
      "        [9.9996e-01, 5.2267e-08, 5.2268e-08],\n",
      "        [9.9954e-01, 8.2988e-06, 8.2993e-06],\n",
      "        [9.9892e-01, 1.6136e-05, 1.6086e-05],\n",
      "        [9.9943e-01, 2.5042e-06, 2.5013e-06],\n",
      "        [9.9921e-01, 7.1543e-06, 7.1639e-06],\n",
      "        [9.9999e-01, 5.3538e-09, 5.3540e-09],\n",
      "        [1.0000e+00, 3.4448e-12, 3.4448e-12],\n",
      "        [9.9963e-01, 7.4102e-06, 7.4159e-06],\n",
      "        [9.9872e-01, 1.5692e-05, 1.5700e-05],\n",
      "        [9.9939e-01, 1.2182e-05, 1.2174e-05],\n",
      "        [9.9948e-01, 7.4055e-05, 7.3971e-05],\n",
      "        [9.9983e-01, 1.1563e-06, 1.1576e-06],\n",
      "        [9.9944e-01, 3.0772e-16, 3.0772e-16],\n",
      "        [9.9948e-01, 3.0032e-06, 3.0032e-06],\n",
      "        [9.9866e-01, 5.8101e-05, 5.8072e-05],\n",
      "        [9.9953e-01, 9.3369e-06, 9.3346e-06],\n",
      "        [9.9955e-01, 2.8710e-05, 2.8932e-05],\n",
      "        [9.9942e-01, 2.6397e-05, 2.6488e-05],\n",
      "        [9.9992e-01, 3.4459e-07, 3.4445e-07],\n",
      "        [9.9955e-01, 1.6012e-05, 1.6006e-05],\n",
      "        [9.9899e-01, 3.0174e-05, 3.0251e-05],\n",
      "        [9.9975e-01, 2.3825e-06, 2.3832e-06],\n",
      "        [9.9943e-01, 3.2065e-07, 3.2067e-07],\n",
      "        [9.9999e-01, 3.6500e-08, 3.6500e-08],\n",
      "        [9.9986e-01, 2.1711e-07, 2.1710e-07],\n",
      "        [9.9896e-01, 1.8229e-05, 1.8216e-05],\n",
      "        [1.0000e+00, 8.0150e-09, 8.0151e-09],\n",
      "        [9.9950e-01, 9.6580e-07, 9.6587e-07],\n",
      "        [9.9965e-01, 7.9999e-06, 8.0035e-06],\n",
      "        [9.9961e-01, 5.1620e-06, 5.1632e-06],\n",
      "        [9.9954e-01, 3.7013e-06, 3.7049e-06],\n",
      "        [9.9968e-01, 9.5620e-07, 9.5857e-07],\n",
      "        [9.9999e-01, 7.4798e-09, 7.4805e-09],\n",
      "        [9.9968e-01, 4.6440e-06, 4.6463e-06],\n",
      "        [9.9959e-01, 2.6843e-06, 2.6832e-06],\n",
      "        [9.9988e-01, 3.3671e-07, 3.3659e-07],\n",
      "        [9.9959e-01, 1.3157e-05, 1.3160e-05],\n",
      "        [9.9953e-01, 4.2683e-07, 4.2690e-07],\n",
      "        [9.9968e-01, 8.5771e-06, 8.5692e-06],\n",
      "        [9.9953e-01, 1.2537e-06, 1.2541e-06],\n",
      "        [9.9897e-01, 9.4886e-05, 9.4697e-05],\n",
      "        [9.9981e-01, 2.6047e-06, 2.6046e-06],\n",
      "        [9.9904e-01, 2.8199e-07, 2.8203e-07],\n",
      "        [9.9999e-01, 2.1156e-10, 2.1156e-10],\n",
      "        [9.9970e-01, 7.6987e-06, 7.6915e-06],\n",
      "        [9.9993e-01, 1.1391e-10, 1.1391e-10],\n",
      "        [9.9979e-01, 2.4553e-07, 2.4555e-07],\n",
      "        [9.9982e-01, 9.9013e-09, 9.9015e-09],\n",
      "        [9.9984e-01, 4.6203e-07, 4.6212e-07],\n",
      "        [9.9998e-01, 2.0649e-08, 2.0650e-08],\n",
      "        [9.9973e-01, 6.1573e-08, 6.1574e-08],\n",
      "        [1.0000e+00, 9.7120e-11, 9.7120e-11],\n",
      "        [9.9864e-01, 3.2608e-05, 3.2609e-05],\n",
      "        [9.9961e-01, 5.7134e-08, 5.7132e-08],\n",
      "        [9.9953e-01, 1.1061e-05, 1.1065e-05],\n",
      "        [1.0000e+00, 2.0494e-09, 2.0495e-09],\n",
      "        [9.9995e-01, 1.5476e-06, 1.5473e-06],\n",
      "        [9.9960e-01, 1.2141e-05, 1.2120e-05],\n",
      "        [9.9989e-01, 4.9524e-07, 4.9522e-07],\n",
      "        [9.9918e-01, 1.1282e-05, 1.1289e-05],\n",
      "        [9.9871e-01, 8.3134e-06, 8.3223e-06],\n",
      "        [9.9998e-01, 1.5120e-09, 1.5120e-09],\n",
      "        [9.9971e-01, 1.0546e-07, 1.0546e-07],\n",
      "        [9.9909e-01, 1.8695e-05, 1.8657e-05],\n",
      "        [9.9954e-01, 6.9625e-06, 6.9665e-06],\n",
      "        [9.9852e-01, 4.2386e-05, 4.2398e-05],\n",
      "        [9.9996e-01, 6.3735e-08, 6.3771e-08],\n",
      "        [9.9999e-01, 3.4160e-09, 3.4160e-09],\n",
      "        [9.9983e-01, 2.2944e-06, 2.2952e-06],\n",
      "        [9.9930e-01, 1.4675e-05, 1.4671e-05],\n",
      "        [9.9894e-01, 7.3612e-06, 7.3763e-06],\n",
      "        [9.9924e-01, 1.4814e-05, 1.4824e-05],\n",
      "        [9.9817e-01, 1.9510e-05, 1.9564e-05],\n",
      "        [9.9948e-01, 1.0427e-05, 1.0443e-05],\n",
      "        [9.9976e-01, 3.7163e-06, 3.7169e-06],\n",
      "        [9.9957e-01, 2.3726e-08, 2.3726e-08],\n",
      "        [1.0000e+00, 1.0309e-09, 1.0309e-09],\n",
      "        [9.9968e-01, 1.4067e-05, 1.4069e-05],\n",
      "        [9.9737e-01, 1.4140e-07, 1.4140e-07],\n",
      "        [9.9945e-01, 1.0644e-05, 1.0666e-05],\n",
      "        [9.9963e-01, 9.3836e-07, 9.3853e-07],\n",
      "        [9.9889e-01, 1.4321e-05, 1.4341e-05],\n",
      "        [9.9966e-01, 9.1115e-06, 9.0980e-06],\n",
      "        [9.9904e-01, 1.3810e-05, 1.3821e-05],\n",
      "        [9.9792e-01, 8.1522e-05, 8.1817e-05],\n",
      "        [9.9999e-01, 1.0910e-13, 1.0910e-13],\n",
      "        [9.9911e-01, 2.9162e-05, 2.9200e-05],\n",
      "        [9.9905e-01, 7.6630e-06, 7.6614e-06],\n",
      "        [9.9952e-01, 7.9708e-06, 7.9696e-06],\n",
      "        [9.9840e-01, 1.4205e-05, 1.4201e-05],\n",
      "        [9.9975e-01, 2.9521e-19, 2.9521e-19],\n",
      "        [9.9968e-01, 2.0754e-08, 2.0755e-08],\n",
      "        [9.9961e-01, 7.5074e-06, 7.5096e-06],\n",
      "        [9.9982e-01, 1.9925e-06, 1.9933e-06],\n",
      "        [9.9881e-01, 3.3842e-05, 3.3830e-05]], device='cuda:0'), tensor([[7.7926e-01, 4.8260e-03, 1.6651e-05],\n",
      "        [7.4649e-01, 1.5552e-02, 7.0363e-07],\n",
      "        [6.3471e-01, 1.6382e-02, 3.2626e-05],\n",
      "        [6.8438e-01, 5.2496e-02, 7.1909e-04],\n",
      "        [7.2540e-01, 1.0541e-01, 1.3009e-03],\n",
      "        [4.3293e-01, 1.5904e-01, 1.3599e-03],\n",
      "        [5.0214e-01, 6.0276e-02, 9.5966e-05],\n",
      "        [3.1411e-01, 2.7330e-01, 1.6703e-03],\n",
      "        [3.6810e-01, 1.6538e-03, 1.8571e-07],\n",
      "        [3.8048e-01, 2.4882e-01, 1.8059e-03],\n",
      "        [6.9506e-01, 1.3074e-02, 2.1712e-05],\n",
      "        [6.3482e-01, 1.1538e-02, 2.2993e-05],\n",
      "        [4.3030e-01, 2.4124e-01, 2.7242e-03],\n",
      "        [2.8863e-01, 2.4954e-01, 8.3317e-04],\n",
      "        [5.6001e-01, 7.5223e-02, 2.6552e-03],\n",
      "        [5.0060e-01, 1.8113e-01, 1.3312e-03],\n",
      "        [4.3234e-01, 6.9730e-02, 1.0719e-06],\n",
      "        [6.6739e-01, 2.4706e-02, 9.3176e-04],\n",
      "        [2.3070e-01, 2.1323e-01, 1.3311e-03],\n",
      "        [5.2648e-01, 4.5543e-02, 9.1384e-05],\n",
      "        [7.5435e-01, 2.0524e-02, 1.9061e-05],\n",
      "        [3.2873e-01, 1.1355e-01, 1.6398e-03],\n",
      "        [5.3184e-01, 1.6338e-01, 3.4806e-03],\n",
      "        [5.4015e-01, 2.4080e-02, 9.4974e-06],\n",
      "        [5.1008e-01, 1.2310e-02, 4.9703e-09],\n",
      "        [5.4332e-01, 1.8178e-02, 2.0346e-04],\n",
      "        [4.2399e-01, 2.2188e-02, 2.9854e-08],\n",
      "        [4.3322e-01, 3.6599e-02, 1.1461e-04],\n",
      "        [4.6063e-01, 1.3358e-01, 1.7192e-03],\n",
      "        [4.8127e-01, 1.1813e-01, 6.5342e-04],\n",
      "        [2.1976e-01, 3.0342e-01, 1.7648e-03],\n",
      "        [5.9358e-01, 7.7280e-02, 2.5121e-04],\n",
      "        [3.4020e-01, 2.2572e-01, 1.6144e-03],\n",
      "        [4.6927e-01, 1.8988e-01, 1.5300e-03],\n",
      "        [4.0482e-01, 6.3584e-02, 3.0296e-04],\n",
      "        [9.2145e-01, 4.4687e-03, 2.8507e-05],\n",
      "        [5.4469e-01, 3.8209e-02, 2.4623e-04],\n",
      "        [5.5811e-01, 2.0905e-02, 2.8656e-04],\n",
      "        [3.8123e-01, 3.0540e-02, 4.1022e-05],\n",
      "        [4.2205e-01, 1.8396e-01, 1.3638e-03],\n",
      "        [4.4815e-01, 9.1717e-02, 9.6484e-04],\n",
      "        [6.9932e-01, 2.6043e-02, 8.7873e-07],\n",
      "        [7.3227e-01, 5.1125e-02, 9.4371e-04],\n",
      "        [7.6526e-01, 4.6952e-04, 1.8233e-08],\n",
      "        [3.4752e-01, 2.9428e-01, 2.1552e-03],\n",
      "        [6.0175e-01, 1.5525e-02, 2.0888e-05],\n",
      "        [7.2585e-01, 4.8161e-02, 1.8834e-03],\n",
      "        [3.2321e-01, 9.9940e-02, 3.3039e-04],\n",
      "        [4.3656e-01, 1.2692e-01, 3.3826e-03],\n",
      "        [5.3547e-01, 1.4031e-01, 2.2512e-03],\n",
      "        [6.9534e-01, 8.0892e-03, 1.2472e-05],\n",
      "        [5.9882e-01, 9.8198e-02, 1.6658e-03],\n",
      "        [9.0084e-01, 2.4322e-03, 3.0242e-05],\n",
      "        [5.0537e-01, 1.1975e-01, 1.6426e-03],\n",
      "        [3.9889e-01, 1.5087e-01, 2.4580e-03],\n",
      "        [4.0094e-01, 5.5095e-02, 1.7009e-03],\n",
      "        [6.1280e-01, 1.5022e-01, 1.4643e-03],\n",
      "        [6.6894e-01, 2.3741e-02, 2.0520e-05],\n",
      "        [7.8222e-01, 2.5714e-03, 3.2586e-07],\n",
      "        [4.6288e-01, 1.7863e-01, 1.2680e-03],\n",
      "        [3.7716e-01, 2.0388e-01, 2.6055e-03],\n",
      "        [6.7498e-01, 1.0613e-01, 1.5303e-03],\n",
      "        [4.6059e-01, 1.8516e-01, 3.1509e-03],\n",
      "        [1.9930e-01, 2.5441e-01, 3.1913e-04],\n",
      "        [2.2825e-01, 6.9276e-02, 5.8443e-09],\n",
      "        [2.2929e-01, 3.0486e-01, 1.1017e-03],\n",
      "        [4.1461e-01, 2.6862e-01, 3.9100e-03],\n",
      "        [4.9712e-01, 1.7448e-01, 1.2408e-03],\n",
      "        [5.6354e-01, 8.9969e-02, 2.2205e-03],\n",
      "        [3.2716e-01, 2.1715e-01, 2.7013e-03],\n",
      "        [4.7988e-01, 5.9094e-02, 1.4387e-04],\n",
      "        [7.4162e-01, 1.8802e-02, 1.1007e-03],\n",
      "        [3.1829e-01, 1.8992e-01, 1.9830e-03],\n",
      "        [5.4299e-01, 6.8257e-02, 7.7225e-04],\n",
      "        [5.8017e-01, 2.0495e-02, 1.9441e-04],\n",
      "        [3.8215e-01, 4.6327e-02, 4.3649e-05],\n",
      "        [7.0679e-01, 3.3000e-02, 1.3576e-04],\n",
      "        [4.9690e-01, 9.6294e-02, 1.6805e-03],\n",
      "        [7.2949e-01, 4.7217e-03, 6.4852e-06],\n",
      "        [3.6019e-01, 7.8324e-02, 8.7958e-04],\n",
      "        [3.9621e-01, 1.6967e-01, 1.8869e-03],\n",
      "        [5.0837e-01, 5.2716e-02, 1.3587e-03],\n",
      "        [5.9418e-01, 4.7007e-02, 8.1999e-04],\n",
      "        [3.9012e-01, 1.1695e-01, 9.0426e-04],\n",
      "        [6.8379e-01, 2.1924e-02, 2.9772e-05],\n",
      "        [2.2745e-01, 3.6461e-01, 1.9965e-03],\n",
      "        [6.0045e-01, 6.6113e-02, 1.2336e-03],\n",
      "        [2.6189e-01, 2.8815e-01, 5.5188e-04],\n",
      "        [3.6629e-01, 1.9922e-01, 1.5345e-03],\n",
      "        [8.1372e-01, 5.9328e-03, 7.1138e-05],\n",
      "        [2.4380e-01, 2.7076e-01, 2.1402e-03],\n",
      "        [2.2897e-01, 3.4665e-01, 1.3610e-03],\n",
      "        [5.6203e-01, 1.3302e-01, 2.9231e-03],\n",
      "        [3.1744e-01, 1.9193e-01, 9.2705e-04],\n",
      "        [5.1721e-01, 1.4954e-01, 3.0217e-04],\n",
      "        [5.6393e-01, 9.9547e-03, 3.4003e-06],\n",
      "        [5.1830e-01, 2.1743e-01, 1.8864e-03],\n",
      "        [6.8719e-01, 9.2723e-03, 1.5272e-06],\n",
      "        [4.8751e-01, 4.3952e-02, 2.5311e-04],\n",
      "        [7.2011e-01, 6.4172e-03, 1.9442e-05],\n",
      "        [4.4625e-01, 5.3341e-02, 4.5693e-04],\n",
      "        [5.7882e-01, 3.4233e-02, 1.1837e-04],\n",
      "        [6.7876e-01, 5.9008e-02, 1.1882e-04],\n",
      "        [6.3516e-01, 1.6669e-02, 2.3553e-06],\n",
      "        [5.3072e-01, 1.7599e-01, 2.9896e-03],\n",
      "        [8.1046e-01, 4.0914e-03, 2.5961e-05],\n",
      "        [6.0638e-01, 9.3686e-02, 1.1992e-03],\n",
      "        [7.1192e-01, 3.3430e-03, 1.0595e-05],\n",
      "        [4.6637e-01, 1.4150e-01, 7.4949e-04],\n",
      "        [3.5117e-01, 1.5188e-01, 1.9207e-03],\n",
      "        [6.1549e-01, 3.1993e-02, 2.1665e-04],\n",
      "        [4.5443e-01, 1.6175e-01, 1.2147e-03],\n",
      "        [3.6369e-01, 1.4529e-01, 1.3768e-03],\n",
      "        [7.0043e-01, 3.7096e-03, 7.0745e-06],\n",
      "        [6.2649e-01, 5.6670e-03, 3.8577e-05],\n",
      "        [3.3610e-01, 1.0142e-01, 3.1797e-03],\n",
      "        [3.2672e-01, 3.0226e-01, 1.0402e-03],\n",
      "        [4.6701e-01, 2.6858e-01, 3.6779e-03],\n",
      "        [5.0054e-01, 1.8229e-02, 5.5689e-05],\n",
      "        [6.1137e-01, 1.3880e-02, 1.1451e-05],\n",
      "        [5.4001e-01, 3.8481e-02, 3.3452e-04],\n",
      "        [7.6826e-01, 1.9145e-02, 6.8473e-04],\n",
      "        [4.9640e-01, 1.0496e-01, 2.0253e-03],\n",
      "        [5.0039e-01, 1.0639e-01, 2.1815e-03],\n",
      "        [6.1720e-01, 1.1976e-01, 2.0417e-03],\n",
      "        [4.4001e-01, 2.2431e-01, 1.4537e-03],\n",
      "        [5.1327e-01, 8.3151e-02, 1.2780e-03],\n",
      "        [2.5441e-01, 3.8528e-02, 6.9087e-05],\n",
      "        [7.2104e-01, 1.0865e-02, 8.9154e-06],\n",
      "        [3.3732e-01, 1.7718e-01, 2.5317e-03],\n",
      "        [5.0999e-01, 1.0245e-01, 2.2183e-04],\n",
      "        [3.9290e-01, 1.6293e-01, 1.9567e-03],\n",
      "        [5.7895e-01, 5.7440e-02, 3.6317e-04],\n",
      "        [5.6285e-01, 1.2909e-01, 1.8586e-03],\n",
      "        [3.8204e-01, 2.7348e-01, 1.3505e-03],\n",
      "        [6.6828e-01, 5.2073e-02, 1.8138e-03],\n",
      "        [5.9349e-01, 1.0494e-01, 2.9611e-03],\n",
      "        [6.3107e-01, 6.1207e-04, 1.3561e-07],\n",
      "        [3.4988e-01, 2.6726e-01, 2.5059e-03],\n",
      "        [7.3846e-01, 2.7074e-02, 1.0442e-03],\n",
      "        [4.9958e-01, 1.3526e-01, 1.3290e-03],\n",
      "        [4.2938e-01, 1.0729e-01, 2.1429e-03],\n",
      "        [2.3668e-01, 5.3282e-03, 1.6752e-10],\n",
      "        [5.5669e-01, 3.9632e-02, 7.6209e-05],\n",
      "        [4.5733e-01, 9.5902e-02, 2.1524e-03],\n",
      "        [6.8624e-01, 1.3447e-02, 3.5528e-04],\n",
      "        [4.5732e-01, 1.0304e-01, 2.9450e-03]], device='cuda:0'), tensor([[3.2291e-04, 9.6957e-01, 3.0589e-04, 2.8741e-04],\n",
      "        [1.6324e-06, 9.9591e-01, 1.4121e-06, 1.4037e-06],\n",
      "        [1.6823e-04, 9.6531e-01, 1.6410e-04, 1.6260e-04],\n",
      "        [1.9420e-03, 9.3365e-01, 1.8733e-03, 1.8334e-03],\n",
      "        [2.9078e-03, 9.2022e-01, 2.5159e-03, 2.3509e-03],\n",
      "        [3.2647e-03, 9.2550e-01, 3.0363e-03, 2.8215e-03],\n",
      "        [1.8507e-04, 9.4123e-01, 1.8325e-04, 1.8124e-04],\n",
      "        [3.2509e-03, 8.9721e-01, 2.6566e-03, 2.4924e-03],\n",
      "        [7.7621e-07, 9.8787e-01, 7.6919e-07, 7.6714e-07],\n",
      "        [2.5984e-03, 9.2826e-01, 2.5355e-03, 2.2971e-03],\n",
      "        [2.4564e-04, 9.6814e-01, 2.4465e-04, 2.4036e-04],\n",
      "        [4.4560e-04, 9.5679e-01, 4.4390e-04, 4.3103e-04],\n",
      "        [4.0553e-03, 9.4118e-01, 3.7535e-03, 3.3973e-03],\n",
      "        [3.2666e-03, 9.4766e-01, 2.4419e-03, 2.4139e-03],\n",
      "        [5.2815e-03, 8.8173e-01, 4.8975e-03, 4.7954e-03],\n",
      "        [3.3767e-03, 9.1832e-01, 3.1630e-03, 3.0883e-03],\n",
      "        [1.7775e-06, 9.1759e-01, 1.7757e-06, 1.7749e-06],\n",
      "        [3.0580e-03, 9.3243e-01, 2.9576e-03, 2.8384e-03],\n",
      "        [2.0492e-03, 9.4395e-01, 1.9062e-03, 1.8466e-03],\n",
      "        [2.1263e-04, 9.8494e-01, 2.2094e-04, 2.0648e-04],\n",
      "        [8.1998e-05, 9.8750e-01, 7.2662e-05, 7.0067e-05],\n",
      "        [3.6385e-03, 9.2835e-01, 3.7347e-03, 3.1384e-03],\n",
      "        [1.0173e-02, 8.7674e-01, 9.2298e-03, 8.5531e-03],\n",
      "        [6.4860e-05, 9.4557e-01, 6.3318e-05, 6.3257e-05],\n",
      "        [3.1707e-08, 9.2087e-01, 3.1071e-08, 3.0989e-08],\n",
      "        [9.8998e-04, 9.6984e-01, 9.6261e-04, 9.0740e-04],\n",
      "        [1.9906e-07, 9.8589e-01, 1.9870e-07, 1.9855e-07],\n",
      "        [1.3896e-04, 9.5025e-01, 1.3691e-04, 1.3572e-04],\n",
      "        [4.7892e-03, 9.2942e-01, 4.6108e-03, 4.4452e-03],\n",
      "        [4.0577e-03, 9.1427e-01, 3.5051e-03, 3.3093e-03],\n",
      "        [3.7422e-03, 8.6452e-01, 3.5223e-03, 3.1499e-03],\n",
      "        [4.9266e-04, 8.9698e-01, 4.5651e-04, 4.5292e-04],\n",
      "        [2.3009e-03, 9.1090e-01, 2.0747e-03, 1.9557e-03],\n",
      "        [2.7721e-03, 9.2311e-01, 2.5777e-03, 2.5113e-03],\n",
      "        [7.7038e-04, 9.3653e-01, 7.1762e-04, 6.6166e-04],\n",
      "        [1.7245e-04, 9.7167e-01, 1.6682e-04, 1.6238e-04],\n",
      "        [6.5548e-04, 9.3743e-01, 6.0843e-04, 5.9439e-04],\n",
      "        [1.1956e-03, 9.2542e-01, 1.0870e-03, 1.0461e-03],\n",
      "        [1.6625e-04, 9.8452e-01, 1.5581e-04, 1.5508e-04],\n",
      "        [5.4072e-03, 9.1617e-01, 4.1500e-03, 3.7732e-03],\n",
      "        [2.6424e-03, 9.6651e-01, 2.4860e-03, 2.3035e-03],\n",
      "        [1.2015e-06, 9.8804e-01, 1.1173e-06, 1.1159e-06],\n",
      "        [2.8064e-03, 9.0265e-01, 2.2967e-03, 2.2304e-03],\n",
      "        [1.7697e-07, 9.9258e-01, 1.7361e-07, 1.7355e-07],\n",
      "        [6.0167e-03, 9.1856e-01, 4.2615e-03, 4.0672e-03],\n",
      "        [1.4282e-04, 9.5885e-01, 1.4207e-04, 1.4050e-04],\n",
      "        [4.3296e-03, 9.0635e-01, 3.6317e-03, 3.3896e-03],\n",
      "        [1.2445e-03, 9.4353e-01, 1.1154e-03, 1.0655e-03],\n",
      "        [7.8078e-03, 9.2687e-01, 7.1909e-03, 6.5294e-03],\n",
      "        [7.2766e-03, 8.7393e-01, 7.4382e-03, 6.5654e-03],\n",
      "        [8.7334e-05, 9.8983e-01, 8.3231e-05, 8.2688e-05],\n",
      "        [5.8302e-03, 9.1320e-01, 4.7851e-03, 4.4248e-03],\n",
      "        [2.1387e-04, 9.7707e-01, 2.0562e-04, 2.0506e-04],\n",
      "        [4.3781e-03, 9.1876e-01, 4.1483e-03, 3.4840e-03],\n",
      "        [6.0028e-03, 9.0842e-01, 4.6313e-03, 4.4011e-03],\n",
      "        [2.1876e-03, 9.0725e-01, 2.1653e-03, 1.9512e-03],\n",
      "        [2.2352e-03, 9.2131e-01, 2.0173e-03, 1.9930e-03],\n",
      "        [4.3696e-05, 9.7994e-01, 4.1988e-05, 4.0610e-05],\n",
      "        [2.8122e-06, 9.9593e-01, 2.6049e-06, 2.6035e-06],\n",
      "        [3.3480e-03, 9.4770e-01, 3.1770e-03, 3.1080e-03],\n",
      "        [7.0671e-03, 8.6164e-01, 6.8703e-03, 6.2327e-03],\n",
      "        [3.5935e-03, 9.0710e-01, 3.2568e-03, 3.0706e-03],\n",
      "        [7.7280e-03, 9.1214e-01, 7.4897e-03, 6.9556e-03],\n",
      "        [1.5575e-03, 9.6504e-01, 1.6575e-03, 1.5022e-03],\n",
      "        [1.4299e-07, 9.4762e-01, 1.4302e-07, 1.4292e-07],\n",
      "        [1.7493e-03, 9.4706e-01, 1.5792e-03, 1.5218e-03],\n",
      "        [9.9257e-03, 9.2180e-01, 9.6971e-03, 9.0958e-03],\n",
      "        [4.6646e-03, 9.1325e-01, 4.2573e-03, 4.1276e-03],\n",
      "        [5.6004e-03, 9.2003e-01, 5.4507e-03, 5.0157e-03],\n",
      "        [6.9860e-03, 9.4870e-01, 6.9761e-03, 6.1027e-03],\n",
      "        [4.0280e-04, 9.8508e-01, 3.9455e-04, 3.8302e-04],\n",
      "        [5.9909e-03, 9.1847e-01, 5.5405e-03, 5.4067e-03],\n",
      "        [9.2666e-03, 9.2463e-01, 8.0967e-03, 7.6209e-03],\n",
      "        [2.5391e-03, 9.3916e-01, 2.4009e-03, 2.2547e-03],\n",
      "        [5.3256e-04, 9.6636e-01, 4.8648e-04, 4.7484e-04],\n",
      "        [3.9535e-04, 9.6873e-01, 4.0011e-04, 3.9282e-04],\n",
      "        [4.9975e-04, 9.7163e-01, 4.6479e-04, 4.6190e-04],\n",
      "        [7.0013e-03, 8.7447e-01, 6.2025e-03, 6.0814e-03],\n",
      "        [1.7319e-04, 9.8128e-01, 1.5999e-04, 1.5783e-04],\n",
      "        [1.7564e-03, 9.4472e-01, 1.6839e-03, 1.6723e-03],\n",
      "        [3.5929e-03, 9.3664e-01, 3.5990e-03, 3.0183e-03],\n",
      "        [4.0450e-03, 9.4545e-01, 3.8173e-03, 3.4997e-03],\n",
      "        [1.8165e-03, 9.3870e-01, 1.7397e-03, 1.6633e-03],\n",
      "        [1.5025e-03, 9.3147e-01, 1.4928e-03, 1.4532e-03],\n",
      "        [1.6603e-04, 9.7814e-01, 1.6162e-04, 1.5698e-04],\n",
      "        [5.4792e-03, 9.3571e-01, 5.1134e-03, 4.7731e-03],\n",
      "        [2.1459e-03, 9.5082e-01, 2.0721e-03, 2.0153e-03],\n",
      "        [9.4811e-04, 9.7429e-01, 8.2635e-04, 7.8331e-04],\n",
      "        [4.3449e-03, 9.4023e-01, 3.6164e-03, 3.3490e-03],\n",
      "        [4.9358e-04, 9.4214e-01, 5.1494e-04, 4.5905e-04],\n",
      "        [5.7945e-03, 9.3640e-01, 5.2516e-03, 5.0528e-03],\n",
      "        [1.2969e-03, 9.2209e-01, 1.2339e-03, 1.1962e-03],\n",
      "        [9.6996e-03, 9.0886e-01, 9.5762e-03, 8.8358e-03],\n",
      "        [1.9581e-03, 9.1963e-01, 1.8848e-03, 1.7857e-03],\n",
      "        [4.1094e-04, 9.2621e-01, 3.7213e-04, 3.6608e-04],\n",
      "        [4.3826e-05, 9.9318e-01, 3.6862e-05, 3.6826e-05],\n",
      "        [3.6919e-03, 9.3874e-01, 3.2727e-03, 3.1228e-03],\n",
      "        [2.1031e-05, 9.8898e-01, 2.0791e-05, 2.0774e-05],\n",
      "        [7.0071e-04, 9.3717e-01, 6.7593e-04, 6.5688e-04],\n",
      "        [2.1515e-04, 9.4747e-01, 2.0214e-04, 2.0129e-04],\n",
      "        [8.1941e-04, 9.6289e-01, 8.1232e-04, 7.9797e-04],\n",
      "        [4.3455e-04, 9.8644e-01, 4.3068e-04, 4.2302e-04],\n",
      "        [2.4172e-04, 9.3222e-01, 2.3062e-04, 2.2865e-04],\n",
      "        [1.6673e-05, 9.9578e-01, 1.6520e-05, 1.6511e-05],\n",
      "        [7.3847e-03, 9.0025e-01, 6.5118e-03, 6.2242e-03],\n",
      "        [4.7805e-04, 9.4934e-01, 4.2452e-04, 4.2357e-04],\n",
      "        [8.3145e-03, 9.1376e-01, 6.6694e-03, 6.5275e-03],\n",
      "        [6.3935e-05, 9.7810e-01, 6.4127e-05, 6.0266e-05],\n",
      "        [1.7056e-03, 9.3436e-01, 1.6501e-03, 1.5651e-03],\n",
      "        [4.2288e-03, 9.3017e-01, 4.1768e-03, 3.9029e-03],\n",
      "        [7.2646e-04, 9.6016e-01, 7.2341e-04, 6.9747e-04],\n",
      "        [5.2298e-03, 9.1748e-01, 5.3560e-03, 4.9314e-03],\n",
      "        [4.9441e-03, 8.9912e-01, 4.8491e-03, 4.4001e-03],\n",
      "        [5.9048e-05, 9.8456e-01, 5.4091e-05, 5.3808e-05],\n",
      "        [4.0320e-04, 9.4373e-01, 3.6652e-04, 3.6248e-04],\n",
      "        [6.1888e-03, 8.8146e-01, 5.6301e-03, 5.3130e-03],\n",
      "        [4.9296e-03, 9.1081e-01, 4.2144e-03, 3.9951e-03],\n",
      "        [8.9101e-03, 8.5281e-01, 8.1742e-03, 7.6362e-03],\n",
      "        [2.7544e-04, 9.9040e-01, 2.8557e-04, 2.7044e-04],\n",
      "        [5.7274e-05, 9.9153e-01, 5.0728e-05, 5.0360e-05],\n",
      "        [1.5345e-03, 9.5107e-01, 1.5190e-03, 1.4568e-03],\n",
      "        [4.4738e-03, 9.3277e-01, 4.0344e-03, 3.7890e-03],\n",
      "        [3.7378e-03, 9.1413e-01, 3.1964e-03, 2.9723e-03],\n",
      "        [2.5524e-03, 8.9849e-01, 2.5507e-03, 2.3546e-03],\n",
      "        [7.1414e-03, 9.1550e-01, 6.5542e-03, 6.3417e-03],\n",
      "        [3.7062e-03, 9.2679e-01, 2.9152e-03, 2.7220e-03],\n",
      "        [3.8215e-03, 9.4145e-01, 3.7271e-03, 3.2543e-03],\n",
      "        [1.0805e-04, 9.1760e-01, 9.8902e-05, 9.8298e-05],\n",
      "        [1.0606e-04, 9.9624e-01, 1.0495e-04, 1.0388e-04],\n",
      "        [6.5790e-03, 9.1417e-01, 6.3414e-03, 6.0507e-03],\n",
      "        [6.9954e-04, 8.8582e-01, 6.9900e-04, 6.7674e-04],\n",
      "        [2.9294e-03, 9.3167e-01, 2.4293e-03, 2.3821e-03],\n",
      "        [9.7688e-04, 9.4047e-01, 9.3995e-04, 9.3029e-04],\n",
      "        [3.9645e-03, 9.3446e-01, 3.5857e-03, 3.4093e-03],\n",
      "        [3.8023e-03, 9.1983e-01, 3.7732e-03, 3.6226e-03],\n",
      "        [5.3930e-03, 9.1690e-01, 4.7428e-03, 4.6057e-03],\n",
      "        [1.0241e-02, 8.9968e-01, 8.8361e-03, 8.3085e-03],\n",
      "        [8.9057e-07, 9.8868e-01, 8.8832e-07, 8.8775e-07],\n",
      "        [9.9867e-03, 9.4565e-01, 9.4789e-03, 8.7577e-03],\n",
      "        [4.6536e-03, 9.1575e-01, 4.3922e-03, 4.0906e-03],\n",
      "        [2.0127e-03, 9.3552e-01, 2.0109e-03, 1.9214e-03],\n",
      "        [5.2119e-03, 9.0175e-01, 5.4729e-03, 4.7727e-03],\n",
      "        [1.6453e-09, 9.6588e-01, 1.6290e-09, 1.6289e-09],\n",
      "        [1.1672e-04, 9.4925e-01, 1.2064e-04, 1.1470e-04],\n",
      "        [4.5050e-03, 9.3143e-01, 3.8404e-03, 3.7413e-03],\n",
      "        [1.6969e-03, 9.5136e-01, 1.7123e-03, 1.5250e-03],\n",
      "        [9.6891e-03, 9.3201e-01, 7.8274e-03, 7.3278e-03]], device='cuda:0'), tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.9032e-04, 3.8735e-06, 7.7611e-05, 9.8721e-05, 1.3336e-04],\n",
      "        [3.4738e-03, 1.8996e-04, 6.5502e-04, 9.2955e-04, 1.9246e-03],\n",
      "        [1.5353e-02, 3.9886e-03, 6.3205e-03, 1.1254e-02, 4.5485e-03],\n",
      "        [1.3973e-02, 5.1620e-03, 6.9212e-03, 1.3267e-02, 1.1363e-02],\n",
      "        [1.5238e-02, 4.7053e-03, 8.5128e-03, 1.4919e-02, 1.1999e-02],\n",
      "        [1.7540e-03, 2.5497e-04, 6.2980e-04, 4.8171e-04, 1.2896e-03],\n",
      "        [1.0942e-02, 2.8723e-03, 5.4223e-03, 1.1543e-02, 9.3698e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.9535e-03, 1.4927e-04, 2.2669e-04, 1.1451e-03, 1.2011e-03],\n",
      "        [3.8860e-03, 1.3788e-04, 6.6011e-04, 6.5995e-04, 1.4755e-03],\n",
      "        [1.3210e-02, 7.2936e-03, 8.7685e-03, 1.0894e-02, 1.3128e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.1383e-02, 5.0608e-03, 1.0084e-02, 1.1017e-02, 1.0151e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.8367e-05, 2.0931e-06, 2.6447e-06, 6.0748e-05, 2.1751e-05],\n",
      "        [1.7106e-02, 2.8896e-03, 5.2875e-03, 7.5559e-03, 9.3360e-03],\n",
      "        [1.0565e-02, 3.3316e-03, 5.8912e-03, 5.9683e-03, 1.5981e-02],\n",
      "        [3.5919e-03, 1.3711e-04, 6.5340e-04, 1.6786e-03, 1.2244e-03],\n",
      "        [2.0022e-03, 1.8179e-04, 1.4662e-04, 7.5928e-04, 6.5398e-04],\n",
      "        [1.5255e-02, 4.5153e-03, 7.2966e-03, 7.6319e-03, 6.6375e-03],\n",
      "        [2.9237e-02, 8.4319e-03, 1.4371e-02, 1.9849e-02, 1.5919e-02],\n",
      "        [1.1173e-03, 5.8376e-05, 1.1426e-04, 1.6556e-04, 1.6382e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4085e-02, 5.8512e-04, 2.4586e-03, 4.4496e-03, 3.3991e-03],\n",
      "        [4.1034e-06, 5.1162e-07, 1.6858e-07, 3.5914e-07, 2.4784e-06],\n",
      "        [6.6964e-03, 2.0225e-04, 8.5852e-04, 1.1653e-03, 8.0099e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.5364e-02, 3.8248e-03, 5.7361e-03, 5.9733e-03, 1.1301e-02],\n",
      "        [6.9404e-03, 1.1947e-03, 1.5201e-03, 2.8681e-03, 2.4579e-03],\n",
      "        [1.3324e-02, 1.9310e-03, 4.6728e-03, 9.5577e-03, 1.1933e-02],\n",
      "        [1.3134e-02, 3.3373e-03, 8.1877e-03, 1.1638e-02, 9.4980e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.2710e-03, 2.8638e-04, 1.4901e-03, 3.8167e-03, 8.5923e-04],\n",
      "        [1.3381e-02, 1.5778e-03, 2.4364e-03, 2.5634e-03, 6.6263e-03],\n",
      "        [8.7165e-03, 1.2485e-03, 5.9164e-03, 5.9406e-03, 7.3849e-03],\n",
      "        [1.5607e-03, 5.1270e-05, 2.0180e-04, 3.1957e-04, 1.5865e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1387e-02, 2.5113e-03, 5.1741e-03, 9.1495e-03, 7.9384e-03],\n",
      "        [1.7246e-04, 1.2670e-05, 7.8020e-06, 3.2919e-05, 5.4402e-05],\n",
      "        [2.3351e-02, 1.9090e-03, 7.5173e-03, 1.1393e-02, 7.2454e-03],\n",
      "        [7.5757e-05, 5.3579e-08, 2.8274e-06, 1.1951e-05, 6.1010e-06],\n",
      "        [1.6596e-02, 4.2875e-03, 7.3497e-03, 9.2153e-03, 1.2009e-02],\n",
      "        [4.4061e-03, 1.1164e-04, 2.3752e-04, 7.0665e-04, 8.8839e-04],\n",
      "        [2.0877e-02, 5.4897e-03, 1.0893e-02, 1.7797e-02, 1.3523e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3677e-02, 5.3174e-03, 6.2441e-03, 9.8632e-03, 1.0584e-02],\n",
      "        [1.7603e-02, 4.1653e-03, 1.2196e-02, 1.3355e-02, 1.4276e-02],\n",
      "        [2.7885e-03, 9.6301e-05, 2.3100e-04, 3.1390e-04, 8.2992e-04],\n",
      "        [1.6730e-02, 4.5848e-03, 9.7949e-03, 1.2672e-02, 1.0763e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4785e-02, 3.4554e-03, 6.8025e-03, 7.0411e-03, 8.9758e-03],\n",
      "        [1.8475e-02, 6.5678e-03, 1.5069e-02, 9.8124e-03, 2.3819e-02],\n",
      "        [2.6781e-02, 5.7087e-03, 7.7980e-03, 1.5427e-02, 1.0698e-02],\n",
      "        [2.8729e-02, 5.0948e-03, 4.5840e-03, 6.2171e-03, 1.0067e-02],\n",
      "        [1.7813e-03, 5.1835e-05, 6.0951e-04, 3.5936e-04, 3.4669e-04],\n",
      "        [5.7274e-04, 3.2583e-06, 3.2875e-05, 3.8686e-05, 8.3821e-05],\n",
      "        [1.4820e-02, 1.9519e-03, 4.4136e-03, 4.2496e-03, 6.6980e-03],\n",
      "        [1.7368e-02, 4.2801e-03, 8.6285e-03, 8.9424e-03, 1.5123e-02],\n",
      "        [2.0635e-02, 3.6507e-03, 8.6609e-03, 1.1137e-02, 1.3955e-02],\n",
      "        [3.2985e-02, 6.1765e-03, 1.4826e-02, 1.3313e-02, 1.2194e-02],\n",
      "        [6.3595e-03, 1.9456e-03, 2.3591e-03, 4.3313e-03, 5.5431e-03],\n",
      "        [2.3401e-06, 1.2640e-07, 1.8774e-07, 7.1466e-07, 4.9731e-07],\n",
      "        [1.1014e-02, 1.5965e-03, 4.8948e-03, 6.4007e-03, 7.9053e-03],\n",
      "        [2.6438e-02, 7.2393e-03, 2.0284e-02, 1.4430e-02, 2.3962e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.3407e-02, 5.9421e-03, 1.2711e-02, 1.7108e-02, 2.1106e-02],\n",
      "        [2.3546e-02, 4.1370e-03, 8.4470e-03, 1.4305e-02, 1.1569e-02],\n",
      "        [7.4463e-03, 1.2209e-03, 1.3061e-03, 3.9248e-03, 3.2940e-03],\n",
      "        [1.8858e-02, 4.9271e-03, 8.2772e-03, 9.6518e-03, 1.1344e-02],\n",
      "        [1.4470e-02, 7.0527e-03, 1.0403e-02, 1.1868e-02, 1.6514e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.2785e-03, 7.1715e-04, 1.2837e-03, 3.3731e-03, 2.2750e-03],\n",
      "        [4.3009e-03, 3.6343e-04, 6.8872e-04, 8.8484e-04, 6.9337e-04],\n",
      "        [5.4295e-03, 4.7099e-04, 9.4357e-04, 2.5865e-03, 1.9861e-03],\n",
      "        [3.4145e-02, 5.1476e-03, 9.9672e-03, 1.1783e-02, 1.5725e-02],\n",
      "        [1.8747e-03, 1.5534e-04, 1.7588e-04, 5.1524e-04, 7.5801e-04],\n",
      "        [6.0469e-03, 1.7071e-03, 3.5392e-03, 6.7613e-03, 5.3529e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.7643e-02, 3.7286e-03, 7.9941e-03, 8.8772e-03, 9.4613e-03],\n",
      "        [1.7674e-02, 2.6260e-03, 3.5327e-03, 1.0514e-02, 8.3924e-03],\n",
      "        [1.8483e-02, 1.2604e-03, 2.0423e-03, 5.6521e-03, 5.1225e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5345e-02, 7.4748e-03, 7.6616e-03, 9.8136e-03, 1.4764e-02],\n",
      "        [1.3685e-02, 1.1937e-03, 4.1805e-03, 6.5259e-03, 8.6834e-03],\n",
      "        [5.2829e-03, 9.2955e-04, 1.3062e-03, 3.4922e-03, 2.4373e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2293e-02, 6.7379e-04, 1.7742e-03, 3.9484e-03, 3.6333e-03],\n",
      "        [1.5613e-02, 3.2847e-03, 1.0623e-02, 7.6993e-03, 1.3525e-02],\n",
      "        [5.0390e-03, 2.6763e-03, 2.8400e-03, 5.3937e-03, 8.4953e-03],\n",
      "        [2.7249e-02, 8.5727e-03, 1.0932e-02, 1.2689e-02, 2.5922e-02],\n",
      "        [1.1352e-02, 1.7800e-03, 2.9918e-03, 9.4561e-03, 8.1412e-03],\n",
      "        [1.5484e-02, 1.1629e-03, 1.5608e-03, 2.2363e-03, 3.1901e-03],\n",
      "        [9.9753e-04, 1.3664e-05, 1.2072e-04, 6.9225e-04, 1.1059e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.5057e-04, 1.0480e-05, 3.8494e-05, 9.2521e-05, 9.3635e-05],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0627e-03, 1.1119e-04, 2.7965e-04, 1.2418e-03, 1.0105e-03],\n",
      "        [8.5789e-03, 1.6305e-03, 2.8092e-03, 2.0914e-03, 4.8344e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.6341e-03, 3.7226e-04, 7.4515e-04, 4.4548e-03, 1.1791e-03],\n",
      "        [1.4321e-03, 2.8305e-05, 1.1558e-04, 2.1467e-04, 2.1256e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.8210e-02, 3.9105e-03, 5.7082e-03, 8.4614e-03, 6.1915e-03],\n",
      "        [1.1571e-02, 9.7123e-04, 1.6373e-03, 3.2564e-03, 5.3426e-03],\n",
      "        [2.2748e-02, 5.3420e-03, 1.0142e-02, 1.1794e-02, 8.6325e-03],\n",
      "        [9.2295e-03, 5.7566e-03, 7.0195e-03, 1.5932e-02, 1.6918e-02],\n",
      "        [1.8175e-03, 5.5729e-05, 3.5276e-04, 2.6701e-04, 1.7981e-04],\n",
      "        [2.1433e-03, 3.8051e-04, 6.2828e-04, 2.5434e-03, 2.4557e-03],\n",
      "        [3.1452e-02, 8.2602e-03, 9.3931e-03, 1.2111e-02, 1.6656e-02],\n",
      "        [1.0854e-02, 4.5262e-03, 4.7557e-03, 4.9951e-03, 1.0966e-02],\n",
      "        [3.4526e-02, 1.0499e-02, 8.3716e-03, 2.2048e-02, 1.3357e-02],\n",
      "        [2.9553e-03, 2.0970e-04, 4.7925e-04, 2.1561e-03, 1.4119e-03],\n",
      "        [1.9922e-03, 9.6264e-05, 2.7319e-04, 6.5612e-04, 6.3758e-04],\n",
      "        [2.0885e-02, 2.5220e-03, 3.6446e-03, 4.6922e-03, 5.6395e-03],\n",
      "        [2.3490e-02, 4.4434e-03, 7.4000e-03, 1.2438e-02, 9.9503e-03],\n",
      "        [1.1700e-02, 4.3661e-03, 9.0853e-03, 1.2601e-02, 9.2476e-03],\n",
      "        [1.3320e-02, 4.3538e-03, 8.1868e-03, 1.1839e-02, 1.0409e-02],\n",
      "        [2.0700e-02, 5.6270e-03, 1.4280e-02, 1.8956e-02, 2.0103e-02],\n",
      "        [8.8365e-03, 4.4754e-03, 6.4767e-03, 9.2321e-03, 9.9381e-03],\n",
      "        [1.8792e-02, 3.4846e-03, 4.4612e-03, 7.5748e-03, 8.9993e-03],\n",
      "        [5.3175e-03, 2.7675e-04, 1.2299e-03, 1.1533e-03, 1.8125e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.3133e-03, 9.6356e-04, 2.5017e-03, 2.1286e-03, 2.7414e-03],\n",
      "        [1.1791e-02, 2.3828e-03, 4.8632e-03, 1.0027e-02, 1.1317e-02],\n",
      "        [1.2465e-02, 2.0639e-03, 6.4115e-03, 6.9132e-03, 4.7998e-03],\n",
      "        [2.0406e-02, 6.9986e-03, 8.6543e-03, 1.7210e-02, 1.3290e-02],\n",
      "        [1.4462e-02, 4.0665e-03, 5.9897e-03, 8.8659e-03, 1.0957e-02],\n",
      "        [3.4135e-02, 5.3464e-03, 1.0468e-02, 1.1050e-02, 1.3307e-02],\n",
      "        [2.6104e-02, 7.2502e-03, 1.3317e-02, 2.1405e-02, 2.1946e-02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0846e-02, 4.9159e-03, 1.4744e-02, 1.5453e-02, 2.1069e-02],\n",
      "        [2.6521e-02, 2.4264e-03, 5.2071e-03, 9.7388e-03, 6.6554e-03],\n",
      "        [1.5133e-02, 3.1830e-03, 3.8403e-03, 8.8319e-03, 1.2042e-02],\n",
      "        [1.8442e-02, 3.7726e-03, 1.2873e-02, 5.5997e-03, 1.7158e-02],\n",
      "        [1.3156e-07, 4.4389e-09, 2.2026e-08, 2.7340e-08, 5.0929e-08],\n",
      "        [3.6831e-03, 4.3344e-04, 6.4440e-04, 1.5099e-03, 1.4249e-03],\n",
      "        [1.4727e-02, 4.6976e-03, 4.1718e-03, 9.7532e-03, 1.0160e-02],\n",
      "        [1.4773e-02, 3.1723e-03, 5.9032e-03, 7.1905e-03, 5.9160e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       device='cuda:0')], '95%': [tensor([[1.0000e+00, 1.0472e-04, 1.0421e-04],\n",
      "        [1.0000e+00, 1.0120e-06, 1.0122e-06],\n",
      "        [1.0000e+00, 4.5541e-05, 4.5370e-05],\n",
      "        [9.9998e-01, 2.1580e-04, 2.1554e-04],\n",
      "        [9.9999e-01, 4.5499e-04, 4.5360e-04],\n",
      "        [9.9997e-01, 3.6694e-04, 3.6766e-04],\n",
      "        [1.0000e+00, 8.4766e-05, 8.5068e-05],\n",
      "        [9.9999e-01, 2.3975e-04, 2.4059e-04],\n",
      "        [1.0000e+00, 3.2425e-06, 3.2425e-06],\n",
      "        [9.9999e-01, 4.7564e-04, 4.7498e-04],\n",
      "        [1.0000e+00, 6.8274e-05, 6.8246e-05],\n",
      "        [1.0000e+00, 9.0792e-05, 9.0727e-05],\n",
      "        [9.9996e-01, 3.9187e-04, 3.9332e-04],\n",
      "        [1.0000e+00, 3.8363e-04, 3.8293e-04],\n",
      "        [9.9994e-01, 5.6100e-04, 5.5815e-04],\n",
      "        [9.9998e-01, 1.9240e-04, 1.9380e-04],\n",
      "        [1.0000e+00, 1.1305e-03, 1.1254e-03],\n",
      "        [9.9999e-01, 2.8122e-04, 2.8122e-04],\n",
      "        [9.9999e-01, 2.3403e-04, 2.3485e-04],\n",
      "        [1.0000e+00, 1.3704e-05, 1.3719e-05],\n",
      "        [1.0000e+00, 3.2145e-06, 3.2130e-06],\n",
      "        [9.9999e-01, 2.0160e-04, 2.0075e-04],\n",
      "        [9.9986e-01, 1.1434e-03, 1.1485e-03],\n",
      "        [1.0000e+00, 6.0446e-05, 6.0422e-05],\n",
      "        [1.0000e+00, 6.7386e-05, 6.7633e-05],\n",
      "        [1.0000e+00, 2.5682e-05, 2.5807e-05],\n",
      "        [1.0000e+00, 4.6722e-06, 4.6728e-06],\n",
      "        [1.0000e+00, 1.9682e-04, 1.9682e-04],\n",
      "        [9.9998e-01, 2.3863e-04, 2.3874e-04],\n",
      "        [9.9998e-01, 3.4867e-04, 3.4705e-04],\n",
      "        [9.9999e-01, 3.6950e-04, 3.7202e-04],\n",
      "        [1.0000e+00, 7.0503e-04, 7.0271e-04],\n",
      "        [9.9999e-01, 3.1911e-04, 3.2136e-04],\n",
      "        [9.9999e-01, 7.7943e-04, 7.8962e-04],\n",
      "        [1.0000e+00, 9.4087e-05, 9.4387e-05],\n",
      "        [1.0000e+00, 1.0605e-05, 1.0600e-05],\n",
      "        [1.0000e+00, 8.7728e-05, 8.7923e-05],\n",
      "        [1.0000e+00, 5.0628e-04, 5.0651e-04],\n",
      "        [1.0000e+00, 4.0170e-06, 4.0290e-06],\n",
      "        [9.9999e-01, 2.3182e-04, 2.3296e-04],\n",
      "        [9.9999e-01, 1.2645e-04, 1.2634e-04],\n",
      "        [1.0000e+00, 3.2766e-05, 3.2836e-05],\n",
      "        [9.9999e-01, 3.4016e-04, 3.4009e-04],\n",
      "        [1.0000e+00, 3.4030e-06, 3.4039e-06],\n",
      "        [9.9996e-01, 3.3055e-04, 3.3393e-04],\n",
      "        [1.0000e+00, 1.2836e-04, 1.2841e-04],\n",
      "        [9.9996e-01, 4.1844e-04, 4.1974e-04],\n",
      "        [1.0000e+00, 1.7145e-04, 1.7273e-04],\n",
      "        [9.9995e-01, 2.9486e-04, 2.9732e-04],\n",
      "        [9.9995e-01, 6.1672e-04, 6.1998e-04],\n",
      "        [1.0000e+00, 3.3066e-06, 3.3073e-06],\n",
      "        [9.9996e-01, 1.2566e-03, 1.2657e-03],\n",
      "        [1.0000e+00, 2.0604e-05, 2.0635e-05],\n",
      "        [9.9998e-01, 2.2929e-04, 2.2822e-04],\n",
      "        [9.9997e-01, 5.4139e-04, 5.4331e-04],\n",
      "        [9.9999e-01, 2.8356e-04, 2.8386e-04],\n",
      "        [9.9999e-01, 3.9485e-04, 3.9562e-04],\n",
      "        [1.0000e+00, 7.3465e-06, 7.3261e-06],\n",
      "        [1.0000e+00, 5.3514e-07, 5.3511e-07],\n",
      "        [9.9999e-01, 1.8266e-04, 1.8372e-04],\n",
      "        [9.9997e-01, 6.3925e-04, 6.3741e-04],\n",
      "        [9.9998e-01, 3.0356e-04, 3.0416e-04],\n",
      "        [9.9985e-01, 2.6152e-04, 2.6115e-04],\n",
      "        [1.0000e+00, 8.4098e-05, 8.4093e-05],\n",
      "        [1.0000e+00, 2.7790e-04, 2.7861e-04],\n",
      "        [9.9999e-01, 2.6108e-04, 2.6050e-04],\n",
      "        [9.9988e-01, 6.6877e-04, 6.7290e-04],\n",
      "        [9.9998e-01, 2.3648e-04, 2.3780e-04],\n",
      "        [9.9994e-01, 2.2544e-04, 2.2510e-04],\n",
      "        [9.9995e-01, 2.8768e-04, 2.8973e-04],\n",
      "        [1.0000e+00, 4.0575e-05, 4.0580e-05],\n",
      "        [9.9997e-01, 2.2327e-04, 2.2317e-04],\n",
      "        [9.9994e-01, 5.0180e-04, 5.0327e-04],\n",
      "        [1.0000e+00, 1.2743e-04, 1.2722e-04],\n",
      "        [1.0000e+00, 2.8666e-04, 2.8691e-04],\n",
      "        [1.0000e+00, 5.3467e-06, 5.3513e-06],\n",
      "        [1.0000e+00, 7.0032e-05, 7.0283e-05],\n",
      "        [9.9996e-01, 5.1715e-04, 5.1826e-04],\n",
      "        [1.0000e+00, 2.3265e-06, 2.3213e-06],\n",
      "        [1.0000e+00, 2.4995e-04, 2.4957e-04],\n",
      "        [9.9998e-01, 1.7492e-04, 1.7579e-04],\n",
      "        [9.9999e-01, 1.9241e-04, 1.9466e-04],\n",
      "        [9.9999e-01, 2.2799e-04, 2.2887e-04],\n",
      "        [1.0000e+00, 1.6144e-04, 1.6189e-04],\n",
      "        [1.0000e+00, 6.0350e-06, 6.0333e-06],\n",
      "        [9.9999e-01, 1.5990e-04, 1.5979e-04],\n",
      "        [9.9999e-01, 2.0608e-04, 2.0643e-04],\n",
      "        [1.0000e+00, 5.9544e-05, 5.9707e-05],\n",
      "        [9.9997e-01, 2.0304e-04, 2.0393e-04],\n",
      "        [1.0000e+00, 2.3269e-04, 2.3280e-04],\n",
      "        [9.9998e-01, 1.5724e-04, 1.5847e-04],\n",
      "        [1.0000e+00, 2.3352e-04, 2.3510e-04],\n",
      "        [9.9981e-01, 5.1441e-04, 5.1304e-04],\n",
      "        [9.9999e-01, 9.5111e-05, 9.4795e-05],\n",
      "        [1.0000e+00, 4.7910e-04, 4.7886e-04],\n",
      "        [1.0000e+00, 5.1758e-06, 5.1798e-06],\n",
      "        [9.9998e-01, 1.4801e-04, 1.4823e-04],\n",
      "        [1.0000e+00, 3.5611e-05, 3.5597e-05],\n",
      "        [1.0000e+00, 1.0314e-04, 1.0298e-04],\n",
      "        [1.0000e+00, 8.8161e-05, 8.8155e-05],\n",
      "        [1.0000e+00, 8.0957e-05, 8.1332e-05],\n",
      "        [1.0000e+00, 1.1483e-05, 1.1499e-05],\n",
      "        [1.0000e+00, 1.3547e-04, 1.3576e-04],\n",
      "        [1.0000e+00, 2.8024e-07, 2.8028e-07],\n",
      "        [9.9993e-01, 6.7892e-04, 6.8047e-04],\n",
      "        [1.0000e+00, 1.9260e-04, 1.9332e-04],\n",
      "        [9.9998e-01, 2.3701e-04, 2.3785e-04],\n",
      "        [1.0000e+00, 1.7624e-06, 1.7678e-06],\n",
      "        [1.0000e+00, 2.7381e-05, 2.7373e-05],\n",
      "        [9.9998e-01, 2.0203e-04, 2.0267e-04],\n",
      "        [1.0000e+00, 5.2566e-05, 5.2626e-05],\n",
      "        [9.9998e-01, 4.0775e-04, 4.1172e-04],\n",
      "        [9.9998e-01, 6.4264e-04, 6.4331e-04],\n",
      "        [1.0000e+00, 1.0826e-05, 1.0822e-05],\n",
      "        [1.0000e+00, 1.4256e-04, 1.4255e-04],\n",
      "        [9.9996e-01, 4.5492e-04, 4.5615e-04],\n",
      "        [9.9999e-01, 2.2974e-04, 2.2994e-04],\n",
      "        [9.9992e-01, 7.3780e-04, 7.4036e-04],\n",
      "        [1.0000e+00, 1.8946e-05, 1.8972e-05],\n",
      "        [1.0000e+00, 2.6200e-06, 2.6189e-06],\n",
      "        [1.0000e+00, 8.3837e-05, 8.4182e-05],\n",
      "        [9.9997e-01, 3.4803e-04, 3.4964e-04],\n",
      "        [9.9999e-01, 5.3321e-04, 5.2621e-04],\n",
      "        [9.9997e-01, 3.8077e-04, 3.7984e-04],\n",
      "        [9.9996e-01, 9.1863e-04, 9.1579e-04],\n",
      "        [9.9998e-01, 2.6190e-04, 2.6288e-04],\n",
      "        [9.9999e-01, 1.1820e-04, 1.1827e-04],\n",
      "        [1.0000e+00, 2.1430e-04, 2.1686e-04],\n",
      "        [1.0000e+00, 5.3032e-07, 5.3040e-07],\n",
      "        [9.9997e-01, 1.6230e-04, 1.6160e-04],\n",
      "        [1.0000e+00, 1.3027e-03, 1.3273e-03],\n",
      "        [9.9998e-01, 2.7415e-04, 2.7659e-04],\n",
      "        [1.0000e+00, 1.8607e-04, 1.8665e-04],\n",
      "        [9.9997e-01, 5.5720e-04, 5.5270e-04],\n",
      "        [9.9998e-01, 1.7218e-04, 1.7228e-04],\n",
      "        [9.9997e-01, 4.7850e-04, 4.7784e-04],\n",
      "        [9.9984e-01, 1.0406e-03, 1.0436e-03],\n",
      "        [1.0000e+00, 7.2194e-06, 7.2208e-06],\n",
      "        [9.9994e-01, 4.4627e-04, 4.4566e-04],\n",
      "        [9.9998e-01, 4.7561e-04, 4.7671e-04],\n",
      "        [9.9998e-01, 2.3983e-04, 2.4073e-04],\n",
      "        [9.9997e-01, 7.8932e-04, 8.0729e-04],\n",
      "        [1.0000e+00, 1.2307e-04, 1.2365e-04],\n",
      "        [1.0000e+00, 1.5845e-04, 1.5877e-04],\n",
      "        [9.9998e-01, 1.9610e-04, 1.9563e-04],\n",
      "        [1.0000e+00, 8.9399e-05, 8.9396e-05],\n",
      "        [9.9993e-01, 5.9654e-04, 5.9420e-04]], device='cuda:0'), tensor([[9.9517e-01, 2.1922e-01, 4.0961e-03],\n",
      "        [9.8445e-01, 2.5348e-01, 2.8829e-04],\n",
      "        [9.8355e-01, 3.6482e-01, 3.5077e-03],\n",
      "        [9.4506e-01, 3.0516e-01, 1.2337e-02],\n",
      "        [8.9273e-01, 2.6671e-01, 1.1344e-02],\n",
      "        [8.3664e-01, 5.6411e-01, 9.0516e-03],\n",
      "        [9.3960e-01, 4.9711e-01, 8.7805e-03],\n",
      "        [7.2029e-01, 6.8190e-01, 1.5001e-02],\n",
      "        [9.9835e-01, 6.3174e-01, 1.2869e-03],\n",
      "        [7.4995e-01, 6.1550e-01, 1.1573e-02],\n",
      "        [9.8684e-01, 3.0248e-01, 4.4863e-03],\n",
      "        [9.8838e-01, 3.5864e-01, 7.3571e-03],\n",
      "        [7.4909e-01, 5.6373e-01, 1.2712e-02],\n",
      "        [7.4924e-01, 7.0990e-01, 1.2384e-02],\n",
      "        [9.1918e-01, 4.1722e-01, 1.1631e-02],\n",
      "        [8.1754e-01, 4.9569e-01, 8.6971e-03],\n",
      "        [9.2850e-01, 5.6611e-01, 1.5853e-02],\n",
      "        [9.7366e-01, 3.2537e-01, 1.1557e-02],\n",
      "        [7.8363e-01, 7.6744e-01, 8.5773e-03],\n",
      "        [9.5405e-01, 4.7307e-01, 1.1903e-03],\n",
      "        [9.7941e-01, 2.4558e-01, 9.3581e-04],\n",
      "        [8.8394e-01, 6.6863e-01, 7.4323e-03],\n",
      "        [8.3283e-01, 4.6167e-01, 2.1079e-02],\n",
      "        [9.7584e-01, 4.5911e-01, 4.4963e-03],\n",
      "        [9.8769e-01, 4.8975e-01, 2.9095e-03],\n",
      "        [9.8153e-01, 4.5533e-01, 3.2142e-03],\n",
      "        [9.7768e-01, 5.7601e-01, 1.4284e-03],\n",
      "        [9.6321e-01, 5.3383e-01, 7.7916e-03],\n",
      "        [8.6412e-01, 5.2736e-01, 9.2811e-03],\n",
      "        [8.8126e-01, 5.1101e-01, 8.6133e-03],\n",
      "        [6.8744e-01, 7.7817e-01, 1.3332e-02],\n",
      "        [9.2260e-01, 3.9409e-01, 1.4853e-02],\n",
      "        [7.6758e-01, 6.5677e-01, 1.1663e-02],\n",
      "        [8.0105e-01, 5.2360e-01, 1.2167e-02],\n",
      "        [9.3608e-01, 5.9319e-01, 6.9588e-03],\n",
      "        [9.9542e-01, 7.6843e-02, 1.7076e-03],\n",
      "        [9.5991e-01, 4.5373e-01, 5.8616e-03],\n",
      "        [9.7891e-01, 4.3494e-01, 1.2881e-02],\n",
      "        [9.6942e-01, 6.1755e-01, 2.4085e-03],\n",
      "        [8.0790e-01, 5.7207e-01, 1.0545e-02],\n",
      "        [9.0727e-01, 5.4997e-01, 6.7412e-03],\n",
      "        [9.7395e-01, 2.9922e-01, 1.7720e-03],\n",
      "        [9.4759e-01, 2.6649e-01, 9.2401e-03],\n",
      "        [9.9953e-01, 2.3333e-01, 1.0090e-03],\n",
      "        [6.9912e-01, 6.5049e-01, 9.2324e-03],\n",
      "        [9.8431e-01, 3.9309e-01, 6.5556e-03],\n",
      "        [9.4985e-01, 2.6607e-01, 7.1943e-03],\n",
      "        [8.9663e-01, 6.7590e-01, 8.0889e-03],\n",
      "        [8.6854e-01, 5.5199e-01, 1.2276e-02],\n",
      "        [8.5701e-01, 4.5777e-01, 1.6215e-02],\n",
      "        [9.9186e-01, 3.0382e-01, 1.2343e-03],\n",
      "        [8.9940e-01, 3.8417e-01, 1.5845e-02],\n",
      "        [9.9754e-01, 9.6222e-02, 2.0536e-03],\n",
      "        [8.7773e-01, 4.9279e-01, 1.1365e-02],\n",
      "        [8.4609e-01, 5.8906e-01, 1.3945e-02],\n",
      "        [9.4427e-01, 5.9532e-01, 1.1181e-02],\n",
      "        [8.4580e-01, 3.8018e-01, 9.8056e-03],\n",
      "        [9.7624e-01, 3.3096e-01, 2.1535e-03],\n",
      "        [9.9742e-01, 2.1769e-01, 3.0882e-04],\n",
      "        [8.1995e-01, 5.3041e-01, 8.7605e-03],\n",
      "        [7.9230e-01, 6.1007e-01, 1.3664e-02],\n",
      "        [8.9127e-01, 3.1662e-01, 8.9869e-03],\n",
      "        [8.0905e-01, 5.3354e-01, 9.3101e-03],\n",
      "        [7.3938e-01, 8.0018e-01, 5.4750e-03],\n",
      "        [9.3019e-01, 7.7175e-01, 9.5384e-03],\n",
      "        [6.8027e-01, 7.6924e-01, 8.4066e-03],\n",
      "        [7.2610e-01, 5.7096e-01, 1.7724e-02],\n",
      "        [8.2237e-01, 4.9929e-01, 1.3305e-02],\n",
      "        [9.0783e-01, 4.3382e-01, 1.0294e-02],\n",
      "        [7.7602e-01, 6.6269e-01, 1.1167e-02],\n",
      "        [9.4076e-01, 5.1938e-01, 3.0567e-03],\n",
      "        [9.7929e-01, 2.4724e-01, 7.7455e-03],\n",
      "        [8.0235e-01, 6.7615e-01, 1.0222e-02],\n",
      "        [9.3113e-01, 4.5499e-01, 6.7344e-03],\n",
      "        [9.7925e-01, 4.1426e-01, 6.2976e-03],\n",
      "        [9.5329e-01, 6.1776e-01, 2.4734e-03],\n",
      "        [9.6678e-01, 2.9236e-01, 4.7753e-03],\n",
      "        [8.9847e-01, 4.9629e-01, 1.6303e-02],\n",
      "        [9.9521e-01, 2.7008e-01, 8.9291e-04],\n",
      "        [9.1965e-01, 6.3349e-01, 1.0246e-02],\n",
      "        [8.2448e-01, 5.9968e-01, 1.0456e-02],\n",
      "        [9.4545e-01, 4.8754e-01, 1.1034e-02],\n",
      "        [9.5100e-01, 3.9771e-01, 1.0877e-02],\n",
      "        [8.7874e-01, 6.0792e-01, 8.4858e-03],\n",
      "        [9.7780e-01, 3.1111e-01, 1.8265e-03],\n",
      "        [6.3282e-01, 7.7000e-01, 8.1663e-03],\n",
      "        [9.3255e-01, 3.9252e-01, 7.6498e-03],\n",
      "        [7.0758e-01, 7.3535e-01, 5.5452e-03],\n",
      "        [7.9756e-01, 6.1957e-01, 1.2801e-02],\n",
      "        [9.9402e-01, 1.8439e-01, 5.0062e-03],\n",
      "        [7.2630e-01, 7.5109e-01, 6.3887e-03],\n",
      "        [6.3746e-01, 7.6603e-01, 1.2373e-02],\n",
      "        [8.6369e-01, 4.2647e-01, 1.4360e-02],\n",
      "        [8.0585e-01, 6.7690e-01, 8.1513e-03],\n",
      "        [8.4981e-01, 4.6379e-01, 1.7896e-02],\n",
      "        [9.9004e-01, 4.3575e-01, 1.0641e-03],\n",
      "        [7.7976e-01, 4.8033e-01, 1.0938e-02],\n",
      "        [9.9072e-01, 3.1270e-01, 1.0870e-03],\n",
      "        [9.5587e-01, 5.0877e-01, 4.3350e-03],\n",
      "        [9.9357e-01, 2.7159e-01, 5.5305e-03],\n",
      "        [9.4502e-01, 5.3603e-01, 7.1100e-03],\n",
      "        [9.6534e-01, 4.2040e-01, 2.8555e-03],\n",
      "        [9.3928e-01, 3.1475e-01, 9.0381e-03],\n",
      "        [9.8333e-01, 3.6452e-01, 2.7996e-04],\n",
      "        [8.1823e-01, 4.5230e-01, 1.6769e-02],\n",
      "        [9.9588e-01, 1.8877e-01, 4.2059e-03],\n",
      "        [9.0512e-01, 3.8987e-01, 1.1082e-02],\n",
      "        [9.9665e-01, 2.8692e-01, 4.3876e-04],\n",
      "        [8.5676e-01, 5.2901e-01, 4.3771e-03],\n",
      "        [8.4541e-01, 6.4324e-01, 1.1254e-02],\n",
      "        [9.6764e-01, 3.8328e-01, 5.2153e-03],\n",
      "        [8.3688e-01, 5.3586e-01, 1.0738e-02],\n",
      "        [8.5366e-01, 6.2769e-01, 1.2140e-02],\n",
      "        [9.9626e-01, 2.9878e-01, 1.4794e-03],\n",
      "        [9.9427e-01, 3.6976e-01, 6.3529e-03],\n",
      "        [8.9529e-01, 6.4715e-01, 1.1796e-02],\n",
      "        [6.9475e-01, 6.6912e-01, 1.1505e-02],\n",
      "        [7.1913e-01, 5.2589e-01, 1.8105e-02],\n",
      "        [9.8172e-01, 4.9915e-01, 2.8190e-03],\n",
      "        [9.8610e-01, 3.8766e-01, 1.4611e-03],\n",
      "        [9.6117e-01, 4.5770e-01, 6.9724e-03],\n",
      "        [9.7971e-01, 2.2467e-01, 1.1194e-02],\n",
      "        [8.9287e-01, 4.9694e-01, 8.7328e-03],\n",
      "        [8.8758e-01, 4.8069e-01, 1.1967e-02],\n",
      "        [8.7587e-01, 3.7300e-01, 9.8045e-03],\n",
      "        [7.6866e-01, 5.5591e-01, 8.9246e-03],\n",
      "        [9.1510e-01, 4.8476e-01, 6.8016e-03],\n",
      "        [9.6141e-01, 7.3687e-01, 1.0048e-02],\n",
      "        [9.8910e-01, 2.7821e-01, 8.0071e-04],\n",
      "        [8.1663e-01, 6.5882e-01, 1.0563e-02],\n",
      "        [8.9732e-01, 4.8630e-01, 1.7034e-02],\n",
      "        [8.3298e-01, 5.9715e-01, 8.2659e-03],\n",
      "        [9.4203e-01, 4.1238e-01, 7.8982e-03],\n",
      "        [8.6972e-01, 4.2022e-01, 1.3315e-02],\n",
      "        [7.2314e-01, 6.1592e-01, 7.1892e-03],\n",
      "        [9.4587e-01, 3.2096e-01, 9.9269e-03],\n",
      "        [8.9203e-01, 3.9623e-01, 2.0635e-02],\n",
      "        [9.9939e-01, 3.6159e-01, 7.4828e-04],\n",
      "        [7.2998e-01, 6.3614e-01, 1.2483e-02],\n",
      "        [9.7102e-01, 2.4676e-01, 1.1590e-02],\n",
      "        [8.5870e-01, 4.9515e-01, 9.3262e-03],\n",
      "        [8.9162e-01, 5.5460e-01, 1.9769e-02],\n",
      "        [9.9467e-01, 7.5993e-01, 6.3515e-03],\n",
      "        [9.6017e-01, 4.4008e-01, 8.3385e-03],\n",
      "        [9.0295e-01, 5.3678e-01, 9.4748e-03],\n",
      "        [9.8606e-01, 3.1103e-01, 4.8193e-03],\n",
      "        [8.9178e-01, 5.3602e-01, 9.5805e-03]], device='cuda:0'), tensor([[0.0134, 0.9991, 0.0094, 0.0076],\n",
      "        [0.0014, 1.0000, 0.0014, 0.0013],\n",
      "        [0.0117, 0.9995, 0.0122, 0.0108],\n",
      "        [0.0245, 0.9944, 0.0214, 0.0203],\n",
      "        [0.0290, 0.9922, 0.0264, 0.0244],\n",
      "        [0.0254, 0.9909, 0.0264, 0.0227],\n",
      "        [0.0213, 0.9995, 0.0196, 0.0178],\n",
      "        [0.0372, 0.9916, 0.0335, 0.0311],\n",
      "        [0.0044, 1.0000, 0.0040, 0.0037],\n",
      "        [0.0254, 0.9925, 0.0238, 0.0225],\n",
      "        [0.0109, 0.9993, 0.0109, 0.0101],\n",
      "        [0.0161, 0.9987, 0.0141, 0.0130],\n",
      "        [0.0212, 0.9892, 0.0201, 0.0187],\n",
      "        [0.0188, 0.9919, 0.0190, 0.0156],\n",
      "        [0.0416, 0.9852, 0.0404, 0.0362],\n",
      "        [0.0323, 0.9904, 0.0258, 0.0226],\n",
      "        [0.0301, 1.0000, 0.0285, 0.0227],\n",
      "        [0.0236, 0.9911, 0.0227, 0.0213],\n",
      "        [0.0199, 0.9942, 0.0188, 0.0174],\n",
      "        [0.0052, 0.9994, 0.0049, 0.0047],\n",
      "        [0.0044, 0.9998, 0.0041, 0.0040],\n",
      "        [0.0282, 0.9896, 0.0232, 0.0203],\n",
      "        [0.0489, 0.9711, 0.0393, 0.0351],\n",
      "        [0.0189, 0.9998, 0.0193, 0.0162],\n",
      "        [0.0289, 1.0000, 0.0256, 0.0246],\n",
      "        [0.0101, 0.9970, 0.0104, 0.0097],\n",
      "        [0.0048, 1.0000, 0.0047, 0.0046],\n",
      "        [0.0187, 0.9996, 0.0155, 0.0144],\n",
      "        [0.0288, 0.9862, 0.0236, 0.0213],\n",
      "        [0.0363, 0.9892, 0.0254, 0.0240],\n",
      "        [0.0495, 0.9896, 0.0443, 0.0410],\n",
      "        [0.0377, 0.9986, 0.0337, 0.0316],\n",
      "        [0.0353, 0.9936, 0.0325, 0.0259],\n",
      "        [0.0303, 0.9921, 0.0257, 0.0231],\n",
      "        [0.0259, 0.9979, 0.0198, 0.0178],\n",
      "        [0.0106, 0.9995, 0.0090, 0.0087],\n",
      "        [0.0241, 0.9981, 0.0183, 0.0169],\n",
      "        [0.0285, 0.9967, 0.0236, 0.0225],\n",
      "        [0.0054, 0.9995, 0.0051, 0.0048],\n",
      "        [0.0303, 0.9857, 0.0293, 0.0243],\n",
      "        [0.0117, 0.9924, 0.0118, 0.0102],\n",
      "        [0.0041, 1.0000, 0.0041, 0.0038],\n",
      "        [0.0345, 0.9927, 0.0329, 0.0299],\n",
      "        [0.0025, 1.0000, 0.0025, 0.0024],\n",
      "        [0.0298, 0.9862, 0.0258, 0.0220],\n",
      "        [0.0171, 0.9996, 0.0126, 0.0114],\n",
      "        [0.0383, 0.9887, 0.0285, 0.0268],\n",
      "        [0.0191, 0.9966, 0.0192, 0.0179],\n",
      "        [0.0294, 0.9783, 0.0228, 0.0215],\n",
      "        [0.0442, 0.9787, 0.0425, 0.0392],\n",
      "        [0.0035, 0.9997, 0.0034, 0.0033],\n",
      "        [0.0340, 0.9849, 0.0308, 0.0266],\n",
      "        [0.0084, 0.9994, 0.0074, 0.0072],\n",
      "        [0.0271, 0.9880, 0.0308, 0.0234],\n",
      "        [0.0328, 0.9853, 0.0327, 0.0261],\n",
      "        [0.0346, 0.9937, 0.0331, 0.0284],\n",
      "        [0.0284, 0.9938, 0.0267, 0.0234],\n",
      "        [0.0070, 0.9999, 0.0067, 0.0064],\n",
      "        [0.0015, 1.0000, 0.0013, 0.0012],\n",
      "        [0.0188, 0.9904, 0.0176, 0.0166],\n",
      "        [0.0574, 0.9798, 0.0409, 0.0380],\n",
      "        [0.0336, 0.9901, 0.0308, 0.0285],\n",
      "        [0.0311, 0.9778, 0.0298, 0.0269],\n",
      "        [0.0125, 0.9953, 0.0115, 0.0110],\n",
      "        [0.0200, 1.0000, 0.0175, 0.0149],\n",
      "        [0.0192, 0.9952, 0.0174, 0.0163],\n",
      "        [0.0305, 0.9713, 0.0265, 0.0236],\n",
      "        [0.0345, 0.9870, 0.0276, 0.0257],\n",
      "        [0.0299, 0.9839, 0.0273, 0.0247],\n",
      "        [0.0177, 0.9799, 0.0176, 0.0152],\n",
      "        [0.0065, 0.9988, 0.0048, 0.0045],\n",
      "        [0.0277, 0.9831, 0.0268, 0.0258],\n",
      "        [0.0268, 0.9750, 0.0257, 0.0233],\n",
      "        [0.0231, 0.9929, 0.0194, 0.0184],\n",
      "        [0.0120, 0.9985, 0.0112, 0.0104],\n",
      "        [0.0104, 0.9988, 0.0106, 0.0102],\n",
      "        [0.0097, 0.9986, 0.0094, 0.0092],\n",
      "        [0.0455, 0.9807, 0.0427, 0.0374],\n",
      "        [0.0064, 0.9995, 0.0062, 0.0060],\n",
      "        [0.0199, 0.9949, 0.0185, 0.0175],\n",
      "        [0.0218, 0.9899, 0.0223, 0.0196],\n",
      "        [0.0208, 0.9886, 0.0186, 0.0166],\n",
      "        [0.0225, 0.9948, 0.0209, 0.0188],\n",
      "        [0.0265, 0.9956, 0.0225, 0.0193],\n",
      "        [0.0085, 0.9995, 0.0072, 0.0060],\n",
      "        [0.0231, 0.9847, 0.0211, 0.0201],\n",
      "        [0.0177, 0.9938, 0.0162, 0.0149],\n",
      "        [0.0090, 0.9974, 0.0086, 0.0081],\n",
      "        [0.0228, 0.9887, 0.0195, 0.0182],\n",
      "        [0.0211, 0.9985, 0.0189, 0.0178],\n",
      "        [0.0236, 0.9837, 0.0205, 0.0192],\n",
      "        [0.0285, 0.9963, 0.0254, 0.0240],\n",
      "        [0.0350, 0.9719, 0.0286, 0.0276],\n",
      "        [0.0287, 0.9943, 0.0265, 0.0251],\n",
      "        [0.0261, 0.9989, 0.0252, 0.0225],\n",
      "        [0.0025, 0.9999, 0.0022, 0.0021],\n",
      "        [0.0232, 0.9895, 0.0198, 0.0181],\n",
      "        [0.0039, 0.9999, 0.0037, 0.0034],\n",
      "        [0.0215, 0.9980, 0.0212, 0.0186],\n",
      "        [0.0179, 0.9994, 0.0185, 0.0161],\n",
      "        [0.0132, 0.9976, 0.0122, 0.0117],\n",
      "        [0.0050, 0.9987, 0.0045, 0.0041],\n",
      "        [0.0258, 0.9993, 0.0217, 0.0203],\n",
      "        [0.0015, 1.0000, 0.0014, 0.0014],\n",
      "        [0.0400, 0.9799, 0.0312, 0.0284],\n",
      "        [0.0207, 0.9987, 0.0145, 0.0136],\n",
      "        [0.0341, 0.9785, 0.0274, 0.0258],\n",
      "        [0.0078, 0.9998, 0.0076, 0.0065],\n",
      "        [0.0242, 0.9950, 0.0185, 0.0183],\n",
      "        [0.0259, 0.9877, 0.0235, 0.0205],\n",
      "        [0.0139, 0.9979, 0.0132, 0.0126],\n",
      "        [0.0295, 0.9847, 0.0282, 0.0246],\n",
      "        [0.0435, 0.9858, 0.0328, 0.0281],\n",
      "        [0.0052, 0.9998, 0.0052, 0.0050],\n",
      "        [0.0190, 0.9989, 0.0201, 0.0175],\n",
      "        [0.0415, 0.9830, 0.0417, 0.0351],\n",
      "        [0.0345, 0.9869, 0.0289, 0.0256],\n",
      "        [0.0575, 0.9753, 0.0478, 0.0418],\n",
      "        [0.0035, 0.9992, 0.0031, 0.0029],\n",
      "        [0.0029, 0.9998, 0.0029, 0.0027],\n",
      "        [0.0181, 0.9955, 0.0161, 0.0147],\n",
      "        [0.0227, 0.9877, 0.0239, 0.0206],\n",
      "        [0.0297, 0.9901, 0.0300, 0.0261],\n",
      "        [0.0379, 0.9925, 0.0368, 0.0296],\n",
      "        [0.0321, 0.9800, 0.0284, 0.0249],\n",
      "        [0.0260, 0.9906, 0.0262, 0.0209],\n",
      "        [0.0204, 0.9892, 0.0200, 0.0182],\n",
      "        [0.0285, 0.9997, 0.0287, 0.0240],\n",
      "        [0.0013, 0.9997, 0.0013, 0.0012],\n",
      "        [0.0314, 0.9810, 0.0275, 0.0260],\n",
      "        [0.0386, 0.9979, 0.0412, 0.0344],\n",
      "        [0.0239, 0.9923, 0.0235, 0.0217],\n",
      "        [0.0204, 0.9972, 0.0196, 0.0180],\n",
      "        [0.0240, 0.9890, 0.0230, 0.0186],\n",
      "        [0.0310, 0.9888, 0.0258, 0.0237],\n",
      "        [0.0310, 0.9853, 0.0267, 0.0249],\n",
      "        [0.0405, 0.9725, 0.0315, 0.0283],\n",
      "        [0.0039, 1.0000, 0.0038, 0.0036],\n",
      "        [0.0210, 0.9718, 0.0183, 0.0172],\n",
      "        [0.0310, 0.9867, 0.0274, 0.0259],\n",
      "        [0.0222, 0.9941, 0.0230, 0.0198],\n",
      "        [0.0357, 0.9844, 0.0349, 0.0293],\n",
      "        [0.0127, 1.0000, 0.0108, 0.0097],\n",
      "        [0.0198, 0.9996, 0.0163, 0.0145],\n",
      "        [0.0257, 0.9879, 0.0219, 0.0209],\n",
      "        [0.0170, 0.9951, 0.0168, 0.0149],\n",
      "        [0.0249, 0.9741, 0.0225, 0.0205]], device='cuda:0'), tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0233, 0.0023, 0.0068, 0.0098, 0.0102],\n",
      "        [0.0646, 0.0123, 0.0156, 0.0212, 0.0185],\n",
      "        [0.0824, 0.0225, 0.0444, 0.0520, 0.0605],\n",
      "        [0.0968, 0.0283, 0.0436, 0.0576, 0.0537],\n",
      "        [0.0680, 0.0288, 0.0353, 0.0586, 0.0613],\n",
      "        [0.0663, 0.0167, 0.0200, 0.0471, 0.0335],\n",
      "        [0.0864, 0.0274, 0.0491, 0.0554, 0.0688],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0262, 0.0223, 0.0226, 0.0346, 0.0160],\n",
      "        [0.0604, 0.0198, 0.0270, 0.0488, 0.0269],\n",
      "        [0.0597, 0.0454, 0.0384, 0.0762, 0.0703],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1116, 0.0381, 0.0541, 0.0554, 0.0526],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0742, 0.0385, 0.0644, 0.0830, 0.0666],\n",
      "        [0.0808, 0.0338, 0.0417, 0.0575, 0.0602],\n",
      "        [0.0599, 0.0354, 0.0298, 0.0559, 0.0596],\n",
      "        [0.0387, 0.0054, 0.0087, 0.0138, 0.0139],\n",
      "        [0.0257, 0.0051, 0.0101, 0.0076, 0.0118],\n",
      "        [0.0648, 0.0251, 0.0415, 0.0427, 0.0384],\n",
      "        [0.1176, 0.0458, 0.0818, 0.0974, 0.0934],\n",
      "        [0.0914, 0.0194, 0.0446, 0.0239, 0.0244],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0542, 0.0130, 0.0189, 0.0393, 0.0419],\n",
      "        [0.0350, 0.0086, 0.0149, 0.0363, 0.0095],\n",
      "        [0.0918, 0.0174, 0.0488, 0.0366, 0.0508],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1201, 0.0500, 0.0446, 0.0470, 0.0549],\n",
      "        [0.0807, 0.0341, 0.0499, 0.0696, 0.0615],\n",
      "        [0.0736, 0.0269, 0.0320, 0.0525, 0.0482],\n",
      "        [0.0911, 0.0367, 0.0506, 0.0704, 0.0896],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0582, 0.0056, 0.0170, 0.0286, 0.0446],\n",
      "        [0.0980, 0.0196, 0.0272, 0.0450, 0.0320],\n",
      "        [0.0883, 0.0237, 0.0448, 0.0527, 0.0792],\n",
      "        [0.0314, 0.0040, 0.0072, 0.0141, 0.0135],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0619, 0.0150, 0.0241, 0.0477, 0.0381],\n",
      "        [0.0404, 0.0084, 0.0075, 0.0234, 0.0104],\n",
      "        [0.0950, 0.0389, 0.0406, 0.0729, 0.0515],\n",
      "        [0.0475, 0.0054, 0.0050, 0.0163, 0.0375],\n",
      "        [0.0564, 0.0307, 0.0618, 0.0645, 0.0470],\n",
      "        [0.0528, 0.0218, 0.0359, 0.0266, 0.0324],\n",
      "        [0.1088, 0.0263, 0.0367, 0.0564, 0.0545],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0881, 0.0316, 0.0496, 0.0674, 0.0632],\n",
      "        [0.0852, 0.0552, 0.0494, 0.0689, 0.0645],\n",
      "        [0.0260, 0.0034, 0.0038, 0.0055, 0.0119],\n",
      "        [0.0799, 0.0366, 0.0460, 0.0654, 0.0753],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0581, 0.0217, 0.0287, 0.0617, 0.0478],\n",
      "        [0.0871, 0.0361, 0.0448, 0.0775, 0.0530],\n",
      "        [0.1269, 0.0303, 0.0456, 0.0545, 0.0452],\n",
      "        [0.0940, 0.0315, 0.0507, 0.0682, 0.0634],\n",
      "        [0.0679, 0.0050, 0.0100, 0.0164, 0.0404],\n",
      "        [0.0348, 0.0055, 0.0024, 0.0082, 0.0131],\n",
      "        [0.0638, 0.0340, 0.0304, 0.0323, 0.0495],\n",
      "        [0.0751, 0.0457, 0.0441, 0.0670, 0.0594],\n",
      "        [0.1043, 0.0296, 0.0403, 0.0444, 0.0440],\n",
      "        [0.1126, 0.0251, 0.0602, 0.0497, 0.0683],\n",
      "        [0.0494, 0.0180, 0.0196, 0.0373, 0.0297],\n",
      "        [0.0594, 0.0301, 0.0341, 0.0415, 0.0451],\n",
      "        [0.0843, 0.0205, 0.0304, 0.0524, 0.0495],\n",
      "        [0.1241, 0.0360, 0.0548, 0.0754, 0.0794],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0986, 0.0383, 0.0493, 0.0417, 0.0717],\n",
      "        [0.1108, 0.0227, 0.0345, 0.0467, 0.0659],\n",
      "        [0.0427, 0.0094, 0.0167, 0.0234, 0.0418],\n",
      "        [0.1140, 0.0266, 0.0394, 0.0552, 0.0483],\n",
      "        [0.0935, 0.0346, 0.0315, 0.0670, 0.0676],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0560, 0.0305, 0.0273, 0.0426, 0.0399],\n",
      "        [0.0533, 0.0073, 0.0141, 0.0195, 0.0135],\n",
      "        [0.0677, 0.0127, 0.0164, 0.0293, 0.0263],\n",
      "        [0.1304, 0.0288, 0.0475, 0.0704, 0.0746],\n",
      "        [0.0318, 0.0057, 0.0045, 0.0123, 0.0187],\n",
      "        [0.0776, 0.0222, 0.0405, 0.0450, 0.0459],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0877, 0.0327, 0.0382, 0.0642, 0.0593],\n",
      "        [0.0832, 0.0226, 0.0440, 0.0424, 0.0491],\n",
      "        [0.0631, 0.0256, 0.0260, 0.0482, 0.0489],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0621, 0.0310, 0.0307, 0.0485, 0.0656],\n",
      "        [0.0652, 0.0283, 0.0307, 0.0502, 0.0510],\n",
      "        [0.0364, 0.0242, 0.0125, 0.0316, 0.0264],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0766, 0.0158, 0.0342, 0.0469, 0.0294],\n",
      "        [0.0605, 0.0214, 0.0411, 0.0367, 0.0840],\n",
      "        [0.0651, 0.0245, 0.0455, 0.0425, 0.0654],\n",
      "        [0.1187, 0.0214, 0.0578, 0.0556, 0.0624],\n",
      "        [0.0605, 0.0111, 0.0245, 0.0580, 0.0423],\n",
      "        [0.1078, 0.0371, 0.0581, 0.0628, 0.0688],\n",
      "        [0.0364, 0.0044, 0.0065, 0.0070, 0.0070],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0623, 0.0047, 0.0142, 0.0246, 0.0151],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0741, 0.0090, 0.0157, 0.0337, 0.0488],\n",
      "        [0.0739, 0.0242, 0.0194, 0.0341, 0.0443],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0773, 0.0113, 0.0376, 0.0273, 0.0528],\n",
      "        [0.0328, 0.0009, 0.0029, 0.0111, 0.0128],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0908, 0.0290, 0.0446, 0.0612, 0.0617],\n",
      "        [0.0622, 0.0153, 0.0252, 0.0298, 0.0270],\n",
      "        [0.0847, 0.0356, 0.0372, 0.0467, 0.0493],\n",
      "        [0.0871, 0.0321, 0.0489, 0.0824, 0.0885],\n",
      "        [0.0835, 0.0108, 0.0127, 0.0189, 0.0100],\n",
      "        [0.0674, 0.0244, 0.0268, 0.0332, 0.0556],\n",
      "        [0.1014, 0.0269, 0.0432, 0.0902, 0.0715],\n",
      "        [0.0900, 0.0331, 0.0396, 0.0487, 0.0652],\n",
      "        [0.1588, 0.0488, 0.0549, 0.0662, 0.0788],\n",
      "        [0.0514, 0.0106, 0.0137, 0.0160, 0.0375],\n",
      "        [0.0364, 0.0058, 0.0046, 0.0111, 0.0245],\n",
      "        [0.0667, 0.0099, 0.0281, 0.0333, 0.0398],\n",
      "        [0.1036, 0.0329, 0.0505, 0.0569, 0.0695],\n",
      "        [0.0804, 0.0416, 0.0522, 0.0661, 0.0643],\n",
      "        [0.0864, 0.0334, 0.0554, 0.0646, 0.0587],\n",
      "        [0.1277, 0.0298, 0.0614, 0.0795, 0.0832],\n",
      "        [0.0718, 0.0288, 0.0526, 0.0372, 0.0566],\n",
      "        [0.0752, 0.0319, 0.0324, 0.0320, 0.0408],\n",
      "        [0.0654, 0.0209, 0.0361, 0.0500, 0.0517],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1368, 0.0489, 0.0512, 0.0544, 0.0720],\n",
      "        [0.0528, 0.0368, 0.0488, 0.0504, 0.0654],\n",
      "        [0.1017, 0.0239, 0.0328, 0.0397, 0.0397],\n",
      "        [0.1288, 0.0287, 0.0532, 0.0680, 0.0645],\n",
      "        [0.0779, 0.0218, 0.0508, 0.0697, 0.0388],\n",
      "        [0.0918, 0.0295, 0.0512, 0.0625, 0.0539],\n",
      "        [0.1059, 0.0369, 0.0551, 0.0789, 0.0718],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1380, 0.0320, 0.0559, 0.0410, 0.0657],\n",
      "        [0.0900, 0.0508, 0.0359, 0.0511, 0.0531],\n",
      "        [0.0573, 0.0161, 0.0425, 0.0642, 0.0565],\n",
      "        [0.1028, 0.0451, 0.0600, 0.0627, 0.1007],\n",
      "        [0.0396, 0.0106, 0.0285, 0.0321, 0.0328],\n",
      "        [0.0552, 0.0232, 0.0292, 0.0371, 0.0284],\n",
      "        [0.0728, 0.0273, 0.0372, 0.0614, 0.0651],\n",
      "        [0.0670, 0.0162, 0.0289, 0.0367, 0.0498],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')], 'order': ['pd', 'nd', 'mod', 'dlt']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.3333333333333333,\n",
       "  'auc_micro': 0.9091844369622148,\n",
       "  'auc_mean': 0.7637496207870599,\n",
       "  'auc_weighted': 0.6764454721144771},\n",
       " 'nd': {'accuracy': 0.3605972086984745,\n",
       "  'auc_micro': 0.7578723404255319,\n",
       "  'auc_mean': 0.5144727637975773,\n",
       "  'auc_weighted': 0.5495057525091257},\n",
       " 'mod': {'accuracy': 0.3605972086984745,\n",
       "  'auc_micro': 0.7578723404255319,\n",
       "  'auc_mean': 0.5144727637975773,\n",
       "  'auc_weighted': 0.5495057525091257},\n",
       " 'dlts': {'accuracy': [0.9523809523809523,\n",
       "   0.9659863945578231,\n",
       "   0.9659863945578231,\n",
       "   0.9795918367346939,\n",
       "   0.9183673469387755],\n",
       "  'accuracy_mean': 0.9564625850340136,\n",
       "  'auc': [0.8357142857142856,\n",
       "   0.6380281690140845,\n",
       "   0.5140845070422535,\n",
       "   0.6921296296296295,\n",
       "   0.6234567901234568],\n",
       "  'auc_mean': 0.660682676304742}}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel2 = train_state(model_args=t1_args,state=2,lr=.001,weights=[1,1,.1,1],balanced=False)\n",
    "tmodel2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "310c657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "epoch 0 train loss 1.3574738502502441\n",
      "val loss 1.3396203517913818\n",
      "______________\n",
      "epoch 1 train loss 1.3154988288879395\n",
      "val loss 1.3146865367889404\n",
      "______________\n",
      "epoch 2 train loss 1.2916728258132935\n",
      "val loss 1.2912061214447021\n",
      "______________\n",
      "epoch 3 train loss 1.25283944606781\n",
      "val loss 1.269127368927002\n",
      "______________\n",
      "epoch 4 train loss 1.2128483057022095\n",
      "val loss 1.2484186887741089\n",
      "______________\n",
      "epoch 5 train loss 1.2084474563598633\n",
      "val loss 1.229184865951538\n",
      "______________\n",
      "epoch 6 train loss 1.1698085069656372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.2111448049545288\n",
      "______________\n",
      "epoch 7 train loss 1.1484793424606323\n",
      "val loss 1.1943089962005615\n",
      "______________\n",
      "epoch 8 train loss 1.1444820165634155\n",
      "val loss 1.1786493062973022\n",
      "______________\n",
      "epoch 9 train loss 1.1283105611801147\n",
      "val loss 1.164149522781372\n",
      "______________\n",
      "epoch 10 train loss 1.1080957651138306\n",
      "val loss 1.1508152484893799\n",
      "______________\n",
      "epoch 11 train loss 1.093427062034607\n",
      "val loss 1.1385594606399536\n",
      "______________\n",
      "epoch 12 train loss 1.0821189880371094\n",
      "val loss 1.1272752285003662\n",
      "______________\n",
      "epoch 13 train loss 1.0568914413452148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.1168701648712158\n",
      "______________\n",
      "epoch 14 train loss 1.0572773218154907\n",
      "val loss 1.1074199676513672\n",
      "______________\n",
      "epoch 15 train loss 1.0461626052856445\n",
      "val loss 1.0987952947616577\n",
      "______________\n",
      "epoch 16 train loss 1.0456511974334717\n",
      "val loss 1.090928554534912\n",
      "______________\n",
      "epoch 17 train loss 1.0354140996932983\n",
      "val loss 1.0837584733963013\n",
      "______________\n",
      "epoch 18 train loss 1.00705087184906\n",
      "val loss 1.0771305561065674\n",
      "______________\n",
      "epoch 19 train loss 1.0334019660949707\n",
      "val loss 1.07109797000885\n",
      "______________\n",
      "epoch 20 train loss 1.0346660614013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.0656005144119263\n",
      "______________\n",
      "epoch 21 train loss 1.0245482921600342\n",
      "val loss 1.0605837106704712\n",
      "______________\n",
      "epoch 22 train loss 1.0117319822311401\n",
      "val loss 1.055977702140808\n",
      "______________\n",
      "epoch 23 train loss 1.0214866399765015\n",
      "val loss 1.0517412424087524\n",
      "______________\n",
      "epoch 24 train loss 1.0098751783370972\n",
      "val loss 1.0477542877197266\n",
      "______________\n",
      "epoch 25 train loss 0.9985355138778687\n",
      "val loss 1.0439465045928955\n",
      "______________\n",
      "epoch 26 train loss 1.0069655179977417\n",
      "val loss 1.0403517484664917\n",
      "______________\n",
      "epoch 27 train loss 0.9928261637687683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.0368767976760864\n",
      "______________\n",
      "epoch 28 train loss 0.991825520992279\n",
      "val loss 1.0335240364074707\n",
      "______________\n",
      "epoch 29 train loss 0.9868125915527344\n",
      "val loss 1.0302460193634033\n",
      "______________\n",
      "epoch 30 train loss 0.9763442277908325\n",
      "val loss 1.0270785093307495\n",
      "______________\n",
      "epoch 31 train loss 1.002873182296753\n",
      "val loss 1.0240323543548584\n",
      "______________\n",
      "epoch 32 train loss 0.9839648604393005\n",
      "val loss 1.0210736989974976\n",
      "______________\n",
      "epoch 33 train loss 0.9671902656555176\n",
      "val loss 1.0181752443313599\n",
      "______________\n",
      "epoch 34 train loss 0.9786010980606079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.0153671503067017\n",
      "______________\n",
      "epoch 35 train loss 0.9717006683349609\n",
      "val loss 1.012687087059021\n",
      "______________\n",
      "epoch 36 train loss 0.9470551609992981\n",
      "val loss 1.0100911855697632\n",
      "______________\n",
      "epoch 37 train loss 0.9248089790344238\n",
      "val loss 1.0075644254684448\n",
      "______________\n",
      "epoch 38 train loss 0.9344580769538879\n",
      "val loss 1.0050780773162842\n",
      "______________\n",
      "epoch 39 train loss 0.9543741345405579\n",
      "val loss 1.0026793479919434\n",
      "______________\n",
      "epoch 40 train loss 0.9489702582359314\n",
      "val loss 1.0003211498260498\n",
      "______________\n",
      "epoch 41 train loss 0.9223778247833252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9980369210243225\n",
      "______________\n",
      "epoch 42 train loss 0.9325927495956421\n",
      "val loss 0.9957759380340576\n",
      "______________\n",
      "epoch 43 train loss 0.9167171120643616\n",
      "val loss 0.9935022592544556\n",
      "______________\n",
      "epoch 44 train loss 0.9032253623008728\n",
      "val loss 0.9912445545196533\n",
      "______________\n",
      "epoch 45 train loss 0.9241993427276611\n",
      "val loss 0.9890167117118835\n",
      "______________\n",
      "epoch 46 train loss 0.9018024802207947\n",
      "val loss 0.9867734313011169\n",
      "______________\n",
      "epoch 47 train loss 0.9258854985237122\n",
      "val loss 0.9845708608627319\n",
      "______________\n",
      "epoch 48 train loss 0.9125723242759705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9823660254478455\n",
      "______________\n",
      "epoch 49 train loss 0.9126425385475159\n",
      "val loss 0.9801567196846008\n",
      "______________\n",
      "epoch 50 train loss 0.8986115455627441\n",
      "val loss 0.9779512882232666\n",
      "______________\n",
      "epoch 51 train loss 0.9040296673774719\n",
      "val loss 0.9757497310638428\n",
      "______________\n",
      "epoch 52 train loss 0.8913795351982117\n",
      "val loss 0.9735744595527649\n",
      "______________\n",
      "epoch 53 train loss 0.8840897679328918\n",
      "val loss 0.9714134335517883\n",
      "______________\n",
      "epoch 54 train loss 0.9164157509803772\n",
      "val loss 0.9693021178245544\n",
      "______________\n",
      "epoch 55 train loss 0.8861061930656433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9671953320503235\n",
      "______________\n",
      "epoch 56 train loss 0.8757188320159912\n",
      "val loss 0.9650702476501465\n",
      "______________\n",
      "epoch 57 train loss 0.8760347366333008\n",
      "val loss 0.9629417061805725\n",
      "______________\n",
      "epoch 58 train loss 0.874550461769104\n",
      "val loss 0.960807204246521\n",
      "______________\n",
      "epoch 59 train loss 0.8601459264755249\n",
      "val loss 0.9586449861526489\n",
      "______________\n",
      "epoch 60 train loss 0.8855356574058533\n",
      "val loss 0.9564666152000427\n",
      "______________\n",
      "epoch 61 train loss 0.8438268303871155\n",
      "val loss 0.9542394280433655\n",
      "______________\n",
      "epoch 62 train loss 0.8697618246078491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9520553946495056\n",
      "______________\n",
      "epoch 63 train loss 0.8418664932250977\n",
      "val loss 0.9498945474624634\n",
      "______________\n",
      "epoch 64 train loss 0.8407280445098877\n",
      "val loss 0.9476929903030396\n",
      "______________\n",
      "epoch 65 train loss 0.8504858613014221\n",
      "val loss 0.9454843997955322\n",
      "______________\n",
      "epoch 66 train loss 0.8423816561698914\n",
      "val loss 0.9433176517486572\n",
      "______________\n",
      "epoch 67 train loss 0.8622784614562988\n",
      "val loss 0.9412416219711304\n",
      "______________\n",
      "epoch 68 train loss 0.8357423543930054\n",
      "val loss 0.9392521977424622\n",
      "______________\n",
      "epoch 69 train loss 0.8380593657493591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9373369216918945\n",
      "______________\n",
      "epoch 70 train loss 0.843306303024292\n",
      "val loss 0.9355131387710571\n",
      "______________\n",
      "epoch 71 train loss 0.8374859690666199\n",
      "val loss 0.9337259531021118\n",
      "______________\n",
      "epoch 72 train loss 0.8290356993675232\n",
      "val loss 0.9319931864738464\n",
      "______________\n",
      "epoch 73 train loss 0.8502295613288879\n",
      "val loss 0.9303345680236816\n",
      "______________\n",
      "epoch 74 train loss 0.8367541432380676\n",
      "val loss 0.9287209510803223\n",
      "______________\n",
      "epoch 75 train loss 0.8244505524635315\n",
      "val loss 0.9271388053894043\n",
      "______________\n",
      "epoch 76 train loss 0.8422021269798279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.925626277923584\n",
      "______________\n",
      "epoch 77 train loss 0.8124300837516785\n",
      "val loss 0.9241383671760559\n",
      "______________\n",
      "epoch 78 train loss 0.80866539478302\n",
      "val loss 0.9226700067520142\n",
      "______________\n",
      "epoch 79 train loss 0.7996692061424255\n",
      "val loss 0.9213011264801025\n",
      "______________\n",
      "epoch 80 train loss 0.8041038513183594\n",
      "val loss 0.9199666976928711\n",
      "______________\n",
      "epoch 81 train loss 0.8041696548461914\n",
      "val loss 0.9187549948692322\n",
      "______________\n",
      "epoch 82 train loss 0.795799732208252\n",
      "val loss 0.9176332950592041\n",
      "______________\n",
      "epoch 83 train loss 0.792749285697937\n",
      "val loss 0.9166354537010193\n",
      "______________\n",
      "epoch 84 train loss 0.7953153252601624\n",
      "val loss 0.9156736135482788\n",
      "______________\n",
      "epoch 85 train loss 0.7900003790855408\n",
      "val loss 0.914716362953186\n",
      "______________\n",
      "epoch 86 train loss 0.7831299304962158\n",
      "val loss 0.913865864276886\n",
      "______________\n",
      "epoch 87 train loss 0.7927619218826294\n",
      "val loss 0.9130504131317139\n",
      "______________\n",
      "epoch 88 train loss 0.775921106338501\n",
      "val loss 0.9123044013977051\n",
      "______________\n",
      "epoch 89 train loss 0.7972850203514099\n",
      "val loss 0.9115811586380005\n",
      "______________\n",
      "epoch 90 train loss 0.8083622455596924\n",
      "val loss 0.9109212160110474\n",
      "______________\n",
      "epoch 91 train loss 0.7819118499755859\n",
      "val loss 0.9103029370307922\n",
      "______________\n",
      "epoch 92 train loss 0.7708942294120789\n",
      "val loss 0.9097474217414856\n",
      "______________\n",
      "epoch 93 train loss 0.7783365845680237\n",
      "val loss 0.9093037247657776\n",
      "______________\n",
      "epoch 94 train loss 0.7760722637176514\n",
      "val loss 0.908882200717926\n",
      "______________\n",
      "epoch 95 train loss 0.7855337858200073\n",
      "val loss 0.9085335731506348\n",
      "______________\n",
      "epoch 96 train loss 0.7743188738822937\n",
      "val loss 0.9081763029098511\n",
      "______________\n",
      "epoch 97 train loss 0.7819778323173523\n",
      "val loss 0.9077924489974976\n",
      "______________\n",
      "epoch 98 train loss 0.7937794327735901\n",
      "val loss 0.9074514508247375\n",
      "______________\n",
      "epoch 99 train loss 0.7636070847511292\n",
      "val loss 0.9071046710014343\n",
      "______________\n",
      "epoch 100 train loss 0.7631043195724487\n",
      "val loss 0.9068099856376648\n",
      "______________\n",
      "epoch 101 train loss 0.7734307646751404\n",
      "val loss 0.90656578540802\n",
      "______________\n",
      "epoch 102 train loss 0.8043529987335205\n",
      "val loss 0.9062851071357727\n",
      "______________\n",
      "epoch 103 train loss 0.7586098909378052\n",
      "val loss 0.9060866832733154\n",
      "______________\n",
      "epoch 104 train loss 0.7748509645462036\n",
      "val loss 0.905911922454834\n",
      "______________\n",
      "epoch 105 train loss 0.7916810512542725\n",
      "val loss 0.9056832790374756\n",
      "______________\n",
      "epoch 106 train loss 0.7721922993659973\n",
      "val loss 0.905379593372345\n",
      "______________\n",
      "epoch 107 train loss 0.7590699195861816\n",
      "val loss 0.905053436756134\n",
      "______________\n",
      "epoch 108 train loss 0.7913907766342163\n",
      "val loss 0.9048100709915161\n",
      "______________\n",
      "epoch 109 train loss 0.742952823638916\n",
      "val loss 0.9046121835708618\n",
      "______________\n",
      "epoch 110 train loss 0.776060163974762\n",
      "val loss 0.9045013189315796\n",
      "______________\n",
      "epoch 111 train loss 0.756097137928009\n",
      "val loss 0.9044510722160339\n",
      "______________\n",
      "epoch 112 train loss 0.7664998173713684\n",
      "val loss 0.9043679237365723\n",
      "______________\n",
      "epoch 113 train loss 0.7514281868934631\n",
      "val loss 0.9042602181434631\n",
      "______________\n",
      "epoch 114 train loss 0.7425095438957214\n",
      "val loss 0.904133677482605\n",
      "______________\n",
      "epoch 115 train loss 0.7672140598297119\n",
      "val loss 0.9041097164154053\n",
      "______________\n",
      "epoch 116 train loss 0.7429627776145935\n",
      "val loss 0.9040393829345703\n",
      "______________\n",
      "epoch 117 train loss 0.7539992332458496\n",
      "val loss 0.9039814472198486\n",
      "______________\n",
      "epoch 118 train loss 0.7298445105552673\n",
      "val loss 0.9038599133491516\n",
      "______________\n",
      "epoch 119 train loss 0.7546911835670471\n",
      "val loss 0.9036949872970581\n",
      "______________\n",
      "epoch 120 train loss 0.7336130142211914\n",
      "val loss 0.9034173488616943\n",
      "______________\n",
      "epoch 121 train loss 0.7334138751029968\n",
      "val loss 0.9031462073326111\n",
      "______________\n",
      "epoch 122 train loss 0.7348455786705017\n",
      "val loss 0.9029123187065125\n",
      "______________\n",
      "epoch 123 train loss 0.7623264193534851\n",
      "val loss 0.9027882218360901\n",
      "______________\n",
      "epoch 124 train loss 0.7823241353034973\n",
      "val loss 0.9027546644210815\n",
      "______________\n",
      "epoch 125 train loss 0.7592849135398865\n",
      "val loss 0.9027464985847473\n",
      "______________\n",
      "epoch 126 train loss 0.7579199075698853\n",
      "val loss 0.902746319770813\n",
      "______________\n",
      "epoch 127 train loss 0.7890267372131348\n",
      "val loss 0.9027847051620483\n",
      "______________\n",
      "epoch 128 train loss 0.7345324158668518\n",
      "val loss 0.9028840661048889\n",
      "______________\n",
      "epoch 129 train loss 0.7465698719024658\n",
      "val loss 0.9030460119247437\n",
      "______________\n",
      "epoch 130 train loss 0.7381482720375061\n",
      "val loss 0.9032381176948547\n",
      "______________\n",
      "epoch 131 train loss 0.7269604802131653\n",
      "val loss 0.9033786058425903\n",
      "______________\n",
      "epoch 132 train loss 0.7264265418052673\n",
      "val loss 0.9035580158233643\n",
      "______________\n",
      "epoch 133 train loss 0.717491865158081\n",
      "val loss 0.9038254022598267\n",
      "______________\n",
      "epoch 134 train loss 0.7227908372879028\n",
      "val loss 0.9040527939796448\n",
      "______________\n",
      "epoch 135 train loss 0.7809873223304749\n",
      "val loss 0.9042680263519287\n",
      "______________\n",
      "epoch 136 train loss 0.7590438723564148\n",
      "val loss 0.9045065641403198\n",
      "______________\n",
      "epoch 137 train loss 0.7433350682258606\n",
      "val loss 0.9047189354896545\n",
      "______________\n",
      "best loss 0.902746319770813 {'Overall Survival (4 Years)': {'accuracy': 0.891156462585034, 'mse': 0.12181496, 'auc': 0.46278625954198477, 'precision': 0.891156462585034, 'recall': 1.0, 'f1': 0.9424460431654677}, 'FT': {'accuracy': 0.7959183673469388, 'mse': 0.16233434, 'auc': 0.6608695652173914, 'precision': 0.6, 'recall': 0.1875, 'f1': 0.2857142857142857}, 'Aspiration rate Post-therapy': {'accuracy': 0.8231292517006803, 'mse': 0.123743095, 'auc': 0.8092816274634456, 'precision': 0.5, 'recall': 0.23076923076923078, 'f1': 0.3157894736842105}, 'LRC': {'accuracy': 0.8979591836734694, 'mse': 0.10898266, 'auc': 0.5737373737373738, 'precision': 0.8979591836734694, 'recall': 1.0, 'f1': 0.9462365591397849}}\n",
      "{'predictions': tensor([[0.8054, 0.1093, 0.1556, 0.8302],\n",
      "        [0.8050, 0.3770, 0.5452, 0.8299],\n",
      "        [0.7295, 0.5020, 0.5559, 0.7655],\n",
      "        [0.6986, 0.3604, 0.3360, 0.7252],\n",
      "        [0.6895, 0.1886, 0.2281, 0.6991],\n",
      "        [0.8119, 0.0688, 0.0709, 0.8317],\n",
      "        [0.6699, 0.4513, 0.4500, 0.6502],\n",
      "        [0.7588, 0.1182, 0.1206, 0.7831],\n",
      "        [0.8539, 0.0287, 0.0407, 0.8612],\n",
      "        [0.8312, 0.0445, 0.0496, 0.8403],\n",
      "        [0.7636, 0.1196, 0.1178, 0.7785],\n",
      "        [0.7266, 0.2165, 0.2886, 0.8019],\n",
      "        [0.7715, 0.1510, 0.1016, 0.7751],\n",
      "        [0.8617, 0.0251, 0.0404, 0.8834],\n",
      "        [0.7048, 0.2536, 0.2780, 0.6870],\n",
      "        [0.8114, 0.0466, 0.0644, 0.8564],\n",
      "        [0.8461, 0.1239, 0.1476, 0.8352],\n",
      "        [0.7415, 0.1443, 0.1605, 0.7417],\n",
      "        [0.7870, 0.0714, 0.0689, 0.8207],\n",
      "        [0.7076, 0.2622, 0.1897, 0.7247],\n",
      "        [0.6554, 0.4021, 0.3862, 0.6910],\n",
      "        [0.7908, 0.0935, 0.0721, 0.8294],\n",
      "        [0.7009, 0.2702, 0.2824, 0.6702],\n",
      "        [0.7190, 0.5332, 0.4874, 0.7549],\n",
      "        [0.9426, 0.0038, 0.0065, 0.9775],\n",
      "        [0.7324, 0.1922, 0.1950, 0.7713],\n",
      "        [0.9103, 0.0120, 0.0135, 0.9694],\n",
      "        [0.7106, 0.3156, 0.3394, 0.7506],\n",
      "        [0.7961, 0.0802, 0.1194, 0.8070],\n",
      "        [0.8373, 0.0333, 0.0437, 0.8677],\n",
      "        [0.7914, 0.0748, 0.0810, 0.8076],\n",
      "        [0.7130, 0.2330, 0.2109, 0.7147],\n",
      "        [0.8062, 0.0613, 0.0559, 0.8383],\n",
      "        [0.6890, 0.3022, 0.3371, 0.7209],\n",
      "        [0.8412, 0.0345, 0.0441, 0.8590],\n",
      "        [0.7092, 0.4627, 0.6120, 0.7176],\n",
      "        [0.6799, 0.3514, 0.4076, 0.6692],\n",
      "        [0.7370, 0.1912, 0.1704, 0.7870],\n",
      "        [0.6293, 0.4984, 0.4251, 0.6811],\n",
      "        [0.8540, 0.0289, 0.0409, 0.8710],\n",
      "        [0.7043, 0.2188, 0.2358, 0.6900],\n",
      "        [0.8183, 0.3294, 0.3970, 0.8224],\n",
      "        [0.7038, 0.3490, 0.2924, 0.7176],\n",
      "        [0.6883, 0.3938, 0.5203, 0.7135],\n",
      "        [0.7906, 0.0882, 0.0692, 0.8284],\n",
      "        [0.8595, 0.0460, 0.0818, 0.8690],\n",
      "        [0.7447, 0.2073, 0.2062, 0.7448],\n",
      "        [0.8084, 0.0828, 0.0593, 0.8353],\n",
      "        [0.6837, 0.2134, 0.2124, 0.7263],\n",
      "        [0.7916, 0.0788, 0.0804, 0.8167],\n",
      "        [0.7098, 0.4952, 0.3249, 0.7357],\n",
      "        [0.6928, 0.2432, 0.2188, 0.7096],\n",
      "        [0.8101, 0.0740, 0.1379, 0.8015],\n",
      "        [0.7901, 0.0802, 0.0777, 0.8127],\n",
      "        [0.8083, 0.0817, 0.0909, 0.8113],\n",
      "        [0.6738, 0.3935, 0.4771, 0.6918],\n",
      "        [0.7626, 0.2504, 0.2377, 0.7537],\n",
      "        [0.7442, 0.1993, 0.1523, 0.7471],\n",
      "        [0.8271, 0.3665, 0.6305, 0.7902],\n",
      "        [0.7139, 0.1657, 0.2167, 0.7101],\n",
      "        [0.7695, 0.0910, 0.0800, 0.8193],\n",
      "        [0.6899, 0.2370, 0.2486, 0.6896],\n",
      "        [0.6993, 0.2774, 0.3803, 0.6924],\n",
      "        [0.8057, 0.0642, 0.0827, 0.8291],\n",
      "        [0.9220, 0.0093, 0.0114, 0.9713],\n",
      "        [0.8084, 0.0783, 0.0662, 0.8249],\n",
      "        [0.7217, 0.1987, 0.2177, 0.7518],\n",
      "        [0.6986, 0.3078, 0.3473, 0.7068],\n",
      "        [0.7697, 0.1112, 0.1335, 0.7775],\n",
      "        [0.7490, 0.1710, 0.2166, 0.7352],\n",
      "        [0.6395, 0.5941, 0.6256, 0.6540],\n",
      "        [0.6941, 0.2251, 0.2416, 0.7156],\n",
      "        [0.7575, 0.0952, 0.0930, 0.7984],\n",
      "        [0.8404, 0.0434, 0.0542, 0.8609],\n",
      "        [0.6646, 0.5309, 0.4877, 0.6776],\n",
      "        [0.7759, 0.1802, 0.1745, 0.7405],\n",
      "        [0.7142, 0.6716, 0.5172, 0.7562],\n",
      "        [0.6288, 0.6254, 0.5322, 0.6850],\n",
      "        [0.6836, 0.4599, 0.4345, 0.6863],\n",
      "        [0.6983, 0.2981, 0.2266, 0.7332],\n",
      "        [0.8208, 0.0549, 0.0669, 0.8458],\n",
      "        [0.7884, 0.1312, 0.1156, 0.7928],\n",
      "        [0.6240, 0.4192, 0.4771, 0.6528],\n",
      "        [0.7567, 0.1573, 0.1275, 0.7616],\n",
      "        [0.8235, 0.0689, 0.1947, 0.8527],\n",
      "        [0.7988, 0.0732, 0.0789, 0.8311],\n",
      "        [0.7286, 0.2732, 0.2183, 0.7252],\n",
      "        [0.7582, 0.2871, 0.1356, 0.7753],\n",
      "        [0.8361, 0.0298, 0.0394, 0.8727],\n",
      "        [0.7540, 0.2031, 0.3091, 0.7438],\n",
      "        [0.7444, 0.1816, 0.1655, 0.7693],\n",
      "        [0.8082, 0.0821, 0.0651, 0.8386],\n",
      "        [0.6453, 0.3344, 0.4238, 0.6558],\n",
      "        [0.8163, 0.0560, 0.0534, 0.8354],\n",
      "        [0.6726, 0.3840, 0.3614, 0.6989],\n",
      "        [0.6549, 0.6134, 0.5822, 0.6994],\n",
      "        [0.7616, 0.1177, 0.2138, 0.7380],\n",
      "        [0.7505, 0.6335, 0.5591, 0.7367],\n",
      "        [0.8415, 0.0330, 0.0412, 0.8665],\n",
      "        [0.6916, 0.5098, 0.4627, 0.7236],\n",
      "        [0.7409, 0.2444, 0.2056, 0.7337],\n",
      "        [0.7927, 0.0703, 0.0996, 0.8018],\n",
      "        [0.7265, 0.1454, 0.1796, 0.7398],\n",
      "        [0.7619, 0.3553, 0.5006, 0.7470],\n",
      "        [0.8424, 0.0350, 0.0415, 0.8689],\n",
      "        [0.7955, 0.0692, 0.0969, 0.7881],\n",
      "        [0.7677, 0.0771, 0.1149, 0.7835],\n",
      "        [0.8553, 0.0283, 0.0484, 0.8711],\n",
      "        [0.8231, 0.0907, 0.1340, 0.8420],\n",
      "        [0.7822, 0.1256, 0.1410, 0.7951],\n",
      "        [0.6735, 0.4344, 0.4117, 0.6948],\n",
      "        [0.7787, 0.0960, 0.0801, 0.8093],\n",
      "        [0.7778, 0.0871, 0.0807, 0.8036],\n",
      "        [0.7076, 0.2728, 0.2879, 0.7124],\n",
      "        [0.7504, 0.1594, 0.1460, 0.7444],\n",
      "        [0.7823, 0.1076, 0.1372, 0.7928],\n",
      "        [0.8069, 0.0555, 0.0549, 0.8415],\n",
      "        [0.7174, 0.1543, 0.1648, 0.7661],\n",
      "        [0.6972, 0.3330, 0.2395, 0.7005],\n",
      "        [0.6213, 0.5450, 0.5840, 0.6385],\n",
      "        [0.7322, 0.2070, 0.3098, 0.7061],\n",
      "        [0.7129, 0.1786, 0.2348, 0.7058],\n",
      "        [0.7174, 0.1598, 0.2240, 0.7126],\n",
      "        [0.7196, 0.1497, 0.1365, 0.7572],\n",
      "        [0.6903, 0.2412, 0.2437, 0.7396],\n",
      "        [0.8030, 0.0613, 0.0532, 0.8386],\n",
      "        [0.6806, 0.5353, 0.3962, 0.7021],\n",
      "        [0.8517, 0.0365, 0.0580, 0.8616],\n",
      "        [0.7582, 0.4427, 0.5010, 0.7695],\n",
      "        [0.8437, 0.0349, 0.0322, 0.8700],\n",
      "        [0.7479, 0.1675, 0.2044, 0.7452],\n",
      "        [0.8177, 0.0734, 0.0774, 0.8356],\n",
      "        [0.6626, 0.3484, 0.3374, 0.6606],\n",
      "        [0.7211, 0.1717, 0.2900, 0.7266],\n",
      "        [0.7673, 0.1374, 0.1142, 0.8039],\n",
      "        [0.6883, 0.2507, 0.2539, 0.6960],\n",
      "        [0.7123, 0.3490, 0.2653, 0.7235],\n",
      "        [0.7641, 0.1359, 0.2169, 0.7312],\n",
      "        [0.7034, 0.2616, 0.2935, 0.7175],\n",
      "        [0.7249, 0.1554, 0.1885, 0.7397],\n",
      "        [0.7260, 0.3164, 0.3054, 0.7168],\n",
      "        [0.6977, 0.3707, 0.3257, 0.7216],\n",
      "        [0.8618, 0.0943, 0.1339, 0.8741],\n",
      "        [0.7772, 0.1174, 0.2826, 0.7641],\n",
      "        [0.6654, 0.5529, 0.5295, 0.7237],\n",
      "        [0.7068, 0.2193, 0.2909, 0.6971],\n",
      "        [0.9111, 0.0137, 0.0317, 0.9333]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>), '5%': tensor([[7.7270e-01, 2.9840e-02, 4.6256e-02, 8.1665e-01],\n",
      "        [7.6937e-01, 7.5314e-02, 2.8025e-01, 7.8432e-01],\n",
      "        [7.4589e-01, 2.0353e-01, 2.4810e-01, 7.2811e-01],\n",
      "        [7.0307e-01, 1.6041e-01, 1.3525e-01, 7.3982e-01],\n",
      "        [6.7601e-01, 8.7698e-02, 1.1142e-01, 6.9234e-01],\n",
      "        [7.8301e-01, 3.3590e-02, 3.2052e-02, 7.7808e-01],\n",
      "        [6.8076e-01, 2.3567e-01, 2.0677e-01, 6.7578e-01],\n",
      "        [7.3567e-01, 7.5671e-02, 7.4021e-02, 7.4842e-01],\n",
      "        [8.3154e-01, 6.1666e-03, 9.6000e-03, 8.4396e-01],\n",
      "        [7.6722e-01, 1.1429e-02, 1.7923e-02, 7.6826e-01],\n",
      "        [7.2293e-01, 5.8872e-02, 5.2103e-02, 7.6984e-01],\n",
      "        [7.8003e-01, 6.2779e-02, 1.0162e-01, 7.8569e-01],\n",
      "        [7.6426e-01, 6.0462e-02, 3.4261e-02, 8.0047e-01],\n",
      "        [7.9719e-01, 8.6857e-03, 1.7179e-02, 8.4989e-01],\n",
      "        [6.9105e-01, 1.2761e-01, 1.4389e-01, 7.0572e-01],\n",
      "        [7.4811e-01, 1.6760e-02, 2.3110e-02, 8.4978e-01],\n",
      "        [7.1397e-01, 1.2308e-02, 2.1607e-02, 7.2124e-01],\n",
      "        [7.3818e-01, 4.1110e-02, 5.8930e-02, 7.7433e-01],\n",
      "        [7.4093e-01, 3.5198e-02, 3.6581e-02, 7.6357e-01],\n",
      "        [7.3032e-01, 1.2466e-01, 9.8800e-02, 7.5510e-01],\n",
      "        [6.6811e-01, 1.8344e-01, 2.1541e-01, 6.9623e-01],\n",
      "        [7.8491e-01, 4.8668e-02, 2.4761e-02, 7.9399e-01],\n",
      "        [7.0035e-01, 1.5480e-01, 1.7445e-01, 6.7570e-01],\n",
      "        [7.2006e-01, 3.0248e-01, 2.0667e-01, 7.4256e-01],\n",
      "        [8.3163e-01, 5.9973e-05, 2.4563e-04, 8.6759e-01],\n",
      "        [6.8716e-01, 7.3662e-02, 6.9383e-02, 7.4066e-01],\n",
      "        [7.7651e-01, 2.9937e-04, 8.3870e-04, 8.1376e-01],\n",
      "        [7.4127e-01, 1.0641e-01, 1.4110e-01, 7.5366e-01],\n",
      "        [7.5523e-01, 2.1244e-02, 3.3142e-02, 7.6129e-01],\n",
      "        [7.7111e-01, 8.1108e-03, 1.2876e-02, 7.9163e-01],\n",
      "        [7.6578e-01, 1.9088e-02, 2.1537e-02, 7.7029e-01],\n",
      "        [6.5681e-01, 1.3457e-01, 1.2846e-01, 6.7523e-01],\n",
      "        [7.7679e-01, 3.7439e-02, 3.2945e-02, 7.6915e-01],\n",
      "        [7.0091e-01, 1.2821e-01, 1.7058e-01, 7.0511e-01],\n",
      "        [7.9275e-01, 1.1734e-02, 1.1648e-02, 8.1989e-01],\n",
      "        [6.9742e-01, 1.8721e-01, 2.3508e-01, 6.7496e-01],\n",
      "        [6.6827e-01, 1.4325e-01, 1.9445e-01, 6.8411e-01],\n",
      "        [7.3308e-01, 7.2332e-02, 6.9243e-02, 7.5422e-01],\n",
      "        [6.9401e-01, 2.9166e-01, 2.2804e-01, 6.6987e-01],\n",
      "        [7.6294e-01, 4.8392e-03, 7.2352e-03, 8.1427e-01],\n",
      "        [6.9920e-01, 7.5857e-02, 1.1810e-01, 6.7175e-01],\n",
      "        [7.5341e-01, 4.2421e-02, 1.0351e-01, 7.6587e-01],\n",
      "        [6.8854e-01, 1.4333e-01, 1.6398e-01, 6.8553e-01],\n",
      "        [7.3118e-01, 1.5610e-01, 2.1091e-01, 7.2095e-01],\n",
      "        [7.6769e-01, 4.2108e-02, 3.9278e-02, 7.9483e-01],\n",
      "        [8.4301e-01, 5.2341e-03, 1.8935e-02, 8.4402e-01],\n",
      "        [7.5479e-01, 8.3200e-02, 7.3997e-02, 7.2521e-01],\n",
      "        [8.3176e-01, 1.8514e-02, 1.3328e-02, 8.3386e-01],\n",
      "        [6.9322e-01, 1.0784e-01, 1.2381e-01, 7.0486e-01],\n",
      "        [7.4684e-01, 2.8144e-02, 3.2273e-02, 8.0063e-01],\n",
      "        [7.2869e-01, 2.7480e-01, 1.2353e-01, 7.0626e-01],\n",
      "        [7.0988e-01, 1.0466e-01, 1.1623e-01, 7.1525e-01],\n",
      "        [7.9041e-01, 2.2701e-02, 4.7035e-02, 7.9311e-01],\n",
      "        [7.7320e-01, 3.7583e-02, 4.2802e-02, 7.8252e-01],\n",
      "        [7.5989e-01, 2.2806e-02, 3.2403e-02, 8.0593e-01],\n",
      "        [7.1684e-01, 1.5016e-01, 1.7300e-01, 7.0869e-01],\n",
      "        [7.3432e-01, 1.1049e-01, 8.0393e-02, 6.9979e-01],\n",
      "        [6.9633e-01, 7.5842e-02, 5.6013e-02, 7.4392e-01],\n",
      "        [7.4157e-01, 3.7806e-02, 2.1108e-01, 7.7546e-01],\n",
      "        [7.0330e-01, 1.0960e-01, 1.2405e-01, 7.1023e-01],\n",
      "        [7.4500e-01, 4.4028e-02, 2.7657e-02, 7.7855e-01],\n",
      "        [6.8672e-01, 1.3222e-01, 1.7129e-01, 7.0706e-01],\n",
      "        [7.2109e-01, 1.3426e-01, 1.9151e-01, 6.8256e-01],\n",
      "        [7.6082e-01, 2.6803e-02, 4.0252e-02, 7.6716e-01],\n",
      "        [7.7542e-01, 3.6712e-04, 6.1926e-04, 7.8060e-01],\n",
      "        [7.6712e-01, 2.8527e-02, 3.1157e-02, 7.7376e-01],\n",
      "        [7.2199e-01, 5.2388e-02, 8.4017e-02, 7.8510e-01],\n",
      "        [6.9979e-01, 1.2131e-01, 1.3800e-01, 6.9116e-01],\n",
      "        [7.2908e-01, 5.4878e-02, 6.3685e-02, 7.3572e-01],\n",
      "        [7.4333e-01, 7.7085e-02, 1.1807e-01, 7.2843e-01],\n",
      "        [6.2881e-01, 3.6502e-01, 3.7111e-01, 6.6470e-01],\n",
      "        [6.9709e-01, 1.1572e-01, 1.2540e-01, 7.2379e-01],\n",
      "        [7.2267e-01, 4.1364e-02, 4.3901e-02, 7.5098e-01],\n",
      "        [8.2227e-01, 1.9534e-02, 3.4232e-02, 8.1928e-01],\n",
      "        [6.1711e-01, 2.6897e-01, 2.7749e-01, 6.8344e-01],\n",
      "        [7.5335e-01, 5.8840e-02, 7.0003e-02, 7.4622e-01],\n",
      "        [7.4058e-01, 2.8362e-01, 1.5649e-01, 7.8249e-01],\n",
      "        [6.6039e-01, 3.0936e-01, 2.1381e-01, 6.9753e-01],\n",
      "        [6.8037e-01, 1.4634e-01, 1.1818e-01, 6.8469e-01],\n",
      "        [6.9222e-01, 1.4455e-01, 1.2425e-01, 7.0778e-01],\n",
      "        [7.9533e-01, 2.4326e-02, 2.7274e-02, 8.0626e-01],\n",
      "        [7.8046e-01, 5.1752e-02, 4.4667e-02, 8.0532e-01],\n",
      "        [6.1982e-01, 2.5129e-01, 3.2580e-01, 6.7327e-01],\n",
      "        [7.5200e-01, 6.1394e-02, 5.1180e-02, 7.6083e-01],\n",
      "        [8.2400e-01, 1.3615e-02, 4.8849e-02, 8.0398e-01],\n",
      "        [7.7057e-01, 2.3165e-02, 2.8417e-02, 7.8760e-01],\n",
      "        [7.5814e-01, 1.4911e-01, 8.7151e-02, 7.5014e-01],\n",
      "        [7.7632e-01, 7.5437e-02, 3.5539e-02, 7.7236e-01],\n",
      "        [7.8695e-01, 1.0772e-02, 2.1332e-02, 8.4514e-01],\n",
      "        [7.3716e-01, 7.6752e-02, 1.2371e-01, 7.8848e-01],\n",
      "        [7.1608e-01, 6.7513e-02, 5.5575e-02, 7.5017e-01],\n",
      "        [7.9043e-01, 2.9321e-02, 3.4985e-02, 8.0147e-01],\n",
      "        [6.2195e-01, 1.5410e-01, 1.8729e-01, 6.5977e-01],\n",
      "        [7.5654e-01, 1.7142e-02, 2.1223e-02, 7.9031e-01],\n",
      "        [6.6304e-01, 2.1173e-01, 1.6421e-01, 6.9299e-01],\n",
      "        [6.3701e-01, 3.0741e-01, 2.5661e-01, 7.2187e-01],\n",
      "        [7.7331e-01, 3.4003e-02, 5.3349e-02, 7.4215e-01],\n",
      "        [6.9399e-01, 2.4636e-01, 2.3293e-01, 6.9921e-01],\n",
      "        [7.7997e-01, 1.1912e-02, 2.0172e-02, 8.2717e-01],\n",
      "        [7.1665e-01, 2.0444e-01, 1.4117e-01, 7.3498e-01],\n",
      "        [7.2708e-01, 8.9418e-02, 7.3246e-02, 7.2266e-01],\n",
      "        [7.3587e-01, 1.6932e-02, 2.4003e-02, 7.5186e-01],\n",
      "        [7.2729e-01, 8.4879e-02, 9.8528e-02, 7.3991e-01],\n",
      "        [7.3303e-01, 7.9771e-02, 1.2515e-01, 7.5204e-01],\n",
      "        [7.8186e-01, 1.0975e-02, 1.5852e-02, 8.3452e-01],\n",
      "        [7.8507e-01, 2.1964e-02, 4.2235e-02, 7.3359e-01],\n",
      "        [7.1891e-01, 2.7666e-02, 4.7590e-02, 7.3548e-01],\n",
      "        [8.3513e-01, 8.9327e-03, 1.7284e-02, 8.6082e-01],\n",
      "        [7.9966e-01, 1.6931e-02, 2.3716e-02, 8.3285e-01],\n",
      "        [7.8194e-01, 5.0823e-02, 4.8843e-02, 7.8230e-01],\n",
      "        [6.7189e-01, 2.4259e-01, 1.9847e-01, 7.1217e-01],\n",
      "        [7.5640e-01, 3.4938e-02, 2.4421e-02, 7.9086e-01],\n",
      "        [7.4847e-01, 3.2320e-02, 4.3534e-02, 7.4792e-01],\n",
      "        [7.3826e-01, 9.6822e-02, 1.2654e-01, 7.5563e-01],\n",
      "        [7.1904e-01, 8.3409e-02, 5.2830e-02, 7.1905e-01],\n",
      "        [7.3634e-01, 4.3148e-02, 4.6564e-02, 8.0414e-01],\n",
      "        [8.0362e-01, 1.5756e-02, 1.4465e-02, 8.2424e-01],\n",
      "        [7.0121e-01, 8.8306e-02, 9.4671e-02, 7.2242e-01],\n",
      "        [6.8696e-01, 1.5702e-01, 1.0445e-01, 7.1704e-01],\n",
      "        [6.4842e-01, 1.7840e-01, 2.6050e-01, 6.7034e-01],\n",
      "        [7.4631e-01, 1.1925e-01, 1.0697e-01, 6.9141e-01],\n",
      "        [7.0651e-01, 8.2768e-02, 1.2844e-01, 7.0943e-01],\n",
      "        [7.0091e-01, 6.8443e-02, 1.1934e-01, 6.8886e-01],\n",
      "        [6.8703e-01, 5.4893e-02, 5.7657e-02, 7.5182e-01],\n",
      "        [6.9349e-01, 1.2803e-01, 1.3058e-01, 7.1659e-01],\n",
      "        [7.4482e-01, 1.8359e-02, 1.4389e-02, 7.8532e-01],\n",
      "        [6.7408e-01, 2.7168e-01, 1.7458e-01, 7.1296e-01],\n",
      "        [7.9303e-01, 6.2576e-03, 1.3137e-02, 7.9106e-01],\n",
      "        [7.8896e-01, 1.4285e-01, 1.2664e-01, 8.0103e-01],\n",
      "        [7.8185e-01, 1.0472e-02, 1.5165e-02, 8.3830e-01],\n",
      "        [6.9957e-01, 8.0089e-02, 1.0600e-01, 7.0579e-01],\n",
      "        [7.8216e-01, 2.3898e-02, 3.1462e-02, 8.4524e-01],\n",
      "        [6.6505e-01, 1.4935e-01, 1.4557e-01, 6.5046e-01],\n",
      "        [6.8294e-01, 7.4460e-02, 1.6040e-01, 6.9596e-01],\n",
      "        [7.0898e-01, 4.4764e-02, 4.4123e-02, 7.3934e-01],\n",
      "        [6.7216e-01, 1.3668e-01, 1.5034e-01, 6.5077e-01],\n",
      "        [7.2754e-01, 1.5307e-01, 1.2020e-01, 6.9298e-01],\n",
      "        [7.3687e-01, 6.1841e-02, 9.1948e-02, 6.8244e-01],\n",
      "        [7.2151e-01, 1.2865e-01, 1.5166e-01, 7.3888e-01],\n",
      "        [7.0856e-01, 8.1715e-02, 9.6870e-02, 7.1542e-01],\n",
      "        [7.2553e-01, 1.3163e-01, 1.1234e-01, 7.1703e-01],\n",
      "        [6.8418e-01, 1.6546e-01, 1.3736e-01, 7.2626e-01],\n",
      "        [7.1783e-01, 4.0002e-03, 3.2829e-03, 6.9494e-01],\n",
      "        [6.7724e-01, 2.3519e-02, 9.7131e-02, 7.1704e-01],\n",
      "        [6.8594e-01, 2.3285e-01, 2.7787e-01, 7.2516e-01],\n",
      "        [7.4010e-01, 8.6055e-02, 1.4992e-01, 7.0847e-01],\n",
      "        [7.9124e-01, 1.1084e-04, 4.1614e-04, 7.9916e-01]], device='cuda:0'), '95%': tensor([[0.9282, 0.1552, 0.2566, 0.9159],\n",
      "        [0.9518, 0.6338, 0.6360, 0.9677],\n",
      "        [0.8840, 0.6544, 0.6883, 0.9036],\n",
      "        [0.8211, 0.3823, 0.3080, 0.8409],\n",
      "        [0.7810, 0.2536, 0.2647, 0.8258],\n",
      "        [0.8770, 0.0989, 0.1095, 0.9034],\n",
      "        [0.8143, 0.5596, 0.6005, 0.7753],\n",
      "        [0.8370, 0.1817, 0.1740, 0.8659],\n",
      "        [0.9289, 0.0517, 0.0545, 0.9403],\n",
      "        [0.9071, 0.0934, 0.1011, 0.9264],\n",
      "        [0.8679, 0.1520, 0.1528, 0.8859],\n",
      "        [0.8783, 0.3139, 0.4209, 0.9044],\n",
      "        [0.8863, 0.1631, 0.1395, 0.8957],\n",
      "        [0.9294, 0.0392, 0.0733, 0.9515],\n",
      "        [0.8119, 0.3424, 0.3362, 0.7887],\n",
      "        [0.8831, 0.0945, 0.1185, 0.9403],\n",
      "        [0.9635, 0.4345, 0.3618, 0.9734],\n",
      "        [0.8766, 0.1588, 0.1688, 0.8601],\n",
      "        [0.8629, 0.1315, 0.1419, 0.8824],\n",
      "        [0.8500, 0.3333, 0.2310, 0.8358],\n",
      "        [0.7822, 0.4552, 0.4116, 0.8304],\n",
      "        [0.8897, 0.1245, 0.1131, 0.9155],\n",
      "        [0.7850, 0.3079, 0.2865, 0.7615],\n",
      "        [0.8740, 0.6450, 0.5631, 0.9159],\n",
      "        [0.9946, 0.0549, 0.0528, 0.9991],\n",
      "        [0.8268, 0.2920, 0.2867, 0.8879],\n",
      "        [0.9821, 0.2029, 0.0895, 0.9983],\n",
      "        [0.8669, 0.2863, 0.4010, 0.8978],\n",
      "        [0.8913, 0.1360, 0.1858, 0.9299],\n",
      "        [0.9319, 0.1043, 0.1121, 0.9360],\n",
      "        [0.8932, 0.0907, 0.0993, 0.8912],\n",
      "        [0.8129, 0.3612, 0.3260, 0.8141],\n",
      "        [0.8703, 0.1011, 0.0984, 0.9072],\n",
      "        [0.8055, 0.3018, 0.3529, 0.8328],\n",
      "        [0.9141, 0.0596, 0.0803, 0.9290],\n",
      "        [0.8107, 0.5635, 0.6405, 0.8120],\n",
      "        [0.7798, 0.4815, 0.4785, 0.7652],\n",
      "        [0.8656, 0.1977, 0.1843, 0.8807],\n",
      "        [0.7734, 0.6029, 0.4704, 0.7999],\n",
      "        [0.9419, 0.0574, 0.0877, 0.9472],\n",
      "        [0.8155, 0.3779, 0.3395, 0.7869],\n",
      "        [0.9585, 0.4820, 0.4201, 0.9404],\n",
      "        [0.8286, 0.4417, 0.3992, 0.8314],\n",
      "        [0.8501, 0.4673, 0.6271, 0.8677],\n",
      "        [0.8733, 0.1849, 0.1318, 0.9086],\n",
      "        [0.9531, 0.0957, 0.1161, 0.9697],\n",
      "        [0.8643, 0.2538, 0.2429, 0.8477],\n",
      "        [0.9307, 0.1205, 0.0711, 0.9153],\n",
      "        [0.7815, 0.2737, 0.2977, 0.8246],\n",
      "        [0.8848, 0.0980, 0.1286, 0.9135],\n",
      "        [0.8850, 0.5353, 0.3518, 0.9083],\n",
      "        [0.7997, 0.2624, 0.2367, 0.7980],\n",
      "        [0.9129, 0.1123, 0.1696, 0.9211],\n",
      "        [0.8605, 0.1222, 0.1336, 0.9049],\n",
      "        [0.9037, 0.1312, 0.1374, 0.8948],\n",
      "        [0.8293, 0.5099, 0.6103, 0.8132],\n",
      "        [0.8963, 0.2692, 0.3028, 0.9065],\n",
      "        [0.8495, 0.2466, 0.2237, 0.8463],\n",
      "        [0.9724, 0.5857, 0.7478, 0.9438],\n",
      "        [0.8135, 0.2011, 0.2360, 0.8041],\n",
      "        [0.8749, 0.1699, 0.1290, 0.9120],\n",
      "        [0.7871, 0.3002, 0.2871, 0.8018],\n",
      "        [0.8269, 0.2665, 0.3373, 0.8079],\n",
      "        [0.8703, 0.1310, 0.1762, 0.9028],\n",
      "        [0.9925, 0.1106, 0.0774, 0.9980],\n",
      "        [0.9080, 0.1262, 0.1282, 0.9180],\n",
      "        [0.8249, 0.2433, 0.2557, 0.8696],\n",
      "        [0.8267, 0.4388, 0.5159, 0.8120],\n",
      "        [0.8635, 0.1542, 0.1688, 0.8688],\n",
      "        [0.8494, 0.1860, 0.2313, 0.8465],\n",
      "        [0.7165, 0.6909, 0.7075, 0.7351],\n",
      "        [0.7929, 0.2503, 0.2566, 0.8134],\n",
      "        [0.8379, 0.1669, 0.1845, 0.8883],\n",
      "        [0.9153, 0.0788, 0.0982, 0.9074],\n",
      "        [0.7971, 0.6378, 0.5559, 0.7754],\n",
      "        [0.8954, 0.1674, 0.1859, 0.8678],\n",
      "        [0.8579, 0.7856, 0.6621, 0.8776],\n",
      "        [0.7922, 0.7445, 0.5868, 0.8126],\n",
      "        [0.8193, 0.6103, 0.5932, 0.8225],\n",
      "        [0.7743, 0.3741, 0.2745, 0.8332],\n",
      "        [0.8841, 0.1100, 0.1125, 0.9113],\n",
      "        [0.8793, 0.1561, 0.1368, 0.8947],\n",
      "        [0.7332, 0.5324, 0.5613, 0.7747],\n",
      "        [0.8684, 0.1745, 0.1238, 0.8795],\n",
      "        [0.9367, 0.1420, 0.3017, 0.9597],\n",
      "        [0.8926, 0.1209, 0.1251, 0.9074],\n",
      "        [0.8643, 0.3044, 0.2658, 0.8510],\n",
      "        [0.9050, 0.3295, 0.1321, 0.9010],\n",
      "        [0.9194, 0.0600, 0.0649, 0.9238],\n",
      "        [0.9009, 0.2474, 0.3815, 0.8791],\n",
      "        [0.8608, 0.2468, 0.2284, 0.8802],\n",
      "        [0.8691, 0.1139, 0.1034, 0.9064],\n",
      "        [0.7763, 0.4315, 0.4743, 0.8035],\n",
      "        [0.8824, 0.0701, 0.0746, 0.9122],\n",
      "        [0.7917, 0.4967, 0.4567, 0.8326],\n",
      "        [0.7945, 0.6681, 0.6313, 0.8430],\n",
      "        [0.8520, 0.1922, 0.3338, 0.8783],\n",
      "        [0.8901, 0.6699, 0.5771, 0.8821],\n",
      "        [0.8892, 0.0788, 0.0756, 0.9335],\n",
      "        [0.8166, 0.5509, 0.5948, 0.8345],\n",
      "        [0.8818, 0.2885, 0.2419, 0.8648],\n",
      "        [0.8914, 0.1889, 0.1808, 0.9025],\n",
      "        [0.8208, 0.1783, 0.2173, 0.8389],\n",
      "        [0.9026, 0.4152, 0.5470, 0.9295],\n",
      "        [0.9063, 0.0775, 0.0817, 0.9365],\n",
      "        [0.9014, 0.1011, 0.1510, 0.8813],\n",
      "        [0.8412, 0.1346, 0.2225, 0.8953],\n",
      "        [0.9130, 0.0457, 0.0729, 0.9351],\n",
      "        [0.9317, 0.1370, 0.1556, 0.9451],\n",
      "        [0.8733, 0.1481, 0.2714, 0.8872],\n",
      "        [0.8293, 0.5536, 0.4999, 0.8265],\n",
      "        [0.8574, 0.1338, 0.1081, 0.8893],\n",
      "        [0.8795, 0.1217, 0.1287, 0.8793],\n",
      "        [0.8185, 0.2573, 0.2932, 0.8371],\n",
      "        [0.8506, 0.1965, 0.2333, 0.8943],\n",
      "        [0.8714, 0.1202, 0.1653, 0.8931],\n",
      "        [0.9005, 0.0645, 0.0830, 0.9098],\n",
      "        [0.8158, 0.1955, 0.1843, 0.8205],\n",
      "        [0.8251, 0.3382, 0.3435, 0.8734],\n",
      "        [0.7744, 0.6830, 0.6951, 0.7851],\n",
      "        [0.8538, 0.2336, 0.3991, 0.8489],\n",
      "        [0.8155, 0.1977, 0.2370, 0.8276],\n",
      "        [0.8344, 0.2182, 0.3026, 0.8322],\n",
      "        [0.8151, 0.2272, 0.2154, 0.8265],\n",
      "        [0.7737, 0.3311, 0.3343, 0.8258],\n",
      "        [0.8921, 0.1075, 0.0971, 0.9042],\n",
      "        [0.8224, 0.5586, 0.5066, 0.8344],\n",
      "        [0.9293, 0.0798, 0.0895, 0.9378],\n",
      "        [0.9074, 0.6736, 0.8021, 0.9133],\n",
      "        [0.9152, 0.0713, 0.0430, 0.9400],\n",
      "        [0.8493, 0.2050, 0.2230, 0.8565],\n",
      "        [0.9081, 0.0982, 0.1002, 0.9349],\n",
      "        [0.7559, 0.4061, 0.3912, 0.7820],\n",
      "        [0.8357, 0.2461, 0.3112, 0.8431],\n",
      "        [0.8906, 0.1794, 0.1753, 0.8721],\n",
      "        [0.7898, 0.2917, 0.3247, 0.8030],\n",
      "        [0.8356, 0.3961, 0.2951, 0.8495],\n",
      "        [0.8417, 0.2451, 0.3704, 0.8297],\n",
      "        [0.8246, 0.3007, 0.2814, 0.8455],\n",
      "        [0.8312, 0.2015, 0.2187, 0.8479],\n",
      "        [0.8196, 0.4340, 0.4118, 0.8216],\n",
      "        [0.8060, 0.4957, 0.4711, 0.8381],\n",
      "        [0.9878, 0.3298, 0.4875, 0.9878],\n",
      "        [0.9147, 0.2322, 0.3975, 0.9162],\n",
      "        [0.8483, 0.6757, 0.6788, 0.8682],\n",
      "        [0.8324, 0.2413, 0.2992, 0.8132],\n",
      "        [0.9952, 0.0897, 0.1232, 0.9962]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall Survival (4 Years)': {'accuracy': 0.891156462585034,\n",
       "  'mse': 0.12181496,\n",
       "  'auc': 0.46278625954198477,\n",
       "  'precision': 0.891156462585034,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9424460431654677},\n",
       " 'FT': {'accuracy': 0.7959183673469388,\n",
       "  'mse': 0.16233434,\n",
       "  'auc': 0.6608695652173914,\n",
       "  'precision': 0.6,\n",
       "  'recall': 0.1875,\n",
       "  'f1': 0.2857142857142857},\n",
       " 'Aspiration rate Post-therapy': {'accuracy': 0.8231292517006803,\n",
       "  'mse': 0.123743095,\n",
       "  'auc': 0.8092816274634456,\n",
       "  'precision': 0.5,\n",
       "  'recall': 0.23076923076923078,\n",
       "  'f1': 0.3157894736842105},\n",
       " 'LRC': {'accuracy': 0.8979591836734694,\n",
       "  'mse': 0.10898266,\n",
       "  'auc': 0.5737373737373738,\n",
       "  'precision': 0.8979591836734694,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9462365591397849}}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel3 = train_state(model_args=t1_args,state=3,lr=.0001,weights=[.01,1,1,.01],balanced=False)\n",
    "tmodel3[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "24b7134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "I dont do balancing on the outputs because Idk how that would work\n",
      "epoch 0 train loss 1.3964802026748657\n",
      "val loss 1.1963471174240112\n",
      "______________\n",
      "epoch 1 train loss 1.1404660940170288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.106649398803711\n",
      "______________\n",
      "epoch 2 train loss 1.059977650642395\n",
      "val loss 1.0775866508483887\n",
      "______________\n",
      "epoch 3 train loss 1.0262750387191772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.0668699741363525\n",
      "______________\n",
      "epoch 4 train loss 1.0928176641464233\n",
      "val loss 1.0498102903366089\n",
      "______________\n",
      "epoch 5 train loss 1.0171576738357544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.0268012285232544\n",
      "______________\n",
      "epoch 6 train loss 0.994662880897522\n",
      "val loss 1.0035358667373657\n",
      "______________\n",
      "epoch 7 train loss 0.9928768873214722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9851148128509521\n",
      "______________\n",
      "epoch 8 train loss 0.9309216737747192\n",
      "val loss 0.973649263381958\n",
      "______________\n",
      "epoch 9 train loss 0.9165459275245667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.967697024345398\n",
      "______________\n",
      "epoch 10 train loss 0.8732008337974548\n",
      "val loss 0.9630144834518433\n",
      "______________\n",
      "epoch 11 train loss 0.861106812953949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9561439752578735\n",
      "______________\n",
      "epoch 12 train loss 0.8554192185401917\n",
      "val loss 0.9457665085792542\n",
      "______________\n",
      "epoch 13 train loss 0.8295349478721619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9321502447128296\n",
      "______________\n",
      "epoch 14 train loss 0.8176907896995544\n",
      "val loss 0.9187045693397522\n",
      "______________\n",
      "epoch 15 train loss 0.7976666688919067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 0.9072685241699219\n",
      "______________\n",
      "epoch 16 train loss 0.7850359678268433\n",
      "val loss 0.8999933004379272\n",
      "______________\n",
      "epoch 17 train loss 0.7819223999977112\n",
      "val loss 0.8971668481826782\n",
      "______________\n",
      "epoch 18 train loss 0.7677599787712097\n",
      "val loss 0.8978080153465271\n",
      "______________\n",
      "epoch 19 train loss 0.7467177510261536\n",
      "val loss 0.9008331298828125\n",
      "______________\n",
      "epoch 20 train loss 0.7714910507202148\n",
      "val loss 0.9040116667747498\n",
      "______________\n",
      "epoch 21 train loss 0.7713718414306641\n",
      "val loss 0.9060133099555969\n",
      "______________\n",
      "epoch 22 train loss 0.7566870450973511\n",
      "val loss 0.9070581197738647\n",
      "______________\n",
      "epoch 23 train loss 0.759768545627594\n",
      "val loss 0.9077432751655579\n",
      "______________\n",
      "epoch 24 train loss 0.7474350333213806\n",
      "val loss 0.9085972309112549\n",
      "______________\n",
      "epoch 25 train loss 0.7027341723442078\n",
      "val loss 0.9105086922645569\n",
      "______________\n",
      "epoch 26 train loss 0.7426238059997559\n",
      "val loss 0.9117539525032043\n",
      "______________\n",
      "epoch 27 train loss 0.7268173098564148\n",
      "val loss 0.9121626019477844\n",
      "______________\n",
      "epoch 28 train loss 0.7020962238311768\n",
      "val loss 0.9123637080192566\n",
      "______________\n",
      "best loss 0.8971668481826782 {'Overall Survival (4 Years)': {'accuracy': 0.891156462585034, 'mse': 0.11325208, 'auc': 0.5333969465648855, 'precision': 0.891156462585034, 'recall': 1.0, 'f1': 0.9424460431654677}, 'FT': {'accuracy': 0.7959183673469388, 'mse': 0.15967897, 'auc': 0.6739130434782609, 'precision': 0.6666666666666666, 'recall': 0.125, 'f1': 0.21052631578947367}, 'Aspiration rate Post-therapy': {'accuracy': 0.8027210884353742, 'mse': 0.123974934, 'auc': 0.799745708836618, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'LRC': {'accuracy': 0.8979591836734694, 'mse': 0.096907504, 'auc': 0.6979797979797979, 'precision': 0.8979591836734694, 'recall': 1.0, 'f1': 0.9462365591397849}}\n",
      "{'predictions': tensor([[0.8726, 0.0979, 0.1750, 0.8769],\n",
      "        [0.7492, 0.3951, 0.4788, 0.7727],\n",
      "        [0.6483, 0.4359, 0.4818, 0.6634],\n",
      "        [0.7097, 0.3380, 0.3475, 0.6720],\n",
      "        [0.7812, 0.2052, 0.2252, 0.7616],\n",
      "        [0.9211, 0.0766, 0.0537, 0.9228],\n",
      "        [0.7252, 0.3135, 0.3336, 0.7190],\n",
      "        [0.8817, 0.1182, 0.0857, 0.8877],\n",
      "        [0.9507, 0.0335, 0.0348, 0.9491],\n",
      "        [0.9132, 0.0683, 0.0568, 0.9212],\n",
      "        [0.8690, 0.1212, 0.0991, 0.8767],\n",
      "        [0.8212, 0.1425, 0.2501, 0.8492],\n",
      "        [0.8739, 0.1652, 0.0886, 0.8707],\n",
      "        [0.9438, 0.0322, 0.0451, 0.9509],\n",
      "        [0.6932, 0.3312, 0.2924, 0.7053],\n",
      "        [0.9249, 0.0440, 0.0723, 0.9254],\n",
      "        [0.8857, 0.1852, 0.0846, 0.8967],\n",
      "        [0.8374, 0.1722, 0.1456, 0.8272],\n",
      "        [0.9124, 0.0695, 0.0577, 0.9193],\n",
      "        [0.7935, 0.3315, 0.1859, 0.7408],\n",
      "        [0.6686, 0.4124, 0.3190, 0.6625],\n",
      "        [0.8846, 0.1216, 0.0817, 0.8776],\n",
      "        [0.6889, 0.3446, 0.3048, 0.6989],\n",
      "        [0.6630, 0.4667, 0.4480, 0.6161],\n",
      "        [0.9862, 0.0089, 0.0054, 0.9908],\n",
      "        [0.7923, 0.2031, 0.2178, 0.7830],\n",
      "        [0.9790, 0.0196, 0.0095, 0.9835],\n",
      "        [0.7672, 0.3195, 0.2848, 0.7560],\n",
      "        [0.8730, 0.0963, 0.1281, 0.8670],\n",
      "        [0.9320, 0.0448, 0.0460, 0.9443],\n",
      "        [0.9118, 0.0695, 0.0677, 0.9140],\n",
      "        [0.7202, 0.2854, 0.2359, 0.7470],\n",
      "        [0.9280, 0.0592, 0.0452, 0.9323],\n",
      "        [0.6814, 0.3559, 0.3551, 0.6821],\n",
      "        [0.9349, 0.0433, 0.0407, 0.9472],\n",
      "        [0.6622, 0.3720, 0.5411, 0.6561],\n",
      "        [0.6243, 0.3922, 0.4070, 0.6446],\n",
      "        [0.8213, 0.2098, 0.1653, 0.8340],\n",
      "        [0.6295, 0.4748, 0.3901, 0.6213],\n",
      "        [0.9385, 0.0399, 0.0418, 0.9494],\n",
      "        [0.7762, 0.2336, 0.1967, 0.7860],\n",
      "        [0.7717, 0.3048, 0.2852, 0.7951],\n",
      "        [0.6851, 0.4174, 0.2921, 0.6842],\n",
      "        [0.7163, 0.2912, 0.5064, 0.6962],\n",
      "        [0.9073, 0.1128, 0.0570, 0.9023],\n",
      "        [0.8856, 0.0810, 0.0985, 0.9102],\n",
      "        [0.8057, 0.2394, 0.1857, 0.7928],\n",
      "        [0.9055, 0.1135, 0.0495, 0.9090],\n",
      "        [0.7520, 0.2667, 0.2420, 0.7306],\n",
      "        [0.9100, 0.0830, 0.0768, 0.8991],\n",
      "        [0.7287, 0.4570, 0.2769, 0.6939],\n",
      "        [0.7274, 0.3150, 0.2396, 0.7185],\n",
      "        [0.7978, 0.1426, 0.2129, 0.8192],\n",
      "        [0.8965, 0.0925, 0.0680, 0.9076],\n",
      "        [0.9034, 0.0962, 0.0523, 0.9150],\n",
      "        [0.6152, 0.4726, 0.4637, 0.6144],\n",
      "        [0.7873, 0.2970, 0.1995, 0.7790],\n",
      "        [0.8375, 0.2158, 0.1229, 0.8364],\n",
      "        [0.7127, 0.2951, 0.4284, 0.7878],\n",
      "        [0.7914, 0.2086, 0.2065, 0.7871],\n",
      "        [0.8912, 0.1142, 0.0802, 0.8852],\n",
      "        [0.7562, 0.2448, 0.2204, 0.7560],\n",
      "        [0.6636, 0.3330, 0.3632, 0.6777],\n",
      "        [0.9108, 0.0620, 0.0794, 0.9189],\n",
      "        [0.9798, 0.0206, 0.0077, 0.9850],\n",
      "        [0.9025, 0.1045, 0.0653, 0.9059],\n",
      "        [0.8053, 0.1944, 0.1814, 0.8077],\n",
      "        [0.6081, 0.4461, 0.4117, 0.6191],\n",
      "        [0.8153, 0.1546, 0.1938, 0.8079],\n",
      "        [0.7862, 0.2218, 0.2075, 0.7824],\n",
      "        [0.5637, 0.5185, 0.5164, 0.5918],\n",
      "        [0.7477, 0.2644, 0.2758, 0.7236],\n",
      "        [0.8962, 0.0921, 0.0707, 0.8998],\n",
      "        [0.9335, 0.0458, 0.0563, 0.9334],\n",
      "        [0.6272, 0.4748, 0.4200, 0.6276],\n",
      "        [0.8152, 0.1736, 0.2132, 0.8174],\n",
      "        [0.6059, 0.5480, 0.4948, 0.6208],\n",
      "        [0.6057, 0.5449, 0.4415, 0.5849],\n",
      "        [0.6453, 0.3949, 0.3617, 0.6902],\n",
      "        [0.7619, 0.2779, 0.1913, 0.7669],\n",
      "        [0.9258, 0.0613, 0.0547, 0.9346],\n",
      "        [0.8472, 0.1938, 0.1203, 0.8350],\n",
      "        [0.6352, 0.3972, 0.4280, 0.6252],\n",
      "        [0.8390, 0.2187, 0.1259, 0.8208],\n",
      "        [0.8816, 0.0803, 0.2390, 0.8823],\n",
      "        [0.9158, 0.0747, 0.0710, 0.9122],\n",
      "        [0.7556, 0.3344, 0.2456, 0.7315],\n",
      "        [0.8443, 0.3246, 0.0997, 0.8182],\n",
      "        [0.9488, 0.0323, 0.0325, 0.9563],\n",
      "        [0.7666, 0.2097, 0.3459, 0.7553],\n",
      "        [0.7993, 0.2609, 0.1730, 0.8017],\n",
      "        [0.9029, 0.1116, 0.0630, 0.9005],\n",
      "        [0.6040, 0.4226, 0.4008, 0.6185],\n",
      "        [0.9360, 0.0591, 0.0382, 0.9388],\n",
      "        [0.6652, 0.4054, 0.3501, 0.6547],\n",
      "        [0.6252, 0.5265, 0.4826, 0.6105],\n",
      "        [0.7338, 0.2012, 0.2944, 0.7512],\n",
      "        [0.6173, 0.5641, 0.4990, 0.6545],\n",
      "        [0.9412, 0.0327, 0.0495, 0.9386],\n",
      "        [0.5978, 0.5075, 0.4492, 0.6173],\n",
      "        [0.7671, 0.2832, 0.2400, 0.7476],\n",
      "        [0.8716, 0.0949, 0.1190, 0.8723],\n",
      "        [0.7906, 0.1862, 0.1922, 0.7837],\n",
      "        [0.7195, 0.3371, 0.4693, 0.7092],\n",
      "        [0.9311, 0.0463, 0.0489, 0.9388],\n",
      "        [0.8408, 0.1248, 0.1482, 0.8405],\n",
      "        [0.8715, 0.0933, 0.1416, 0.8611],\n",
      "        [0.9337, 0.0403, 0.0679, 0.9210],\n",
      "        [0.8975, 0.0915, 0.1143, 0.9053],\n",
      "        [0.8452, 0.1375, 0.1362, 0.8508],\n",
      "        [0.6370, 0.4421, 0.4259, 0.6502],\n",
      "        [0.8992, 0.0910, 0.0713, 0.9042],\n",
      "        [0.8977, 0.1007, 0.0702, 0.8975],\n",
      "        [0.7381, 0.2737, 0.3264, 0.7289],\n",
      "        [0.7950, 0.2543, 0.1744, 0.7786],\n",
      "        [0.8463, 0.1144, 0.1395, 0.8619],\n",
      "        [0.9358, 0.0497, 0.0421, 0.9422],\n",
      "        [0.8546, 0.1421, 0.1232, 0.8392],\n",
      "        [0.7272, 0.4340, 0.2473, 0.6730],\n",
      "        [0.5668, 0.4646, 0.4927, 0.5977],\n",
      "        [0.7062, 0.3086, 0.3739, 0.6823],\n",
      "        [0.7605, 0.2448, 0.2673, 0.7446],\n",
      "        [0.7886, 0.1904, 0.2510, 0.7652],\n",
      "        [0.8416, 0.1575, 0.1189, 0.8480],\n",
      "        [0.7150, 0.3163, 0.2412, 0.7181],\n",
      "        [0.9327, 0.0540, 0.0462, 0.9335],\n",
      "        [0.6245, 0.5262, 0.3698, 0.6195],\n",
      "        [0.9454, 0.0347, 0.0404, 0.9558],\n",
      "        [0.6953, 0.3874, 0.4010, 0.7051],\n",
      "        [0.9378, 0.0493, 0.0339, 0.9474],\n",
      "        [0.8386, 0.1349, 0.1706, 0.8411],\n",
      "        [0.8912, 0.0980, 0.0857, 0.9021],\n",
      "        [0.6686, 0.3641, 0.3136, 0.6829],\n",
      "        [0.6898, 0.2851, 0.2885, 0.7376],\n",
      "        [0.8457, 0.2077, 0.1090, 0.8439],\n",
      "        [0.6996, 0.2965, 0.3096, 0.7087],\n",
      "        [0.7420, 0.4331, 0.2097, 0.7354],\n",
      "        [0.7264, 0.2354, 0.2970, 0.7438],\n",
      "        [0.7123, 0.3106, 0.2592, 0.7264],\n",
      "        [0.8195, 0.1667, 0.1889, 0.7976],\n",
      "        [0.7494, 0.2917, 0.2353, 0.7454],\n",
      "        [0.6882, 0.4008, 0.3238, 0.6654],\n",
      "        [0.9028, 0.1122, 0.1915, 0.8775],\n",
      "        [0.7706, 0.1370, 0.2486, 0.8295],\n",
      "        [0.6332, 0.5131, 0.4378, 0.6552],\n",
      "        [0.7590, 0.2350, 0.2917, 0.7290],\n",
      "        [0.9638, 0.0316, 0.0298, 0.9685]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>), '5%': tensor([[8.2457e-01, 4.5836e-02, 4.8468e-02, 8.4647e-01],\n",
      "        [7.9406e-01, 7.7908e-02, 1.4575e-01, 7.4755e-01],\n",
      "        [6.2476e-01, 1.4895e-01, 2.7886e-01, 6.4122e-01],\n",
      "        [6.7793e-01, 1.2791e-01, 1.2750e-01, 6.8779e-01],\n",
      "        [7.9265e-01, 1.0783e-01, 8.9656e-02, 7.6539e-01],\n",
      "        [8.9708e-01, 2.7189e-02, 1.8979e-02, 8.9931e-01],\n",
      "        [6.8532e-01, 1.4908e-01, 2.0362e-01, 7.1577e-01],\n",
      "        [8.3260e-01, 3.3699e-02, 3.0447e-02, 8.2523e-01],\n",
      "        [9.2912e-01, 8.9520e-03, 1.6721e-02, 9.2497e-01],\n",
      "        [8.7300e-01, 3.4818e-02, 2.8803e-02, 8.6282e-01],\n",
      "        [7.9479e-01, 6.1213e-02, 4.3652e-02, 8.0143e-01],\n",
      "        [7.9798e-01, 5.6333e-02, 9.1051e-02, 8.3640e-01],\n",
      "        [8.5218e-01, 7.4341e-02, 3.8851e-02, 8.2132e-01],\n",
      "        [9.1856e-01, 1.5618e-02, 1.4761e-02, 9.0459e-01],\n",
      "        [6.9807e-01, 1.8371e-01, 1.9728e-01, 7.2334e-01],\n",
      "        [8.9772e-01, 1.6253e-02, 2.1362e-02, 8.8677e-01],\n",
      "        [6.6218e-01, 2.1570e-02, 8.7083e-03, 6.7763e-01],\n",
      "        [8.0563e-01, 9.4147e-02, 7.7273e-02, 7.7991e-01],\n",
      "        [8.3213e-01, 2.3999e-02, 1.7636e-02, 8.6648e-01],\n",
      "        [8.1034e-01, 1.2235e-01, 6.1299e-02, 7.6467e-01],\n",
      "        [6.6637e-01, 2.1090e-01, 1.3598e-01, 6.7349e-01],\n",
      "        [8.5398e-01, 6.0524e-02, 3.6009e-02, 8.5043e-01],\n",
      "        [7.0164e-01, 2.3647e-01, 2.1132e-01, 6.9394e-01],\n",
      "        [6.7374e-01, 2.6829e-01, 2.2847e-01, 6.4077e-01],\n",
      "        [9.1263e-01, 4.7522e-04, 3.3276e-04, 9.1529e-01],\n",
      "        [7.4544e-01, 5.6256e-02, 6.0047e-02, 7.7643e-01],\n",
      "        [9.1493e-01, 1.0083e-03, 1.5123e-04, 9.1858e-01],\n",
      "        [7.3846e-01, 1.0509e-01, 1.0909e-01, 7.7112e-01],\n",
      "        [7.4356e-01, 2.9731e-02, 5.2416e-02, 8.0004e-01],\n",
      "        [8.7275e-01, 2.0693e-02, 1.1255e-02, 9.0126e-01],\n",
      "        [8.5969e-01, 2.6028e-02, 3.7966e-02, 8.5249e-01],\n",
      "        [7.1190e-01, 1.9079e-01, 1.1722e-01, 7.4212e-01],\n",
      "        [8.8698e-01, 2.1283e-02, 2.3185e-02, 8.9332e-01],\n",
      "        [7.1874e-01, 1.7239e-01, 1.7581e-01, 7.1436e-01],\n",
      "        [9.0998e-01, 2.0129e-02, 1.4770e-02, 9.3182e-01],\n",
      "        [6.5621e-01, 1.3466e-01, 3.2155e-01, 6.2568e-01],\n",
      "        [6.2093e-01, 2.4647e-01, 1.9010e-01, 6.5475e-01],\n",
      "        [8.2364e-01, 8.1444e-02, 6.4614e-02, 8.2665e-01],\n",
      "        [6.2002e-01, 2.5580e-01, 1.8763e-01, 6.3100e-01],\n",
      "        [8.9776e-01, 8.7428e-03, 7.6501e-03, 9.0969e-01],\n",
      "        [6.8663e-01, 8.2848e-02, 8.1195e-02, 7.8139e-01],\n",
      "        [7.2941e-01, 8.0667e-02, 1.5987e-01, 7.2946e-01],\n",
      "        [7.0511e-01, 2.0510e-01, 1.5339e-01, 7.0576e-01],\n",
      "        [7.2442e-01, 1.3948e-01, 3.4434e-01, 7.5527e-01],\n",
      "        [8.3367e-01, 4.4177e-02, 2.4541e-02, 8.2223e-01],\n",
      "        [8.1746e-01, 1.5133e-02, 1.8646e-02, 8.5958e-01],\n",
      "        [8.0048e-01, 1.0950e-01, 7.9354e-02, 7.5614e-01],\n",
      "        [8.9770e-01, 4.0800e-02, 1.4739e-02, 8.7817e-01],\n",
      "        [7.3812e-01, 1.1691e-01, 1.2444e-01, 7.1943e-01],\n",
      "        [8.5884e-01, 6.4608e-02, 5.2371e-02, 8.4149e-01],\n",
      "        [7.1476e-01, 2.8945e-01, 1.3591e-01, 7.4170e-01],\n",
      "        [7.0513e-01, 1.9261e-01, 1.1328e-01, 7.0651e-01],\n",
      "        [7.7609e-01, 6.8862e-02, 1.0567e-01, 7.9915e-01],\n",
      "        [8.7293e-01, 3.1384e-02, 2.3420e-02, 8.6682e-01],\n",
      "        [8.6138e-01, 4.0364e-02, 1.1805e-02, 9.0221e-01],\n",
      "        [6.3995e-01, 2.7635e-01, 1.8076e-01, 6.3511e-01],\n",
      "        [7.2927e-01, 1.3557e-01, 7.2756e-02, 7.8333e-01],\n",
      "        [8.2448e-01, 9.8666e-02, 3.8585e-02, 8.4665e-01],\n",
      "        [6.2744e-01, 6.3935e-02, 1.4888e-01, 7.7157e-01],\n",
      "        [7.5442e-01, 9.2961e-02, 9.7019e-02, 7.4974e-01],\n",
      "        [8.5866e-01, 4.9017e-02, 2.9573e-02, 8.7705e-01],\n",
      "        [6.8135e-01, 1.5570e-01, 1.4324e-01, 7.1489e-01],\n",
      "        [7.0882e-01, 1.7765e-01, 2.3130e-01, 6.9164e-01],\n",
      "        [8.9800e-01, 1.8265e-02, 1.6474e-02, 8.9674e-01],\n",
      "        [9.2123e-01, 1.3956e-03, 4.6728e-04, 9.3264e-01],\n",
      "        [8.5971e-01, 3.4602e-02, 2.1488e-02, 8.7876e-01],\n",
      "        [8.1751e-01, 1.0821e-01, 8.8821e-02, 7.9619e-01],\n",
      "        [6.4736e-01, 2.6865e-01, 2.2816e-01, 6.4314e-01],\n",
      "        [7.7496e-01, 5.7757e-02, 7.3982e-02, 7.7233e-01],\n",
      "        [7.4413e-01, 8.4156e-02, 9.0129e-02, 7.5747e-01],\n",
      "        [5.6015e-01, 3.1829e-01, 2.8300e-01, 6.2368e-01],\n",
      "        [7.3681e-01, 1.3675e-01, 1.1273e-01, 7.5233e-01],\n",
      "        [8.5479e-01, 4.0896e-02, 2.7134e-02, 8.4258e-01],\n",
      "        [9.2121e-01, 1.4819e-02, 1.7682e-02, 9.2282e-01],\n",
      "        [6.7049e-01, 3.3457e-01, 2.5332e-01, 6.3880e-01],\n",
      "        [8.0417e-01, 9.0471e-02, 1.0668e-01, 8.2120e-01],\n",
      "        [6.4566e-01, 2.4333e-01, 1.5160e-01, 6.4603e-01],\n",
      "        [6.1878e-01, 3.6160e-01, 2.4893e-01, 6.1525e-01],\n",
      "        [6.2317e-01, 1.9404e-01, 1.4047e-01, 7.1182e-01],\n",
      "        [7.4593e-01, 1.2590e-01, 8.1715e-02, 7.2294e-01],\n",
      "        [8.6746e-01, 2.1024e-02, 2.5055e-02, 8.7341e-01],\n",
      "        [7.9095e-01, 8.7232e-02, 6.1628e-02, 7.7895e-01],\n",
      "        [6.2216e-01, 2.4931e-01, 2.3885e-01, 6.4994e-01],\n",
      "        [8.0404e-01, 9.8045e-02, 5.4846e-02, 8.1814e-01],\n",
      "        [8.3566e-01, 1.6808e-02, 6.8801e-02, 8.3078e-01],\n",
      "        [8.7536e-01, 2.7756e-02, 3.5263e-02, 8.7510e-01],\n",
      "        [7.0698e-01, 1.9994e-01, 1.1098e-01, 7.1514e-01],\n",
      "        [8.7386e-01, 1.5230e-01, 2.4834e-02, 8.1104e-01],\n",
      "        [9.2517e-01, 1.0893e-02, 9.5952e-03, 9.2009e-01],\n",
      "        [7.9012e-01, 9.8571e-02, 1.1899e-01, 7.4983e-01],\n",
      "        [8.1833e-01, 1.2517e-01, 7.2142e-02, 8.0543e-01],\n",
      "        [8.9035e-01, 3.0294e-02, 1.8365e-02, 8.6116e-01],\n",
      "        [5.8573e-01, 2.3911e-01, 2.3426e-01, 6.0578e-01],\n",
      "        [8.6877e-01, 1.3925e-02, 1.3014e-02, 8.6374e-01],\n",
      "        [6.6678e-01, 2.5256e-01, 1.9345e-01, 6.3065e-01],\n",
      "        [6.4587e-01, 3.4570e-01, 2.7404e-01, 6.2956e-01],\n",
      "        [6.7610e-01, 6.9153e-02, 1.2890e-01, 6.8882e-01],\n",
      "        [6.0999e-01, 2.4203e-01, 2.6900e-01, 6.7018e-01],\n",
      "        [9.1335e-01, 1.1967e-02, 1.7844e-02, 9.1084e-01],\n",
      "        [6.3360e-01, 2.1610e-01, 1.7137e-01, 6.5979e-01],\n",
      "        [7.4629e-01, 1.4829e-01, 8.3660e-02, 7.8274e-01],\n",
      "        [8.2187e-01, 2.7522e-02, 5.0982e-02, 8.3455e-01],\n",
      "        [7.7231e-01, 9.2569e-02, 8.4946e-02, 7.4627e-01],\n",
      "        [7.0675e-01, 1.2754e-01, 2.6205e-01, 7.2402e-01],\n",
      "        [8.8050e-01, 2.2220e-02, 3.5136e-02, 8.8468e-01],\n",
      "        [8.0580e-01, 4.6642e-02, 6.8049e-02, 7.8785e-01],\n",
      "        [7.8386e-01, 3.7018e-02, 6.2162e-02, 7.5653e-01],\n",
      "        [9.0059e-01, 1.8911e-02, 1.7207e-02, 9.1920e-01],\n",
      "        [8.6772e-01, 3.6624e-02, 2.8317e-02, 8.5255e-01],\n",
      "        [8.1019e-01, 5.2296e-02, 4.2557e-02, 8.3379e-01],\n",
      "        [6.3922e-01, 2.6406e-01, 2.0323e-01, 6.5361e-01],\n",
      "        [8.5613e-01, 3.7008e-02, 2.4532e-02, 8.7709e-01],\n",
      "        [8.3862e-01, 4.8151e-02, 2.3427e-02, 8.5173e-01],\n",
      "        [7.5107e-01, 1.5444e-01, 1.5946e-01, 6.9045e-01],\n",
      "        [7.5965e-01, 1.3210e-01, 8.3804e-02, 7.8940e-01],\n",
      "        [8.5397e-01, 4.6387e-02, 6.3268e-02, 8.5736e-01],\n",
      "        [9.0574e-01, 1.7200e-02, 1.9399e-02, 8.9279e-01],\n",
      "        [8.0889e-01, 3.9194e-02, 4.3769e-02, 8.0100e-01],\n",
      "        [7.1464e-01, 2.6395e-01, 1.1982e-01, 6.7945e-01],\n",
      "        [5.8547e-01, 2.6275e-01, 3.4146e-01, 5.9880e-01],\n",
      "        [6.7969e-01, 1.4360e-01, 1.6007e-01, 6.8140e-01],\n",
      "        [7.7051e-01, 1.2336e-01, 1.7211e-01, 7.6231e-01],\n",
      "        [7.5517e-01, 6.9204e-02, 8.6143e-02, 7.2413e-01],\n",
      "        [8.1610e-01, 7.3316e-02, 5.6826e-02, 8.0367e-01],\n",
      "        [7.5083e-01, 1.2198e-01, 1.3397e-01, 7.2723e-01],\n",
      "        [8.8808e-01, 2.3856e-02, 1.6927e-02, 8.9617e-01],\n",
      "        [6.5836e-01, 3.3493e-01, 2.0013e-01, 6.4751e-01],\n",
      "        [8.8249e-01, 9.2106e-03, 1.6434e-02, 9.1176e-01],\n",
      "        [6.6571e-01, 1.5094e-01, 9.5257e-02, 6.9504e-01],\n",
      "        [9.1120e-01, 1.6073e-02, 1.5298e-02, 9.1255e-01],\n",
      "        [8.1981e-01, 3.8890e-02, 7.8811e-02, 8.1207e-01],\n",
      "        [8.3276e-01, 2.9291e-02, 3.1140e-02, 8.6461e-01],\n",
      "        [6.7516e-01, 2.3145e-01, 1.5107e-01, 6.9496e-01],\n",
      "        [6.5691e-01, 1.2032e-01, 1.3078e-01, 6.8480e-01],\n",
      "        [8.4834e-01, 8.0921e-02, 3.8326e-02, 8.2530e-01],\n",
      "        [6.9082e-01, 2.1620e-01, 2.3913e-01, 6.8892e-01],\n",
      "        [7.1090e-01, 2.7122e-01, 6.6166e-02, 7.1286e-01],\n",
      "        [7.0224e-01, 1.3424e-01, 1.5630e-01, 7.1599e-01],\n",
      "        [6.8387e-01, 1.4696e-01, 1.3359e-01, 7.4868e-01],\n",
      "        [7.7246e-01, 7.5149e-02, 9.4131e-02, 7.8154e-01],\n",
      "        [7.3000e-01, 1.0785e-01, 8.4695e-02, 7.4003e-01],\n",
      "        [6.7136e-01, 2.4817e-01, 1.6528e-01, 6.4350e-01],\n",
      "        [6.8975e-01, 1.2295e-02, 1.3992e-02, 6.4660e-01],\n",
      "        [7.0440e-01, 2.4496e-02, 7.3971e-02, 7.0189e-01],\n",
      "        [6.2751e-01, 2.8453e-01, 2.2098e-01, 6.5620e-01],\n",
      "        [7.3737e-01, 1.2602e-01, 1.6896e-01, 7.2676e-01],\n",
      "        [7.8135e-01, 1.2724e-03, 8.2663e-04, 8.1604e-01]], device='cuda:0'), '95%': tensor([[0.9473, 0.1792, 0.2085, 0.9455],\n",
      "        [0.9460, 0.5006, 0.4839, 0.9512],\n",
      "        [0.8516, 0.5318, 0.4875, 0.8526],\n",
      "        [0.8662, 0.4099, 0.4206, 0.8634],\n",
      "        [0.8976, 0.2021, 0.2176, 0.8908],\n",
      "        [0.9751, 0.1014, 0.0849, 0.9680],\n",
      "        [0.8931, 0.3432, 0.3192, 0.8531],\n",
      "        [0.9613, 0.1780, 0.1487, 0.9597],\n",
      "        [0.9868, 0.0744, 0.0597, 0.9829],\n",
      "        [0.9494, 0.1071, 0.0819, 0.9547],\n",
      "        [0.9328, 0.2308, 0.1615, 0.9353],\n",
      "        [0.9126, 0.1686, 0.3239, 0.9339],\n",
      "        [0.9501, 0.1850, 0.1287, 0.9583],\n",
      "        [0.9747, 0.0662, 0.0914, 0.9814],\n",
      "        [0.8219, 0.3323, 0.3078, 0.8067],\n",
      "        [0.9676, 0.0696, 0.1121, 0.9742],\n",
      "        [0.9768, 0.4164, 0.3777, 0.9837],\n",
      "        [0.9173, 0.2374, 0.2263, 0.9082],\n",
      "        [0.9762, 0.1180, 0.1197, 0.9655],\n",
      "        [0.9367, 0.3258, 0.1860, 0.8799],\n",
      "        [0.8586, 0.4170, 0.4085, 0.8484],\n",
      "        [0.9452, 0.1639, 0.1476, 0.9348],\n",
      "        [0.7973, 0.3643, 0.3422, 0.7909],\n",
      "        [0.8236, 0.5026, 0.4484, 0.7800],\n",
      "        [0.9994, 0.0940, 0.0716, 0.9995],\n",
      "        [0.9258, 0.2320, 0.2349, 0.9276],\n",
      "        [0.9990, 0.0876, 0.0760, 0.9993],\n",
      "        [0.9416, 0.3561, 0.2691, 0.9343],\n",
      "        [0.9354, 0.2202, 0.2621, 0.9379],\n",
      "        [0.9744, 0.0812, 0.0929, 0.9685],\n",
      "        [0.9653, 0.1434, 0.1448, 0.9653],\n",
      "        [0.8935, 0.3340, 0.2669, 0.8627],\n",
      "        [0.9738, 0.0805, 0.0645, 0.9705],\n",
      "        [0.8288, 0.3413, 0.3700, 0.7967],\n",
      "        [0.9775, 0.0724, 0.0646, 0.9793],\n",
      "        [0.7998, 0.4752, 0.5991, 0.7947],\n",
      "        [0.7895, 0.4033, 0.4121, 0.8087],\n",
      "        [0.9421, 0.2630, 0.1834, 0.9484],\n",
      "        [0.8184, 0.4998, 0.4923, 0.7686],\n",
      "        [0.9865, 0.0796, 0.0663, 0.9883],\n",
      "        [0.9075, 0.2736, 0.2422, 0.9021],\n",
      "        [0.9294, 0.4540, 0.3249, 0.9440],\n",
      "        [0.8280, 0.3901, 0.3052, 0.8082],\n",
      "        [0.8620, 0.3474, 0.5609, 0.8424],\n",
      "        [0.9454, 0.1837, 0.0979, 0.9579],\n",
      "        [0.9830, 0.1615, 0.1800, 0.9816],\n",
      "        [0.9011, 0.2553, 0.2720, 0.8921],\n",
      "        [0.9659, 0.1710, 0.0505, 0.9738],\n",
      "        [0.8968, 0.3311, 0.2852, 0.8586],\n",
      "        [0.9350, 0.1446, 0.1368, 0.9261],\n",
      "        [0.8614, 0.5239, 0.2415, 0.8650],\n",
      "        [0.8532, 0.4153, 0.2486, 0.8506],\n",
      "        [0.8998, 0.1766, 0.2376, 0.9017],\n",
      "        [0.9696, 0.1415, 0.1122, 0.9667],\n",
      "        [0.9747, 0.1090, 0.0742, 0.9735],\n",
      "        [0.7795, 0.4888, 0.5078, 0.8127],\n",
      "        [0.9327, 0.3604, 0.2817, 0.9284],\n",
      "        [0.9324, 0.2162, 0.1211, 0.9261],\n",
      "        [0.9153, 0.5286, 0.4716, 0.9587],\n",
      "        [0.9089, 0.2608, 0.2616, 0.8809],\n",
      "        [0.9517, 0.1418, 0.1327, 0.9480],\n",
      "        [0.8519, 0.3524, 0.2940, 0.8466],\n",
      "        [0.8123, 0.3198, 0.3593, 0.8257],\n",
      "        [0.9766, 0.0894, 0.1121, 0.9812],\n",
      "        [0.9987, 0.0624, 0.0640, 0.9990],\n",
      "        [0.9605, 0.1381, 0.1105, 0.9681],\n",
      "        [0.9179, 0.1880, 0.1950, 0.8983],\n",
      "        [0.7368, 0.4692, 0.4290, 0.7866],\n",
      "        [0.9467, 0.1949, 0.2225, 0.9256],\n",
      "        [0.8878, 0.2771, 0.2420, 0.9157],\n",
      "        [0.7241, 0.5295, 0.5060, 0.7349],\n",
      "        [0.8736, 0.2679, 0.2689, 0.8569],\n",
      "        [0.9689, 0.1419, 0.1371, 0.9578],\n",
      "        [0.9709, 0.0736, 0.0876, 0.9651],\n",
      "        [0.8014, 0.4514, 0.4266, 0.7820],\n",
      "        [0.8922, 0.2107, 0.2146, 0.9048],\n",
      "        [0.8356, 0.6114, 0.5215, 0.8521],\n",
      "        [0.7329, 0.6148, 0.4575, 0.7196],\n",
      "        [0.8119, 0.4723, 0.4804, 0.8467],\n",
      "        [0.8928, 0.3133, 0.2369, 0.8907],\n",
      "        [0.9663, 0.1425, 0.0986, 0.9693],\n",
      "        [0.9356, 0.3127, 0.1872, 0.9114],\n",
      "        [0.7817, 0.4206, 0.4896, 0.7445],\n",
      "        [0.9390, 0.2598, 0.1802, 0.9198],\n",
      "        [0.9743, 0.1387, 0.3033, 0.9821],\n",
      "        [0.9452, 0.1246, 0.1120, 0.9564],\n",
      "        [0.8588, 0.3570, 0.3091, 0.8557],\n",
      "        [0.9483, 0.3196, 0.0989, 0.9248],\n",
      "        [0.9809, 0.0611, 0.0615, 0.9824],\n",
      "        [0.8934, 0.2389, 0.3108, 0.8782],\n",
      "        [0.9059, 0.3209, 0.1624, 0.9047],\n",
      "        [0.9589, 0.2020, 0.1094, 0.9631],\n",
      "        [0.7473, 0.4659, 0.4706, 0.7632],\n",
      "        [0.9837, 0.1450, 0.1169, 0.9838],\n",
      "        [0.7960, 0.4472, 0.3932, 0.8195],\n",
      "        [0.8032, 0.5650, 0.4774, 0.7333],\n",
      "        [0.8809, 0.3282, 0.4046, 0.8919],\n",
      "        [0.8387, 0.5908, 0.5588, 0.8490],\n",
      "        [0.9829, 0.0482, 0.0847, 0.9771],\n",
      "        [0.8225, 0.5405, 0.4281, 0.7913],\n",
      "        [0.8958, 0.3000, 0.2573, 0.8802],\n",
      "        [0.9476, 0.1482, 0.1508, 0.9499],\n",
      "        [0.9180, 0.2852, 0.2424, 0.8777],\n",
      "        [0.8895, 0.3060, 0.4686, 0.8978],\n",
      "        [0.9648, 0.1031, 0.0946, 0.9645],\n",
      "        [0.9222, 0.1603, 0.2183, 0.9148],\n",
      "        [0.9354, 0.1959, 0.2596, 0.9314],\n",
      "        [0.9759, 0.0479, 0.1150, 0.9656],\n",
      "        [0.9600, 0.1526, 0.1737, 0.9720],\n",
      "        [0.9404, 0.1643, 0.2015, 0.9478],\n",
      "        [0.7941, 0.4259, 0.4360, 0.8076],\n",
      "        [0.9698, 0.1286, 0.1024, 0.9577],\n",
      "        [0.9689, 0.1247, 0.1218, 0.9526],\n",
      "        [0.8721, 0.2913, 0.3799, 0.8685],\n",
      "        [0.8724, 0.2555, 0.2300, 0.9149],\n",
      "        [0.9310, 0.1057, 0.1469, 0.9338],\n",
      "        [0.9738, 0.1291, 0.1105, 0.9708],\n",
      "        [0.9296, 0.1927, 0.1726, 0.9249],\n",
      "        [0.8498, 0.4353, 0.2619, 0.8284],\n",
      "        [0.7124, 0.5144, 0.5391, 0.7631],\n",
      "        [0.8903, 0.3691, 0.4436, 0.8619],\n",
      "        [0.8837, 0.2325, 0.3022, 0.8529],\n",
      "        [0.9102, 0.2565, 0.3130, 0.9055],\n",
      "        [0.9097, 0.1971, 0.1784, 0.9248],\n",
      "        [0.8650, 0.3152, 0.2408, 0.8543],\n",
      "        [0.9658, 0.1014, 0.0752, 0.9804],\n",
      "        [0.8264, 0.5631, 0.3764, 0.7904],\n",
      "        [0.9817, 0.1253, 0.0668, 0.9855],\n",
      "        [0.9006, 0.4498, 0.5368, 0.8753],\n",
      "        [0.9734, 0.0672, 0.0721, 0.9810],\n",
      "        [0.9460, 0.1678, 0.2371, 0.9530],\n",
      "        [0.9659, 0.1506, 0.1355, 0.9674],\n",
      "        [0.8167, 0.3857, 0.3332, 0.8417],\n",
      "        [0.8233, 0.3361, 0.3790, 0.8805],\n",
      "        [0.9578, 0.2125, 0.1288, 0.9358],\n",
      "        [0.7922, 0.3461, 0.3141, 0.8116],\n",
      "        [0.8914, 0.5360, 0.2508, 0.8792],\n",
      "        [0.8270, 0.2882, 0.3727, 0.8606],\n",
      "        [0.8577, 0.3683, 0.3093, 0.8725],\n",
      "        [0.9026, 0.2152, 0.1975, 0.9007],\n",
      "        [0.8735, 0.2973, 0.3253, 0.8784],\n",
      "        [0.8186, 0.4327, 0.3709, 0.7674],\n",
      "        [0.9919, 0.3217, 0.4067, 0.9907],\n",
      "        [0.9373, 0.2514, 0.3641, 0.9573],\n",
      "        [0.8147, 0.5317, 0.5472, 0.8243],\n",
      "        [0.8982, 0.2859, 0.2977, 0.8445],\n",
      "        [0.9986, 0.1584, 0.2509, 0.9992]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall Survival (4 Years)': {'accuracy': 0.891156462585034,\n",
       "  'mse': 0.11325208,\n",
       "  'auc': 0.5333969465648855,\n",
       "  'precision': 0.891156462585034,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9424460431654677},\n",
       " 'FT': {'accuracy': 0.7959183673469388,\n",
       "  'mse': 0.15967897,\n",
       "  'auc': 0.6739130434782609,\n",
       "  'precision': 0.6666666666666666,\n",
       "  'recall': 0.125,\n",
       "  'f1': 0.21052631578947367},\n",
       " 'Aspiration rate Post-therapy': {'accuracy': 0.8027210884353742,\n",
       "  'mse': 0.123974934,\n",
       "  'auc': 0.799745708836618,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'LRC': {'accuracy': 0.8979591836734694,\n",
       "  'mse': 0.096907504,\n",
       "  'auc': 0.6979797979797979,\n",
       "  'precision': 0.8979591836734694,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.9462365591397849}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmodel3_balanced = train_state(model_args=t1_args,state=3,lr=.001,weights=[.01,1,1,.01])\n",
    "tmodel3_balanced[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "82f379d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2187044620513916,\n",
       " 2.7142395973205566,\n",
       " 1.985084891319275,\n",
       " 2.5229952335357666,\n",
       " 0.902746319770813,\n",
       " 0.8971668481826782]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[1] for m in [tmodel1,tmodel_balanced,tmodel2,tmodel2_balanced,tmodel3,tmodel3_balanced]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "30998ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel1[0].set_device('cpu')\n",
    "tmodel2[0].set_device('cpu')\n",
    "\n",
    "\n",
    "torch.save(tmodel1[0],'../resources/transition1_model.pt')\n",
    "torch.save(tmodel2[0],'../resources/transition2_model.pt')\n",
    "\n",
    "# tmodel3[0].set_device('cpu')\n",
    "# torch.save(tmodel3[0],'../resources/outcome_model.pt')\n",
    "tmodel3[0].set_device('cpu')\n",
    "torch.save(tmodel3[0],'../resources/outcome_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eeb018f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>outcome</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pd</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.617216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.538744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.582615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>nd</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.161384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.407307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.278573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>mod</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.161384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.407307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.278573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Hematological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Dermatological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Neurological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Other</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Gastrointestinal</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>dlts</td>\n",
       "      <td>accuracy_mean</td>\n",
       "      <td>0.867857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Hematological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.378788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Dermatological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Neurological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.596078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Other</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.503145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>DLT_Gastrointestinal</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.527273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>dlts</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.491723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>pd</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.417933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.573771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>pd</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.669821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>nd</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.479606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.558771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.646286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>nd</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.545582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>mod</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.479606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_micro</td>\n",
       "      <td>0.558771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.646286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>mod</td>\n",
       "      <td>auc_weighted</td>\n",
       "      <td>0.545582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Hematological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Dermatological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Neurological</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.965986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Other</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Gastrointestinal</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>dlts</td>\n",
       "      <td>accuracy_mean</td>\n",
       "      <td>0.956463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Hematological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Dermatological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.643662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Neurological</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.461972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Other</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.743056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>DLT_Gastrointestinal</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.575926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>dlts</td>\n",
       "      <td>auc_mean</td>\n",
       "      <td>0.604923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.891156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.113252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.533397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.891156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>Overall Survival (4 Years)</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.942446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.159679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.673913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>FT</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.802721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.123975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.799746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiration rate Post-therapy</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.096908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.697980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>LRC</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state                       outcome         metric     value\n",
       "0       1                            pd       accuracy  0.309524\n",
       "1       1                            pd      auc_micro  0.617216\n",
       "2       1                            pd       auc_mean  0.538744\n",
       "3       1                            pd   auc_weighted  0.582615\n",
       "4       1                            nd       accuracy  0.296296\n",
       "5       1                            nd      auc_micro  0.161384\n",
       "6       1                            nd       auc_mean  0.407307\n",
       "7       1                            nd   auc_weighted  0.278573\n",
       "8       1                           mod       accuracy  0.296296\n",
       "9       1                           mod      auc_micro  0.161384\n",
       "10      1                           mod       auc_mean  0.407307\n",
       "11      1                           mod   auc_weighted  0.278573\n",
       "12      1             DLT_Hematological       accuracy  0.785714\n",
       "13      1            DLT_Dermatological       accuracy  0.892857\n",
       "14      1              DLT_Neurological       accuracy  0.910714\n",
       "15      1                     DLT_Other       accuracy  0.946429\n",
       "16      1          DLT_Gastrointestinal       accuracy  0.803571\n",
       "17      1                          dlts  accuracy_mean  0.867857\n",
       "18      1             DLT_Hematological            auc  0.378788\n",
       "19      1            DLT_Dermatological            auc  0.453333\n",
       "20      1              DLT_Neurological            auc  0.596078\n",
       "21      1                     DLT_Other            auc  0.503145\n",
       "22      1          DLT_Gastrointestinal            auc  0.527273\n",
       "23      1                          dlts       auc_mean  0.491723\n",
       "24      2                            pd       accuracy  0.417933\n",
       "25      2                            pd      auc_micro  0.794800\n",
       "26      2                            pd       auc_mean  0.573771\n",
       "27      2                            pd   auc_weighted  0.669821\n",
       "28      2                            nd       accuracy  0.479606\n",
       "29      2                            nd      auc_micro  0.558771\n",
       "30      2                            nd       auc_mean  0.646286\n",
       "31      2                            nd   auc_weighted  0.545582\n",
       "32      2                           mod       accuracy  0.479606\n",
       "33      2                           mod      auc_micro  0.558771\n",
       "34      2                           mod       auc_mean  0.646286\n",
       "35      2                           mod   auc_weighted  0.545582\n",
       "36      2             DLT_Hematological       accuracy  0.952381\n",
       "37      2            DLT_Dermatological       accuracy  0.965986\n",
       "38      2              DLT_Neurological       accuracy  0.965986\n",
       "39      2                     DLT_Other       accuracy  0.979592\n",
       "40      2          DLT_Gastrointestinal       accuracy  0.918367\n",
       "41      2                          dlts  accuracy_mean  0.956463\n",
       "42      2             DLT_Hematological            auc  0.600000\n",
       "43      2            DLT_Dermatological            auc  0.643662\n",
       "44      2              DLT_Neurological            auc  0.461972\n",
       "45      2                     DLT_Other            auc  0.743056\n",
       "46      2          DLT_Gastrointestinal            auc  0.575926\n",
       "47      2                          dlts       auc_mean  0.604923\n",
       "48      3    Overall Survival (4 Years)       accuracy  0.891156\n",
       "49      3    Overall Survival (4 Years)            mse  0.113252\n",
       "50      3    Overall Survival (4 Years)            auc  0.533397\n",
       "51      3    Overall Survival (4 Years)      precision  0.891156\n",
       "52      3    Overall Survival (4 Years)         recall  1.000000\n",
       "53      3    Overall Survival (4 Years)             f1  0.942446\n",
       "54      3                            FT       accuracy  0.795918\n",
       "55      3                            FT            mse  0.159679\n",
       "56      3                            FT            auc  0.673913\n",
       "57      3                            FT      precision  0.666667\n",
       "58      3                            FT         recall  0.125000\n",
       "59      3                            FT             f1  0.210526\n",
       "60      3  Aspiration rate Post-therapy       accuracy  0.802721\n",
       "61      3  Aspiration rate Post-therapy            mse  0.123975\n",
       "62      3  Aspiration rate Post-therapy            auc  0.799746\n",
       "63      3  Aspiration rate Post-therapy      precision  0.000000\n",
       "64      3  Aspiration rate Post-therapy         recall  0.000000\n",
       "65      3  Aspiration rate Post-therapy             f1  0.000000\n",
       "66      3                           LRC       accuracy  0.897959\n",
       "67      3                           LRC            mse  0.096908\n",
       "68      3                           LRC            auc  0.697980\n",
       "69      3                           LRC      precision  0.897959\n",
       "70      3                           LRC         recall  1.000000\n",
       "71      3                           LRC             f1  0.946237"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_tmodel_results(t1,t2,t3):\n",
    "    r1 = t1[-1]\n",
    "    r2 = t2[-1]\n",
    "    r3 = t3[-1]\n",
    "    res_list = []\n",
    "    for state, result in enumerate([r1,r2,r3]):\n",
    "        for outcome, metricdict in result.items():\n",
    "            if outcome == 'dlts':\n",
    "                for metric, values in metricdict.items():\n",
    "                    try:\n",
    "                        for dltname, value in zip(Const.dlt1,values):\n",
    "                            entry = {\n",
    "                                'state': state + 1,\n",
    "                                'outcome': dltname,\n",
    "                                'metric': metric,\n",
    "                                'value': value,\n",
    "                            }\n",
    "                            res_list.append(entry)\n",
    "                    except:\n",
    "                        entry = {\n",
    "                            'state': state + 1,\n",
    "                            'outcome': outcome,\n",
    "                            'metric': metric,\n",
    "                            'value': values\n",
    "                        }\n",
    "                        res_list.append(entry)\n",
    "            else:\n",
    "                for metric, value in metricdict.items():\n",
    "                    entry = {\n",
    "                        'state': state + 1,\n",
    "                        'outcome': outcome,\n",
    "                        'metric': metric,\n",
    "                        'value': value\n",
    "                    }\n",
    "                    res_list.append(entry)\n",
    "    return pd.DataFrame(res_list)\n",
    "import time\n",
    "model_results = merge_tmodel_results(tmodel1,tmodel2,tmodel3_balanced)\n",
    "model_results.to_csv('../results/transition_models_' + str(time.time()) + '.csv')\n",
    "model_results_balanced = merge_tmodel_results(tmodel_balanced,tmodel2_balanced,tmodel3_balanced)\n",
    "model_results_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fe204000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of matplotlib.style.core failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 315, in update_instances\n",
      "    refs = gc.get_referrers(old)\n",
      "KeyboardInterrupt\n",
      "]\n",
      "[autoreload of matplotlib.container failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: __class__ assignment: 'BarContainer' object layout differs from 'BarContainer'\n",
      "]\n",
      "[autoreload of matplotlib.axes failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 361, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 319, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to _SubplotBaseMeta object\n",
      "]\n",
      "[autoreload of matplotlib.pyplot failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 848, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\", line 593, in <module>\n",
      "    def rc_context(rc=None, fname=None):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\", line 101, in _copy_docstring_and_deprecators\n",
      "    decorator = _api.deprecation.DECORATORS.get(method)\n",
      "AttributeError: module 'matplotlib._api' has no attribute 'deprecation'\n",
      "]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(value,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     36\u001b[0m             ax\u001b[38;5;241m.\u001b[39mtext(x,y,\u001b[38;5;28mstr\u001b[39m(value),verticalalignment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mplot_mc_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[186], line 12\u001b[0m, in \u001b[0;36mplot_mc_results\u001b[0;34m(mr, title)\u001b[0m\n\u001b[1;32m     10\u001b[0m temp \u001b[38;5;241m=\u001b[39m temp[temp\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01min\u001b[39;00m metrics)]\n\u001b[1;32m     11\u001b[0m temp \u001b[38;5;241m=\u001b[39m temp[temp\u001b[38;5;241m.\u001b[39moutcome\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Survival (4 Years)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLRC\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[0;32m---> 12\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(\n\u001b[1;32m     14\u001b[0m     data\u001b[38;5;241m=\u001b[39mtemp,\n\u001b[1;32m     15\u001b[0m     y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolorblind\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(title)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py:1501\u001b[0m, in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubplots\u001b[39m(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, squeeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1356\u001b[0m              width_ratios\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, height_ratios\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1357\u001b[0m              subplot_kw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, gridspec_kw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw):\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;124;03m    Create a figure and a set of subplots.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \n\u001b[1;32m   1500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1501\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfig_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m     axs \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey,\n\u001b[1;32m   1503\u001b[0m                        squeeze\u001b[38;5;241m=\u001b[39msqueeze, subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw,\n\u001b[1;32m   1504\u001b[0m                        gridspec_kw\u001b[38;5;241m=\u001b[39mgridspec_kw, height_ratios\u001b[38;5;241m=\u001b[39mheight_ratios,\n\u001b[1;32m   1505\u001b[0m                        width_ratios\u001b[38;5;241m=\u001b[39mwidth_ratios)\n\u001b[1;32m   1506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py:840\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    831\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m--> 840\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py:384\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib_inline/backend_inline.py:27\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, FigureClass, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_figure_manager\u001b[39m(num, \u001b[38;5;241m*\u001b[39margs, FigureClass\u001b[38;5;241m=\u001b[39mFigure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Return a new figure manager for a new figure instance.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    This function is part of the API expected by Matplotlib backends.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_figure_manager_given_figure(num, \u001b[43mFigureClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/_api/deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    449\u001b[0m     warn_deprecated(\n\u001b[1;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py:2470\u001b[0m, in \u001b[0;36mFigure.__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout, layout, **kwargs)\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mmake_keyword_only(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2375\u001b[0m              figsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2386\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2387\u001b[0m              ):\n\u001b[1;32m   2388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;124;03m        %(Figure:kwdoc)s\u001b[39;00m\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2470\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py:214\u001b[0m, in \u001b[0;36mFigureBase.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py:147\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_autogenerated_signature\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# has defined a set method set itself.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py:1231\u001b[0m, in \u001b[0;36mArtist.set\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;66;03m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;66;03m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;66;03m# module.\u001b[39;00m\n\u001b[0;32m-> 1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_update(\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/__init__.py:1776\u001b[0m, in \u001b[0;36mnormalize_kwargs\u001b[0;34m(kw, alias_mapping)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(alias_mapping, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(alias_mapping, Artist)\n\u001b[1;32m   1772\u001b[0m       \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(alias_mapping, Artist)):\n\u001b[1;32m   1773\u001b[0m     alias_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(alias_mapping, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_alias_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1775\u001b[0m to_canonical \u001b[38;5;241m=\u001b[39m {alias: canonical\n\u001b[0;32m-> 1776\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m canonical, alias_list \u001b[38;5;129;01min\u001b[39;00m \u001b[43malias_mapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[1;32m   1777\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m alias \u001b[38;5;129;01min\u001b[39;00m alias_list}\n\u001b[1;32m   1778\u001b[0m canonical_to_seen \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1779\u001b[0m ret \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# output dictionary\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from matplotlib.container import BarContainer\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_mc_results(mr,title='Model Performance for Multiclass Outcomes'):\n",
    "    temp = mr.copy()\n",
    "    temp['title'] = temp['outcome'] + temp['state'].astype(str)\n",
    "    temp = temp.groupby('title').filter(lambda x: x[x.metric == 'auc_micro'].shape[0] > 0).reset_index()\n",
    "    metrics = set(['auc_mean','accuracy','auc_micro','auc_weighted'])\n",
    "    temp = temp[temp.metric.apply(lambda x: x in metrics)]\n",
    "    temp = temp[temp.outcome.apply(lambda x: x not in ['Overall Survival (4 Years)', 'LRC'])]\n",
    "    fig,ax = plt.subplots(1,1,figsize=(5,8))\n",
    "    sns.barplot(\n",
    "        data=temp,\n",
    "        y='title',\n",
    "        x='value',\n",
    "        orient='h',\n",
    "        hue='metric',\n",
    "        ax=ax,\n",
    "        palette='colorblind',\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Outcome')\n",
    "    ax.set_xlabel('')\n",
    "    ax.axvline(.5,c='white')\n",
    "    ax.axvline(.75,c='white')\n",
    "    ax.axvline(.25,c=\"white\")\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_xticks([.25,.5,.75])\n",
    "    for container in ax.containers:\n",
    "        for patch,value in zip(container.patches,container.datavalues):\n",
    "            x,y = patch.xy\n",
    "            x = x + patch._width\n",
    "            y = y + (patch._height/2)\n",
    "            value = np.round(value,2)\n",
    "            ax.text(x,y,str(value),verticalalignment='center')\n",
    "\n",
    "plot_mc_results(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mc_results(model_results_balanced,title=\"Balanced Model Performance for Multiclass Outcomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bool_results(mr,model_name=''):\n",
    "    temp = mr.copy()\n",
    "    temp['title'] = temp['outcome'] + temp['state'].apply(lambda x: str(x) if x < 3 else '')\n",
    "    temp = temp.groupby('title').filter(lambda x: x[x.metric == 'auc'].shape[0] > 0).reset_index()\n",
    "    metrics = set(['auc','accuracy'])\n",
    "    temp = temp[temp.metric.apply(lambda x: x in metrics)]\n",
    "    temp = temp[temp.outcome.apply(lambda x: x not in ['Overall Survival (4 Years)', 'LRC'])]\n",
    "    fig,ax = plt.subplots(1,1,figsize=(5,8))\n",
    "    sns.barplot(\n",
    "        data=temp,\n",
    "        y='title',\n",
    "        x='value',\n",
    "        orient='h',\n",
    "        hue='metric',\n",
    "        ax=ax,\n",
    "        palette='colorblind',\n",
    "    )\n",
    "    ax.set_title(model_name + ' Model Performance for Boolean Outcomes')\n",
    "    ax.set_ylabel('Outcome')\n",
    "    ax.set_xlabel('')\n",
    "    ax.axvline(.5,c='white')\n",
    "    ax.axvline(.75,c='white')\n",
    "    ax.axvline(.25,c=\"white\")\n",
    "    ax.set_xticks([.25,.5,.75])\n",
    "    ax.set_xlim(0,1)\n",
    "    for container in ax.containers:\n",
    "        for patch,value in zip(container.patches,container.datavalues):\n",
    "            x,y = patch.xy\n",
    "            x = x + patch._width\n",
    "            y = y + (patch._height/2)\n",
    "            value = np.round(value,2)\n",
    "            ax.text(x,y,str(value),verticalalignment='center')\n",
    "plot_bool_results(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845efada",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bool_results(model_results_balanced,'Balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca480b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Axes(0.125,0.653529;0.0407895x0.226471)\n",
      "1\n",
      "Axes(0.173947,0.653529;0.0407895x0.226471)\n",
      "2\n",
      "Axes(0.222895,0.653529;0.0407895x0.226471)\n",
      "3\n",
      "Axes(0.271842,0.653529;0.0407895x0.226471)\n",
      "4\n",
      "Axes(0.320789,0.653529;0.0407895x0.226471)\n",
      "5\n",
      "Axes(0.369737,0.653529;0.0407895x0.226471)\n",
      "6\n",
      "Axes(0.418684,0.653529;0.0407895x0.226471)\n",
      "7\n",
      "Axes(0.467632,0.653529;0.0407895x0.226471)\n",
      "8\n",
      "Axes(0.516579,0.653529;0.0407895x0.226471)\n",
      "9\n",
      "Axes(0.565526,0.653529;0.0407895x0.226471)\n",
      "10\n",
      "Axes(0.614474,0.653529;0.0407895x0.226471)\n",
      "11\n",
      "Axes(0.663421,0.653529;0.0407895x0.226471)\n",
      "12\n",
      "Axes(0.712368,0.653529;0.0407895x0.226471)\n",
      "13\n",
      "Axes(0.761316,0.653529;0.0407895x0.226471)\n",
      "14\n",
      "Axes(0.810263,0.653529;0.0407895x0.226471)\n",
      "15\n",
      "Axes(0.859211,0.653529;0.0407895x0.226471)\n",
      "0\n",
      "Axes(0.125,0.381765;0.0407895x0.226471)\n",
      "1\n",
      "Axes(0.173947,0.381765;0.0407895x0.226471)\n",
      "2\n",
      "Axes(0.222895,0.381765;0.0407895x0.226471)\n",
      "3\n",
      "Axes(0.271842,0.381765;0.0407895x0.226471)\n",
      "4\n",
      "Axes(0.320789,0.381765;0.0407895x0.226471)\n",
      "5\n",
      "Axes(0.369737,0.381765;0.0407895x0.226471)\n",
      "6\n",
      "Axes(0.418684,0.381765;0.0407895x0.226471)\n",
      "7\n",
      "Axes(0.467632,0.381765;0.0407895x0.226471)\n",
      "8\n",
      "Axes(0.516579,0.381765;0.0407895x0.226471)\n",
      "9\n",
      "Axes(0.565526,0.381765;0.0407895x0.226471)\n",
      "10\n",
      "Axes(0.614474,0.381765;0.0407895x0.226471)\n",
      "11\n",
      "Axes(0.663421,0.381765;0.0407895x0.226471)\n",
      "12\n",
      "Axes(0.712368,0.381765;0.0407895x0.226471)\n",
      "13\n",
      "Axes(0.761316,0.381765;0.0407895x0.226471)\n",
      "14\n",
      "Axes(0.810263,0.381765;0.0407895x0.226471)\n",
      "15\n",
      "Axes(0.859211,0.381765;0.0407895x0.226471)\n",
      "0\n",
      "Axes(0.125,0.11;0.0407895x0.226471)\n",
      "1\n",
      "Axes(0.173947,0.11;0.0407895x0.226471)\n",
      "2\n",
      "Axes(0.222895,0.11;0.0407895x0.226471)\n",
      "3\n",
      "Axes(0.271842,0.11;0.0407895x0.226471)\n",
      "4\n",
      "Axes(0.320789,0.11;0.0407895x0.226471)\n",
      "5\n",
      "Axes(0.369737,0.11;0.0407895x0.226471)\n",
      "6\n",
      "Axes(0.418684,0.11;0.0407895x0.226471)\n",
      "7\n",
      "Axes(0.467632,0.11;0.0407895x0.226471)\n",
      "8\n",
      "Axes(0.516579,0.11;0.0407895x0.226471)\n",
      "9\n",
      "Axes(0.565526,0.11;0.0407895x0.226471)\n",
      "10\n",
      "Axes(0.614474,0.11;0.0407895x0.226471)\n",
      "11\n",
      "Axes(0.663421,0.11;0.0407895x0.226471)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 8000x1500 with 48 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "metrics = set(['auc','accuracy','f1','auc_weighted'])\n",
    "subdf = model_results[model_results.metric.apply(lambda x: x in metrics)]\n",
    "lengths = [subdf[subdf.state == i+1].shape[0] for i in range(3)]\n",
    "fig, axes = plt.subplots(3,max(lengths),figsize=(5*max(lengths),15))\n",
    "for i in range(3):\n",
    "    axx = axes[i]\n",
    "    subsubdf = subdf[subdf.state == i + 1]\n",
    "    ii =0\n",
    "    for iii,row in subsubdf.iterrows():\n",
    "        ax = axes[i,ii]\n",
    "        ii += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c01c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outdated code for doing an ensembel of stuff instead of using bayesian inference via dropout\n",
    "def train_model_ensemble(model_arg_list,state,\n",
    "                         n_bags=20,\n",
    "                         smote_options=[True,False],\n",
    "                         smote_baseline_options=[True,False],\n",
    "                         weight_options=[None],\n",
    "                         weight_baseline_options=[None],\n",
    "                         **kwargs):\n",
    "    resampled_models =[]\n",
    "    base_models = []\n",
    "    base_metrics = []\n",
    "    resample_metrics = []\n",
    "    base_losses = []\n",
    "    resample_losses = []\n",
    "    n_errors = 0\n",
    "    for margs in model_arg_list:\n",
    "        for s in smote_baseline_options:\n",
    "            for w in weight_baseline_options:\n",
    "                [base_model,blosses,bmetrics] = train_state(model_args=margs,state=state,\n",
    "                                         resample_training=False,\n",
    "                                         use_smote=smote_options,\n",
    "                                         weights=w,\n",
    "                                         verbose=False,**kwargs)\n",
    "                base_models.append(base_model)\n",
    "                base_metrics.append(bmetrics)\n",
    "                base_losses.append(blosses)\n",
    "        for n in range(n_bags):\n",
    "            for s in smote_options:\n",
    "                for w in weight_options:\n",
    "                    #this can fail if I resample a bad distribution with no minority classes\n",
    "                    done = False\n",
    "                    while not done:\n",
    "                        try:\n",
    "                            [model,loss,metrics] = train_state(model_args=margs,\n",
    "                                                state=state,resample_training=True,\n",
    "                                                use_smote=s,\n",
    "                                                weights=w,\n",
    "                                                verbose=False,**kwargs)\n",
    "                            resampled_models.append(model)\n",
    "                            resample_metrics.append(metrics)\n",
    "                            resample_losses.append(loss)\n",
    "                            done=True\n",
    "                            print('model_done',len(base_models)+len(resampled_models))\n",
    "                        except Exception as e:\n",
    "                            print('error training model')\n",
    "                            print(e)\n",
    "                            n_errors += 1\n",
    "    print('done with',n_errors,'errors')\n",
    "    return base_models,resampled_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
