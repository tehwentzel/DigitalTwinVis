{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no_dose_adjustment',\n",
       " 1: 'dose_modified',\n",
       " 2: 'dose_delayed',\n",
       " 3: 'dose_cancelled',\n",
       " 4: 'dose_delayed_&_modified',\n",
       " 5: 'regiment_modification',\n",
       " 9: 'unknown'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Const:\n",
    "    data_dir = '../data'\n",
    "    twin_data = data_dir + 'digital_twin_data.csv'\n",
    "    twin_ln_data = data_dir + 'digital_twin_ln_data.csv'\n",
    "    \n",
    "    rename_dict = {\n",
    "        'Dummy ID': 'id',\n",
    "        'Age at Diagnosis (Calculated)': 'age',\n",
    "        'Feeding tube 6m': 'FT',\n",
    "        'Affected Lymph node UPPER': 'affected_nodes',\n",
    "        'Aspiration rate(Y/N)': 'AS',\n",
    "        'Neck boost (Y/N)': 'neck_boost',\n",
    "        'Gender': 'gender',\n",
    "        'Tm Laterality (R/L)': 'laterality',\n",
    "        'AJCC 8th edition': 'ajcc8',\n",
    "        'AJCC 7th edition':'ajcc7',\n",
    "        'N_category_full': 'N-category',\n",
    "        'HPV/P16 status': 'hpv',\n",
    "        'Tumor subsite (BOT/Tonsil/Soft Palate/Pharyngeal wall/GPS/NOS)': 'subsite',\n",
    "        'Total dose': 'total_dose',\n",
    "        'Therapeutic combination': 'treatment',\n",
    "        'Smoking status at Diagnosis (Never/Former/Current)': 'smoking_status',\n",
    "        'Smoking status (Packs/Year)': 'packs_per_year',\n",
    "        'Overall Survival (1=alive,0=dead)': 'os',\n",
    "        'Dose/fraction (Gy)': 'dose_fraction'\n",
    "    }\n",
    "    \n",
    "    dlt_dict = {\n",
    "         'Allergic reaction to Cetuximab': 'DLT_Other',\n",
    "         'Cardiological (A-fib)': 'DLT_Other',\n",
    "         'Dermatological': 'DLT_Dermatological',\n",
    "         'Failure to Thrive': 'DLT_Other',\n",
    "         'Failure to thrive': 'DLT_Other',\n",
    "         'GIT [elevated liver enzymes]': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestina': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestinal': 'DLT_Gastrointestinal',\n",
    "         'General': 'DLT_Other',\n",
    "         'Hematological': 'DLT_Hematological',\n",
    "         'Hematological (Neutropenia)': 'DLT_Hematological',\n",
    "         'Hyponatremia': 'DLT_Other',\n",
    "         'Immunological': 'DLT_Other',\n",
    "         'Infection': 'DLT_Infection (Pneumonia)',\n",
    "         'NOS': 'DLT_Other',\n",
    "         'Nephrological': 'DLT_Nephrological',\n",
    "         'Nephrological (ARF)': 'DLT_Nephrological',\n",
    "         'Neurological': 'DLT_Neurological',\n",
    "         'Neutropenia': 'DLT_Hematological',\n",
    "         'Nutritional': 'DLT_Other',\n",
    "         'Pancreatitis': 'DLT_Other',\n",
    "         'Pulmonary': 'DLT_Other',\n",
    "         'Respiratory (Pneumonia)': 'DLT_Infection (Pneumonia)',\n",
    "         'Sepsis': 'DLT_Infection (Pneumonia)',\n",
    "         'Suboptimal response to treatment' : 'DLT_Other',\n",
    "         'Vascular': 'DLT_Vascular'\n",
    "    }\n",
    "    \n",
    "    decision1 = 'Decision 1 (Induction Chemo) Y/N'\n",
    "    decision2 = 'Decision 2 (CC / RT alone)'\n",
    "    decision3 = 'Decision 3 Neck Dissection (Y/N)'\n",
    "    decisions = [decision1,decision2, decision3]\n",
    "    outcomes = ['Overall Survival (4 Years)', 'FT', 'Aspiration rate Post-therapy']\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    primary_disease_states = ['CR Primary','PR Primary','SD Primary']\n",
    "    nodal_disease_states = [t.replace('Primary','Nodal') for t in primary_disease_states]\n",
    "    dlt1 = list(set(dlt_dict.values()))\n",
    "    \n",
    "    modifications =  list(modification_types.values())\n",
    "    state2 = modifications + primary_disease_states+nodal_disease_states +dlt1 #+['No imaging 0=N,1=Y']\n",
    "    \n",
    "    primary_disease_states2 = [t + ' 2' for t in primary_disease_states]\n",
    "    nodal_disease_states2 = [t + ' 2' for t in nodal_disease_states]\n",
    "    dlt2 = [d + ' 2' for d in dlt1]\n",
    "    \n",
    "    ccs = list(cc_types.values())\n",
    "    state3 = ccs + primary_disease_states2 + nodal_disease_states2 + dlt2\n",
    "    \n",
    "Const.modification_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d02b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_cleaned):\n",
    "    #this was Elisa's preprocessing except I removed all the Ifs because that's dumb\n",
    "    if len(data_cleaned.shape) < 2:\n",
    "        data_cleaned = pd.DataFrame([data], columns=data.index)\n",
    "        \n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'N', 'Aspiration rate Pre-therapy'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'Y', 'Aspiration rate Pre-therapy'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'I', 'Pathological Grade'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'II', 'Pathological Grade'] = 2\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'III', 'Pathological Grade'] = 3\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'IV', 'Pathological Grade'] = 4\n",
    "\n",
    "    data_cleaned.loc[(data_cleaned['T-category'] == 'Tx') | (data_cleaned['T-category'] == 'Tis'), 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T1', 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T2', 'T-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T3', 'T-category'] = 3\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T4', 'T-category'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N0', 'N-category'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N1', 'N-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N2', 'N-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N3', 'N-category'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N0', 'N-category_8th_edition'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N1', 'N-category_8th_edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N2', 'N-category_8th_edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N3', 'N-category_8th_edition'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'I', 'AJCC 7th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'II', 'AJCC 7th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'III', 'AJCC 7th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'IV', 'AJCC 7th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'I', 'AJCC 8th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'II', 'AJCC 8th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'III', 'AJCC 8th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'IV', 'AJCC 8th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Male', 'Gender'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Female', 'Gender'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Positive', 'HPV/P16 status'] = 1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Negative', 'HPV/P16 status'] = -1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Unknown', 'HPV/P16 status'] = 0\n",
    "\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Formar', 'Smoking status at Diagnosis (Never/Former/Current)'] = .5\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Current', 'Smoking status at Diagnosis (Never/Former/Current)'] = 1\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Never', 'Smoking status at Diagnosis (Never/Former/Current)'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Chemo Modification (Y/N)'] == 'Y', 'Chemo Modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'N', 'DLT (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'Y', 'DLT (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Other'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT_Type'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT_Type']):\n",
    "            if i.strip() != '' and data_cleaned.loc[index, Const.dlt_dict[i.strip()]] == 0:\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()]] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'RT alone', 'Decision 2 (CC / RT alone)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'CC', 'Decision 2 (CC / RT alone)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'N', 'CC modification (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'Y', 'CC modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Dermatological 2'] = 0\n",
    "    data_cleaned['DLT_Neurological 2'] = 0\n",
    "    data_cleaned['DLT_Gastrointestinal 2'] = 0\n",
    "    data_cleaned['DLT_Hematological 2'] = 0\n",
    "    data_cleaned['DLT_Nephrological 2'] = 0\n",
    "    data_cleaned['DLT_Vascular 2'] = 0\n",
    "    data_cleaned['DLT_Infection (Pneumonia) 2'] = 0\n",
    "    data_cleaned['DLT_Other 2'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT 2'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT 2']):\n",
    "            if i.strip() != '':\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()] + ' 2'] = 1\n",
    "\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'N', 'Decision 3 Neck Dissection (Y/N)'] = 0\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'Y', 'Decision 3 Neck Dissection (Y/N)'] = 1\n",
    "\n",
    "    return data_cleaned\n",
    "\n",
    "def merge_editions(row,basecol='AJCC 8th edition',fallback='AJCC 7th edition'):\n",
    "    if pd.isnull(row[basecol]):\n",
    "        return row[fallback]\n",
    "    return row[basecol]\n",
    "\n",
    "\n",
    "def preprocess_dt_data(df,extra_to_keep=None):\n",
    "    \n",
    "    to_keep = ['id','hpv','age','packs_per_year','smoking_status','gender','Aspiration rate Pre-therapy','total_dose','dose_fraction'] \n",
    "    to_onehot = ['T-category','N-category','AJCC','Pathological Grade','subsite','treatment','ln_cluster']\n",
    "    if extra_to_keep is not None:\n",
    "        to_keep = to_keep + [c for c in extra_to_keep if c not in to_keep and c not in to_onehot]\n",
    "    \n",
    "    decisions =Const.decisions\n",
    "    outcomes = Const.outcomes\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    for k,v in Const.cc_types.items():\n",
    "        df[v] = df['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)'].apply(lambda x: int(Const.cc_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    for k,v in Const.modification_types.items():\n",
    "        name = 'Modification Type (0= no dose adjustment, 1=dose modified, 2=dose delayed, 3=dose cancelled, 4=dose delayed & modified, 5=regimen modification, 9=unknown)'\n",
    "        df[v] = df[name].apply(lambda x: int(Const.modification_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    #Features to keep. I think gender is is in \n",
    "    \n",
    "    keywords = []\n",
    "    for keyword in keywords:\n",
    "        toadd = [c for c in df.columns if keyword in c and c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    \n",
    "    df['packs_per_year'] = df['packs_per_year'].apply(lambda x: str(x).replace('>','').replace('<','')).astype(float).fillna(0)\n",
    "    #so I'm actually not sure if this is biological sex or gender given this is texas\n",
    "    df['AJCC'] = df.apply(lambda row: merge_editions(row,'ajcc8','ajcc7'),axis=1)\n",
    "    df['N-category'] = df.apply(lambda row: merge_editions(row,'N-category_8th_edition','N-category'),axis=1)\n",
    "    \n",
    "    dummy_df = pd.get_dummies(df[to_onehot].fillna(0).astype(str),drop_first=False)\n",
    "    for col in dummy_df.columns:\n",
    "        df[col] = dummy_df[col]\n",
    "        to_keep.append(col)\n",
    "        \n",
    "    yn_to_binary = ['FT','Aspiration rate Post-therapy','Decision 1 (Induction Chemo) Y/N']\n",
    "    for col in yn_to_binary:\n",
    "        df[col] = df[col].apply(lambda x: int(x == 'Y'))\n",
    "        \n",
    "    to_keep = to_keep + [c for c in df.columns if 'DLT' in c]\n",
    "    \n",
    "        \n",
    "    for statelist in [Const.state2,Const.state3,Const.decisions,Const.outcomes]:\n",
    "        toadd = [c for c in statelist if c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    return df[to_keep].set_index('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d7e64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/1992661605.py:2: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    3,     5,     6,     7,     8,     9,    10,    11,    13,\n",
       "          14,    15,    16,    17,    18,    21,    23,    24,    25,\n",
       "          26,    27,    28,    31,    32,    33,    35,    36,    37,\n",
       "          38,    39,    40,    41,    42,    44,    45,    47,    48,\n",
       "          49,    50,    51,    53,    55,    56,    57,    60,    64,\n",
       "          65,    67,    68,    69,    71,    74,    75,    77,    78,\n",
       "          79,    80,    81,    82,    87,    88,    91,    94,    96,\n",
       "          99,   103,   109,   116,   117,   119,   120,   121,   125,\n",
       "         133,   148,   150,   153,   168,   178,   181,   183,   184,\n",
       "         185,   186,   187,   188,   189,   190,   191,   192,   193,\n",
       "         194,   195,   196,   197,   198,   199,   200,   201,   202,\n",
       "         203,   204,   205,   206,   207,   208,   209,   210,   211,\n",
       "         212,   213,   214,   215,   216,   217,   218,   219,   220,\n",
       "         221,   222,   223,   224,   225,   226,   227,   228,   229,\n",
       "         230,   231,   232,   233,   234,   235,   236,   237,   238,\n",
       "         239,   240,   241,   242,   243,   244,   245,   246,   247,\n",
       "         248,   249,   251,   252,   253,   254,   255,   256,   257,\n",
       "         258,   259,   260,   261,   262,   263,   264,   265,   266,\n",
       "         267,   268,   269,   270,   271,   272,   273,   274,   275,\n",
       "         276,   277,   278,   279,   280,   281,   282,   283,   284,\n",
       "         285,   286,   287,   288,   289,  2000,  2001,  2002,  2003,\n",
       "        2004,  2005,  2006,  2007,  2008,  2009,  2010,  2011,  2012,\n",
       "        2013,  2014,  2015,  2016,  2017,  2018,  2019,  2020,  2021,\n",
       "        2022,  2023,  2024,  2025,  2026,  2027,  2028,  2029,  2030,\n",
       "        2031,  2032,  2033,  5000,  5001,  5002,  5003,  5004,  5005,\n",
       "        5006,  5007,  5008,  5009,  5010,  5011,  5012,  5013,  5014,\n",
       "        5015,  5016,  5017,  5018,  5019,  5020,  5021,  5022,  5023,\n",
       "        5024,  5025,  5026,  5027,  5028,  5029,  5030,  5031,  5032,\n",
       "        5033,  5034,  5035,  5036,  5037,  5038,  5039,  5040,  5041,\n",
       "        5042,  5043,  5044,  5045,  5047,  5048,  5049,  5050,  5051,\n",
       "        5052,  5053,  5054,  5055,  5056,  5057,  5058,  5059,  5060,\n",
       "        5061,  5062,  5063,  5064,  5065,  5066,  5067,  5068,  5069,\n",
       "        5070,  5071,  5072,  5073,  5074,  5075,  5076,  5077,  5078,\n",
       "        5079,  5080,  5081,  5082,  5083,  5084,  5085,  5086,  5087,\n",
       "        5088,  5089,  5090,  5091,  5092,  5093,  5094,  5095,  5096,\n",
       "        5097,  5098,  5099,  5100,  5101,  5102,  5103,  5104,  5105,\n",
       "        5106,  5107,  5108,  5109,  5110,  5111,  5112,  5113,  5114,\n",
       "        5115,  5117,  5118,  5119,  5120, 10001, 10002, 10003, 10004,\n",
       "       10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013,\n",
       "       10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022,\n",
       "       10023, 10024, 10025, 10026, 10027, 10028, 10029, 10031, 10033,\n",
       "       10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042,\n",
       "       10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051,\n",
       "       10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060,\n",
       "       10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069,\n",
       "       10070, 10071, 10072, 10073, 10074, 10075, 10077, 10078, 10079,\n",
       "       10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088,\n",
       "       10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097,\n",
       "       10098, 10099, 10100, 10101, 10102, 10103, 10104, 10105, 10106,\n",
       "       10107, 10108, 10109, 10110, 10111, 10113, 10114, 10115, 10116,\n",
       "       10117, 10118, 10119, 10120, 10121, 10123, 10124, 10125, 10126,\n",
       "       10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135,\n",
       "       10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144,\n",
       "       10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153,\n",
       "       10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162,\n",
       "       10163, 10164, 10165, 10167, 10168, 10169, 10170, 10171, 10172,\n",
       "       10173, 10174, 10175, 10176, 10177, 10178, 10180, 10181, 10182,\n",
       "       10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191,\n",
       "       10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200,\n",
       "       10201, 10202, 10203, 10204, 10205])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_digital_twin(file='../data/digital_twin_data.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "    return df.rename(columns = Const.rename_dict)\n",
    "\n",
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "get_dt_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e719a1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/42072186.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/42072186.py:19: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/42072186.py:20: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_dose_adjustment</th>\n",
       "      <th>dose_modified</th>\n",
       "      <th>dose_delayed</th>\n",
       "      <th>dose_cancelled</th>\n",
       "      <th>dose_delayed_&amp;_modified</th>\n",
       "      <th>regiment_modification</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_dose_adjustment  dose_modified  dose_delayed  dose_cancelled  \\\n",
       "id                                                                       \n",
       "3                       1              0             0               0   \n",
       "5                       1              0             0               0   \n",
       "6                       1              0             0               0   \n",
       "7                       1              0             0               0   \n",
       "8                       1              0             0               0   \n",
       "...                   ...            ...           ...             ...   \n",
       "10201                   1              0             0               0   \n",
       "10202                   1              0             0               0   \n",
       "10203                   1              0             0               0   \n",
       "10204                   1              0             0               0   \n",
       "10205                   1              0             0               0   \n",
       "\n",
       "       dose_delayed_&_modified  regiment_modification  unknown  \n",
       "id                                                              \n",
       "3                            0                      0        0  \n",
       "5                            0                      0        0  \n",
       "6                            0                      0        0  \n",
       "7                            0                      0        0  \n",
       "8                            0                      0        0  \n",
       "...                        ...                    ...      ...  \n",
       "10201                        0                      0        0  \n",
       "10202                        0                      0        0  \n",
       "10203                        0                      0        0  \n",
       "10204                        0                      0        0  \n",
       "10205                        0                      0        0  \n",
       "\n",
       "[536 rows x 7 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DTDataset():\n",
    "    \n",
    "    def __init__(self,data_file = '../data/digital_twin_data.csv',ln_data_file = '../data/digital_twin_ln_data.csv',ids=None):\n",
    "        df = pd.read_csv(data_file)\n",
    "        \n",
    "        df = preprocess(df)\n",
    "        df = df.rename(columns = Const.rename_dict).copy()\n",
    "        df = df.drop('MRN OPC',axis=1)\n",
    "\n",
    "        ln_data = pd.read_csv(ln_data_file)\n",
    "        ln_data = ln_data.rename(columns={'cluster':'ln_cluster'})\n",
    "        self.ln_cols = [c for c in ln_data.columns if c not in df.columns]\n",
    "        df = df.merge(ln_data,on='id')\n",
    "        df.index = df.index.astype(int)\n",
    "        if ids is not None:\n",
    "            df = df[df.id.apply(lambda x: x in ids)]\n",
    "        self.processed_df = preprocess_dt_data(df,self.ln_cols).fillna(0)\n",
    "        \n",
    "        self.means = self.processed_df.mean(axis=0)\n",
    "        self.stds = self.processed_df.std(axis=0)\n",
    "        self.maxes = self.processed_df.max(axis=0)\n",
    "        self.mins = self.processed_df.min(axis=0)\n",
    "        \n",
    "        arrays = self.get_states()\n",
    "        self.state_sizes = {k: (v.shape[1] if v.ndim > 1 else 1) for k,v in arrays.items()}\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.processed_df\n",
    "    \n",
    "    def sample(self,frac=.5):\n",
    "        return self.processed_df.sample(frac=frac)\n",
    "    \n",
    "    def split_sample(self,ratio = .3):\n",
    "        assert(ratio > 0 and ratio <= 1)\n",
    "        df1 = self.processed_df.sample(frac=1-ratio)\n",
    "        df2 = self.processed_df.drop(index=df1.index)\n",
    "        return df1,df2\n",
    "    \n",
    "    def get_states(self,fixed=None,ids = None):\n",
    "        processed_df = self.processed_df.copy()\n",
    "        if ids is not None:\n",
    "            processed_df = processed_df.loc[ids]\n",
    "        if fixed is not None:\n",
    "            for col,val in fixed.items():\n",
    "                if col in processed_df.columns:\n",
    "                    processed_df[col] = val\n",
    "                else:\n",
    "                    print('bad fixed entry',col)\n",
    "                    \n",
    "        to_skip = ['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)','DLT_Type','DLT 2'] + [c for c in processed_df.columns if 'treatment' in c]\n",
    "        other_states = set(Const.decisions + Const.state3 + Const.state2 + Const.outcomes  + to_skip)\n",
    "\n",
    "        base_state = sorted([c for c in processed_df.columns if c not in other_states])\n",
    "\n",
    "        dlt1 = Const.dlt1\n",
    "        dlt2 = Const.dlt2\n",
    "        \n",
    "        modifications = Const.modifications\n",
    "        ccs = Const.ccs\n",
    "        pds = Const.primary_disease_states\n",
    "        nds = Const.nodal_disease_states\n",
    "        pds2 = Const.primary_disease_states2\n",
    "        nds2 = Const.nodal_disease_states2\n",
    "        outcomes = Const.outcomes\n",
    "        decisions= Const.decisions\n",
    "        \n",
    "        #intermediate states are only udated values. Models should use baseline + state2 etc\n",
    "        results = {\n",
    "            'baseline': processed_df[base_state],\n",
    "            'pd_states1': processed_df[pds],\n",
    "            'nd_states1': processed_df[nds],\n",
    "            'modifications': processed_df[modifications],\n",
    "            'ccs': processed_df[ccs],\n",
    "            'pd_states2': processed_df[pds2],\n",
    "            'nd_states2': processed_df[nds2],\n",
    "            'outcomes': processed_df[outcomes],\n",
    "            'dlt1': processed_df[dlt1],\n",
    "            'dlt2': processed_df[dlt2],\n",
    "            'decision1': processed_df[decisions[0]],\n",
    "            'decision2': processed_df[decisions[1]],\n",
    "            'decision3': processed_df[decisions[2]],\n",
    "        }\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def get_state(self,name,**kwargs):\n",
    "        return self.get_states(**kwargs)[name]\n",
    "    \n",
    "    def normalize(self,df):\n",
    "        means = self.means[df.columns]\n",
    "        std = self.stds[df.columns]\n",
    "        return ((df - means)/std).fillna(0)\n",
    "    \n",
    "    def get_intermediate_outcomes(self,step=1,**kwargs):\n",
    "        assert(step in [1,2])\n",
    "        states = self.get_states(**kwargs)\n",
    "        if step == 1:\n",
    "            keys = ['pd_states1','nd_states1','modifications','dlt1']\n",
    "        else:\n",
    "            keys =  ['pd_states2','nd_states2','ccs','dlt2']\n",
    "        return [states[key] for key in keys]\n",
    "    \n",
    "    def get_input_state(self,step=1,**kwargs):\n",
    "        assert(step in [1,2,3])\n",
    "        states = self.get_states(**kwargs)\n",
    "        if step == 1:\n",
    "            keys = ['baseline']\n",
    "        if step == 2:\n",
    "            keys =  ['baseline','pd_states1','nd_states1','modifications','dlt1']\n",
    "        if step == 3:\n",
    "            keys = ['baseline','pd_states2','nd_states2','ccs','dlt2']\n",
    "        arrays = [states[key].values for key in keys]\n",
    "        return np.concatenate(arrays,axis=1)\n",
    "    \n",
    "data = DTDataset()\n",
    "data.get_states()['modifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8fee2ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <th>DLT_Other</th>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <th>DLT_Hematological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DLT_Gastrointestinal  DLT_Other  DLT_Neurological  DLT_Dermatological  \\\n",
       "id                                                                             \n",
       "3                         0          0                 0                   0   \n",
       "5                         0          0                 0                   0   \n",
       "6                         0          0                 0                   0   \n",
       "7                         0          0                 0                   0   \n",
       "8                         0          0                 0                   0   \n",
       "...                     ...        ...               ...                 ...   \n",
       "10201                     0          0                 0                   0   \n",
       "10202                     0          0                 0                   0   \n",
       "10203                     0          0                 0                   0   \n",
       "10204                     0          0                 0                   0   \n",
       "10205                     0          0                 0                   0   \n",
       "\n",
       "       DLT_Infection (Pneumonia)  DLT_Vascular  DLT_Nephrological  \\\n",
       "id                                                                  \n",
       "3                              0             0                  0   \n",
       "5                              0             0                  0   \n",
       "6                              0             0                  0   \n",
       "7                              0             0                  0   \n",
       "8                              0             0                  0   \n",
       "...                          ...           ...                ...   \n",
       "10201                          0             0                  0   \n",
       "10202                          0             0                  0   \n",
       "10203                          0             0                  0   \n",
       "10204                          0             0                  0   \n",
       "10205                          0             0                  0   \n",
       "\n",
       "       DLT_Hematological  \n",
       "id                        \n",
       "3                      0  \n",
       "5                      0  \n",
       "6                      0  \n",
       "7                      0  \n",
       "8                      0  \n",
       "...                  ...  \n",
       "10201                  0  \n",
       "10202                  0  \n",
       "10203                  0  \n",
       "10204                  0  \n",
       "10205                  0  \n",
       "\n",
       "[536 rows x 8 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_states()['dlt1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ad5bd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a87a4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeSimulator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_layers = [100,100],\n",
    "                 dropout = 0.5,\n",
    "                 input_dropout=0.1,\n",
    "                 state = 1,\n",
    "                ):\n",
    "        #predicts disease state (sd, pr, cr) for primar and nodal, then dose modications or cc type (depending on state), and [dlt ratings]\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.state = state\n",
    "        self.input_dropout = torch.nn.Dropout(input_dropout)\n",
    "        \n",
    "        first_layer =torch.nn.Linear(input_size,hidden_layers[0],bias=True)\n",
    "        layers = [first_layer,torch.nn.ReLU()]\n",
    "        curr_size = hidden_layers[0]\n",
    "        for ndim in hidden_layers[1:]:\n",
    "            layer = torch.nn.Linear(curr_size,ndim)\n",
    "            curr_size = ndim\n",
    "            layers.append(layer)\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(hidden_layers[-1])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.primary_disease_states))\n",
    "        self.nodal_disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.nodal_disease_states))\n",
    "        #dlt ratings are 0-4 even though they don't always appear\n",
    "        \n",
    "        assert( state in [1,2])\n",
    "        if state == 1:\n",
    "            self.dlt_layers = torch.nn.ModuleList([torch.nn.Linear(hidden_layers[-1],5) for i in Const.dlt1])\n",
    "            self.treatment_layer = torch.nn.Linear(hidden_layers[-1],len(Const.modifications))\n",
    "        else:\n",
    "            #we only have dlt yes or no for the second state?\n",
    "            self.dlt_layers = torch.nn.ModuleList([torch.nn.Linear(hidden_layers[-1],2) for i in Const.dlt2])\n",
    "            self.treatment_layer = torch.nn.Linear(hidden_layers[-1],len(Const.ccs))\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pd = self.disease_layer(x)\n",
    "        x_nd = self.nodal_disease_layer(x)\n",
    "        x_mod = self.treatment_layer(x)\n",
    "        x_dlts = [layer(x) for layer in self.dlt_layers]\n",
    "        \n",
    "        x_pd = self.softmax(x_pd)\n",
    "        x_nd = self.softmax(x_nd)\n",
    "        x_mod = self.softmax(x_mod)\n",
    "        #dlts are array of nbatch x n_dlts x predictions\n",
    "        x_dlts = torch.stack([self.softmax(xx) for xx in x_dlts],axis=1)\n",
    "        return [x_pd, x_nd, x_mod, x_dlts]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "bf9d387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n",
      "torch.Size([536, 5]) torch.Size([536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.4036416150292683,\n",
       "  'roc_micro': 0.5183652906692722,\n",
       "  'roc_macro': 0.512076444677321},\n",
       " 'nd': {'accuracy': 0.39749364749364746,\n",
       "  'roc_micro': 0.4835434551423331,\n",
       "  'roc_macro': 0.5266376305484145},\n",
       " 'mod': {'accuracy': 0.39749364749364746,\n",
       "  'roc_micro': 0.4835434551423331,\n",
       "  'roc_macro': 0.5266376305484145},\n",
       " 'dlts': {'accuracy': [0.4400205907412667,\n",
       "   0.25205566097406706,\n",
       "   0.14526936988387587,\n",
       "   0.23241930171277997,\n",
       "   0.2557848655409631,\n",
       "   0.3545568039950062,\n",
       "   0.04690431519699812,\n",
       "   0.06951790841771195],\n",
       "  'error': [4.4085820895522385,\n",
       "   7.130597014925373,\n",
       "   6.229477611940299,\n",
       "   6.132462686567164,\n",
       "   4.986940298507463,\n",
       "   5.108208955223881,\n",
       "   6.100746268656716,\n",
       "   6.425373134328358],\n",
       "  'error_mean': 5.815298507462686,\n",
       "  'accuracy_mean': 0.22456610205783364}}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = nloss(dlt_pred[:,i,:],dlt_true[:,i].type(torch.LongTensor))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "def mc_metrics(yt,yp):\n",
    "    yt = yt .cpu().detach().numpy()\n",
    "    yp = yp.cpu().detach().numpy()\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    if yt.ndim > 1:\n",
    "        bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    else:\n",
    "        yp = yp.argmax(axis=1)\n",
    "        bacc = balanced_accuracy_score(yt,yp)\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error}\n",
    "\n",
    "def state_metrics(ytrue,ypred):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0])\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1])\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1])\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        print(dlt_pred[:,i,:].shape,dlt_true[:,i].shape)\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i,:])\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'error': dlt_error,'error_mean': np.mean(dlt_error),'accuracy_mean': np.mean(dlt_acc)}}\n",
    "    \n",
    "ytrue = [df_to_torch(temp) for temp in data.get_intermediate_outcomes()]\n",
    "ypred = outcomes1_model(x)\n",
    "state_metrics(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "cea6f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/1992661605.py:2: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2180157/42072186.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/42072186.py:19: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/42072186.py:20: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 8.992998123168945\n",
      "val loss 7.27439022064209\n",
      "______________\n",
      "epoch 1 train loss 7.257967472076416\n",
      "val loss 4.929393291473389\n",
      "______________\n",
      "epoch 2 train loss 4.996738433837891\n",
      "val loss 3.139324903488159\n",
      "______________\n",
      "epoch 3 train loss 3.2896461486816406\n",
      "val loss 2.838001012802124\n",
      "______________\n",
      "epoch 4 train loss 2.939560890197754\n",
      "val loss 2.8147075176239014\n",
      "______________\n",
      "epoch 5 train loss 2.8629417419433594\n",
      "val loss 2.715360403060913\n",
      "______________\n",
      "epoch 6 train loss 2.738968849182129\n",
      "val loss 2.5231707096099854\n",
      "______________\n",
      "epoch 7 train loss 2.4634146690368652\n",
      "val loss 2.4013559818267822\n",
      "______________\n",
      "epoch 8 train loss 2.338526964187622\n",
      "val loss 2.231795072555542\n",
      "______________\n",
      "epoch 9 train loss 2.198930025100708\n",
      "val loss 2.121391773223877\n",
      "______________\n",
      "epoch 10 train loss 2.1234805583953857\n",
      "val loss 2.079785108566284\n",
      "______________\n",
      "epoch 11 train loss 1.9946142435073853\n",
      "val loss 2.0406172275543213\n",
      "______________\n",
      "epoch 12 train loss 2.006450891494751\n",
      "val loss 1.9927316904067993\n",
      "______________\n",
      "epoch 13 train loss 1.9568274021148682\n",
      "val loss 1.936582326889038\n",
      "______________\n",
      "epoch 14 train loss 1.9039733409881592\n",
      "val loss 1.8815611600875854\n",
      "______________\n",
      "epoch 15 train loss 1.855589747428894\n",
      "val loss 1.8365925550460815\n",
      "______________\n",
      "epoch 16 train loss 1.7714707851409912\n",
      "val loss 1.8112733364105225\n",
      "______________\n",
      "epoch 17 train loss 1.687447190284729\n",
      "val loss 1.8028419017791748\n",
      "______________\n",
      "epoch 18 train loss 1.6815277338027954\n",
      "val loss 1.8018980026245117\n",
      "______________\n",
      "epoch 19 train loss 1.6259567737579346\n",
      "val loss 1.806343913078308\n",
      "______________\n",
      "epoch 20 train loss 1.5944617986679077\n",
      "val loss 1.8298029899597168\n",
      "______________\n",
      "epoch 21 train loss 1.5942741632461548\n",
      "val loss 1.8650119304656982\n",
      "______________\n",
      "epoch 22 train loss 1.5581340789794922\n",
      "val loss 1.8905609846115112\n",
      "______________\n",
      "epoch 23 train loss 1.5620205402374268\n",
      "val loss 1.8771781921386719\n",
      "______________\n",
      "epoch 24 train loss 1.500453233718872\n",
      "val loss 1.8274447917938232\n",
      "______________\n",
      "epoch 25 train loss 1.5257487297058105\n",
      "val loss 1.7767510414123535\n",
      "______________\n",
      "epoch 26 train loss 1.4479119777679443\n",
      "val loss 1.7453112602233887\n",
      "______________\n",
      "epoch 27 train loss 1.401214838027954\n",
      "val loss 1.7264635562896729\n",
      "______________\n",
      "epoch 28 train loss 1.4702671766281128\n",
      "val loss 1.708412766456604\n",
      "______________\n",
      "epoch 29 train loss 1.369357943534851\n",
      "val loss 1.700790286064148\n",
      "______________\n",
      "epoch 30 train loss 1.3781503438949585\n",
      "val loss 1.7000975608825684\n",
      "______________\n",
      "epoch 31 train loss 1.3829855918884277\n",
      "val loss 1.6971192359924316\n",
      "______________\n",
      "epoch 32 train loss 1.357194423675537\n",
      "val loss 1.6988089084625244\n",
      "______________\n",
      "epoch 33 train loss 1.3364413976669312\n",
      "val loss 1.6999863386154175\n",
      "______________\n",
      "epoch 34 train loss 1.3103811740875244\n",
      "val loss 1.7006926536560059\n",
      "______________\n",
      "epoch 35 train loss 1.3426611423492432\n",
      "val loss 1.7064290046691895\n",
      "______________\n",
      "epoch 36 train loss 1.3148177862167358\n",
      "val loss 1.713858962059021\n",
      "______________\n",
      "epoch 37 train loss 1.2996101379394531\n",
      "val loss 1.715281367301941\n",
      "______________\n",
      "epoch 38 train loss 1.2593096494674683\n",
      "val loss 1.7147716283798218\n",
      "______________\n",
      "epoch 39 train loss 1.2490586042404175\n",
      "val loss 1.717077612876892\n",
      "______________\n",
      "epoch 40 train loss 1.2536195516586304\n",
      "val loss 1.7206201553344727\n",
      "______________\n",
      "epoch 41 train loss 1.2527343034744263\n",
      "val loss 1.7230852842330933\n",
      "______________\n",
      "epoch 42 train loss 1.1724313497543335\n",
      "val loss 1.7258192300796509\n",
      "______________\n",
      "best loss 1.6971192359924316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeSimulator(\n",
       "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=61, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (disease_layer): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (1): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (2): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (3): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (4): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (5): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (6): Linear(in_features=100, out_features=5, bias=True)\n",
       "    (7): Linear(in_features=100, out_features=5, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=100, out_features=7, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_state1(model_args={},lr=.01,epochs=1000,patience=10,weights=[1,1,1,3]):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    \n",
    "    model = OutcomeSimulator(dataset.state_sizes['baseline'],state=1,**model_args)\n",
    "    \n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    xtrain = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest = dataset.get_state('baseline',ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "    unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_val_metrics = {}\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(normalize(xtrain_sample))\n",
    "        loss = state_loss(ytrain,ypred,weights=weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(normalize(xtest))\n",
    "        val_loss = state_loss(ytest,yval,weights=weights)\n",
    "        val_metrics = s\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = \n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        print('val loss',val_loss.item())\n",
    "        print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss)\n",
    "    return model\n",
    "train_state1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dcc8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1f9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dce54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
