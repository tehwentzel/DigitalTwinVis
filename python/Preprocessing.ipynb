{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no_dose_adjustment',\n",
       " 1: 'dose_modified',\n",
       " 2: 'dose_delayed',\n",
       " 3: 'dose_cancelled',\n",
       " 4: 'dose_delayed_&_modified',\n",
       " 5: 'regiment_modification',\n",
       " 9: 'unknown'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Const:\n",
    "    data_dir = '../data'\n",
    "    twin_data = data_dir + 'digital_twin_data.csv'\n",
    "    twin_ln_data = data_dir + 'digital_twin_ln_data.csv'\n",
    "    \n",
    "    rename_dict = {\n",
    "        'Dummy ID': 'id',\n",
    "        'Age at Diagnosis (Calculated)': 'age',\n",
    "        'Feeding tube 6m': 'FT',\n",
    "        'Affected Lymph node UPPER': 'affected_nodes',\n",
    "        'Aspiration rate(Y/N)': 'AS',\n",
    "        'Neck boost (Y/N)': 'neck_boost',\n",
    "        'Gender': 'gender',\n",
    "        'Tm Laterality (R/L)': 'laterality',\n",
    "        'AJCC 8th edition': 'ajcc8',\n",
    "        'AJCC 7th edition':'ajcc7',\n",
    "        'N_category_full': 'N-category',\n",
    "        'HPV/P16 status': 'hpv',\n",
    "        'Tumor subsite (BOT/Tonsil/Soft Palate/Pharyngeal wall/GPS/NOS)': 'subsite',\n",
    "        'Total dose': 'total_dose',\n",
    "        'Therapeutic combination': 'treatment',\n",
    "        'Smoking status at Diagnosis (Never/Former/Current)': 'smoking_status',\n",
    "        'Smoking status (Packs/Year)': 'packs_per_year',\n",
    "        'Overall Survival (1=alive,0=dead)': 'os',\n",
    "        'Dose/fraction (Gy)': 'dose_fraction'\n",
    "    }\n",
    "    \n",
    "    dlt_dict = {\n",
    "         'Allergic reaction to Cetuximab': 'DLT_Other',\n",
    "         'Cardiological (A-fib)': 'DLT_Other',\n",
    "         'Dermatological': 'DLT_Dermatological',\n",
    "         'Failure to Thrive': 'DLT_Other',\n",
    "         'Failure to thrive': 'DLT_Other',\n",
    "         'GIT [elevated liver enzymes]': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestina': 'DLT_Gastrointestinal',\n",
    "         'Gastrointestinal': 'DLT_Gastrointestinal',\n",
    "         'General': 'DLT_Other',\n",
    "         'Hematological': 'DLT_Hematological',\n",
    "         'Hematological (Neutropenia)': 'DLT_Hematological',\n",
    "         'Hyponatremia': 'DLT_Other',\n",
    "         'Immunological': 'DLT_Other',\n",
    "         'Infection': 'DLT_Infection (Pneumonia)',\n",
    "         'NOS': 'DLT_Other',\n",
    "         'Nephrological': 'DLT_Nephrological',\n",
    "         'Nephrological (ARF)': 'DLT_Nephrological',\n",
    "         'Neurological': 'DLT_Neurological',\n",
    "         'Neutropenia': 'DLT_Hematological',\n",
    "         'Nutritional': 'DLT_Other',\n",
    "         'Pancreatitis': 'DLT_Other',\n",
    "         'Pulmonary': 'DLT_Other',\n",
    "         'Respiratory (Pneumonia)': 'DLT_Infection (Pneumonia)',\n",
    "         'Sepsis': 'DLT_Infection (Pneumonia)',\n",
    "         'Suboptimal response to treatment' : 'DLT_Other',\n",
    "         'Vascular': 'DLT_Vascular'\n",
    "    }\n",
    "    \n",
    "    decision1 = 'Decision 1 (Induction Chemo) Y/N'\n",
    "    decision2 = 'Decision 2 (CC / RT alone)'\n",
    "    decision3 = 'Decision 3 Neck Dissection (Y/N)'\n",
    "    decisions = [decision1,decision2, decision3]\n",
    "    outcomes = ['Overall Survival (4 Years)', 'FT', 'Aspiration rate Post-therapy']\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    primary_disease_states = ['CR Primary','PR Primary','SD Primary']\n",
    "    nodal_disease_states = [t.replace('Primary','Nodal') for t in primary_disease_states]\n",
    "    dlt1 = list(set(dlt_dict.values()))\n",
    "    \n",
    "    modifications =  list(modification_types.values())\n",
    "    state2 = modifications + primary_disease_states+nodal_disease_states +dlt1 #+['No imaging 0=N,1=Y']\n",
    "    \n",
    "    primary_disease_states2 = [t + ' 2' for t in primary_disease_states]\n",
    "    nodal_disease_states2 = [t + ' 2' for t in nodal_disease_states]\n",
    "    dlt2 = [d + ' 2' for d in dlt1]\n",
    "    \n",
    "    ccs = list(cc_types.values())\n",
    "    state3 = ccs + primary_disease_states2 + nodal_disease_states2 + dlt2\n",
    "    \n",
    "Const.modification_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d02b309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_cleaned):\n",
    "    #this was Elisa's preprocessing except I removed all the Ifs because that's dumb\n",
    "    if len(data_cleaned.shape) < 2:\n",
    "        data_cleaned = pd.DataFrame([data], columns=data.index)\n",
    "        \n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'N', 'Aspiration rate Pre-therapy'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Aspiration rate Pre-therapy'] == 'Y', 'Aspiration rate Pre-therapy'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'I', 'Pathological Grade'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'II', 'Pathological Grade'] = 2\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'III', 'Pathological Grade'] = 3\n",
    "    data_cleaned.loc[data_cleaned['Pathological Grade'] == 'IV', 'Pathological Grade'] = 4\n",
    "\n",
    "    data_cleaned.loc[(data_cleaned['T-category'] == 'Tx') | (data_cleaned['T-category'] == 'Tis'), 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T1', 'T-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T2', 'T-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T3', 'T-category'] = 3\n",
    "    data_cleaned.loc[data_cleaned['T-category'] == 'T4', 'T-category'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N0', 'N-category'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N1', 'N-category'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N2', 'N-category'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category'] == 'N3', 'N-category'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N0', 'N-category_8th_edition'] = 0\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N1', 'N-category_8th_edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N2', 'N-category_8th_edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['N-category_8th_edition'] == 'N3', 'N-category_8th_edition'] = 3\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'I', 'AJCC 7th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'II', 'AJCC 7th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'III', 'AJCC 7th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 7th edition'] == 'IV', 'AJCC 7th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'I', 'AJCC 8th edition'] = 1\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'II', 'AJCC 8th edition'] = 2\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'III', 'AJCC 8th edition'] = 3\n",
    "    data_cleaned.loc[data_cleaned['AJCC 8th edition'] == 'IV', 'AJCC 8th edition'] = 4\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Male', 'Gender'] = 1\n",
    "    data_cleaned.loc[data_cleaned['Gender'] == 'Female', 'Gender'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Positive', 'HPV/P16 status'] = 1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Negative', 'HPV/P16 status'] = -1\n",
    "    data_cleaned.loc[data_cleaned['HPV/P16 status'] == 'Unknown', 'HPV/P16 status'] = 0\n",
    "\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Formar', 'Smoking status at Diagnosis (Never/Former/Current)'] = .5\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Current', 'Smoking status at Diagnosis (Never/Former/Current)'] = 1\n",
    "    data_cleaned.loc[data_cleaned[\n",
    "                         'Smoking status at Diagnosis (Never/Former/Current)'] == 'Never', 'Smoking status at Diagnosis (Never/Former/Current)'] = 0\n",
    "\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Chemo Modification (Y/N)'] == 'Y', 'Chemo Modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'N', 'DLT (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['DLT (Y/N)'] == 'Y', 'DLT (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Other'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT_Type'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT_Type']):\n",
    "            if i.strip() != '' and data_cleaned.loc[index, Const.dlt_dict[i.strip()]] == 0:\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()]] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'RT alone', 'Decision 2 (CC / RT alone)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['Decision 2 (CC / RT alone)'] == 'CC', 'Decision 2 (CC / RT alone)'] = 1\n",
    "\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'N', 'CC modification (Y/N)'] = 0\n",
    "    data_cleaned.loc[data_cleaned['CC modification (Y/N)'] == 'Y', 'CC modification (Y/N)'] = 1\n",
    "\n",
    "    data_cleaned['DLT_Dermatological 2'] = 0\n",
    "    data_cleaned['DLT_Neurological 2'] = 0\n",
    "    data_cleaned['DLT_Gastrointestinal 2'] = 0\n",
    "    data_cleaned['DLT_Hematological 2'] = 0\n",
    "    data_cleaned['DLT_Nephrological 2'] = 0\n",
    "    data_cleaned['DLT_Vascular 2'] = 0\n",
    "    data_cleaned['DLT_Infection (Pneumonia) 2'] = 0\n",
    "    data_cleaned['DLT_Other 2'] = 0\n",
    "    for index, row in data_cleaned.iterrows():\n",
    "        if row['DLT 2'] == 'None':\n",
    "            continue\n",
    "        for i in re.split('&|and|,', row['DLT 2']):\n",
    "            if i.strip() != '':\n",
    "                data_cleaned.loc[index, Const.dlt_dict[i.strip()] + ' 2'] = 1\n",
    "\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'N', 'Decision 3 Neck Dissection (Y/N)'] = 0\n",
    "    data_cleaned.loc[\n",
    "        data_cleaned['Decision 3 Neck Dissection (Y/N)'] == 'Y', 'Decision 3 Neck Dissection (Y/N)'] = 1\n",
    "\n",
    "    return data_cleaned\n",
    "\n",
    "def merge_editions(row,basecol='AJCC 8th edition',fallback='AJCC 7th edition'):\n",
    "    if pd.isnull(row[basecol]):\n",
    "        return row[fallback]\n",
    "    return row[basecol]\n",
    "\n",
    "\n",
    "def preprocess_dt_data(df,extra_to_keep=None):\n",
    "    \n",
    "    to_keep = ['id','hpv','age','packs_per_year','smoking_status','gender','Aspiration rate Pre-therapy','total_dose','dose_fraction'] \n",
    "    to_onehot = ['T-category','N-category','AJCC','Pathological Grade','subsite','treatment','ln_cluster']\n",
    "    if extra_to_keep is not None:\n",
    "        to_keep = to_keep + [c for c in extra_to_keep if c not in to_keep and c not in to_onehot]\n",
    "    \n",
    "    decisions =Const.decisions\n",
    "    outcomes = Const.outcomes\n",
    "    \n",
    "    modification_types = {\n",
    "        0: 'no_dose_adjustment',\n",
    "        1: 'dose_modified',\n",
    "        2: 'dose_delayed',\n",
    "        3: 'dose_cancelled',\n",
    "        4: 'dose_delayed_&_modified',\n",
    "        5: 'regiment_modification',\n",
    "        9: 'unknown'\n",
    "    }\n",
    "    \n",
    "    cc_types = {\n",
    "        0: 'cc_none',\n",
    "        1: 'cc_platinum',\n",
    "        2: 'cc_cetuximab',\n",
    "        3: 'cc_others',\n",
    "    }\n",
    "    \n",
    "    for k,v in Const.cc_types.items():\n",
    "        df[v] = df['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)'].apply(lambda x: int(Const.cc_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    for k,v in Const.modification_types.items():\n",
    "        name = 'Modification Type (0= no dose adjustment, 1=dose modified, 2=dose delayed, 3=dose cancelled, 4=dose delayed & modified, 5=regimen modification, 9=unknown)'\n",
    "        df[v] = df[name].apply(lambda x: int(Const.modification_types.get(int(x),0) == v))\n",
    "        to_keep.append(v)\n",
    "    #Features to keep. I think gender is is in \n",
    "    \n",
    "    keywords = []\n",
    "    for keyword in keywords:\n",
    "        toadd = [c for c in df.columns if keyword in c and c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    \n",
    "    df['packs_per_year'] = df['packs_per_year'].apply(lambda x: str(x).replace('>','').replace('<','')).astype(float).fillna(0)\n",
    "    #so I'm actually not sure if this is biological sex or gender given this is texas\n",
    "    df['AJCC'] = df.apply(lambda row: merge_editions(row,'ajcc8','ajcc7'),axis=1)\n",
    "    df['N-category'] = df.apply(lambda row: merge_editions(row,'N-category_8th_edition','N-category'),axis=1)\n",
    "    \n",
    "    dummy_df = pd.get_dummies(df[to_onehot].fillna(0).astype(str),drop_first=False)\n",
    "    for col in dummy_df.columns:\n",
    "        df[col] = dummy_df[col]\n",
    "        to_keep.append(col)\n",
    "        \n",
    "    yn_to_binary = ['FT','Aspiration rate Post-therapy','Decision 1 (Induction Chemo) Y/N']\n",
    "    for col in yn_to_binary:\n",
    "        df[col] = df[col].apply(lambda x: int(x == 'Y'))\n",
    "        \n",
    "    to_keep = to_keep + [c for c in df.columns if 'DLT' in c]\n",
    "    \n",
    "        \n",
    "    for statelist in [Const.state2,Const.state3,Const.decisions,Const.outcomes]:\n",
    "        toadd = [c for c in statelist if c not in to_keep]\n",
    "        to_keep = to_keep + toadd\n",
    "    return df[to_keep].set_index('id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c861bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/1992661605.py:2: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    3,     5,     6,     7,     8,     9,    10,    11,    13,\n",
       "          14,    15,    16,    17,    18,    21,    23,    24,    25,\n",
       "          26,    27,    28,    31,    32,    33,    35,    36,    37,\n",
       "          38,    39,    40,    41,    42,    44,    45,    47,    48,\n",
       "          49,    50,    51,    53,    55,    56,    57,    60,    64,\n",
       "          65,    67,    68,    69,    71,    74,    75,    77,    78,\n",
       "          79,    80,    81,    82,    87,    88,    91,    94,    96,\n",
       "          99,   103,   109,   116,   117,   119,   120,   121,   125,\n",
       "         133,   148,   150,   153,   168,   178,   181,   183,   184,\n",
       "         185,   186,   187,   188,   189,   190,   191,   192,   193,\n",
       "         194,   195,   196,   197,   198,   199,   200,   201,   202,\n",
       "         203,   204,   205,   206,   207,   208,   209,   210,   211,\n",
       "         212,   213,   214,   215,   216,   217,   218,   219,   220,\n",
       "         221,   222,   223,   224,   225,   226,   227,   228,   229,\n",
       "         230,   231,   232,   233,   234,   235,   236,   237,   238,\n",
       "         239,   240,   241,   242,   243,   244,   245,   246,   247,\n",
       "         248,   249,   251,   252,   253,   254,   255,   256,   257,\n",
       "         258,   259,   260,   261,   262,   263,   264,   265,   266,\n",
       "         267,   268,   269,   270,   271,   272,   273,   274,   275,\n",
       "         276,   277,   278,   279,   280,   281,   282,   283,   284,\n",
       "         285,   286,   287,   288,   289,  2000,  2001,  2002,  2003,\n",
       "        2004,  2005,  2006,  2007,  2008,  2009,  2010,  2011,  2012,\n",
       "        2013,  2014,  2015,  2016,  2017,  2018,  2019,  2020,  2021,\n",
       "        2022,  2023,  2024,  2025,  2026,  2027,  2028,  2029,  2030,\n",
       "        2031,  2032,  2033,  5000,  5001,  5002,  5003,  5004,  5005,\n",
       "        5006,  5007,  5008,  5009,  5010,  5011,  5012,  5013,  5014,\n",
       "        5015,  5016,  5017,  5018,  5019,  5020,  5021,  5022,  5023,\n",
       "        5024,  5025,  5026,  5027,  5028,  5029,  5030,  5031,  5032,\n",
       "        5033,  5034,  5035,  5036,  5037,  5038,  5039,  5040,  5041,\n",
       "        5042,  5043,  5044,  5045,  5047,  5048,  5049,  5050,  5051,\n",
       "        5052,  5053,  5054,  5055,  5056,  5057,  5058,  5059,  5060,\n",
       "        5061,  5062,  5063,  5064,  5065,  5066,  5067,  5068,  5069,\n",
       "        5070,  5071,  5072,  5073,  5074,  5075,  5076,  5077,  5078,\n",
       "        5079,  5080,  5081,  5082,  5083,  5084,  5085,  5086,  5087,\n",
       "        5088,  5089,  5090,  5091,  5092,  5093,  5094,  5095,  5096,\n",
       "        5097,  5098,  5099,  5100,  5101,  5102,  5103,  5104,  5105,\n",
       "        5106,  5107,  5108,  5109,  5110,  5111,  5112,  5113,  5114,\n",
       "        5115,  5117,  5118,  5119,  5120, 10001, 10002, 10003, 10004,\n",
       "       10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013,\n",
       "       10014, 10015, 10016, 10017, 10018, 10019, 10020, 10021, 10022,\n",
       "       10023, 10024, 10025, 10026, 10027, 10028, 10029, 10031, 10033,\n",
       "       10034, 10035, 10036, 10037, 10038, 10039, 10040, 10041, 10042,\n",
       "       10043, 10044, 10045, 10046, 10047, 10048, 10049, 10050, 10051,\n",
       "       10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060,\n",
       "       10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069,\n",
       "       10070, 10071, 10072, 10073, 10074, 10075, 10077, 10078, 10079,\n",
       "       10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088,\n",
       "       10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097,\n",
       "       10098, 10099, 10100, 10101, 10102, 10103, 10104, 10105, 10106,\n",
       "       10107, 10108, 10109, 10110, 10111, 10113, 10114, 10115, 10116,\n",
       "       10117, 10118, 10119, 10120, 10121, 10123, 10124, 10125, 10126,\n",
       "       10127, 10128, 10129, 10130, 10131, 10132, 10133, 10134, 10135,\n",
       "       10136, 10137, 10138, 10139, 10140, 10141, 10142, 10143, 10144,\n",
       "       10145, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10153,\n",
       "       10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10162,\n",
       "       10163, 10164, 10165, 10167, 10168, 10169, 10170, 10171, 10172,\n",
       "       10173, 10174, 10175, 10176, 10177, 10178, 10180, 10181, 10182,\n",
       "       10183, 10184, 10185, 10186, 10187, 10188, 10189, 10190, 10191,\n",
       "       10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200,\n",
       "       10201, 10202, 10203, 10204, 10205])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_digital_twin(file='../data/digital_twin_data.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "    return df.rename(columns = Const.rename_dict)\n",
    "\n",
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "get_dt_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e719a1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/42072186.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/42072186.py:19: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/42072186.py:20: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_dose_adjustment</th>\n",
       "      <th>dose_modified</th>\n",
       "      <th>dose_delayed</th>\n",
       "      <th>dose_cancelled</th>\n",
       "      <th>dose_delayed_&amp;_modified</th>\n",
       "      <th>regiment_modification</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_dose_adjustment  dose_modified  dose_delayed  dose_cancelled  \\\n",
       "id                                                                       \n",
       "3                       1              0             0               0   \n",
       "5                       1              0             0               0   \n",
       "6                       1              0             0               0   \n",
       "7                       1              0             0               0   \n",
       "8                       1              0             0               0   \n",
       "...                   ...            ...           ...             ...   \n",
       "10201                   1              0             0               0   \n",
       "10202                   1              0             0               0   \n",
       "10203                   1              0             0               0   \n",
       "10204                   1              0             0               0   \n",
       "10205                   1              0             0               0   \n",
       "\n",
       "       dose_delayed_&_modified  regiment_modification  unknown  \n",
       "id                                                              \n",
       "3                            0                      0        0  \n",
       "5                            0                      0        0  \n",
       "6                            0                      0        0  \n",
       "7                            0                      0        0  \n",
       "8                            0                      0        0  \n",
       "...                        ...                    ...      ...  \n",
       "10201                        0                      0        0  \n",
       "10202                        0                      0        0  \n",
       "10203                        0                      0        0  \n",
       "10204                        0                      0        0  \n",
       "10205                        0                      0        0  \n",
       "\n",
       "[536 rows x 7 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DTDataset():\n",
    "    \n",
    "    def __init__(self,data_file = '../data/digital_twin_data.csv',ln_data_file = '../data/digital_twin_ln_data.csv',ids=None):\n",
    "        df = pd.read_csv(data_file)\n",
    "        \n",
    "        df = preprocess(df)\n",
    "        df = df.rename(columns = Const.rename_dict).copy()\n",
    "        df = df.drop('MRN OPC',axis=1)\n",
    "\n",
    "        ln_data = pd.read_csv(ln_data_file)\n",
    "        ln_data = ln_data.rename(columns={'cluster':'ln_cluster'})\n",
    "        self.ln_cols = [c for c in ln_data.columns if c not in df.columns]\n",
    "        df = df.merge(ln_data,on='id')\n",
    "        df.index = df.index.astype(int)\n",
    "        if ids is not None:\n",
    "            df = df[df.id.apply(lambda x: x in ids)]\n",
    "        self.processed_df = preprocess_dt_data(df,self.ln_cols).fillna(0)\n",
    "        \n",
    "        self.means = self.processed_df.mean(axis=0)\n",
    "        self.stds = self.processed_df.std(axis=0)\n",
    "        self.maxes = self.processed_df.max(axis=0)\n",
    "        self.mins = self.processed_df.min(axis=0)\n",
    "        \n",
    "        arrays = self.get_states()\n",
    "        self.state_sizes = {k: (v.shape[1] if v.ndim > 1 else 1) for k,v in arrays.items()}\n",
    "        \n",
    "    def get_data(self):\n",
    "        return self.processed_df\n",
    "    \n",
    "    def sample(self,frac=.5):\n",
    "        return self.processed_df.sample(frac=frac)\n",
    "    \n",
    "    def split_sample(self,ratio = .3):\n",
    "        assert(ratio > 0 and ratio <= 1)\n",
    "        df1 = self.processed_df.sample(frac=1-ratio)\n",
    "        df2 = self.processed_df.drop(index=df1.index)\n",
    "        return df1,df2\n",
    "    \n",
    "    def get_states(self,fixed=None,ids = None):\n",
    "        processed_df = self.processed_df.copy()\n",
    "        if ids is not None:\n",
    "            processed_df = processed_df.loc[ids]\n",
    "        if fixed is not None:\n",
    "            for col,val in fixed.items():\n",
    "                if col in processed_df.columns:\n",
    "                    processed_df[col] = val\n",
    "                else:\n",
    "                    print('bad fixed entry',col)\n",
    "                    \n",
    "        to_skip = ['CC Regimen(0= none, 1= platinum based, 2= cetuximab based, 3= others, 9=unknown)','DLT_Type','DLT 2'] + [c for c in processed_df.columns if 'treatment' in c]\n",
    "        other_states = set(Const.decisions + Const.state3 + Const.state2 + Const.outcomes  + to_skip)\n",
    "\n",
    "        base_state = sorted([c for c in processed_df.columns if c not in other_states])\n",
    "\n",
    "        dlt1 = Const.dlt1\n",
    "        dlt2 = Const.dlt2\n",
    "        \n",
    "        modifications = Const.modifications\n",
    "        ccs = Const.ccs\n",
    "        pds = Const.primary_disease_states\n",
    "        nds = Const.nodal_disease_states\n",
    "        pds2 = Const.primary_disease_states2\n",
    "        nds2 = Const.nodal_disease_states2\n",
    "        outcomes = Const.outcomes\n",
    "        decisions= Const.decisions\n",
    "        \n",
    "        #intermediate states are only udated values. Models should use baseline + state2 etc\n",
    "        results = {\n",
    "            'baseline': processed_df[base_state],\n",
    "            'pd_states1': processed_df[pds],\n",
    "            'nd_states1': processed_df[nds],\n",
    "            'modifications': processed_df[modifications],\n",
    "            'ccs': processed_df[ccs],\n",
    "            'pd_states2': processed_df[pds2],\n",
    "            'nd_states2': processed_df[nds2],\n",
    "            'outcomes': processed_df[outcomes],\n",
    "            'dlt1': processed_df[dlt1],\n",
    "            'dlt2': processed_df[dlt2],\n",
    "            'decision1': processed_df[decisions[0]],\n",
    "            'decision2': processed_df[decisions[1]],\n",
    "            'decision3': processed_df[decisions[2]],\n",
    "        }\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    def get_state(self,name,**kwargs):\n",
    "        return self.get_states(**kwargs)[name]\n",
    "    \n",
    "    def normalize(self,df):\n",
    "        means = self.means[df.columns]\n",
    "        std = self.stds[df.columns]\n",
    "        return ((df - means)/std).fillna(0)\n",
    "    \n",
    "    def get_intermediate_outcomes(self,step=1,**kwargs):\n",
    "        assert(step in [1,2])\n",
    "        states = self.get_states(**kwargs)\n",
    "        if step == 1:\n",
    "            keys = ['pd_states1','nd_states1','modifications','dlt1']\n",
    "        else:\n",
    "            keys =  ['pd_states2','nd_states2','ccs','dlt2']\n",
    "        return [states[key] for key in keys]\n",
    "    \n",
    "    def get_input_state(self,step=1,**kwargs):\n",
    "        assert(step in [1,2,3])\n",
    "        states = self.get_states(**kwargs)\n",
    "        if step == 1:\n",
    "            keys = ['baseline']\n",
    "        if step == 2:\n",
    "            keys =  ['baseline','pd_states1','nd_states1','modifications','dlt1']\n",
    "        if step == 3:\n",
    "            keys = ['baseline','pd_states2','nd_states2','ccs','dlt2']\n",
    "        arrays = [states[key].values for key in keys]\n",
    "        return np.concatenate(arrays,axis=1)\n",
    "    \n",
    "data = DTDataset()\n",
    "data.get_states()['modifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d6171060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <th>DLT_Other</th>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <th>DLT_Hematological</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DLT_Gastrointestinal  DLT_Other  DLT_Neurological  DLT_Dermatological  \\\n",
       "id                                                                             \n",
       "3                         0          0                 0                   0   \n",
       "5                         0          0                 0                   0   \n",
       "6                         0          0                 0                   0   \n",
       "7                         0          0                 0                   0   \n",
       "8                         0          0                 0                   0   \n",
       "...                     ...        ...               ...                 ...   \n",
       "10201                     0          0                 0                   0   \n",
       "10202                     0          0                 0                   0   \n",
       "10203                     0          0                 0                   0   \n",
       "10204                     0          0                 0                   0   \n",
       "10205                     0          0                 0                   0   \n",
       "\n",
       "       DLT_Infection (Pneumonia)  DLT_Vascular  DLT_Nephrological  \\\n",
       "id                                                                  \n",
       "3                              0             0                  0   \n",
       "5                              0             0                  0   \n",
       "6                              0             0                  0   \n",
       "7                              0             0                  0   \n",
       "8                              0             0                  0   \n",
       "...                          ...           ...                ...   \n",
       "10201                          0             0                  0   \n",
       "10202                          0             0                  0   \n",
       "10203                          0             0                  0   \n",
       "10204                          0             0                  0   \n",
       "10205                          0             0                  0   \n",
       "\n",
       "       DLT_Hematological  \n",
       "id                        \n",
       "3                      0  \n",
       "5                      0  \n",
       "6                      0  \n",
       "7                      0  \n",
       "8                      0  \n",
       "...                  ...  \n",
       "10201                  0  \n",
       "10202                  0  \n",
       "10203                  0  \n",
       "10204                  0  \n",
       "10205                  0  \n",
       "\n",
       "[536 rows x 8 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_states()['dlt1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c748333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a87a4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomeSimulator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_layers = [1000],\n",
    "                 dropout = 0.5,\n",
    "                 input_dropout=0.1,\n",
    "                 state = 1,\n",
    "                ):\n",
    "        #predicts disease state (sd, pr, cr) for primar and nodal, then dose modications or cc type (depending on state), and [dlt ratings]\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.state = state\n",
    "        self.input_dropout = torch.nn.Dropout(input_dropout)\n",
    "        \n",
    "        first_layer =torch.nn.Linear(input_size,hidden_layers[0],bias=True)\n",
    "        layers = [first_layer,torch.nn.ReLU()]\n",
    "        curr_size = hidden_layers[0]\n",
    "        for ndim in hidden_layers[1:]:\n",
    "            layer = torch.nn.Linear(curr_size,ndim)\n",
    "            curr_size = ndim\n",
    "            layers.append(layer)\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.batchnorm = torch.nn.BatchNorm1d(hidden_layers[-1])\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.primary_disease_states))\n",
    "        self.nodal_disease_layer = torch.nn.Linear(hidden_layers[-1],len(Const.nodal_disease_states))\n",
    "        #dlt ratings are 0-4 even though they don't always appear\n",
    "        \n",
    "        assert( state in [1,2])\n",
    "        if state == 1:\n",
    "            self.dlt_layers = torch.nn.ModuleList([torch.nn.Linear(hidden_layers[-1],5) for i in Const.dlt1])\n",
    "            self.treatment_layer = torch.nn.Linear(hidden_layers[-1],len(Const.modifications))\n",
    "        else:\n",
    "            #we only have dlt yes or no for the second state?\n",
    "            self.dlt_layers = torch.nn.ModuleList([torch.nn.Linear(hidden_layers[-1],2) for i in Const.dlt2])\n",
    "            self.treatment_layer = torch.nn.Linear(hidden_layers[-1],len(Const.ccs))\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.input_dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "#         x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pd = self.disease_layer(x)\n",
    "        x_nd = self.nodal_disease_layer(x)\n",
    "        x_mod = self.treatment_layer(x)\n",
    "        x_dlts = [layer(x) for layer in self.dlt_layers]\n",
    "        \n",
    "        x_pd = self.softmax(x_pd)\n",
    "        x_nd = self.softmax(x_nd)\n",
    "        x_mod = self.softmax(x_mod)\n",
    "        #dlts are array of nbatch x n_dlts x predictions\n",
    "        x_dlts = torch.stack([self.softmax(xx) for xx in x_dlts],axis=1)\n",
    "        return [x_pd, x_nd, x_mod, x_dlts]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd': {'accuracy': 0.4825127057996726,\n",
       "  'roc_micro': 0.5565003663898388,\n",
       "  'roc_macro': 0.5933534338186263},\n",
       " 'nd': {'accuracy': 0.33612843612843607,\n",
       "  'roc_micro': 0.4755714131590709,\n",
       "  'roc_macro': 0.5566864156955712},\n",
       " 'mod': {'accuracy': 0.33612843612843607,\n",
       "  'roc_micro': 0.4755714131590709,\n",
       "  'roc_macro': 0.5566864156955712},\n",
       " 'dlts': {'accuracy': [0.34924973965729433,\n",
       "   0.19270503900484925,\n",
       "   0.16143156291642868,\n",
       "   0.14562747035573123,\n",
       "   0.09380863039399624,\n",
       "   0.35205992509363293,\n",
       "   0.04690431519699812,\n",
       "   0.07082766611253842],\n",
       "  'accuracy_mean': 0.17657679359143363,\n",
       "  'auc': [0.5134345442496536,\n",
       "   0.5815939278937381,\n",
       "   0.5441516412390199,\n",
       "   0.5370882740447958,\n",
       "   0.42714196372732954,\n",
       "   0.5280898876404494,\n",
       "   0.3802376485303314,\n",
       "   0.5307429236702321],\n",
       "  'auc_mean': 0.5053101013744437}}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = nloss(dlt_pred[:,i,:],dlt_true[:,i].type(torch.LongTensor))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "def mc_metrics(yt,yp):\n",
    "    yt = yt .cpu().detach().numpy()\n",
    "    yp = yp.cpu().detach().numpy()\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    if yt.ndim > 1:\n",
    "        bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    else:\n",
    "        yp = yp.argmax(axis=1)\n",
    "        bacc = balanced_accuracy_score(yt,yp)\n",
    "        roc = roc_auc_score(yt > 0,yp > 0)\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0])\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1])\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1])\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i,:])\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'accuracy_mean': np.mean(dlt_acc),'auc': dlt_auc,'auc_mean': np.mean(dlt_auc)}}\n",
    "    \n",
    "ytrue = [df_to_torch(temp) for temp in data.get_intermediate_outcomes()]\n",
    "ypred = outcomes1_model(x)\n",
    "state_metrics(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95667ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_state_rf(model_args={}):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "\n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    xtrain = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest = dataset.get_state('baseline',ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "    \n",
    "    model = RandomForestClassifier(**model_args)\n",
    "    \n",
    "    model = model.fit(xtrain)\n",
    "    return model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "4901744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/1992661605.py:2: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_2180157/42072186.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/42072186.py:19: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/42072186.py:20: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 20.273086547851562\n",
      "val loss 4.8459930419921875\n",
      "______________\n",
      "epoch 1 train loss 4.562682628631592\n",
      "val loss 5.105750560760498\n",
      "______________\n",
      "epoch 2 train loss 4.529652118682861\n",
      "val loss 4.746618270874023\n",
      "______________\n",
      "epoch 3 train loss 4.034062385559082\n",
      "val loss 4.432910442352295\n",
      "______________\n",
      "epoch 4 train loss 3.5463716983795166\n",
      "val loss 4.185063362121582\n",
      "______________\n",
      "epoch 5 train loss 3.1654531955718994\n",
      "val loss 3.6867668628692627\n",
      "______________\n",
      "epoch 6 train loss 2.677767515182495\n",
      "val loss 3.1905763149261475\n",
      "______________\n",
      "epoch 7 train loss 2.332118034362793\n",
      "val loss 2.8737423419952393\n",
      "______________\n",
      "epoch 8 train loss 2.1158735752105713\n",
      "val loss 2.7195701599121094\n",
      "______________\n",
      "epoch 9 train loss 2.135974407196045\n",
      "val loss 2.6624999046325684\n",
      "______________\n",
      "best loss 2.6624999046325684 {'pd': {'accuracy': 0.4856220657276995, 'roc_micro': 0.712682379349046, 'roc_macro': 0.6423000688223298}, 'nd': {'accuracy': 0.4897025171624714, 'roc_micro': 0.6826815160148494, 'roc_macro': 0.7265765121996557}, 'mod': {'accuracy': 0.4897025171624714, 'roc_micro': 0.6826815160148494, 'roc_macro': 0.7265765121996557}, 'dlts': {'accuracy': [0.35913185913185913, 0.5, 0.25, 0.31315042573320717, 0.5, 0.3333333333333333, 0.5, 0.4133208839091192], 'accuracy_mean': 0.39611706276343983, 'auc': [0.5701663201663201, 0.5, 0.5, 0.6334437086092716, 0.5, 0.5, 0.5, 0.6646241830065359], 'auc_mean': 0.5460292764727659}}\n"
     ]
    }
   ],
   "source": [
    "def train_state1(model_args={},lr=.01,epochs=10,patience=1000,weights=[1,1,1,10]):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    \n",
    "    model = OutcomeSimulator(dataset.state_sizes['baseline'],state=1,**model_args)\n",
    "    \n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    \n",
    "    xtrain = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest = dataset.get_state('baseline',ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "    unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(normalize(xtrain_sample))\n",
    "        loss = state_loss(ytrain,ypred,weights=weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(normalize(xtest))\n",
    "        val_loss = state_loss(ytest,yval,weights=weights)\n",
    "        val_metrics = state_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        print('val loss',val_loss.item())\n",
    "        print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    return model.eval()\n",
    "model = train_state1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6481203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2180157/42072186.py:4: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/tmp/ipykernel_2180157/42072186.py:19: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/tmp/ipykernel_2180157/42072186.py:20: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[401], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(model)\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m df_to_torch(DTDataset()\u001b[38;5;241m.\u001b[39mget_state(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/_utils/common.py:487\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    482\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/captum/_utils/common.py:494\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m--> 494\u001b[0m num_examples \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    495\u001b[0m dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    496\u001b[0m device \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "ig = IntegratedGradients(model)\n",
    "test = df_to_torch(DTDataset().get_state('baseline'))\n",
    "ig.attribute(test,torch.zeros(test.shape),target=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adc4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321249c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
