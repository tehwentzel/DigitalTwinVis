{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "050c878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4bcfe12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>1A1B</th>\n",
       "      <th>1A6</th>\n",
       "      <th>1B2A</th>\n",
       "      <th>1B3</th>\n",
       "      <th>2A2B</th>\n",
       "      <th>2A3</th>\n",
       "      <th>2B5A</th>\n",
       "      <th>34</th>\n",
       "      <th>...</th>\n",
       "      <th>1A</th>\n",
       "      <th>1B</th>\n",
       "      <th>2A</th>\n",
       "      <th>2B</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5A</th>\n",
       "      <th>5B</th>\n",
       "      <th>6</th>\n",
       "      <th>RPLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5087</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1033726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1033946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1035327</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1035635</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1036374</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1180 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  cluster  1A1B  1A6  1B2A  1B3  2A2B  2A3  2B5A   34  ...   1A  \\\n",
       "0           1        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1        5089        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "2        5088        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "3        5087        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "4        5085        1   0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0  ...  0.0   \n",
       "...       ...      ...   ...  ...   ...  ...   ...  ...   ...  ...  ...  ...   \n",
       "1175  1033726        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "1176  1033946        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "1177  1035327        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1178  1035635        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1179  1036374        1   0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0  ...  0.0   \n",
       "\n",
       "       1B   2A   2B    3    4   5A   5B    6  RPLN  \n",
       "0     0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1     0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2     0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3     0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4     0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "1175  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1176  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1177  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1178  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1179  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[1180 rows x 27 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/digital_twin_ln_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "be070e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>L1A</th>\n",
       "      <th>L1B</th>\n",
       "      <th>L2A</th>\n",
       "      <th>L2B</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5A</th>\n",
       "      <th>L5B</th>\n",
       "      <th>L6</th>\n",
       "      <th>...</th>\n",
       "      <th>R1A</th>\n",
       "      <th>R1B</th>\n",
       "      <th>R2A</th>\n",
       "      <th>R2B</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5A</th>\n",
       "      <th>R5B</th>\n",
       "      <th>R6</th>\n",
       "      <th>RRPLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>10203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>10204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  L1A  L1B  L2A  L2B   L3   L4  L5A  L5B   L6  ...  R1A  R1B  R2A  \\\n",
       "0        3  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1        5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "2        6  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "3        7  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "..     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "531  10201  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "532  10202  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "533  10203  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "534  10204  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "535  10205  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "     R2B   R3   R4  R5A  R5B   R6  RRPLN  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "2    1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "..   ...  ...  ...  ...  ...  ...    ...  \n",
       "531  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "532  1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "533  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "534  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "535  0.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "\n",
       "[536 rows x 21 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/digital_twin_ln_monograms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpv</th>\n",
       "      <th>age</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>bilateral</th>\n",
       "      <th>cc_none</th>\n",
       "      <th>...</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>6_contra</th>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <th>RPLN_contra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55.969444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>45.950000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>49.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpv        age  packs_per_year  smoking_status  gender  \\\n",
       "id                                                              \n",
       "3        1  55.969444             0.0             0.0       1   \n",
       "5        0  20.950000            38.0             1.0       1   \n",
       "6        1  69.930556            35.0             1.0       0   \n",
       "7        1  72.319444             0.0             1.0       1   \n",
       "8        1  59.730556             0.0             0.0       1   \n",
       "...    ...        ...             ...             ...     ...   \n",
       "10201    1  49.566667            30.0             1.0       1   \n",
       "10202    0  48.705556            30.0             1.0       1   \n",
       "10203    1  77.116667             0.0             0.0       1   \n",
       "10204    0  45.950000             5.0             0.5       1   \n",
       "10205    1  49.733333             0.0             0.0       1   \n",
       "\n",
       "       Aspiration rate Pre-therapy  total_dose  dose_fraction  bilateral  \\\n",
       "id                                                                         \n",
       "3                                0       66.00       2.200000      False   \n",
       "5                                0       72.00       1.800000      False   \n",
       "6                                1       70.00       2.121212       True   \n",
       "7                                0       70.00       2.121212      False   \n",
       "8                                0       66.00       2.200000      False   \n",
       "...                            ...         ...            ...        ...   \n",
       "10201                            0       70.00       2.121212      False   \n",
       "10202                            0       72.00       1.714286      False   \n",
       "10203                            0       70.00       2.333333      False   \n",
       "10204                            0       69.96       2.120000       True   \n",
       "10205                            0       69.96       2.120000      False   \n",
       "\n",
       "       cc_none  ...  4_ipsi  4_contra  5A_ipsi  5A_contra  5B_ipsi  5B_contra  \\\n",
       "id              ...                                                             \n",
       "3            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "5            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "6            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "7            1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "8            1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "...        ...  ...     ...       ...      ...        ...      ...        ...   \n",
       "10201        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10202        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10203        1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10204        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10205        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "\n",
       "       6_ipsi  6_contra  RPLN_ipsi  RPLN_contra  \n",
       "id                                               \n",
       "3         0.0       0.0        0.0          0.0  \n",
       "5         0.0       0.0        0.0          0.0  \n",
       "6         0.0       0.0        0.0          0.0  \n",
       "7         0.0       0.0        0.0          0.0  \n",
       "8         0.0       0.0        0.0          0.0  \n",
       "...       ...       ...        ...          ...  \n",
       "10201     0.0       0.0        0.0          0.0  \n",
       "10202     0.0       0.0        0.0          0.0  \n",
       "10203     0.0       0.0        0.0          0.0  \n",
       "10204     0.0       0.0        0.0          0.0  \n",
       "10205     0.0       0.0        0.0          0.0  \n",
       "\n",
       "[536 rows x 98 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False,smote_ids = Const.stratified_train_ids,ln_data_file = '../data/digital_twin_ln_monograms.csv')\n",
    "data.processed_df#.shape, len(data.processed_df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5f57ff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hpv                                         0\n",
       "age                                 74.302778\n",
       "packs_per_year                           40.0\n",
       "smoking_status                            0.5\n",
       "gender                                      1\n",
       "Aspiration rate Pre-therapy                 0\n",
       "total_dose                               66.0\n",
       "dose_fraction                             2.2\n",
       "bilateral                               False\n",
       "cc_none                                     0\n",
       "cc_platinum                                 1\n",
       "cc_cetuximab                                0\n",
       "cc_others                                   0\n",
       "no_dose_adjustment                          1\n",
       "dose_modified                               0\n",
       "dose_delayed                                0\n",
       "dose_cancelled                              0\n",
       "dose_delayed_&_modified                     0\n",
       "regiment_modification                       0\n",
       "unknown                                     0\n",
       "T-category_1                                0\n",
       "T-category_2                                1\n",
       "T-category_3                                0\n",
       "T-category_4                                0\n",
       "N-category_0                                0\n",
       "N-category_1                                0\n",
       "N-category_2                                1\n",
       "N-category_3                                0\n",
       "Pathological Grade_0                        0\n",
       "Pathological Grade_1                        0\n",
       "Pathological Grade_2                        0\n",
       "Pathological Grade_3                        1\n",
       "Pathological Grade_4                        0\n",
       "subsite_BOT                                 0\n",
       "subsite_GPS                                 0\n",
       "subsite_NOS                                 0\n",
       "subsite_Soft palate                         0\n",
       "subsite_Tonsil                              1\n",
       "treatment_CC                                1\n",
       "treatment_IC+CC                             0\n",
       "treatment_IC+Radiation alone                0\n",
       "treatment_Radiation alone                   0\n",
       "DLT (Y/N)                                   0\n",
       "DLT_Dermatological                        0.0\n",
       "DLT_Neurological                          0.0\n",
       "DLT_Gastrointestinal                      0.0\n",
       "DLT_Hematological                         0.0\n",
       "DLT_Nephrological                         0.0\n",
       "DLT_Vascular                              0.0\n",
       "DLT_Infection (Pneumonia)                 0.0\n",
       "DLT_Grade                                   0\n",
       "DLT_Other                                 0.0\n",
       "DLT_Dermatological 2                      0.0\n",
       "DLT_Neurological 2                        0.0\n",
       "DLT_Gastrointestinal 2                    0.0\n",
       "DLT_Hematological 2                       0.0\n",
       "DLT_Nephrological 2                       0.0\n",
       "DLT_Vascular 2                            0.0\n",
       "DLT_Infection (Pneumonia) 2               0.0\n",
       "DLT_Other 2                               0.0\n",
       "CR Primary                                  0\n",
       "PR Primary                                  0\n",
       "SD Primary                                  0\n",
       "CR Nodal                                    0\n",
       "PR Nodal                                    0\n",
       "SD Nodal                                    0\n",
       "CR Primary 2                              1.0\n",
       "PR Primary 2                              0.0\n",
       "SD Primary 2                              0.0\n",
       "CR Nodal 2                                1.0\n",
       "PR Nodal 2                                0.0\n",
       "SD Nodal 2                                0.0\n",
       "Decision 1 (Induction Chemo) Y/N            0\n",
       "Decision 2 (CC / RT alone)                  1\n",
       "Decision 3 Neck Dissection (Y/N)            0\n",
       "Overall Survival (4 Years)                  1\n",
       "FT                                          0\n",
       "Aspiration rate Post-therapy                0\n",
       "1A_ipsi                                   0.0\n",
       "1A_contra                                 0.0\n",
       "1B_ipsi                                   0.0\n",
       "1B_contra                                 0.0\n",
       "2A_ipsi                                   1.0\n",
       "2A_contra                                 0.0\n",
       "2B_ipsi                                   1.0\n",
       "2B_contra                                 0.0\n",
       "3_ipsi                                    0.0\n",
       "3_contra                                  0.0\n",
       "4_ipsi                                    0.0\n",
       "4_contra                                  0.0\n",
       "5A_ipsi                                   0.0\n",
       "5A_contra                                 0.0\n",
       "5B_ipsi                                   0.0\n",
       "5B_contra                                 0.0\n",
       "6_ipsi                                    0.0\n",
       "6_contra                                  0.0\n",
       "RPLN_ipsi                                 0.0\n",
       "RPLN_contra                               0.0\n",
       "Name: 5091, dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.processed_df.loc[5091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c766fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Const.data_dir + '/models/'\n",
    "\n",
    "tuned_transition_models = [\n",
    "    'final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
    "    'final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
    "    'final_outcome_model_state1_input83_dims1000_dropout0,0.pt'\n",
    "]\n",
    "tuned_transition_models = [model_dir + f for f in tuned_transition_models]\n",
    "Const.tuned_transition_models = tuned_transition_models\n",
    "Const.tuned_decision_model = model_dir +  'final_decision_model_statedecisions_input132_dims100,100_dropout0.1,0.7.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3c748333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "\n",
    "def get_tt_split(ids=None,use_default_split=True,use_bagging_split=False,resample_training=False):\n",
    "        if ids is None:\n",
    "            ids = get_dt_ids()\n",
    "        #pre-made, stratified by decision and outcome 72:28\n",
    "        if use_default_split:\n",
    "            train_ids = Const.stratified_train_ids[:]\n",
    "            test_ids = Const.stratified_test_ids[:]\n",
    "        elif use_bagging_split:\n",
    "            train_ids = np.random.choice(ids,len(ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        else:\n",
    "            test_ids = ids[0: int(len(ids)*(1-split))]\n",
    "            train_ids = [i for i in ids if i not in test_ids]\n",
    "\n",
    "        if resample_training:\n",
    "            train_ids = np.random.choice(train_ids,len(train_ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        return train_ids,test_ids\n",
    "    \n",
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "#     nloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = bce(dlt_pred[:,i].view(-1),dlt_true[:,i].view(-1))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "def outcome_loss(ytrue,ypred,weights=[1,1,1]):\n",
    "    loss = 0\n",
    "    nloss = torch.nn.BCELoss()\n",
    "    for i in range(len(weights)):\n",
    "        iloss = nloss(ypred[:,i],ytrue[i])*weights[i]\n",
    "        loss += iloss\n",
    "    return loss\n",
    "\n",
    "def mc_metrics(yt,yp,numpy=False,is_dlt=False):\n",
    "    if not numpy:\n",
    "        yt = yt .cpu().detach().numpy()\n",
    "        yp = yp.cpu().detach().numpy()\n",
    "    #dlt prediction (binary)\n",
    "    if is_dlt:\n",
    "        acc = accuracy_score(yt,yp>.5)\n",
    "        if yt.sum() > 1:\n",
    "            auc = roc_auc_score(yt,yp)\n",
    "        else:\n",
    "            auc=-1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': acc, 'mse': error, 'auc': auc}\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    elif yt.ndim > 1:\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        except:\n",
    "            roc_micro=-1\n",
    "        try:\n",
    "            roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        except:\n",
    "            roc_macro = -1\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    #outcomes (binary)\n",
    "    else:\n",
    "        if yp.ndim > 1:\n",
    "            yp = yp.argmax(axis=1)\n",
    "        try:\n",
    "            bacc = accuracy_score(yt,yp)\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc = roc_auc_score(yt,yp)\n",
    "        except:\n",
    "            roc = -1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred,numpy=False):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0],numpy=numpy)\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i].view(-1),is_dlt=True)\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'accuracy_mean': np.mean(dlt_acc),'auc': dlt_auc,'auc_mean': np.mean(dlt_auc)}}\n",
    "    \n",
    "def outcome_metrics(ytrue,ypred,numpy=False):\n",
    "    res = {}\n",
    "    for i, outcome in enumerate(Const.outcomes):\n",
    "        metrics = mc_metrics(ytrue[i],ypred[:,i])\n",
    "        res[outcome] = metrics\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e95667ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hpv', 'age', 'packs_per_year', 'smoking_status', 'gender',\n",
      "       'Aspiration rate Pre-therapy', 'total_dose', 'dose_fraction', '1A1B',\n",
      "       '1A6',\n",
      "       ...\n",
      "       'SD Primary 2', 'CR Nodal 2', 'PR Nodal 2', 'SD Nodal 2',\n",
      "       'Decision 1 (Induction Chemo) Y/N', 'Decision 2 (CC / RT alone)',\n",
      "       'Decision 3 Neck Dissection (Y/N)', 'Overall Survival (4 Years)', 'FT',\n",
      "       'Aspiration rate Post-therapy'],\n",
      "      dtype='object', length=111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd1': {'accuracy': 0.36326291079812206,\n",
       "  'roc_micro': 0.5126910126910126,\n",
       "  'roc_macro': 0.5150862068965517},\n",
       " 'nd1': {'accuracy': 0.38838037121789987,\n",
       "  'roc_micro': 0.5717430717430717,\n",
       "  'roc_macro': 0.5260869565217391},\n",
       " 'mod': {'accuracy': 0.16666666666666666,\n",
       "  'roc_micro': 0.515527950310559,\n",
       "  'roc_macro': -1}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_state_rf(model_args={}):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "\n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    #most things are multiclass, dlts are several ordinal and outcomes are multiple binary\n",
    "    xtrain1 = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest1 = dataset.get_state('baseline',ids=test_ids)\n",
    "    \n",
    "    xtrain2 = dataset.get_input_state(step=2,ids=train_ids)\n",
    "    xtest2 = dataset.get_input_state(step=2,ids=test_ids)\n",
    "    \n",
    "    xtrain3 = dataset.get_input_state(step=3,ids=train_ids)\n",
    "    xtest3 = dataset.get_input_state(step=3,ids=test_ids)\n",
    "    \n",
    "    [pd1_train,nd1_train, mod_train,dlts1_train] = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    [pd2_train,nd2_train, cc_train,dlts2_train] = dataset.get_intermediate_outcomes(step=2,ids=train_ids)\n",
    "    [pd1_test,nd1_test, mod_test,dlts1_test] = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "    [pd2_test,nd2_test, cc_test,dlts2_test] = dataset.get_intermediate_outcomes(step=2,ids=test_ids)\n",
    "    outcomes_train = dataset.get_state('outcomes',ids=train_ids)\n",
    "    outcomes_test = dataset.get_state('outcomes',ids=test_ids)\n",
    "    \n",
    "\n",
    "    def train_multiclass_rf(xtrain,xtest,ytrain,ytest):\n",
    "        model = RandomForestClassifier(class_weight='balanced',**model_args).fit(xtrain,ytrain)\n",
    "        ypred = model.predict(xtest)\n",
    "        metrics = mc_metrics(ytest.values,ypred,numpy=True)\n",
    "        return model, metrics\n",
    "    \n",
    "    all_metrics = {}\n",
    "    pd1_model, all_metrics['pd1'] = train_multiclass_rf(xtrain1,xtest1,pd1_train,pd1_test)\n",
    "    nd1_model, all_metrics['nd1']  = train_multiclass_rf(xtrain1,xtest1,nd1_train,nd1_test)\n",
    "    mod_model, all_metrics['mod']  = train_multiclass_rf(xtrain1,xtest1,mod_train,mod_test)\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "train_state_rf({'max_depth': 5,'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a513da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_fraction</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dose</th>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                               3      5          6          7      \\\n",
       "1A_contra                          0.0    0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0    0.0        0.0        0.0   \n",
       "1B_contra                          0.0    0.0        0.0        1.0   \n",
       "1B_ipsi                            0.0    0.0        0.0        0.0   \n",
       "2A_contra                          1.0    0.0        1.0        0.0   \n",
       "2A_ipsi                            0.0    1.0        1.0        0.0   \n",
       "2B_contra                          1.0    0.0        1.0        0.0   \n",
       "2B_ipsi                            0.0    1.0        1.0        0.0   \n",
       "3_contra                           0.0    0.0        1.0        0.0   \n",
       "3_ipsi                             0.0    0.0        1.0        0.0   \n",
       "4_contra                           0.0    0.0        0.0        0.0   \n",
       "4_ipsi                             0.0    0.0        0.0        0.0   \n",
       "5A_contra                          0.0    0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0    0.0        0.0        0.0   \n",
       "5B_contra                          0.0    0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0    0.0        0.0        0.0   \n",
       "6_contra                           0.0    0.0        0.0        0.0   \n",
       "6_ipsi                             0.0    0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0      0          1          0   \n",
       "DLT (Y/N)                            0      0          0          0   \n",
       "DLT_Grade                            0      0          0          0   \n",
       "N-category_0                         0      0          0          0   \n",
       "N-category_1                         1      0          0          0   \n",
       "N-category_2                         0      1          1          1   \n",
       "N-category_3                         0      0          0          0   \n",
       "Pathological Grade_0                 1      0          0          1   \n",
       "Pathological Grade_1                 0      0          0          0   \n",
       "Pathological Grade_2                 0      1          1          0   \n",
       "Pathological Grade_3                 0      0          0          0   \n",
       "Pathological Grade_4                 0      0          0          0   \n",
       "RPLN_contra                        0.0    0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0    0.0        0.0        0.0   \n",
       "T-category_1                         0      0          0          1   \n",
       "T-category_2                         1      0          0          0   \n",
       "T-category_3                         0      0          0          0   \n",
       "T-category_4                         0      1          1          0   \n",
       "age                          55.969444  20.95  69.930556  72.319444   \n",
       "bilateral                        False  False       True      False   \n",
       "dose_fraction                      2.2    1.8   2.121212   2.121212   \n",
       "gender                               1      1          0          1   \n",
       "hpv                                  1      0          1          1   \n",
       "packs_per_year                     0.0   38.0       35.0        0.0   \n",
       "smoking_status                     0.0    1.0        1.0        1.0   \n",
       "subsite_BOT                          1      1          1          0   \n",
       "subsite_GPS                          0      0          0          0   \n",
       "subsite_NOS                          0      0          0          1   \n",
       "subsite_Soft palate                  0      0          0          0   \n",
       "subsite_Tonsil                       0      0          0          0   \n",
       "total_dose                        66.0   72.0       70.0       70.0   \n",
       "\n",
       "id                               8          9          10         11     \\\n",
       "1A_contra                          0.0        0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0        0.0        0.0        0.0   \n",
       "1B_contra                          0.0        0.0        0.0        0.0   \n",
       "1B_ipsi                            0.0        0.0        0.0        0.0   \n",
       "2A_contra                          0.0        0.0        0.0        0.0   \n",
       "2A_ipsi                            1.0        1.0        1.0        1.0   \n",
       "2B_contra                          0.0        0.0        0.0        0.0   \n",
       "2B_ipsi                            1.0        1.0        1.0        1.0   \n",
       "3_contra                           0.0        0.0        0.0        0.0   \n",
       "3_ipsi                             0.0        0.0        0.0        1.0   \n",
       "4_contra                           0.0        0.0        0.0        0.0   \n",
       "4_ipsi                             0.0        0.0        0.0        0.0   \n",
       "5A_contra                          0.0        0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0        0.0        0.0        0.0   \n",
       "5B_contra                          0.0        0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0        0.0        0.0        0.0   \n",
       "6_contra                           0.0        0.0        0.0        0.0   \n",
       "6_ipsi                             0.0        0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0          0          0          0   \n",
       "DLT (Y/N)                            0          0          0          0   \n",
       "DLT_Grade                            0          0          0          0   \n",
       "N-category_0                         0          0          0          0   \n",
       "N-category_1                         1          1          1          1   \n",
       "N-category_2                         0          0          0          0   \n",
       "N-category_3                         0          0          0          0   \n",
       "Pathological Grade_0                 0          0          0          0   \n",
       "Pathological Grade_1                 0          0          0          0   \n",
       "Pathological Grade_2                 0          0          1          1   \n",
       "Pathological Grade_3                 1          1          0          0   \n",
       "Pathological Grade_4                 0          0          0          0   \n",
       "RPLN_contra                        0.0        0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0        0.0        0.0        0.0   \n",
       "T-category_1                         1          1          0          0   \n",
       "T-category_2                         0          0          0          1   \n",
       "T-category_3                         0          0          1          0   \n",
       "T-category_4                         0          0          0          0   \n",
       "age                          59.730556  60.083333  67.708333  57.858333   \n",
       "bilateral                        False      False      False      False   \n",
       "dose_fraction                      2.2        2.2       2.12   2.121212   \n",
       "gender                               1          1          1          1   \n",
       "hpv                                  1          1         -1          1   \n",
       "packs_per_year                     0.0        0.0       40.0       44.0   \n",
       "smoking_status                     0.0        0.0        1.0        1.0   \n",
       "subsite_BOT                          0          1          1          0   \n",
       "subsite_GPS                          0          0          0          0   \n",
       "subsite_NOS                          0          0          0          1   \n",
       "subsite_Soft palate                  0          0          0          0   \n",
       "subsite_Tonsil                       1          0          0          0   \n",
       "total_dose                        66.0       66.0      69.96       70.0   \n",
       "\n",
       "id                               13        14     ...      10196      10197  \\\n",
       "1A_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "1A_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "1B_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "1B_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "2A_contra                          1.0       0.0  ...        0.0        0.0   \n",
       "2A_ipsi                            1.0       1.0  ...        0.0        1.0   \n",
       "2B_contra                          1.0       0.0  ...        0.0        0.0   \n",
       "2B_ipsi                            1.0       1.0  ...        0.0        1.0   \n",
       "3_contra                           0.0       1.0  ...        0.0        0.0   \n",
       "3_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "4_contra                           0.0       0.0  ...        0.0        0.0   \n",
       "4_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "5A_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "5A_ipsi                            0.0       0.0  ...        1.0        0.0   \n",
       "5B_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "5B_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "6_contra                           0.0       0.0  ...        0.0        0.0   \n",
       "6_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0         0  ...          0          0   \n",
       "DLT (Y/N)                            0         0  ...          0          1   \n",
       "DLT_Grade                            0         0  ...          0          2   \n",
       "N-category_0                         0         0  ...          0          0   \n",
       "N-category_1                         0         0  ...          0          0   \n",
       "N-category_2                         1         1  ...          1          0   \n",
       "N-category_3                         0         0  ...          0          1   \n",
       "Pathological Grade_0                 0         0  ...          1          0   \n",
       "Pathological Grade_1                 0         0  ...          0          0   \n",
       "Pathological Grade_2                 1         0  ...          0          1   \n",
       "Pathological Grade_3                 0         1  ...          0          0   \n",
       "Pathological Grade_4                 0         0  ...          0          0   \n",
       "RPLN_contra                        0.0       0.0  ...        0.0        0.0   \n",
       "RPLN_ipsi                          0.0       0.0  ...        1.0        0.0   \n",
       "T-category_1                         0         0  ...          0          0   \n",
       "T-category_2                         0         1  ...          1          0   \n",
       "T-category_3                         0         0  ...          0          1   \n",
       "T-category_4                         1         0  ...          0          0   \n",
       "age                          51.758333     56.25  ...  47.619444  50.163889   \n",
       "bilateral                         True     False  ...      False      False   \n",
       "dose_fraction                      2.0  2.121212  ...   2.121212        1.8   \n",
       "gender                               1         1  ...          0          1   \n",
       "hpv                                  0         1  ...          0          1   \n",
       "packs_per_year                     0.0      40.0  ...        5.0        0.0   \n",
       "smoking_status                     0.0       1.0  ...        0.5        0.0   \n",
       "subsite_BOT                          1         1  ...          0          1   \n",
       "subsite_GPS                          0         0  ...          0          0   \n",
       "subsite_NOS                          0         0  ...          0          0   \n",
       "subsite_Soft palate                  0         0  ...          0          0   \n",
       "subsite_Tonsil                       0         0  ...          1          0   \n",
       "total_dose                        70.0      70.0  ...       70.0       72.0   \n",
       "\n",
       "id                               10198     10199      10200      10201  \\\n",
       "1A_contra                          0.0       0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0       0.0        0.0        0.0   \n",
       "1B_contra                          0.0       0.0        0.0        0.0   \n",
       "1B_ipsi                            0.0       0.0        0.0        0.0   \n",
       "2A_contra                          0.0       1.0        0.0        0.0   \n",
       "2A_ipsi                            1.0       0.0        0.0        1.0   \n",
       "2B_contra                          0.0       1.0        0.0        0.0   \n",
       "2B_ipsi                            1.0       0.0        0.0        1.0   \n",
       "3_contra                           0.0       1.0        0.0        0.0   \n",
       "3_ipsi                             0.0       0.0        1.0        0.0   \n",
       "4_contra                           0.0       0.0        0.0        0.0   \n",
       "4_ipsi                             0.0       0.0        0.0        0.0   \n",
       "5A_contra                          0.0       0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0       0.0        0.0        0.0   \n",
       "5B_contra                          0.0       0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0       0.0        0.0        0.0   \n",
       "6_contra                           0.0       0.0        0.0        0.0   \n",
       "6_ipsi                             0.0       0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0         0          0          0   \n",
       "DLT (Y/N)                            0         0          0          0   \n",
       "DLT_Grade                            0         0          0          0   \n",
       "N-category_0                         0         0          0          0   \n",
       "N-category_1                         0         0          1          1   \n",
       "N-category_2                         1         1          0          0   \n",
       "N-category_3                         0         0          0          0   \n",
       "Pathological Grade_0                 0         1          0          0   \n",
       "Pathological Grade_1                 1         0          0          0   \n",
       "Pathological Grade_2                 0         0          1          0   \n",
       "Pathological Grade_3                 0         0          0          1   \n",
       "Pathological Grade_4                 0         0          0          0   \n",
       "RPLN_contra                        0.0       0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0       0.0        0.0        0.0   \n",
       "T-category_1                         1         0          0          0   \n",
       "T-category_2                         0         1          0          0   \n",
       "T-category_3                         0         0          1          1   \n",
       "T-category_4                         0         0          0          0   \n",
       "age                          70.888889    67.825  56.336111  49.566667   \n",
       "bilateral                        False     False      False      False   \n",
       "dose_fraction                      2.2  2.121212       2.12   2.121212   \n",
       "gender                               0         1          1          1   \n",
       "hpv                                 -1         0          1          1   \n",
       "packs_per_year                    50.0       0.0        0.0       30.0   \n",
       "smoking_status                     0.5       0.0        0.0        1.0   \n",
       "subsite_BOT                          0         1          0          1   \n",
       "subsite_GPS                          0         0          0          0   \n",
       "subsite_NOS                          0         0          1          0   \n",
       "subsite_Soft palate                  0         0          0          0   \n",
       "subsite_Tonsil                       1         0          0          0   \n",
       "total_dose                        66.0      70.0      69.96       70.0   \n",
       "\n",
       "id                               10202      10203  10204      10205  \n",
       "1A_contra                          0.0        0.0    0.0        0.0  \n",
       "1A_ipsi                            0.0        0.0    0.0        0.0  \n",
       "1B_contra                          0.0        0.0    0.0        0.0  \n",
       "1B_ipsi                            0.0        0.0    0.0        0.0  \n",
       "2A_contra                          0.0        0.0    0.0        0.0  \n",
       "2A_ipsi                            1.0        1.0    1.0        0.0  \n",
       "2B_contra                          0.0        0.0    0.0        0.0  \n",
       "2B_ipsi                            1.0        1.0    1.0        0.0  \n",
       "3_contra                           0.0        0.0    0.0        0.0  \n",
       "3_ipsi                             0.0        1.0    1.0        1.0  \n",
       "4_contra                           0.0        0.0    0.0        0.0  \n",
       "4_ipsi                             0.0        0.0    0.0        0.0  \n",
       "5A_contra                          0.0        0.0    0.0        0.0  \n",
       "5A_ipsi                            0.0        0.0    0.0        0.0  \n",
       "5B_contra                          0.0        0.0    0.0        0.0  \n",
       "5B_ipsi                            0.0        0.0    0.0        0.0  \n",
       "6_contra                           0.0        0.0    0.0        0.0  \n",
       "6_ipsi                             0.0        0.0    0.0        0.0  \n",
       "Aspiration rate Pre-therapy          0          0      0          0  \n",
       "DLT (Y/N)                            0          0      0          0  \n",
       "DLT_Grade                            0          0      0          0  \n",
       "N-category_0                         0          0      0          0  \n",
       "N-category_1                         0          1      0          1  \n",
       "N-category_2                         1          0      0          0  \n",
       "N-category_3                         0          0      1          0  \n",
       "Pathological Grade_0                 0          1      0          0  \n",
       "Pathological Grade_1                 0          0      0          0  \n",
       "Pathological Grade_2                 0          0      0          1  \n",
       "Pathological Grade_3                 1          0      1          0  \n",
       "Pathological Grade_4                 0          0      0          0  \n",
       "RPLN_contra                        0.0        0.0    0.0        0.0  \n",
       "RPLN_ipsi                          0.0        0.0    0.0        0.0  \n",
       "T-category_1                         0          1      0          0  \n",
       "T-category_2                         0          0      0          0  \n",
       "T-category_3                         0          0      1          0  \n",
       "T-category_4                         1          0      0          1  \n",
       "age                          48.705556  77.116667  45.95  49.733333  \n",
       "bilateral                        False      False   True      False  \n",
       "dose_fraction                 1.714286   2.333333   2.12       2.12  \n",
       "gender                               1          1      1          1  \n",
       "hpv                                  0          1      0          1  \n",
       "packs_per_year                    30.0        0.0    5.0        0.0  \n",
       "smoking_status                     1.0        0.0    0.5        0.0  \n",
       "subsite_BOT                          0          0      0          1  \n",
       "subsite_GPS                          0          0      0          0  \n",
       "subsite_NOS                          1          0      0          0  \n",
       "subsite_Soft palate                  0          0      0          0  \n",
       "subsite_Tonsil                       0          1      1          0  \n",
       "total_dose                        72.0       70.0  69.96      69.96  \n",
       "\n",
       "[49 rows x 536 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DTDataset().get_state('baseline').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "91c4445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 13.470033645629883\n",
      "val loss 11.2970552444458\n",
      "______________\n",
      "epoch 1 train loss 13.214168548583984\n",
      "val loss 11.133837699890137\n",
      "______________\n",
      "epoch 2 train loss 13.090332984924316\n",
      "val loss 10.974069595336914\n",
      "______________\n",
      "epoch 3 train loss 12.935943603515625\n",
      "val loss 10.81753158569336\n",
      "______________\n",
      "epoch 4 train loss 12.650671005249023\n",
      "val loss 10.664196014404297\n",
      "______________\n",
      "epoch 5 train loss 12.583200454711914\n",
      "val loss 10.513541221618652\n",
      "______________\n",
      "epoch 6 train loss 12.080845832824707\n",
      "val loss 10.365581512451172\n",
      "______________\n",
      "epoch 7 train loss 11.798055648803711\n",
      "val loss 10.220637321472168\n",
      "______________\n",
      "epoch 8 train loss 11.700197219848633\n",
      "val loss 10.078390121459961\n",
      "______________\n",
      "epoch 9 train loss 11.420167922973633\n",
      "val loss 9.938918113708496\n",
      "______________\n",
      "epoch 10 train loss 11.699029922485352\n",
      "val loss 9.802186965942383\n",
      "______________\n",
      "epoch 11 train loss 11.395209312438965\n",
      "val loss 9.66819953918457\n",
      "______________\n",
      "epoch 12 train loss 11.004981994628906\n",
      "val loss 9.53685474395752\n",
      "______________\n",
      "epoch 13 train loss 11.059527397155762\n",
      "val loss 9.408100128173828\n",
      "______________\n",
      "epoch 14 train loss 10.876701354980469\n",
      "val loss 9.282341957092285\n",
      "______________\n",
      "epoch 15 train loss 10.609150886535645\n",
      "val loss 9.15937328338623\n",
      "______________\n",
      "epoch 16 train loss 10.514484405517578\n",
      "val loss 9.039029121398926\n",
      "______________\n",
      "epoch 17 train loss 10.119166374206543\n",
      "val loss 8.921304702758789\n",
      "______________\n",
      "epoch 18 train loss 9.952120780944824\n",
      "val loss 8.806342124938965\n",
      "______________\n",
      "epoch 19 train loss 9.94737720489502\n",
      "val loss 8.693938255310059\n",
      "______________\n",
      "epoch 20 train loss 9.804682731628418\n",
      "val loss 8.58362102508545\n",
      "______________\n",
      "epoch 21 train loss 9.446372985839844\n",
      "val loss 8.475796699523926\n",
      "______________\n",
      "epoch 22 train loss 9.237220764160156\n",
      "val loss 8.37056827545166\n",
      "______________\n",
      "epoch 23 train loss 9.399526596069336\n",
      "val loss 8.267858505249023\n",
      "______________\n",
      "epoch 24 train loss 9.139281272888184\n",
      "val loss 8.167404174804688\n",
      "______________\n",
      "epoch 25 train loss 9.18165397644043\n",
      "val loss 8.069307327270508\n",
      "______________\n",
      "epoch 26 train loss 8.822360038757324\n",
      "val loss 7.973524570465088\n",
      "______________\n",
      "epoch 27 train loss 8.957051277160645\n",
      "val loss 7.880208492279053\n",
      "______________\n",
      "epoch 28 train loss 8.720046043395996\n",
      "val loss 7.789431095123291\n",
      "______________\n",
      "epoch 29 train loss 8.555018424987793\n",
      "val loss 7.700800895690918\n",
      "______________\n",
      "epoch 30 train loss 8.191093444824219\n",
      "val loss 7.61444616317749\n",
      "______________\n",
      "epoch 31 train loss 8.074861526489258\n",
      "val loss 7.530398368835449\n",
      "______________\n",
      "epoch 32 train loss 8.092385292053223\n",
      "val loss 7.448286056518555\n",
      "______________\n",
      "epoch 33 train loss 7.960550308227539\n",
      "val loss 7.368167877197266\n",
      "______________\n",
      "epoch 34 train loss 7.886590003967285\n",
      "val loss 7.289910316467285\n",
      "______________\n",
      "epoch 35 train loss 8.101842880249023\n",
      "val loss 7.213362693786621\n",
      "______________\n",
      "epoch 36 train loss 7.752877235412598\n",
      "val loss 7.138783931732178\n",
      "______________\n",
      "epoch 37 train loss 7.782188415527344\n",
      "val loss 7.066049575805664\n",
      "______________\n",
      "epoch 38 train loss 7.425530433654785\n",
      "val loss 6.995062828063965\n",
      "______________\n",
      "epoch 39 train loss 7.524667263031006\n",
      "val loss 6.925734519958496\n",
      "______________\n",
      "epoch 40 train loss 7.43430233001709\n",
      "val loss 6.858172416687012\n",
      "______________\n",
      "epoch 41 train loss 7.389535903930664\n",
      "val loss 6.792196273803711\n",
      "______________\n",
      "epoch 42 train loss 7.171558856964111\n",
      "val loss 6.727935791015625\n",
      "______________\n",
      "epoch 43 train loss 7.176492691040039\n",
      "val loss 6.665209770202637\n",
      "______________\n",
      "epoch 44 train loss 7.167530059814453\n",
      "val loss 6.603903293609619\n",
      "______________\n",
      "epoch 45 train loss 7.00933837890625\n",
      "val loss 6.543936252593994\n",
      "______________\n",
      "epoch 46 train loss 7.141213893890381\n",
      "val loss 6.48537015914917\n",
      "______________\n",
      "epoch 47 train loss 6.8397345542907715\n",
      "val loss 6.428091049194336\n",
      "______________\n",
      "epoch 48 train loss 6.751382827758789\n",
      "val loss 6.372156620025635\n",
      "______________\n",
      "epoch 49 train loss 6.7297186851501465\n",
      "val loss 6.317442893981934\n",
      "______________\n",
      "epoch 50 train loss 6.680963039398193\n",
      "val loss 6.26384162902832\n",
      "______________\n",
      "epoch 51 train loss 6.6681437492370605\n",
      "val loss 6.211446285247803\n",
      "______________\n",
      "epoch 52 train loss 6.572841167449951\n",
      "val loss 6.16011905670166\n",
      "______________\n",
      "epoch 53 train loss 6.506672382354736\n",
      "val loss 6.109892845153809\n",
      "______________\n",
      "epoch 54 train loss 6.52160120010376\n",
      "val loss 6.06076717376709\n",
      "______________\n",
      "epoch 55 train loss 6.438261985778809\n",
      "val loss 6.012693881988525\n",
      "______________\n",
      "epoch 56 train loss 6.302595138549805\n",
      "val loss 5.965628147125244\n",
      "______________\n",
      "epoch 57 train loss 6.282430171966553\n",
      "val loss 5.9194817543029785\n",
      "______________\n",
      "epoch 58 train loss 6.314942836761475\n",
      "val loss 5.874353885650635\n",
      "______________\n",
      "epoch 59 train loss 6.050081253051758\n",
      "val loss 5.830094814300537\n",
      "______________\n",
      "epoch 60 train loss 6.0529704093933105\n",
      "val loss 5.786816596984863\n",
      "______________\n",
      "epoch 61 train loss 6.108379364013672\n",
      "val loss 5.744398593902588\n",
      "______________\n",
      "epoch 62 train loss 6.024590015411377\n",
      "val loss 5.702767372131348\n",
      "______________\n",
      "epoch 63 train loss 6.04730749130249\n",
      "val loss 5.6620192527771\n",
      "______________\n",
      "epoch 64 train loss 6.016575813293457\n",
      "val loss 5.622034072875977\n",
      "______________\n",
      "epoch 65 train loss 5.874911785125732\n",
      "val loss 5.582789421081543\n",
      "______________\n",
      "epoch 66 train loss 5.726780891418457\n",
      "val loss 5.544361591339111\n",
      "______________\n",
      "epoch 67 train loss 5.753410816192627\n",
      "val loss 5.506610870361328\n",
      "______________\n",
      "epoch 68 train loss 5.773955821990967\n",
      "val loss 5.469550609588623\n",
      "______________\n",
      "epoch 69 train loss 5.538440704345703\n",
      "val loss 5.433084964752197\n",
      "______________\n",
      "epoch 70 train loss 5.7828593254089355\n",
      "val loss 5.3973822593688965\n",
      "______________\n",
      "epoch 71 train loss 5.53204345703125\n",
      "val loss 5.362289905548096\n",
      "______________\n",
      "epoch 72 train loss 5.526302814483643\n",
      "val loss 5.327731609344482\n",
      "______________\n",
      "epoch 73 train loss 5.571784019470215\n",
      "val loss 5.293688774108887\n",
      "______________\n",
      "epoch 74 train loss 5.52225399017334\n",
      "val loss 5.260242938995361\n",
      "______________\n",
      "epoch 75 train loss 5.46352481842041\n",
      "val loss 5.227506637573242\n",
      "______________\n",
      "epoch 76 train loss 5.4423065185546875\n",
      "val loss 5.195347785949707\n",
      "______________\n",
      "epoch 77 train loss 5.2592597007751465\n",
      "val loss 5.163753986358643\n",
      "______________\n",
      "epoch 78 train loss 5.379794597625732\n",
      "val loss 5.1327033042907715\n",
      "______________\n",
      "epoch 79 train loss 5.24736213684082\n",
      "val loss 5.102182865142822\n",
      "______________\n",
      "epoch 80 train loss 5.137299537658691\n",
      "val loss 5.0722174644470215\n",
      "______________\n",
      "epoch 81 train loss 5.300742149353027\n",
      "val loss 5.042731761932373\n",
      "______________\n",
      "epoch 82 train loss 5.120610237121582\n",
      "val loss 5.013652324676514\n",
      "______________\n",
      "epoch 83 train loss 4.983604907989502\n",
      "val loss 4.985051155090332\n",
      "______________\n",
      "epoch 84 train loss 5.1282525062561035\n",
      "val loss 4.956939697265625\n",
      "______________\n",
      "epoch 85 train loss 5.0935869216918945\n",
      "val loss 4.929323196411133\n",
      "______________\n",
      "epoch 86 train loss 5.082846641540527\n",
      "val loss 4.902040481567383\n",
      "______________\n",
      "epoch 87 train loss 5.065481185913086\n",
      "val loss 4.875154495239258\n",
      "______________\n",
      "epoch 88 train loss 4.967225551605225\n",
      "val loss 4.848723888397217\n",
      "______________\n",
      "epoch 89 train loss 4.994003772735596\n",
      "val loss 4.822780132293701\n",
      "______________\n",
      "epoch 90 train loss 4.9700212478637695\n",
      "val loss 4.797272682189941\n",
      "______________\n",
      "epoch 91 train loss 4.763088703155518\n",
      "val loss 4.772284030914307\n",
      "______________\n",
      "epoch 92 train loss 4.930315017700195\n",
      "val loss 4.747594833374023\n",
      "______________\n",
      "epoch 93 train loss 4.763826847076416\n",
      "val loss 4.723237991333008\n",
      "______________\n",
      "epoch 94 train loss 4.800165176391602\n",
      "val loss 4.699206352233887\n",
      "______________\n",
      "epoch 95 train loss 4.751394748687744\n",
      "val loss 4.675600051879883\n",
      "______________\n",
      "epoch 96 train loss 4.870641231536865\n",
      "val loss 4.652345180511475\n",
      "______________\n",
      "epoch 97 train loss 4.901223659515381\n",
      "val loss 4.629446029663086\n",
      "______________\n",
      "epoch 98 train loss 4.860817909240723\n",
      "val loss 4.606900691986084\n",
      "______________\n",
      "epoch 99 train loss 4.819669246673584\n",
      "val loss 4.5846381187438965\n",
      "______________\n",
      "epoch 100 train loss 4.799516677856445\n",
      "val loss 4.562744617462158\n",
      "______________\n",
      "epoch 101 train loss 4.81200647354126\n",
      "val loss 4.541200160980225\n",
      "______________\n",
      "epoch 102 train loss 4.7195258140563965\n",
      "val loss 4.520061492919922\n",
      "______________\n",
      "epoch 103 train loss 4.805285930633545\n",
      "val loss 4.499240398406982\n",
      "______________\n",
      "epoch 104 train loss 4.587271690368652\n",
      "val loss 4.478667259216309\n",
      "______________\n",
      "epoch 105 train loss 4.791801929473877\n",
      "val loss 4.4583940505981445\n",
      "______________\n",
      "epoch 106 train loss 4.6299848556518555\n",
      "val loss 4.438329696655273\n",
      "______________\n",
      "epoch 107 train loss 4.549549102783203\n",
      "val loss 4.418561935424805\n",
      "______________\n",
      "epoch 108 train loss 4.457266330718994\n",
      "val loss 4.398998737335205\n",
      "______________\n",
      "epoch 109 train loss 4.6450653076171875\n",
      "val loss 4.37971305847168\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110 train loss 4.557486057281494\n",
      "val loss 4.36065673828125\n",
      "______________\n",
      "epoch 111 train loss 4.5827531814575195\n",
      "val loss 4.341801643371582\n",
      "______________\n",
      "epoch 112 train loss 4.554055213928223\n",
      "val loss 4.323163032531738\n",
      "______________\n",
      "epoch 113 train loss 4.7328782081604\n",
      "val loss 4.304826259613037\n",
      "______________\n",
      "epoch 114 train loss 4.498247146606445\n",
      "val loss 4.286726474761963\n",
      "______________\n",
      "epoch 115 train loss 4.532895088195801\n",
      "val loss 4.268918991088867\n",
      "______________\n",
      "epoch 116 train loss 4.44027853012085\n",
      "val loss 4.25132942199707\n",
      "______________\n",
      "epoch 117 train loss 4.307986736297607\n",
      "val loss 4.233956336975098\n",
      "______________\n",
      "epoch 118 train loss 4.483946323394775\n",
      "val loss 4.2168474197387695\n",
      "______________\n",
      "epoch 119 train loss 4.356116771697998\n",
      "val loss 4.1999053955078125\n",
      "______________\n",
      "epoch 120 train loss 4.480731964111328\n",
      "val loss 4.183228015899658\n",
      "______________\n",
      "epoch 121 train loss 4.489027976989746\n",
      "val loss 4.166811943054199\n",
      "______________\n",
      "epoch 122 train loss 4.284066677093506\n",
      "val loss 4.150527477264404\n",
      "______________\n",
      "epoch 123 train loss 4.346475601196289\n",
      "val loss 4.134439468383789\n",
      "______________\n",
      "epoch 124 train loss 4.318983554840088\n",
      "val loss 4.1185622215271\n",
      "______________\n",
      "epoch 125 train loss 4.228391170501709\n",
      "val loss 4.1029205322265625\n",
      "______________\n",
      "epoch 126 train loss 4.345879077911377\n",
      "val loss 4.087413787841797\n",
      "______________\n",
      "epoch 127 train loss 4.24764347076416\n",
      "val loss 4.072057247161865\n",
      "______________\n",
      "epoch 128 train loss 4.213059425354004\n",
      "val loss 4.056850910186768\n",
      "______________\n",
      "epoch 129 train loss 4.353111743927002\n",
      "val loss 4.041726112365723\n",
      "______________\n",
      "epoch 130 train loss 4.294079303741455\n",
      "val loss 4.026854991912842\n",
      "______________\n",
      "epoch 131 train loss 4.357428550720215\n",
      "val loss 4.012165069580078\n",
      "______________\n",
      "epoch 132 train loss 4.228705883026123\n",
      "val loss 3.9976985454559326\n",
      "______________\n",
      "epoch 133 train loss 4.319773197174072\n",
      "val loss 3.983405590057373\n",
      "______________\n",
      "epoch 134 train loss 4.151138782501221\n",
      "val loss 3.969275951385498\n",
      "______________\n",
      "epoch 135 train loss 4.229151248931885\n",
      "val loss 3.9553635120391846\n",
      "______________\n",
      "epoch 136 train loss 4.319239616394043\n",
      "val loss 3.941680669784546\n",
      "______________\n",
      "epoch 137 train loss 4.071057319641113\n",
      "val loss 3.928168773651123\n",
      "______________\n",
      "epoch 138 train loss 4.168226718902588\n",
      "val loss 3.9147865772247314\n",
      "______________\n",
      "epoch 139 train loss 4.130451679229736\n",
      "val loss 3.9014627933502197\n",
      "______________\n",
      "epoch 140 train loss 4.058216571807861\n",
      "val loss 3.888366222381592\n",
      "______________\n",
      "epoch 141 train loss 3.95300030708313\n",
      "val loss 3.8754403591156006\n",
      "______________\n",
      "epoch 142 train loss 4.282835006713867\n",
      "val loss 3.862663984298706\n",
      "______________\n",
      "epoch 143 train loss 4.108316421508789\n",
      "val loss 3.849971294403076\n",
      "______________\n",
      "epoch 144 train loss 3.973207950592041\n",
      "val loss 3.8374364376068115\n",
      "______________\n",
      "epoch 145 train loss 4.125209331512451\n",
      "val loss 3.8250627517700195\n",
      "______________\n",
      "epoch 146 train loss 4.01600456237793\n",
      "val loss 3.812718152999878\n",
      "______________\n",
      "epoch 147 train loss 4.19718599319458\n",
      "val loss 3.8005714416503906\n",
      "______________\n",
      "epoch 148 train loss 3.9655911922454834\n",
      "val loss 3.78853178024292\n",
      "______________\n",
      "epoch 149 train loss 3.908583879470825\n",
      "val loss 3.7765588760375977\n",
      "______________\n",
      "epoch 150 train loss 3.9323973655700684\n",
      "val loss 3.7646644115448\n",
      "______________\n",
      "epoch 151 train loss 4.025606632232666\n",
      "val loss 3.7529706954956055\n",
      "______________\n",
      "epoch 152 train loss 3.8635663986206055\n",
      "val loss 3.7413768768310547\n",
      "______________\n",
      "epoch 153 train loss 3.8165841102600098\n",
      "val loss 3.7299304008483887\n",
      "______________\n",
      "epoch 154 train loss 4.019555568695068\n",
      "val loss 3.7186689376831055\n",
      "______________\n",
      "epoch 155 train loss 3.858996868133545\n",
      "val loss 3.707487106323242\n",
      "______________\n",
      "epoch 156 train loss 3.9580817222595215\n",
      "val loss 3.6963183879852295\n",
      "______________\n",
      "epoch 157 train loss 3.9868102073669434\n",
      "val loss 3.6852173805236816\n",
      "______________\n",
      "epoch 158 train loss 3.9907724857330322\n",
      "val loss 3.6742711067199707\n",
      "______________\n",
      "epoch 159 train loss 3.665924549102783\n",
      "val loss 3.663386583328247\n",
      "______________\n",
      "epoch 160 train loss 3.7477638721466064\n",
      "val loss 3.652587413787842\n",
      "______________\n",
      "epoch 161 train loss 3.806636095046997\n",
      "val loss 3.6419241428375244\n",
      "______________\n",
      "epoch 162 train loss 3.880667209625244\n",
      "val loss 3.6313459873199463\n",
      "______________\n",
      "epoch 163 train loss 3.7210052013397217\n",
      "val loss 3.620884418487549\n",
      "______________\n",
      "epoch 164 train loss 3.869364023208618\n",
      "val loss 3.6104907989501953\n",
      "______________\n",
      "epoch 165 train loss 3.852747917175293\n",
      "val loss 3.6002089977264404\n",
      "______________\n",
      "epoch 166 train loss 3.8025805950164795\n",
      "val loss 3.5900027751922607\n",
      "______________\n",
      "epoch 167 train loss 3.7746870517730713\n",
      "val loss 3.5798685550689697\n",
      "______________\n",
      "epoch 168 train loss 3.790161371231079\n",
      "val loss 3.569812297821045\n",
      "______________\n",
      "epoch 169 train loss 3.866180896759033\n",
      "val loss 3.5598928928375244\n",
      "______________\n",
      "epoch 170 train loss 3.763214349746704\n",
      "val loss 3.5500905513763428\n",
      "______________\n",
      "epoch 171 train loss 4.088116645812988\n",
      "val loss 3.540395498275757\n",
      "______________\n",
      "epoch 172 train loss 3.8007864952087402\n",
      "val loss 3.5308282375335693\n",
      "______________\n",
      "epoch 173 train loss 3.767068386077881\n",
      "val loss 3.5214219093322754\n",
      "______________\n",
      "epoch 174 train loss 3.7161078453063965\n",
      "val loss 3.5121448040008545\n",
      "______________\n",
      "epoch 175 train loss 3.647771120071411\n",
      "val loss 3.502969264984131\n",
      "______________\n",
      "epoch 176 train loss 3.7483296394348145\n",
      "val loss 3.4938912391662598\n",
      "______________\n",
      "epoch 177 train loss 3.677696466445923\n",
      "val loss 3.4848668575286865\n",
      "______________\n",
      "epoch 178 train loss 3.7937750816345215\n",
      "val loss 3.475921392440796\n",
      "______________\n",
      "epoch 179 train loss 3.6519532203674316\n",
      "val loss 3.467007875442505\n",
      "______________\n",
      "epoch 180 train loss 3.7446885108947754\n",
      "val loss 3.458073616027832\n",
      "______________\n",
      "epoch 181 train loss 3.7132115364074707\n",
      "val loss 3.4492087364196777\n",
      "______________\n",
      "epoch 182 train loss 3.6951911449432373\n",
      "val loss 3.4404215812683105\n",
      "______________\n",
      "epoch 183 train loss 3.6575303077697754\n",
      "val loss 3.431739330291748\n",
      "______________\n",
      "epoch 184 train loss 3.7801740169525146\n",
      "val loss 3.4231393337249756\n",
      "______________\n",
      "epoch 185 train loss 3.7368502616882324\n",
      "val loss 3.414677858352661\n",
      "______________\n",
      "epoch 186 train loss 3.692011594772339\n",
      "val loss 3.4062421321868896\n",
      "______________\n",
      "epoch 187 train loss 3.653331995010376\n",
      "val loss 3.3978874683380127\n",
      "______________\n",
      "epoch 188 train loss 3.568138837814331\n",
      "val loss 3.3895857334136963\n",
      "______________\n",
      "epoch 189 train loss 3.474600076675415\n",
      "val loss 3.381319999694824\n",
      "______________\n",
      "epoch 190 train loss 3.5553348064422607\n",
      "val loss 3.3731422424316406\n",
      "______________\n",
      "epoch 191 train loss 3.6427371501922607\n",
      "val loss 3.3650293350219727\n",
      "______________\n",
      "epoch 192 train loss 3.4992642402648926\n",
      "val loss 3.356984853744507\n",
      "______________\n",
      "epoch 193 train loss 3.4310169219970703\n",
      "val loss 3.348912477493286\n",
      "______________\n",
      "epoch 194 train loss 3.597994565963745\n",
      "val loss 3.340991258621216\n",
      "______________\n",
      "epoch 195 train loss 3.5619964599609375\n",
      "val loss 3.333191394805908\n",
      "______________\n",
      "epoch 196 train loss 3.7051732540130615\n",
      "val loss 3.325493097305298\n",
      "______________\n",
      "epoch 197 train loss 3.5856032371520996\n",
      "val loss 3.3179025650024414\n",
      "______________\n",
      "epoch 198 train loss 3.6764774322509766\n",
      "val loss 3.3103466033935547\n",
      "______________\n",
      "epoch 199 train loss 3.4244372844696045\n",
      "val loss 3.3028316497802734\n",
      "______________\n",
      "epoch 200 train loss 3.4979937076568604\n",
      "val loss 3.2953641414642334\n",
      "______________\n",
      "epoch 201 train loss 3.5766079425811768\n",
      "val loss 3.2880218029022217\n",
      "______________\n",
      "epoch 202 train loss 3.5276806354522705\n",
      "val loss 3.280728578567505\n",
      "______________\n",
      "epoch 203 train loss 3.4456326961517334\n",
      "val loss 3.2734835147857666\n",
      "______________\n",
      "epoch 204 train loss 3.6063592433929443\n",
      "val loss 3.266256332397461\n",
      "______________\n",
      "epoch 205 train loss 3.369018316268921\n",
      "val loss 3.2590396404266357\n",
      "______________\n",
      "epoch 206 train loss 3.419984817504883\n",
      "val loss 3.251894235610962\n",
      "______________\n",
      "epoch 207 train loss 3.4947428703308105\n",
      "val loss 3.244786024093628\n",
      "______________\n",
      "epoch 208 train loss 3.5373728275299072\n",
      "val loss 3.2376954555511475\n",
      "______________\n",
      "epoch 209 train loss 3.4432530403137207\n",
      "val loss 3.230621099472046\n",
      "______________\n",
      "epoch 210 train loss 3.4484243392944336\n",
      "val loss 3.2235305309295654\n",
      "______________\n",
      "epoch 211 train loss 3.5460050106048584\n",
      "val loss 3.2165400981903076\n",
      "______________\n",
      "epoch 212 train loss 3.423022985458374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.209648847579956\n",
      "______________\n",
      "epoch 213 train loss 3.391664743423462\n",
      "val loss 3.202810049057007\n",
      "______________\n",
      "epoch 214 train loss 3.4428515434265137\n",
      "val loss 3.1960768699645996\n",
      "______________\n",
      "epoch 215 train loss 3.467329740524292\n",
      "val loss 3.18940806388855\n",
      "______________\n",
      "epoch 216 train loss 3.4496898651123047\n",
      "val loss 3.182798385620117\n",
      "______________\n",
      "epoch 217 train loss 3.4641168117523193\n",
      "val loss 3.1762795448303223\n",
      "______________\n",
      "epoch 218 train loss 3.487886428833008\n",
      "val loss 3.1698527336120605\n",
      "______________\n",
      "epoch 219 train loss 3.4671506881713867\n",
      "val loss 3.163487195968628\n",
      "______________\n",
      "epoch 220 train loss 3.4526169300079346\n",
      "val loss 3.157176971435547\n",
      "______________\n",
      "epoch 221 train loss 3.3251447677612305\n",
      "val loss 3.150928020477295\n",
      "______________\n",
      "epoch 222 train loss 3.316899061203003\n",
      "val loss 3.144719123840332\n",
      "______________\n",
      "epoch 223 train loss 3.5185577869415283\n",
      "val loss 3.1385908126831055\n",
      "______________\n",
      "epoch 224 train loss 3.4671056270599365\n",
      "val loss 3.132474660873413\n",
      "______________\n",
      "epoch 225 train loss 3.3294641971588135\n",
      "val loss 3.1263949871063232\n",
      "______________\n",
      "epoch 226 train loss 3.4648845195770264\n",
      "val loss 3.120338201522827\n",
      "______________\n",
      "epoch 227 train loss 3.4338490962982178\n",
      "val loss 3.1143534183502197\n",
      "______________\n",
      "epoch 228 train loss 3.4369399547576904\n",
      "val loss 3.1084306240081787\n",
      "______________\n",
      "epoch 229 train loss 3.3359735012054443\n",
      "val loss 3.102538824081421\n",
      "______________\n",
      "epoch 230 train loss 3.311072826385498\n",
      "val loss 3.0966663360595703\n",
      "______________\n",
      "epoch 231 train loss 3.457742691040039\n",
      "val loss 3.09078049659729\n",
      "______________\n",
      "epoch 232 train loss 3.2329213619232178\n",
      "val loss 3.084991455078125\n",
      "______________\n",
      "epoch 233 train loss 3.3210389614105225\n",
      "val loss 3.0792922973632812\n",
      "______________\n",
      "epoch 234 train loss 3.414005756378174\n",
      "val loss 3.0735960006713867\n",
      "______________\n",
      "epoch 235 train loss 3.3599002361297607\n",
      "val loss 3.067936897277832\n",
      "______________\n",
      "epoch 236 train loss 3.3111820220947266\n",
      "val loss 3.062359571456909\n",
      "______________\n",
      "epoch 237 train loss 3.1986005306243896\n",
      "val loss 3.0567660331726074\n",
      "______________\n",
      "epoch 238 train loss 3.291125535964966\n",
      "val loss 3.0511839389801025\n",
      "______________\n",
      "epoch 239 train loss 3.1837246417999268\n",
      "val loss 3.0455753803253174\n",
      "______________\n",
      "epoch 240 train loss 3.281970500946045\n",
      "val loss 3.040057897567749\n",
      "______________\n",
      "epoch 241 train loss 3.368367910385132\n",
      "val loss 3.0345587730407715\n",
      "______________\n",
      "epoch 242 train loss 3.4350967407226562\n",
      "val loss 3.029080390930176\n",
      "______________\n",
      "epoch 243 train loss 3.2259609699249268\n",
      "val loss 3.0235676765441895\n",
      "______________\n",
      "epoch 244 train loss 3.382488250732422\n",
      "val loss 3.018056631088257\n",
      "______________\n",
      "epoch 245 train loss 3.313589572906494\n",
      "val loss 3.0125765800476074\n",
      "______________\n",
      "epoch 246 train loss 3.3558349609375\n",
      "val loss 3.0072293281555176\n",
      "______________\n",
      "epoch 247 train loss 3.2202420234680176\n",
      "val loss 3.001953601837158\n",
      "______________\n",
      "epoch 248 train loss 3.2855935096740723\n",
      "val loss 2.9968249797821045\n",
      "______________\n",
      "epoch 249 train loss 3.2192440032958984\n",
      "val loss 2.991748332977295\n",
      "______________\n",
      "epoch 250 train loss 3.28241229057312\n",
      "val loss 2.9867241382598877\n",
      "______________\n",
      "epoch 251 train loss 3.422806978225708\n",
      "val loss 2.981689453125\n",
      "______________\n",
      "epoch 252 train loss 3.212386131286621\n",
      "val loss 2.976694107055664\n",
      "______________\n",
      "epoch 253 train loss 3.2740020751953125\n",
      "val loss 2.9717049598693848\n",
      "______________\n",
      "epoch 254 train loss 3.2949421405792236\n",
      "val loss 2.9667232036590576\n",
      "______________\n",
      "epoch 255 train loss 3.2324862480163574\n",
      "val loss 2.961742639541626\n",
      "______________\n",
      "epoch 256 train loss 3.2091267108917236\n",
      "val loss 2.956812858581543\n",
      "______________\n",
      "epoch 257 train loss 3.2416954040527344\n",
      "val loss 2.95190167427063\n",
      "______________\n",
      "epoch 258 train loss 3.161546468734741\n",
      "val loss 2.9469895362854004\n",
      "______________\n",
      "epoch 259 train loss 3.114147901535034\n",
      "val loss 2.942079782485962\n",
      "______________\n",
      "epoch 260 train loss 3.2521812915802\n",
      "val loss 2.9372687339782715\n",
      "______________\n",
      "epoch 261 train loss 3.262345790863037\n",
      "val loss 2.9325575828552246\n",
      "______________\n",
      "epoch 262 train loss 3.1536483764648438\n",
      "val loss 2.9279086589813232\n",
      "______________\n",
      "epoch 263 train loss 3.213380813598633\n",
      "val loss 2.923271894454956\n",
      "______________\n",
      "epoch 264 train loss 3.1779770851135254\n",
      "val loss 2.9186675548553467\n",
      "______________\n",
      "epoch 265 train loss 3.2545692920684814\n",
      "val loss 2.914088010787964\n",
      "______________\n",
      "epoch 266 train loss 3.190228223800659\n",
      "val loss 2.909515857696533\n",
      "______________\n",
      "epoch 267 train loss 3.254739284515381\n",
      "val loss 2.9050726890563965\n",
      "______________\n",
      "epoch 268 train loss 3.228397846221924\n",
      "val loss 2.900702714920044\n",
      "______________\n",
      "epoch 269 train loss 2.9926979541778564\n",
      "val loss 2.896254062652588\n",
      "______________\n",
      "epoch 270 train loss 3.2007970809936523\n",
      "val loss 2.8918063640594482\n",
      "______________\n",
      "epoch 271 train loss 3.2613861560821533\n",
      "val loss 2.8874104022979736\n",
      "______________\n",
      "epoch 272 train loss 3.06900691986084\n",
      "val loss 2.882962703704834\n",
      "______________\n",
      "epoch 273 train loss 3.200106143951416\n",
      "val loss 2.8785388469696045\n",
      "______________\n",
      "epoch 274 train loss 3.272216796875\n",
      "val loss 2.874232769012451\n",
      "______________\n",
      "epoch 275 train loss 3.1782004833221436\n",
      "val loss 2.869927406311035\n",
      "______________\n",
      "epoch 276 train loss 3.0249223709106445\n",
      "val loss 2.865589141845703\n",
      "______________\n",
      "epoch 277 train loss 3.1979455947875977\n",
      "val loss 2.86128306388855\n",
      "______________\n",
      "epoch 278 train loss 3.1834657192230225\n",
      "val loss 2.857034921646118\n",
      "______________\n",
      "epoch 279 train loss 3.2529296875\n",
      "val loss 2.8528103828430176\n",
      "______________\n",
      "epoch 280 train loss 3.079490900039673\n",
      "val loss 2.8486130237579346\n",
      "______________\n",
      "epoch 281 train loss 3.1237127780914307\n",
      "val loss 2.844374895095825\n",
      "______________\n",
      "epoch 282 train loss 3.1470324993133545\n",
      "val loss 2.840165853500366\n",
      "______________\n",
      "epoch 283 train loss 3.178292989730835\n",
      "val loss 2.836064100265503\n",
      "______________\n",
      "epoch 284 train loss 3.1448464393615723\n",
      "val loss 2.831965208053589\n",
      "______________\n",
      "epoch 285 train loss 3.232452630996704\n",
      "val loss 2.82798433303833\n",
      "______________\n",
      "epoch 286 train loss 3.1225485801696777\n",
      "val loss 2.8240537643432617\n",
      "______________\n",
      "epoch 287 train loss 3.2423806190490723\n",
      "val loss 2.820230722427368\n",
      "______________\n",
      "epoch 288 train loss 3.092660665512085\n",
      "val loss 2.816426992416382\n",
      "______________\n",
      "epoch 289 train loss 3.026031494140625\n",
      "val loss 2.8125967979431152\n",
      "______________\n",
      "epoch 290 train loss 2.907062530517578\n",
      "val loss 2.808702230453491\n",
      "______________\n",
      "epoch 291 train loss 3.0319576263427734\n",
      "val loss 2.8047914505004883\n",
      "______________\n",
      "epoch 292 train loss 3.1237001419067383\n",
      "val loss 2.8009462356567383\n",
      "______________\n",
      "epoch 293 train loss 3.101538896560669\n",
      "val loss 2.797089099884033\n",
      "______________\n",
      "epoch 294 train loss 3.033933401107788\n",
      "val loss 2.7931816577911377\n",
      "______________\n",
      "epoch 295 train loss 2.9976375102996826\n",
      "val loss 2.789283037185669\n",
      "______________\n",
      "epoch 296 train loss 3.1181447505950928\n",
      "val loss 2.78543758392334\n",
      "______________\n",
      "epoch 297 train loss 3.118403434753418\n",
      "val loss 2.7815887928009033\n",
      "______________\n",
      "epoch 298 train loss 3.0419676303863525\n",
      "val loss 2.777750015258789\n",
      "______________\n",
      "epoch 299 train loss 3.021472215652466\n",
      "val loss 2.773951530456543\n",
      "______________\n",
      "epoch 300 train loss 3.0803914070129395\n",
      "val loss 2.7701363563537598\n",
      "______________\n",
      "epoch 301 train loss 3.083604335784912\n",
      "val loss 2.7663965225219727\n",
      "______________\n",
      "epoch 302 train loss 3.268115758895874\n",
      "val loss 2.7627506256103516\n",
      "______________\n",
      "epoch 303 train loss 3.19812273979187\n",
      "val loss 2.7591707706451416\n",
      "______________\n",
      "epoch 304 train loss 3.1051478385925293\n",
      "val loss 2.7556984424591064\n",
      "______________\n",
      "epoch 305 train loss 3.085888624191284\n",
      "val loss 2.7522380352020264\n",
      "______________\n",
      "epoch 306 train loss 3.0987496376037598\n",
      "val loss 2.7488820552825928\n",
      "______________\n",
      "epoch 307 train loss 3.1293492317199707\n",
      "val loss 2.745560884475708\n",
      "______________\n",
      "epoch 308 train loss 2.9806199073791504\n",
      "val loss 2.7422053813934326\n",
      "______________\n",
      "epoch 309 train loss 3.0429325103759766\n",
      "val loss 2.7388250827789307\n",
      "______________\n",
      "epoch 310 train loss 3.0513710975646973\n",
      "val loss 2.735469102859497\n",
      "______________\n",
      "epoch 311 train loss 3.035076141357422\n",
      "val loss 2.7321224212646484\n",
      "______________\n",
      "epoch 312 train loss 2.9755430221557617\n",
      "val loss 2.7287330627441406\n",
      "______________\n",
      "epoch 313 train loss 2.972870349884033\n",
      "val loss 2.7254295349121094\n",
      "______________\n",
      "epoch 314 train loss 3.006828546524048\n",
      "val loss 2.722100257873535\n",
      "______________\n",
      "epoch 315 train loss 2.949784755706787\n",
      "val loss 2.7187700271606445\n",
      "______________\n",
      "epoch 316 train loss 3.1174795627593994\n",
      "val loss 2.715602159500122\n",
      "______________\n",
      "epoch 317 train loss 2.931708335876465\n",
      "val loss 2.7124199867248535\n",
      "______________\n",
      "epoch 318 train loss 3.007462501525879\n",
      "val loss 2.7092506885528564\n",
      "______________\n",
      "epoch 319 train loss 2.980015277862549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.706130027770996\n",
      "______________\n",
      "epoch 320 train loss 3.0929017066955566\n",
      "val loss 2.703071117401123\n",
      "______________\n",
      "epoch 321 train loss 2.8910391330718994\n",
      "val loss 2.6999683380126953\n",
      "______________\n",
      "epoch 322 train loss 3.020517110824585\n",
      "val loss 2.6969704627990723\n",
      "______________\n",
      "epoch 323 train loss 2.992154836654663\n",
      "val loss 2.693970203399658\n",
      "______________\n",
      "epoch 324 train loss 3.025301456451416\n",
      "val loss 2.691044807434082\n",
      "______________\n",
      "epoch 325 train loss 2.984372615814209\n",
      "val loss 2.6880674362182617\n",
      "______________\n",
      "epoch 326 train loss 3.111245632171631\n",
      "val loss 2.6850943565368652\n",
      "______________\n",
      "epoch 327 train loss 3.024503469467163\n",
      "val loss 2.6820874214172363\n",
      "______________\n",
      "epoch 328 train loss 3.0138776302337646\n",
      "val loss 2.6790502071380615\n",
      "______________\n",
      "epoch 329 train loss 3.027296543121338\n",
      "val loss 2.6760475635528564\n",
      "______________\n",
      "epoch 330 train loss 3.053953170776367\n",
      "val loss 2.673074722290039\n",
      "______________\n",
      "epoch 331 train loss 3.0948398113250732\n",
      "val loss 2.6701605319976807\n",
      "______________\n",
      "epoch 332 train loss 2.956198215484619\n",
      "val loss 2.6672592163085938\n",
      "______________\n",
      "epoch 333 train loss 3.0673604011535645\n",
      "val loss 2.6644234657287598\n",
      "______________\n",
      "epoch 334 train loss 3.021536111831665\n",
      "val loss 2.6616015434265137\n",
      "______________\n",
      "epoch 335 train loss 2.8923661708831787\n",
      "val loss 2.6587352752685547\n",
      "______________\n",
      "epoch 336 train loss 2.9965546131134033\n",
      "val loss 2.655905246734619\n",
      "______________\n",
      "epoch 337 train loss 2.886082410812378\n",
      "val loss 2.6530346870422363\n",
      "______________\n",
      "epoch 338 train loss 2.9849131107330322\n",
      "val loss 2.6501669883728027\n",
      "______________\n",
      "epoch 339 train loss 3.0003952980041504\n",
      "val loss 2.6473052501678467\n",
      "______________\n",
      "epoch 340 train loss 3.0541133880615234\n",
      "val loss 2.644409656524658\n",
      "______________\n",
      "epoch 341 train loss 3.0023159980773926\n",
      "val loss 2.6415107250213623\n",
      "______________\n",
      "epoch 342 train loss 2.8548600673675537\n",
      "val loss 2.638566493988037\n",
      "______________\n",
      "epoch 343 train loss 2.896245002746582\n",
      "val loss 2.635596752166748\n",
      "______________\n",
      "epoch 344 train loss 2.931534767150879\n",
      "val loss 2.6326799392700195\n",
      "______________\n",
      "epoch 345 train loss 2.954390048980713\n",
      "val loss 2.629822015762329\n",
      "______________\n",
      "epoch 346 train loss 3.026832103729248\n",
      "val loss 2.6270668506622314\n",
      "______________\n",
      "epoch 347 train loss 3.0026185512542725\n",
      "val loss 2.624342918395996\n",
      "______________\n",
      "epoch 348 train loss 3.054893970489502\n",
      "val loss 2.621570587158203\n",
      "______________\n",
      "epoch 349 train loss 2.9140071868896484\n",
      "val loss 2.6187844276428223\n",
      "______________\n",
      "epoch 350 train loss 2.931777238845825\n",
      "val loss 2.616042375564575\n",
      "______________\n",
      "epoch 351 train loss 2.9271059036254883\n",
      "val loss 2.6133487224578857\n",
      "______________\n",
      "epoch 352 train loss 2.9448280334472656\n",
      "val loss 2.610729455947876\n",
      "______________\n",
      "epoch 353 train loss 2.8138182163238525\n",
      "val loss 2.608128070831299\n",
      "______________\n",
      "epoch 354 train loss 3.1872525215148926\n",
      "val loss 2.605616569519043\n",
      "______________\n",
      "epoch 355 train loss 2.9855995178222656\n",
      "val loss 2.603166103363037\n",
      "______________\n",
      "epoch 356 train loss 2.991511821746826\n",
      "val loss 2.600738763809204\n",
      "______________\n",
      "epoch 357 train loss 2.8756089210510254\n",
      "val loss 2.5983548164367676\n",
      "______________\n",
      "epoch 358 train loss 2.8418896198272705\n",
      "val loss 2.5959882736206055\n",
      "______________\n",
      "epoch 359 train loss 2.85658860206604\n",
      "val loss 2.5935988426208496\n",
      "______________\n",
      "epoch 360 train loss 2.9021270275115967\n",
      "val loss 2.5911126136779785\n",
      "______________\n",
      "epoch 361 train loss 2.7460978031158447\n",
      "val loss 2.5885567665100098\n",
      "______________\n",
      "epoch 362 train loss 2.86128568649292\n",
      "val loss 2.585980176925659\n",
      "______________\n",
      "epoch 363 train loss 2.9896390438079834\n",
      "val loss 2.583503484725952\n",
      "______________\n",
      "epoch 364 train loss 2.8734118938446045\n",
      "val loss 2.5809481143951416\n",
      "______________\n",
      "epoch 365 train loss 2.6880645751953125\n",
      "val loss 2.578310251235962\n",
      "______________\n",
      "epoch 366 train loss 2.9820406436920166\n",
      "val loss 2.575786590576172\n",
      "______________\n",
      "epoch 367 train loss 2.9764933586120605\n",
      "val loss 2.573389768600464\n",
      "______________\n",
      "epoch 368 train loss 2.811718463897705\n",
      "val loss 2.571019411087036\n",
      "______________\n",
      "epoch 369 train loss 2.939298391342163\n",
      "val loss 2.568636655807495\n",
      "______________\n",
      "epoch 370 train loss 2.8603463172912598\n",
      "val loss 2.566227436065674\n",
      "______________\n",
      "epoch 371 train loss 2.8264338970184326\n",
      "val loss 2.5637688636779785\n",
      "______________\n",
      "epoch 372 train loss 2.6639649868011475\n",
      "val loss 2.561232089996338\n",
      "______________\n",
      "epoch 373 train loss 2.737920045852661\n",
      "val loss 2.5585854053497314\n",
      "______________\n",
      "epoch 374 train loss 2.914389133453369\n",
      "val loss 2.5558977127075195\n",
      "______________\n",
      "epoch 375 train loss 2.8065402507781982\n",
      "val loss 2.553185224533081\n",
      "______________\n",
      "epoch 376 train loss 2.7527191638946533\n",
      "val loss 2.5504560470581055\n",
      "______________\n",
      "epoch 377 train loss 2.7631094455718994\n",
      "val loss 2.5477542877197266\n",
      "______________\n",
      "epoch 378 train loss 2.8081583976745605\n",
      "val loss 2.5451109409332275\n",
      "______________\n",
      "epoch 379 train loss 2.909047842025757\n",
      "val loss 2.542506217956543\n",
      "______________\n",
      "epoch 380 train loss 2.8849058151245117\n",
      "val loss 2.5400052070617676\n",
      "______________\n",
      "epoch 381 train loss 2.7653188705444336\n",
      "val loss 2.53749680519104\n",
      "______________\n",
      "epoch 382 train loss 3.014723777770996\n",
      "val loss 2.535135269165039\n",
      "______________\n",
      "epoch 383 train loss 2.884891986846924\n",
      "val loss 2.532783269882202\n",
      "______________\n",
      "epoch 384 train loss 2.8049609661102295\n",
      "val loss 2.5303614139556885\n",
      "______________\n",
      "epoch 385 train loss 2.8123514652252197\n",
      "val loss 2.5279242992401123\n",
      "______________\n",
      "epoch 386 train loss 2.966647148132324\n",
      "val loss 2.525583505630493\n",
      "______________\n",
      "epoch 387 train loss 2.8401713371276855\n",
      "val loss 2.5232784748077393\n",
      "______________\n",
      "epoch 388 train loss 2.7019031047821045\n",
      "val loss 2.520934581756592\n",
      "______________\n",
      "epoch 389 train loss 2.887077569961548\n",
      "val loss 2.518702983856201\n",
      "______________\n",
      "epoch 390 train loss 2.8416526317596436\n",
      "val loss 2.516505718231201\n",
      "______________\n",
      "epoch 391 train loss 2.8927083015441895\n",
      "val loss 2.514364719390869\n",
      "______________\n",
      "epoch 392 train loss 2.7811198234558105\n",
      "val loss 2.5121915340423584\n",
      "______________\n",
      "epoch 393 train loss 2.6530730724334717\n",
      "val loss 2.509962558746338\n",
      "______________\n",
      "epoch 394 train loss 2.699202299118042\n",
      "val loss 2.507697343826294\n",
      "______________\n",
      "epoch 395 train loss 2.814926862716675\n",
      "val loss 2.5054216384887695\n",
      "______________\n",
      "epoch 396 train loss 2.8520469665527344\n",
      "val loss 2.50319504737854\n",
      "______________\n",
      "epoch 397 train loss 2.712353467941284\n",
      "val loss 2.5010340213775635\n",
      "______________\n",
      "epoch 398 train loss 2.690927028656006\n",
      "val loss 2.4988720417022705\n",
      "______________\n",
      "epoch 399 train loss 2.723997116088867\n",
      "val loss 2.496687889099121\n",
      "______________\n",
      "epoch 400 train loss 2.844536066055298\n",
      "val loss 2.494507312774658\n",
      "______________\n",
      "epoch 401 train loss 2.7156662940979004\n",
      "val loss 2.492288589477539\n",
      "______________\n",
      "epoch 402 train loss 2.800804615020752\n",
      "val loss 2.4901680946350098\n",
      "______________\n",
      "epoch 403 train loss 2.81552791595459\n",
      "val loss 2.4881036281585693\n",
      "______________\n",
      "epoch 404 train loss 2.8179688453674316\n",
      "val loss 2.4860188961029053\n",
      "______________\n",
      "epoch 405 train loss 2.7902157306671143\n",
      "val loss 2.483957052230835\n",
      "______________\n",
      "epoch 406 train loss 2.763815402984619\n",
      "val loss 2.4819211959838867\n",
      "______________\n",
      "epoch 407 train loss 2.7722156047821045\n",
      "val loss 2.4798810482025146\n",
      "______________\n",
      "epoch 408 train loss 2.721299171447754\n",
      "val loss 2.477841854095459\n",
      "______________\n",
      "epoch 409 train loss 2.6695666313171387\n",
      "val loss 2.4758002758026123\n",
      "______________\n",
      "epoch 410 train loss 2.867825746536255\n",
      "val loss 2.4738340377807617\n",
      "______________\n",
      "epoch 411 train loss 2.7656209468841553\n",
      "val loss 2.4718759059906006\n",
      "______________\n",
      "epoch 412 train loss 2.878767490386963\n",
      "val loss 2.469866991043091\n",
      "______________\n",
      "epoch 413 train loss 2.727567195892334\n",
      "val loss 2.467860221862793\n",
      "______________\n",
      "epoch 414 train loss 2.822486400604248\n",
      "val loss 2.46588134765625\n",
      "______________\n",
      "epoch 415 train loss 2.767890691757202\n",
      "val loss 2.4639394283294678\n",
      "______________\n",
      "epoch 416 train loss 2.6437323093414307\n",
      "val loss 2.462008476257324\n",
      "______________\n",
      "epoch 417 train loss 2.8657116889953613\n",
      "val loss 2.4600882530212402\n",
      "______________\n",
      "epoch 418 train loss 2.6874845027923584\n",
      "val loss 2.4582266807556152\n",
      "______________\n",
      "epoch 419 train loss 2.86445689201355\n",
      "val loss 2.4563534259796143\n",
      "______________\n",
      "epoch 420 train loss 2.7789437770843506\n",
      "val loss 2.454427719116211\n",
      "______________\n",
      "epoch 421 train loss 2.7366535663604736\n",
      "val loss 2.4525296688079834\n",
      "______________\n",
      "epoch 422 train loss 2.686149835586548\n",
      "val loss 2.4506804943084717\n",
      "______________\n",
      "epoch 423 train loss 2.7356438636779785\n",
      "val loss 2.4488260746002197\n",
      "______________\n",
      "epoch 424 train loss 2.6824307441711426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.446880340576172\n",
      "______________\n",
      "epoch 425 train loss 2.7612409591674805\n",
      "val loss 2.4449658393859863\n",
      "______________\n",
      "epoch 426 train loss 2.8098208904266357\n",
      "val loss 2.4430694580078125\n",
      "______________\n",
      "epoch 427 train loss 2.7744944095611572\n",
      "val loss 2.4411964416503906\n",
      "______________\n",
      "epoch 428 train loss 2.789022445678711\n",
      "val loss 2.4393973350524902\n",
      "______________\n",
      "epoch 429 train loss 2.5905280113220215\n",
      "val loss 2.4375791549682617\n",
      "______________\n",
      "epoch 430 train loss 2.803084373474121\n",
      "val loss 2.4357821941375732\n",
      "______________\n",
      "epoch 431 train loss 2.564967155456543\n",
      "val loss 2.4340457916259766\n",
      "______________\n",
      "epoch 432 train loss 2.7117435932159424\n",
      "val loss 2.432363271713257\n",
      "______________\n",
      "epoch 433 train loss 2.742067337036133\n",
      "val loss 2.4306395053863525\n",
      "______________\n",
      "epoch 434 train loss 2.7686192989349365\n",
      "val loss 2.428957462310791\n",
      "______________\n",
      "epoch 435 train loss 2.7756974697113037\n",
      "val loss 2.427269697189331\n",
      "______________\n",
      "epoch 436 train loss 2.781867742538452\n",
      "val loss 2.425649404525757\n",
      "______________\n",
      "epoch 437 train loss 2.645536184310913\n",
      "val loss 2.424024820327759\n",
      "______________\n",
      "epoch 438 train loss 2.640052080154419\n",
      "val loss 2.422330379486084\n",
      "______________\n",
      "epoch 439 train loss 2.5966920852661133\n",
      "val loss 2.4205245971679688\n",
      "______________\n",
      "epoch 440 train loss 2.6183695793151855\n",
      "val loss 2.418651580810547\n",
      "______________\n",
      "epoch 441 train loss 2.728694200515747\n",
      "val loss 2.4168100357055664\n",
      "______________\n",
      "epoch 442 train loss 2.679553985595703\n",
      "val loss 2.41498064994812\n",
      "______________\n",
      "epoch 443 train loss 2.6586709022521973\n",
      "val loss 2.41312575340271\n",
      "______________\n",
      "epoch 444 train loss 2.765059471130371\n",
      "val loss 2.4113008975982666\n",
      "______________\n",
      "epoch 445 train loss 2.6246492862701416\n",
      "val loss 2.409438371658325\n",
      "______________\n",
      "epoch 446 train loss 2.5980794429779053\n",
      "val loss 2.4076104164123535\n",
      "______________\n",
      "epoch 447 train loss 2.7813973426818848\n",
      "val loss 2.4058902263641357\n",
      "______________\n",
      "epoch 448 train loss 2.634075880050659\n",
      "val loss 2.4041807651519775\n",
      "______________\n",
      "epoch 449 train loss 2.7263383865356445\n",
      "val loss 2.402561902999878\n",
      "______________\n",
      "epoch 450 train loss 2.5283851623535156\n",
      "val loss 2.4009034633636475\n",
      "______________\n",
      "epoch 451 train loss 2.7371625900268555\n",
      "val loss 2.399327039718628\n",
      "______________\n",
      "epoch 452 train loss 2.608760356903076\n",
      "val loss 2.3977773189544678\n",
      "______________\n",
      "epoch 453 train loss 2.565725088119507\n",
      "val loss 2.3963191509246826\n",
      "______________\n",
      "epoch 454 train loss 2.6844124794006348\n",
      "val loss 2.3949458599090576\n",
      "______________\n",
      "epoch 455 train loss 2.803041458129883\n",
      "val loss 2.393617630004883\n",
      "______________\n",
      "epoch 456 train loss 2.6263222694396973\n",
      "val loss 2.3922064304351807\n",
      "______________\n",
      "epoch 457 train loss 2.694110631942749\n",
      "val loss 2.3907957077026367\n",
      "______________\n",
      "epoch 458 train loss 2.6813740730285645\n",
      "val loss 2.3893532752990723\n",
      "______________\n",
      "epoch 459 train loss 2.576727867126465\n",
      "val loss 2.38795804977417\n",
      "______________\n",
      "epoch 460 train loss 2.620527505874634\n",
      "val loss 2.3865654468536377\n",
      "______________\n",
      "epoch 461 train loss 2.6127524375915527\n",
      "val loss 2.385162591934204\n",
      "______________\n",
      "epoch 462 train loss 2.676992654800415\n",
      "val loss 2.3837077617645264\n",
      "______________\n",
      "epoch 463 train loss 2.6614179611206055\n",
      "val loss 2.382286548614502\n",
      "______________\n",
      "epoch 464 train loss 2.751990795135498\n",
      "val loss 2.3808348178863525\n",
      "______________\n",
      "epoch 465 train loss 2.5777761936187744\n",
      "val loss 2.3793599605560303\n",
      "______________\n",
      "epoch 466 train loss 2.637789487838745\n",
      "val loss 2.377809762954712\n",
      "______________\n",
      "epoch 467 train loss 2.586411714553833\n",
      "val loss 2.3762388229370117\n",
      "______________\n",
      "epoch 468 train loss 2.7090117931365967\n",
      "val loss 2.374673366546631\n",
      "______________\n",
      "epoch 469 train loss 2.5837674140930176\n",
      "val loss 2.373162269592285\n",
      "______________\n",
      "epoch 470 train loss 2.631608009338379\n",
      "val loss 2.371657371520996\n",
      "______________\n",
      "epoch 471 train loss 2.667236566543579\n",
      "val loss 2.370147228240967\n",
      "______________\n",
      "epoch 472 train loss 2.782254695892334\n",
      "val loss 2.368725299835205\n",
      "______________\n",
      "epoch 473 train loss 2.6414594650268555\n",
      "val loss 2.3673980236053467\n",
      "______________\n",
      "epoch 474 train loss 2.6240153312683105\n",
      "val loss 2.3660049438476562\n",
      "______________\n",
      "epoch 475 train loss 2.507338047027588\n",
      "val loss 2.3645637035369873\n",
      "______________\n",
      "epoch 476 train loss 2.6684064865112305\n",
      "val loss 2.363157272338867\n",
      "______________\n",
      "epoch 477 train loss 2.702393054962158\n",
      "val loss 2.361755132675171\n",
      "______________\n",
      "epoch 478 train loss 2.673036575317383\n",
      "val loss 2.3603134155273438\n",
      "______________\n",
      "epoch 479 train loss 2.556142807006836\n",
      "val loss 2.358863353729248\n",
      "______________\n",
      "epoch 480 train loss 2.682434558868408\n",
      "val loss 2.357435703277588\n",
      "______________\n",
      "epoch 481 train loss 2.7133312225341797\n",
      "val loss 2.3560166358947754\n",
      "______________\n",
      "epoch 482 train loss 2.81768798828125\n",
      "val loss 2.3546841144561768\n",
      "______________\n",
      "epoch 483 train loss 2.5516343116760254\n",
      "val loss 2.353325605392456\n",
      "______________\n",
      "epoch 484 train loss 2.671143054962158\n",
      "val loss 2.351989507675171\n",
      "______________\n",
      "epoch 485 train loss 2.5363247394561768\n",
      "val loss 2.3506102561950684\n",
      "______________\n",
      "epoch 486 train loss 2.698784351348877\n",
      "val loss 2.3492953777313232\n",
      "______________\n",
      "epoch 487 train loss 2.5224838256835938\n",
      "val loss 2.348015069961548\n",
      "______________\n",
      "epoch 488 train loss 2.582047939300537\n",
      "val loss 2.3467187881469727\n",
      "______________\n",
      "epoch 489 train loss 2.6218671798706055\n",
      "val loss 2.3454620838165283\n",
      "______________\n",
      "epoch 490 train loss 2.67071270942688\n",
      "val loss 2.3442728519439697\n",
      "______________\n",
      "epoch 491 train loss 2.4941329956054688\n",
      "val loss 2.3430583477020264\n",
      "______________\n",
      "epoch 492 train loss 2.6884605884552\n",
      "val loss 2.3418266773223877\n",
      "______________\n",
      "epoch 493 train loss 2.5797441005706787\n",
      "val loss 2.340622901916504\n",
      "______________\n",
      "epoch 494 train loss 2.6407248973846436\n",
      "val loss 2.3394012451171875\n",
      "______________\n",
      "epoch 495 train loss 2.6886415481567383\n",
      "val loss 2.338165521621704\n",
      "______________\n",
      "epoch 496 train loss 2.5841548442840576\n",
      "val loss 2.3369669914245605\n",
      "______________\n",
      "epoch 497 train loss 2.637352466583252\n",
      "val loss 2.3357341289520264\n",
      "______________\n",
      "epoch 498 train loss 2.6202776432037354\n",
      "val loss 2.3343961238861084\n",
      "______________\n",
      "epoch 499 train loss 2.6216466426849365\n",
      "val loss 2.333116054534912\n",
      "______________\n",
      "epoch 500 train loss 2.568345069885254\n",
      "val loss 2.3318018913269043\n",
      "______________\n",
      "epoch 501 train loss 2.5110995769500732\n",
      "val loss 2.330486297607422\n",
      "______________\n",
      "epoch 502 train loss 2.624521017074585\n",
      "val loss 2.329179048538208\n",
      "______________\n",
      "epoch 503 train loss 2.6234185695648193\n",
      "val loss 2.327852725982666\n",
      "______________\n",
      "epoch 504 train loss 2.6964852809906006\n",
      "val loss 2.326559543609619\n",
      "______________\n",
      "epoch 505 train loss 2.3749024868011475\n",
      "val loss 2.3251938819885254\n",
      "______________\n",
      "epoch 506 train loss 2.6128127574920654\n",
      "val loss 2.3238422870635986\n",
      "______________\n",
      "epoch 507 train loss 2.5821642875671387\n",
      "val loss 2.322498083114624\n",
      "______________\n",
      "epoch 508 train loss 2.6733148097991943\n",
      "val loss 2.321174383163452\n",
      "______________\n",
      "epoch 509 train loss 2.574963331222534\n",
      "val loss 2.319836139678955\n",
      "______________\n",
      "epoch 510 train loss 2.6591930389404297\n",
      "val loss 2.3185181617736816\n",
      "______________\n",
      "epoch 511 train loss 2.53190541267395\n",
      "val loss 2.3172008991241455\n",
      "______________\n",
      "epoch 512 train loss 2.6304049491882324\n",
      "val loss 2.315952777862549\n",
      "______________\n",
      "epoch 513 train loss 2.5739586353302\n",
      "val loss 2.3146820068359375\n",
      "______________\n",
      "epoch 514 train loss 2.476865291595459\n",
      "val loss 2.3134095668792725\n",
      "______________\n",
      "epoch 515 train loss 2.4909677505493164\n",
      "val loss 2.312106132507324\n",
      "______________\n",
      "epoch 516 train loss 2.5060267448425293\n",
      "val loss 2.3108069896698\n",
      "______________\n",
      "epoch 517 train loss 2.5323100090026855\n",
      "val loss 2.3095202445983887\n",
      "______________\n",
      "epoch 518 train loss 2.5743467807769775\n",
      "val loss 2.30825138092041\n",
      "______________\n",
      "epoch 519 train loss 2.7586238384246826\n",
      "val loss 2.307136297225952\n",
      "______________\n",
      "epoch 520 train loss 2.5283467769622803\n",
      "val loss 2.30609393119812\n",
      "______________\n",
      "epoch 521 train loss 2.61175274848938\n",
      "val loss 2.3050262928009033\n",
      "______________\n",
      "epoch 522 train loss 2.6155662536621094\n",
      "val loss 2.3040056228637695\n",
      "______________\n",
      "epoch 523 train loss 2.5680887699127197\n",
      "val loss 2.3030240535736084\n",
      "______________\n",
      "epoch 524 train loss 2.5073606967926025\n",
      "val loss 2.302018880844116\n",
      "______________\n",
      "epoch 525 train loss 2.500241994857788\n",
      "val loss 2.301025152206421\n",
      "______________\n",
      "epoch 526 train loss 2.562976360321045\n",
      "val loss 2.299990653991699\n",
      "______________\n",
      "epoch 527 train loss 2.4496989250183105\n",
      "val loss 2.298985242843628\n",
      "______________\n",
      "epoch 528 train loss 2.5391886234283447\n",
      "val loss 2.2979490756988525\n",
      "______________\n",
      "epoch 529 train loss 2.462865114212036\n",
      "val loss 2.2968664169311523\n",
      "______________\n",
      "epoch 530 train loss 2.485931873321533\n",
      "val loss 2.2957987785339355\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 531 train loss 2.6331429481506348\n",
      "val loss 2.2947604656219482\n",
      "______________\n",
      "epoch 532 train loss 2.413602352142334\n",
      "val loss 2.293632745742798\n",
      "______________\n",
      "epoch 533 train loss 2.5512661933898926\n",
      "val loss 2.2924604415893555\n",
      "______________\n",
      "epoch 534 train loss 2.4554550647735596\n",
      "val loss 2.2912676334381104\n",
      "______________\n",
      "epoch 535 train loss 2.631312370300293\n",
      "val loss 2.2901158332824707\n",
      "______________\n",
      "epoch 536 train loss 2.480426073074341\n",
      "val loss 2.2889420986175537\n",
      "______________\n",
      "epoch 537 train loss 2.7116713523864746\n",
      "val loss 2.2877814769744873\n",
      "______________\n",
      "epoch 538 train loss 2.481032371520996\n",
      "val loss 2.286689519882202\n",
      "______________\n",
      "epoch 539 train loss 2.5509755611419678\n",
      "val loss 2.28556489944458\n",
      "______________\n",
      "epoch 540 train loss 2.6818997859954834\n",
      "val loss 2.284433126449585\n",
      "______________\n",
      "epoch 541 train loss 2.5071282386779785\n",
      "val loss 2.283217668533325\n",
      "______________\n",
      "epoch 542 train loss 2.419431686401367\n",
      "val loss 2.28208327293396\n",
      "______________\n",
      "epoch 543 train loss 2.5712876319885254\n",
      "val loss 2.280883312225342\n",
      "______________\n",
      "epoch 544 train loss 2.484276533126831\n",
      "val loss 2.2796359062194824\n",
      "______________\n",
      "epoch 545 train loss 2.4201056957244873\n",
      "val loss 2.2784242630004883\n",
      "______________\n",
      "epoch 546 train loss 2.4824275970458984\n",
      "val loss 2.2771878242492676\n",
      "______________\n",
      "epoch 547 train loss 2.463146209716797\n",
      "val loss 2.2759313583374023\n",
      "______________\n",
      "epoch 548 train loss 2.3424558639526367\n",
      "val loss 2.2746922969818115\n",
      "______________\n",
      "epoch 549 train loss 2.5711236000061035\n",
      "val loss 2.2734222412109375\n",
      "______________\n",
      "epoch 550 train loss 2.5698142051696777\n",
      "val loss 2.2721750736236572\n",
      "______________\n",
      "epoch 551 train loss 2.523665189743042\n",
      "val loss 2.2709743976593018\n",
      "______________\n",
      "epoch 552 train loss 2.459749221801758\n",
      "val loss 2.269756555557251\n",
      "______________\n",
      "epoch 553 train loss 2.518429756164551\n",
      "val loss 2.2685234546661377\n",
      "______________\n",
      "epoch 554 train loss 2.556445360183716\n",
      "val loss 2.267329454421997\n",
      "______________\n",
      "epoch 555 train loss 2.5681021213531494\n",
      "val loss 2.266155242919922\n",
      "______________\n",
      "epoch 556 train loss 2.597064256668091\n",
      "val loss 2.2650601863861084\n",
      "______________\n",
      "epoch 557 train loss 2.497892141342163\n",
      "val loss 2.2639334201812744\n",
      "______________\n",
      "epoch 558 train loss 2.492051124572754\n",
      "val loss 2.262881278991699\n",
      "______________\n",
      "epoch 559 train loss 2.564127206802368\n",
      "val loss 2.261873960494995\n",
      "______________\n",
      "epoch 560 train loss 2.5569608211517334\n",
      "val loss 2.26092267036438\n",
      "______________\n",
      "epoch 561 train loss 2.544234037399292\n",
      "val loss 2.2601044178009033\n",
      "______________\n",
      "epoch 562 train loss 2.494709014892578\n",
      "val loss 2.259312152862549\n",
      "______________\n",
      "epoch 563 train loss 2.632004499435425\n",
      "val loss 2.2586090564727783\n",
      "______________\n",
      "epoch 564 train loss 2.5215556621551514\n",
      "val loss 2.257809638977051\n",
      "______________\n",
      "epoch 565 train loss 2.518541097640991\n",
      "val loss 2.2569851875305176\n",
      "______________\n",
      "epoch 566 train loss 2.4955286979675293\n",
      "val loss 2.256129026412964\n",
      "______________\n",
      "epoch 567 train loss 2.4947822093963623\n",
      "val loss 2.2552804946899414\n",
      "______________\n",
      "epoch 568 train loss 2.5550594329833984\n",
      "val loss 2.254387855529785\n",
      "______________\n",
      "epoch 569 train loss 2.5149083137512207\n",
      "val loss 2.253492832183838\n",
      "______________\n",
      "epoch 570 train loss 2.4559271335601807\n",
      "val loss 2.2526235580444336\n",
      "______________\n",
      "epoch 571 train loss 2.4267725944519043\n",
      "val loss 2.2517032623291016\n",
      "______________\n",
      "epoch 572 train loss 2.3872389793395996\n",
      "val loss 2.250732660293579\n",
      "______________\n",
      "epoch 573 train loss 2.400635004043579\n",
      "val loss 2.2496581077575684\n",
      "______________\n",
      "epoch 574 train loss 2.562250852584839\n",
      "val loss 2.24859881401062\n",
      "______________\n",
      "epoch 575 train loss 2.5902600288391113\n",
      "val loss 2.247598886489868\n",
      "______________\n",
      "epoch 576 train loss 2.587052345275879\n",
      "val loss 2.2466325759887695\n",
      "______________\n",
      "epoch 577 train loss 2.479304313659668\n",
      "val loss 2.2456512451171875\n",
      "______________\n",
      "epoch 578 train loss 2.4367775917053223\n",
      "val loss 2.244619846343994\n",
      "______________\n",
      "epoch 579 train loss 2.392798900604248\n",
      "val loss 2.243513822555542\n",
      "______________\n",
      "epoch 580 train loss 2.5282375812530518\n",
      "val loss 2.242440938949585\n",
      "______________\n",
      "epoch 581 train loss 2.566333532333374\n",
      "val loss 2.241487979888916\n",
      "______________\n",
      "epoch 582 train loss 2.403707981109619\n",
      "val loss 2.240530490875244\n",
      "______________\n",
      "epoch 583 train loss 2.3699591159820557\n",
      "val loss 2.239535093307495\n",
      "______________\n",
      "epoch 584 train loss 2.4900600910186768\n",
      "val loss 2.238516092300415\n",
      "______________\n",
      "epoch 585 train loss 2.3733112812042236\n",
      "val loss 2.2374682426452637\n",
      "______________\n",
      "epoch 586 train loss 2.537306308746338\n",
      "val loss 2.23648738861084\n",
      "______________\n",
      "epoch 587 train loss 2.450148582458496\n",
      "val loss 2.2355308532714844\n",
      "______________\n",
      "epoch 588 train loss 2.4792277812957764\n",
      "val loss 2.2345407009124756\n",
      "______________\n",
      "epoch 589 train loss 2.4453911781311035\n",
      "val loss 2.2336013317108154\n",
      "______________\n",
      "epoch 590 train loss 2.6231093406677246\n",
      "val loss 2.232733726501465\n",
      "______________\n",
      "epoch 591 train loss 2.516887903213501\n",
      "val loss 2.231889486312866\n",
      "______________\n",
      "epoch 592 train loss 2.531428813934326\n",
      "val loss 2.2311034202575684\n",
      "______________\n",
      "epoch 593 train loss 2.5311951637268066\n",
      "val loss 2.2303707599639893\n",
      "______________\n",
      "epoch 594 train loss 2.4436838626861572\n",
      "val loss 2.229659080505371\n",
      "______________\n",
      "epoch 595 train loss 2.420621395111084\n",
      "val loss 2.2289485931396484\n",
      "______________\n",
      "epoch 596 train loss 2.394077777862549\n",
      "val loss 2.2282190322875977\n",
      "______________\n",
      "epoch 597 train loss 2.354111909866333\n",
      "val loss 2.2274997234344482\n",
      "______________\n",
      "epoch 598 train loss 2.425808906555176\n",
      "val loss 2.226806879043579\n",
      "______________\n",
      "epoch 599 train loss 2.4956209659576416\n",
      "val loss 2.226109027862549\n",
      "______________\n",
      "epoch 600 train loss 2.5020852088928223\n",
      "val loss 2.225484609603882\n",
      "______________\n",
      "epoch 601 train loss 2.541546106338501\n",
      "val loss 2.2248878479003906\n",
      "______________\n",
      "epoch 602 train loss 2.496567726135254\n",
      "val loss 2.2242865562438965\n",
      "______________\n",
      "epoch 603 train loss 2.4547207355499268\n",
      "val loss 2.2236344814300537\n",
      "______________\n",
      "epoch 604 train loss 2.466481924057007\n",
      "val loss 2.2229955196380615\n",
      "______________\n",
      "epoch 605 train loss 2.4598679542541504\n",
      "val loss 2.2223060131073\n",
      "______________\n",
      "epoch 606 train loss 2.5437045097351074\n",
      "val loss 2.2216603755950928\n",
      "______________\n",
      "epoch 607 train loss 2.281057834625244\n",
      "val loss 2.220982551574707\n",
      "______________\n",
      "epoch 608 train loss 2.2805395126342773\n",
      "val loss 2.220322608947754\n",
      "______________\n",
      "epoch 609 train loss 2.583543539047241\n",
      "val loss 2.219696044921875\n",
      "______________\n",
      "epoch 610 train loss 2.467588424682617\n",
      "val loss 2.219071388244629\n",
      "______________\n",
      "epoch 611 train loss 2.3205959796905518\n",
      "val loss 2.2183330059051514\n",
      "______________\n",
      "epoch 612 train loss 2.501924514770508\n",
      "val loss 2.2176694869995117\n",
      "______________\n",
      "epoch 613 train loss 2.4111077785491943\n",
      "val loss 2.21697735786438\n",
      "______________\n",
      "epoch 614 train loss 2.436830759048462\n",
      "val loss 2.2163195610046387\n",
      "______________\n",
      "epoch 615 train loss 2.59224534034729\n",
      "val loss 2.215684652328491\n",
      "______________\n",
      "epoch 616 train loss 2.384243965148926\n",
      "val loss 2.214942693710327\n",
      "______________\n",
      "epoch 617 train loss 2.451395273208618\n",
      "val loss 2.2141971588134766\n",
      "______________\n",
      "epoch 618 train loss 2.3484835624694824\n",
      "val loss 2.213329553604126\n",
      "______________\n",
      "epoch 619 train loss 2.3092353343963623\n",
      "val loss 2.2124240398406982\n",
      "______________\n",
      "epoch 620 train loss 2.3851327896118164\n",
      "val loss 2.211547374725342\n",
      "______________\n",
      "epoch 621 train loss 2.579005241394043\n",
      "val loss 2.210733652114868\n",
      "______________\n",
      "epoch 622 train loss 2.3926966190338135\n",
      "val loss 2.2098464965820312\n",
      "______________\n",
      "epoch 623 train loss 2.450516700744629\n",
      "val loss 2.2089617252349854\n",
      "______________\n",
      "epoch 624 train loss 2.4672303199768066\n",
      "val loss 2.2081220149993896\n",
      "______________\n",
      "epoch 625 train loss 2.5036659240722656\n",
      "val loss 2.2073233127593994\n",
      "______________\n",
      "epoch 626 train loss 2.3855087757110596\n",
      "val loss 2.206423044204712\n",
      "______________\n",
      "epoch 627 train loss 2.5578746795654297\n",
      "val loss 2.205604314804077\n",
      "______________\n",
      "epoch 628 train loss 2.4330835342407227\n",
      "val loss 2.2047202587127686\n",
      "______________\n",
      "epoch 629 train loss 2.4889423847198486\n",
      "val loss 2.2038614749908447\n",
      "______________\n",
      "epoch 630 train loss 2.5650577545166016\n",
      "val loss 2.2030580043792725\n",
      "______________\n",
      "epoch 631 train loss 2.5722930431365967\n",
      "val loss 2.202305793762207\n",
      "______________\n",
      "epoch 632 train loss 2.3165581226348877\n",
      "val loss 2.201585531234741\n",
      "______________\n",
      "epoch 633 train loss 2.3344948291778564\n",
      "val loss 2.200878381729126\n",
      "______________\n",
      "epoch 634 train loss 2.3859148025512695\n",
      "val loss 2.200148344039917\n",
      "______________\n",
      "epoch 635 train loss 2.488478899002075\n",
      "val loss 2.199463367462158\n",
      "______________\n",
      "epoch 636 train loss 2.3678746223449707\n",
      "val loss 2.198768138885498\n",
      "______________\n",
      "epoch 637 train loss 2.4747085571289062\n",
      "val loss 2.1980745792388916\n",
      "______________\n",
      "epoch 638 train loss 2.414341449737549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.197364091873169\n",
      "______________\n",
      "epoch 639 train loss 2.423638105392456\n",
      "val loss 2.196611166000366\n",
      "______________\n",
      "epoch 640 train loss 2.3484134674072266\n",
      "val loss 2.1958463191986084\n",
      "______________\n",
      "epoch 641 train loss 2.3313229084014893\n",
      "val loss 2.1950254440307617\n",
      "______________\n",
      "epoch 642 train loss 2.4148924350738525\n",
      "val loss 2.194106101989746\n",
      "______________\n",
      "epoch 643 train loss 2.3777124881744385\n",
      "val loss 2.193140983581543\n",
      "______________\n",
      "epoch 644 train loss 2.4476308822631836\n",
      "val loss 2.192180871963501\n",
      "______________\n",
      "epoch 645 train loss 2.4658005237579346\n",
      "val loss 2.191211223602295\n",
      "______________\n",
      "epoch 646 train loss 2.4195096492767334\n",
      "val loss 2.190227746963501\n",
      "______________\n",
      "epoch 647 train loss 2.3667447566986084\n",
      "val loss 2.1891822814941406\n",
      "______________\n",
      "epoch 648 train loss 2.3907663822174072\n",
      "val loss 2.188216209411621\n",
      "______________\n",
      "epoch 649 train loss 2.3348028659820557\n",
      "val loss 2.187274694442749\n",
      "______________\n",
      "epoch 650 train loss 2.4062490463256836\n",
      "val loss 2.1863489151000977\n",
      "______________\n",
      "epoch 651 train loss 2.5219876766204834\n",
      "val loss 2.1855177879333496\n",
      "______________\n",
      "epoch 652 train loss 2.4112861156463623\n",
      "val loss 2.184774398803711\n",
      "______________\n",
      "epoch 653 train loss 2.4207048416137695\n",
      "val loss 2.1839592456817627\n",
      "______________\n",
      "epoch 654 train loss 2.2102956771850586\n",
      "val loss 2.1831469535827637\n",
      "______________\n",
      "epoch 655 train loss 2.3915629386901855\n",
      "val loss 2.1822357177734375\n",
      "______________\n",
      "epoch 656 train loss 2.386563301086426\n",
      "val loss 2.1813344955444336\n",
      "______________\n",
      "epoch 657 train loss 2.226741313934326\n",
      "val loss 2.180402994155884\n",
      "______________\n",
      "epoch 658 train loss 2.4588661193847656\n",
      "val loss 2.1795525550842285\n",
      "______________\n",
      "epoch 659 train loss 2.4127681255340576\n",
      "val loss 2.1786789894104004\n",
      "______________\n",
      "epoch 660 train loss 2.4450907707214355\n",
      "val loss 2.1778903007507324\n",
      "______________\n",
      "epoch 661 train loss 2.380450963973999\n",
      "val loss 2.1771018505096436\n",
      "______________\n",
      "epoch 662 train loss 2.4946277141571045\n",
      "val loss 2.176382064819336\n",
      "______________\n",
      "epoch 663 train loss 2.371634006500244\n",
      "val loss 2.175733804702759\n",
      "______________\n",
      "epoch 664 train loss 2.4248337745666504\n",
      "val loss 2.1750879287719727\n",
      "______________\n",
      "epoch 665 train loss 2.4052464962005615\n",
      "val loss 2.1745176315307617\n",
      "______________\n",
      "epoch 666 train loss 2.386704683303833\n",
      "val loss 2.174009084701538\n",
      "______________\n",
      "epoch 667 train loss 2.494551420211792\n",
      "val loss 2.1736032962799072\n",
      "______________\n",
      "epoch 668 train loss 2.395388603210449\n",
      "val loss 2.173123836517334\n",
      "______________\n",
      "epoch 669 train loss 2.437013864517212\n",
      "val loss 2.172639846801758\n",
      "______________\n",
      "epoch 670 train loss 2.570021629333496\n",
      "val loss 2.1721744537353516\n",
      "______________\n",
      "epoch 671 train loss 2.4306654930114746\n",
      "val loss 2.17167067527771\n",
      "______________\n",
      "epoch 672 train loss 2.442868947982788\n",
      "val loss 2.1711390018463135\n",
      "______________\n",
      "epoch 673 train loss 2.329263925552368\n",
      "val loss 2.1706154346466064\n",
      "______________\n",
      "epoch 674 train loss 2.3353381156921387\n",
      "val loss 2.170140504837036\n",
      "______________\n",
      "epoch 675 train loss 2.310929298400879\n",
      "val loss 2.1697022914886475\n",
      "______________\n",
      "epoch 676 train loss 2.2987401485443115\n",
      "val loss 2.1692373752593994\n",
      "______________\n",
      "epoch 677 train loss 2.332042932510376\n",
      "val loss 2.168644428253174\n",
      "______________\n",
      "epoch 678 train loss 2.574080228805542\n",
      "val loss 2.1680734157562256\n",
      "______________\n",
      "epoch 679 train loss 2.3927154541015625\n",
      "val loss 2.1674883365631104\n",
      "______________\n",
      "epoch 680 train loss 2.3934903144836426\n",
      "val loss 2.166923999786377\n",
      "______________\n",
      "epoch 681 train loss 2.3760783672332764\n",
      "val loss 2.16636061668396\n",
      "______________\n",
      "epoch 682 train loss 2.258326768875122\n",
      "val loss 2.1658027172088623\n",
      "______________\n",
      "epoch 683 train loss 2.341397285461426\n",
      "val loss 2.1652870178222656\n",
      "______________\n",
      "epoch 684 train loss 2.400991439819336\n",
      "val loss 2.1647744178771973\n",
      "______________\n",
      "epoch 685 train loss 2.402691602706909\n",
      "val loss 2.1641898155212402\n",
      "______________\n",
      "epoch 686 train loss 2.363255739212036\n",
      "val loss 2.1635422706604004\n",
      "______________\n",
      "epoch 687 train loss 2.3119540214538574\n",
      "val loss 2.162827253341675\n",
      "______________\n",
      "epoch 688 train loss 2.321751117706299\n",
      "val loss 2.1620962619781494\n",
      "______________\n",
      "epoch 689 train loss 2.4061453342437744\n",
      "val loss 2.16137433052063\n",
      "______________\n",
      "epoch 690 train loss 2.4341378211975098\n",
      "val loss 2.1607213020324707\n",
      "______________\n",
      "epoch 691 train loss 2.3831958770751953\n",
      "val loss 2.1600024700164795\n",
      "______________\n",
      "epoch 692 train loss 2.232171058654785\n",
      "val loss 2.159252643585205\n",
      "______________\n",
      "epoch 693 train loss 2.507976770401001\n",
      "val loss 2.1584620475769043\n",
      "______________\n",
      "epoch 694 train loss 2.442293882369995\n",
      "val loss 2.157740831375122\n",
      "______________\n",
      "epoch 695 train loss 2.537088394165039\n",
      "val loss 2.1570825576782227\n",
      "______________\n",
      "epoch 696 train loss 2.3800153732299805\n",
      "val loss 2.1564667224884033\n",
      "______________\n",
      "epoch 697 train loss 2.4789981842041016\n",
      "val loss 2.1558773517608643\n",
      "______________\n",
      "epoch 698 train loss 2.2420053482055664\n",
      "val loss 2.1553328037261963\n",
      "______________\n",
      "epoch 699 train loss 2.345792531967163\n",
      "val loss 2.1548023223876953\n",
      "______________\n",
      "epoch 700 train loss 2.2473983764648438\n",
      "val loss 2.154238224029541\n",
      "______________\n",
      "epoch 701 train loss 2.384713888168335\n",
      "val loss 2.1536753177642822\n",
      "______________\n",
      "epoch 702 train loss 2.4106736183166504\n",
      "val loss 2.1531522274017334\n",
      "______________\n",
      "epoch 703 train loss 2.4256789684295654\n",
      "val loss 2.1526920795440674\n",
      "______________\n",
      "epoch 704 train loss 2.4214415550231934\n",
      "val loss 2.1522328853607178\n",
      "______________\n",
      "epoch 705 train loss 2.271683692932129\n",
      "val loss 2.1517364978790283\n",
      "______________\n",
      "epoch 706 train loss 2.36318302154541\n",
      "val loss 2.1513233184814453\n",
      "______________\n",
      "epoch 707 train loss 2.41277813911438\n",
      "val loss 2.150944709777832\n",
      "______________\n",
      "epoch 708 train loss 2.506612777709961\n",
      "val loss 2.150723934173584\n",
      "______________\n",
      "epoch 709 train loss 2.5043976306915283\n",
      "val loss 2.1504805088043213\n",
      "______________\n",
      "epoch 710 train loss 2.3544392585754395\n",
      "val loss 2.150223970413208\n",
      "______________\n",
      "epoch 711 train loss 2.368879556655884\n",
      "val loss 2.1499693393707275\n",
      "______________\n",
      "epoch 712 train loss 2.3688805103302\n",
      "val loss 2.1497061252593994\n",
      "______________\n",
      "epoch 713 train loss 2.379986524581909\n",
      "val loss 2.1492881774902344\n",
      "______________\n",
      "epoch 714 train loss 2.484424591064453\n",
      "val loss 2.14905047416687\n",
      "______________\n",
      "epoch 715 train loss 2.405285358428955\n",
      "val loss 2.1488146781921387\n",
      "______________\n",
      "epoch 716 train loss 2.454350709915161\n",
      "val loss 2.1485397815704346\n",
      "______________\n",
      "epoch 717 train loss 2.4361493587493896\n",
      "val loss 2.1482417583465576\n",
      "______________\n",
      "epoch 718 train loss 2.410214424133301\n",
      "val loss 2.147970676422119\n",
      "______________\n",
      "epoch 719 train loss 2.357252359390259\n",
      "val loss 2.1476008892059326\n",
      "______________\n",
      "epoch 720 train loss 2.282214403152466\n",
      "val loss 2.1471498012542725\n",
      "______________\n",
      "epoch 721 train loss 2.260146141052246\n",
      "val loss 2.146841287612915\n",
      "______________\n",
      "epoch 722 train loss 2.4525859355926514\n",
      "val loss 2.14650821685791\n",
      "______________\n",
      "epoch 723 train loss 2.3765134811401367\n",
      "val loss 2.1461634635925293\n",
      "______________\n",
      "epoch 724 train loss 2.2852046489715576\n",
      "val loss 2.1457855701446533\n",
      "______________\n",
      "epoch 725 train loss 2.385112762451172\n",
      "val loss 2.145341396331787\n",
      "______________\n",
      "epoch 726 train loss 2.4899699687957764\n",
      "val loss 2.145002603530884\n",
      "______________\n",
      "epoch 727 train loss 2.28825306892395\n",
      "val loss 2.1445767879486084\n",
      "______________\n",
      "epoch 728 train loss 2.3635737895965576\n",
      "val loss 2.1441547870635986\n",
      "______________\n",
      "epoch 729 train loss 2.2464354038238525\n",
      "val loss 2.1437156200408936\n",
      "______________\n",
      "epoch 730 train loss 2.4360077381134033\n",
      "val loss 2.143277645111084\n",
      "______________\n",
      "epoch 731 train loss 2.3632850646972656\n",
      "val loss 2.1428966522216797\n",
      "______________\n",
      "epoch 732 train loss 2.4504406452178955\n",
      "val loss 2.142495632171631\n",
      "______________\n",
      "epoch 733 train loss 2.378727912902832\n",
      "val loss 2.142130136489868\n",
      "______________\n",
      "epoch 734 train loss 2.2923741340637207\n",
      "val loss 2.141683340072632\n",
      "______________\n",
      "epoch 735 train loss 2.394730567932129\n",
      "val loss 2.14121675491333\n",
      "______________\n",
      "epoch 736 train loss 2.332624912261963\n",
      "val loss 2.1406893730163574\n",
      "______________\n",
      "epoch 737 train loss 2.2618656158447266\n",
      "val loss 2.140198230743408\n",
      "______________\n",
      "epoch 738 train loss 2.2648556232452393\n",
      "val loss 2.139732837677002\n",
      "______________\n",
      "epoch 739 train loss 2.263597011566162\n",
      "val loss 2.139315605163574\n",
      "______________\n",
      "epoch 740 train loss 2.4100639820098877\n",
      "val loss 2.1389050483703613\n",
      "______________\n",
      "epoch 741 train loss 2.341804027557373\n",
      "val loss 2.13852858543396\n",
      "______________\n",
      "epoch 742 train loss 2.2696635723114014\n",
      "val loss 2.1381280422210693\n",
      "______________\n",
      "epoch 743 train loss 2.3093788623809814\n",
      "val loss 2.1376760005950928\n",
      "______________\n",
      "epoch 744 train loss 2.2422614097595215\n",
      "val loss 2.137094259262085\n",
      "______________\n",
      "epoch 745 train loss 2.397523880004883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.1365528106689453\n",
      "______________\n",
      "epoch 746 train loss 2.421518564224243\n",
      "val loss 2.1360418796539307\n",
      "______________\n",
      "epoch 747 train loss 2.288177251815796\n",
      "val loss 2.1354470252990723\n",
      "______________\n",
      "epoch 748 train loss 2.4203829765319824\n",
      "val loss 2.1347291469573975\n",
      "______________\n",
      "epoch 749 train loss 2.3228461742401123\n",
      "val loss 2.134099006652832\n",
      "______________\n",
      "epoch 750 train loss 2.277045965194702\n",
      "val loss 2.1333999633789062\n",
      "______________\n",
      "epoch 751 train loss 2.3447539806365967\n",
      "val loss 2.1326446533203125\n",
      "______________\n",
      "epoch 752 train loss 2.156909465789795\n",
      "val loss 2.1318273544311523\n",
      "______________\n",
      "epoch 753 train loss 2.343763589859009\n",
      "val loss 2.1309995651245117\n",
      "______________\n",
      "epoch 754 train loss 2.264204263687134\n",
      "val loss 2.130128860473633\n",
      "______________\n",
      "epoch 755 train loss 2.287170171737671\n",
      "val loss 2.1293118000030518\n",
      "______________\n",
      "epoch 756 train loss 2.2493419647216797\n",
      "val loss 2.1284711360931396\n",
      "______________\n",
      "epoch 757 train loss 2.285388469696045\n",
      "val loss 2.1277122497558594\n",
      "______________\n",
      "epoch 758 train loss 2.3887248039245605\n",
      "val loss 2.1270217895507812\n",
      "______________\n",
      "epoch 759 train loss 2.3918442726135254\n",
      "val loss 2.1263084411621094\n",
      "______________\n",
      "epoch 760 train loss 2.1467790603637695\n",
      "val loss 2.125629186630249\n",
      "______________\n",
      "epoch 761 train loss 2.382655382156372\n",
      "val loss 2.125004529953003\n",
      "______________\n",
      "epoch 762 train loss 2.26824951171875\n",
      "val loss 2.124488592147827\n",
      "______________\n",
      "epoch 763 train loss 2.3723721504211426\n",
      "val loss 2.1240310668945312\n",
      "______________\n",
      "epoch 764 train loss 2.245302677154541\n",
      "val loss 2.123546838760376\n",
      "______________\n",
      "epoch 765 train loss 2.372526168823242\n",
      "val loss 2.1230785846710205\n",
      "______________\n",
      "epoch 766 train loss 2.3441290855407715\n",
      "val loss 2.1227080821990967\n",
      "______________\n",
      "epoch 767 train loss 2.2315046787261963\n",
      "val loss 2.1223061084747314\n",
      "______________\n",
      "epoch 768 train loss 2.4609456062316895\n",
      "val loss 2.1219630241394043\n",
      "______________\n",
      "epoch 769 train loss 2.3273582458496094\n",
      "val loss 2.1216375827789307\n",
      "______________\n",
      "epoch 770 train loss 2.3362953662872314\n",
      "val loss 2.121399164199829\n",
      "______________\n",
      "epoch 771 train loss 2.315924882888794\n",
      "val loss 2.12115216255188\n",
      "______________\n",
      "epoch 772 train loss 2.4884607791900635\n",
      "val loss 2.1209182739257812\n",
      "______________\n",
      "epoch 773 train loss 2.3823740482330322\n",
      "val loss 2.120621681213379\n",
      "______________\n",
      "epoch 774 train loss 2.2995200157165527\n",
      "val loss 2.1203272342681885\n",
      "______________\n",
      "epoch 775 train loss 2.310560703277588\n",
      "val loss 2.120067834854126\n",
      "______________\n",
      "epoch 776 train loss 2.291872978210449\n",
      "val loss 2.1198432445526123\n",
      "______________\n",
      "epoch 777 train loss 2.215113401412964\n",
      "val loss 2.119544267654419\n",
      "______________\n",
      "epoch 778 train loss 2.203195333480835\n",
      "val loss 2.1191670894622803\n",
      "______________\n",
      "epoch 779 train loss 2.243981122970581\n",
      "val loss 2.118833065032959\n",
      "______________\n",
      "epoch 780 train loss 2.194432258605957\n",
      "val loss 2.1184592247009277\n",
      "______________\n",
      "epoch 781 train loss 2.219618558883667\n",
      "val loss 2.118117094039917\n",
      "______________\n",
      "epoch 782 train loss 2.3664865493774414\n",
      "val loss 2.1178102493286133\n",
      "______________\n",
      "epoch 783 train loss 2.2830069065093994\n",
      "val loss 2.117434501647949\n",
      "______________\n",
      "epoch 784 train loss 2.318182945251465\n",
      "val loss 2.117112874984741\n",
      "______________\n",
      "epoch 785 train loss 2.21097731590271\n",
      "val loss 2.11677885055542\n",
      "______________\n",
      "epoch 786 train loss 2.3512067794799805\n",
      "val loss 2.116464138031006\n",
      "______________\n",
      "epoch 787 train loss 2.2437198162078857\n",
      "val loss 2.116137981414795\n",
      "______________\n",
      "epoch 788 train loss 2.274468183517456\n",
      "val loss 2.115878105163574\n",
      "______________\n",
      "epoch 789 train loss 2.232637882232666\n",
      "val loss 2.1155054569244385\n",
      "______________\n",
      "epoch 790 train loss 2.3263473510742188\n",
      "val loss 2.1151864528656006\n",
      "______________\n",
      "epoch 791 train loss 2.1292686462402344\n",
      "val loss 2.1148228645324707\n",
      "______________\n",
      "epoch 792 train loss 2.4411561489105225\n",
      "val loss 2.1144704818725586\n",
      "______________\n",
      "epoch 793 train loss 2.311309337615967\n",
      "val loss 2.1140992641448975\n",
      "______________\n",
      "epoch 794 train loss 2.3495211601257324\n",
      "val loss 2.1137332916259766\n",
      "______________\n",
      "epoch 795 train loss 2.198610305786133\n",
      "val loss 2.113297700881958\n",
      "______________\n",
      "epoch 796 train loss 2.3773703575134277\n",
      "val loss 2.1129355430603027\n",
      "______________\n",
      "epoch 797 train loss 2.171677827835083\n",
      "val loss 2.1125080585479736\n",
      "______________\n",
      "epoch 798 train loss 2.304624557495117\n",
      "val loss 2.112088918685913\n",
      "______________\n",
      "epoch 799 train loss 2.3331000804901123\n",
      "val loss 2.1117911338806152\n",
      "______________\n",
      "epoch 800 train loss 2.3385839462280273\n",
      "val loss 2.1114871501922607\n",
      "______________\n",
      "epoch 801 train loss 2.3272290229797363\n",
      "val loss 2.1111626625061035\n",
      "______________\n",
      "epoch 802 train loss 2.293825387954712\n",
      "val loss 2.1107490062713623\n",
      "______________\n",
      "epoch 803 train loss 2.1877620220184326\n",
      "val loss 2.1101555824279785\n",
      "______________\n",
      "epoch 804 train loss 2.350982904434204\n",
      "val loss 2.10952091217041\n",
      "______________\n",
      "epoch 805 train loss 2.1364786624908447\n",
      "val loss 2.1089024543762207\n",
      "______________\n",
      "epoch 806 train loss 2.317866086959839\n",
      "val loss 2.1083154678344727\n",
      "______________\n",
      "epoch 807 train loss 2.2358474731445312\n",
      "val loss 2.1076345443725586\n",
      "______________\n",
      "epoch 808 train loss 2.279691457748413\n",
      "val loss 2.10701847076416\n",
      "______________\n",
      "epoch 809 train loss 2.234890937805176\n",
      "val loss 2.106365919113159\n",
      "______________\n",
      "epoch 810 train loss 2.319821834564209\n",
      "val loss 2.1057186126708984\n",
      "______________\n",
      "epoch 811 train loss 2.326432466506958\n",
      "val loss 2.1051528453826904\n",
      "______________\n",
      "epoch 812 train loss 2.291325092315674\n",
      "val loss 2.104628324508667\n",
      "______________\n",
      "epoch 813 train loss 2.2118704319000244\n",
      "val loss 2.104025363922119\n",
      "______________\n",
      "epoch 814 train loss 2.261970043182373\n",
      "val loss 2.10349440574646\n",
      "______________\n",
      "epoch 815 train loss 2.549816608428955\n",
      "val loss 2.103111505508423\n",
      "______________\n",
      "epoch 816 train loss 2.281926155090332\n",
      "val loss 2.1027462482452393\n",
      "______________\n",
      "epoch 817 train loss 2.316885471343994\n",
      "val loss 2.102381467819214\n",
      "______________\n",
      "epoch 818 train loss 2.264814853668213\n",
      "val loss 2.1020917892456055\n",
      "______________\n",
      "epoch 819 train loss 2.2802436351776123\n",
      "val loss 2.1017892360687256\n",
      "______________\n",
      "epoch 820 train loss 2.1751389503479004\n",
      "val loss 2.1015546321868896\n",
      "______________\n",
      "epoch 821 train loss 2.263941764831543\n",
      "val loss 2.1012823581695557\n",
      "______________\n",
      "epoch 822 train loss 2.3232338428497314\n",
      "val loss 2.100944757461548\n",
      "______________\n",
      "epoch 823 train loss 2.2480833530426025\n",
      "val loss 2.1006319522857666\n",
      "______________\n",
      "epoch 824 train loss 2.3443751335144043\n",
      "val loss 2.1003167629241943\n",
      "______________\n",
      "epoch 825 train loss 2.3381330966949463\n",
      "val loss 2.099963665008545\n",
      "______________\n",
      "epoch 826 train loss 2.3862953186035156\n",
      "val loss 2.099646806716919\n",
      "______________\n",
      "epoch 827 train loss 2.3262665271759033\n",
      "val loss 2.099320888519287\n",
      "______________\n",
      "epoch 828 train loss 2.2981841564178467\n",
      "val loss 2.0989975929260254\n",
      "______________\n",
      "epoch 829 train loss 2.377300500869751\n",
      "val loss 2.0987844467163086\n",
      "______________\n",
      "epoch 830 train loss 2.3305013179779053\n",
      "val loss 2.098634719848633\n",
      "______________\n",
      "epoch 831 train loss 2.3688178062438965\n",
      "val loss 2.098414421081543\n",
      "______________\n",
      "epoch 832 train loss 2.3715388774871826\n",
      "val loss 2.0982131958007812\n",
      "______________\n",
      "epoch 833 train loss 2.2298812866210938\n",
      "val loss 2.0980136394500732\n",
      "______________\n",
      "epoch 834 train loss 2.316734790802002\n",
      "val loss 2.0978753566741943\n",
      "______________\n",
      "epoch 835 train loss 2.305938482284546\n",
      "val loss 2.097830295562744\n",
      "______________\n",
      "epoch 836 train loss 2.319742441177368\n",
      "val loss 2.0978281497955322\n",
      "______________\n",
      "epoch 837 train loss 2.2391374111175537\n",
      "val loss 2.0976967811584473\n",
      "______________\n",
      "epoch 838 train loss 2.3345353603363037\n",
      "val loss 2.0976009368896484\n",
      "______________\n",
      "epoch 839 train loss 2.199578285217285\n",
      "val loss 2.097337007522583\n",
      "______________\n",
      "epoch 840 train loss 2.224170684814453\n",
      "val loss 2.097062826156616\n",
      "______________\n",
      "epoch 841 train loss 2.337082862854004\n",
      "val loss 2.0968070030212402\n",
      "______________\n",
      "epoch 842 train loss 2.120882749557495\n",
      "val loss 2.0964863300323486\n",
      "______________\n",
      "epoch 843 train loss 2.248110771179199\n",
      "val loss 2.0961406230926514\n",
      "______________\n",
      "epoch 844 train loss 2.2990992069244385\n",
      "val loss 2.0958478450775146\n",
      "______________\n",
      "epoch 845 train loss 2.303586483001709\n",
      "val loss 2.095541000366211\n",
      "______________\n",
      "epoch 846 train loss 2.137220859527588\n",
      "val loss 2.095139265060425\n",
      "______________\n",
      "epoch 847 train loss 2.2783427238464355\n",
      "val loss 2.094791889190674\n",
      "______________\n",
      "epoch 848 train loss 2.277580976486206\n",
      "val loss 2.0944647789001465\n",
      "______________\n",
      "epoch 849 train loss 2.3336334228515625\n",
      "val loss 2.0941500663757324\n",
      "______________\n",
      "epoch 850 train loss 2.1876721382141113\n",
      "val loss 2.0937693119049072\n",
      "______________\n",
      "epoch 851 train loss 2.234424591064453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.0934395790100098\n",
      "______________\n",
      "epoch 852 train loss 2.406705856323242\n",
      "val loss 2.0931806564331055\n",
      "______________\n",
      "epoch 853 train loss 2.3105149269104004\n",
      "val loss 2.0930094718933105\n",
      "______________\n",
      "epoch 854 train loss 2.2468016147613525\n",
      "val loss 2.0928287506103516\n",
      "______________\n",
      "epoch 855 train loss 2.276496410369873\n",
      "val loss 2.092653274536133\n",
      "______________\n",
      "epoch 856 train loss 2.4028759002685547\n",
      "val loss 2.0924646854400635\n",
      "______________\n",
      "epoch 857 train loss 2.2224371433258057\n",
      "val loss 2.092186450958252\n",
      "______________\n",
      "epoch 858 train loss 2.2755298614501953\n",
      "val loss 2.0919830799102783\n",
      "______________\n",
      "epoch 859 train loss 2.2336840629577637\n",
      "val loss 2.0917136669158936\n",
      "______________\n",
      "epoch 860 train loss 2.2495858669281006\n",
      "val loss 2.0914645195007324\n",
      "______________\n",
      "epoch 861 train loss 2.121397018432617\n",
      "val loss 2.091163396835327\n",
      "______________\n",
      "epoch 862 train loss 2.323371410369873\n",
      "val loss 2.0910232067108154\n",
      "______________\n",
      "epoch 863 train loss 2.240656614303589\n",
      "val loss 2.0908453464508057\n",
      "______________\n",
      "epoch 864 train loss 2.2916793823242188\n",
      "val loss 2.09066104888916\n",
      "______________\n",
      "epoch 865 train loss 2.2339119911193848\n",
      "val loss 2.0904653072357178\n",
      "______________\n",
      "epoch 866 train loss 2.37804913520813\n",
      "val loss 2.0903160572052\n",
      "______________\n",
      "epoch 867 train loss 2.2953567504882812\n",
      "val loss 2.0901107788085938\n",
      "______________\n",
      "epoch 868 train loss 2.3151705265045166\n",
      "val loss 2.0897974967956543\n",
      "______________\n",
      "epoch 869 train loss 2.334500551223755\n",
      "val loss 2.089552640914917\n",
      "______________\n",
      "epoch 870 train loss 2.275350570678711\n",
      "val loss 2.08927583694458\n",
      "______________\n",
      "epoch 871 train loss 2.2028799057006836\n",
      "val loss 2.089001417160034\n",
      "______________\n",
      "epoch 872 train loss 2.2159922122955322\n",
      "val loss 2.08866810798645\n",
      "______________\n",
      "epoch 873 train loss 2.2623231410980225\n",
      "val loss 2.088416814804077\n",
      "______________\n",
      "epoch 874 train loss 2.3056957721710205\n",
      "val loss 2.0881435871124268\n",
      "______________\n",
      "epoch 875 train loss 2.3365654945373535\n",
      "val loss 2.0879392623901367\n",
      "______________\n",
      "epoch 876 train loss 2.2344961166381836\n",
      "val loss 2.087660074234009\n",
      "______________\n",
      "epoch 877 train loss 2.2830910682678223\n",
      "val loss 2.0874831676483154\n",
      "______________\n",
      "epoch 878 train loss 2.2466418743133545\n",
      "val loss 2.087338447570801\n",
      "______________\n",
      "epoch 879 train loss 2.2003073692321777\n",
      "val loss 2.087162971496582\n",
      "______________\n",
      "epoch 880 train loss 2.1645283699035645\n",
      "val loss 2.0868141651153564\n",
      "______________\n",
      "epoch 881 train loss 2.192265272140503\n",
      "val loss 2.0864615440368652\n",
      "______________\n",
      "epoch 882 train loss 2.4136009216308594\n",
      "val loss 2.08616304397583\n",
      "______________\n",
      "epoch 883 train loss 2.1648924350738525\n",
      "val loss 2.0858917236328125\n",
      "______________\n",
      "epoch 884 train loss 2.1888370513916016\n",
      "val loss 2.0857038497924805\n",
      "______________\n",
      "epoch 885 train loss 2.076143503189087\n",
      "val loss 2.085343837738037\n",
      "______________\n",
      "epoch 886 train loss 2.3327200412750244\n",
      "val loss 2.084885597229004\n",
      "______________\n",
      "epoch 887 train loss 2.2282371520996094\n",
      "val loss 2.0844202041625977\n",
      "______________\n",
      "epoch 888 train loss 2.139296531677246\n",
      "val loss 2.0839271545410156\n",
      "______________\n",
      "epoch 889 train loss 2.1644225120544434\n",
      "val loss 2.083343505859375\n",
      "______________\n",
      "epoch 890 train loss 2.256885051727295\n",
      "val loss 2.082822799682617\n",
      "______________\n",
      "epoch 891 train loss 2.2870354652404785\n",
      "val loss 2.0823497772216797\n",
      "______________\n",
      "epoch 892 train loss 2.1844236850738525\n",
      "val loss 2.081864833831787\n",
      "______________\n",
      "epoch 893 train loss 2.275228261947632\n",
      "val loss 2.081387996673584\n",
      "______________\n",
      "epoch 894 train loss 2.350994110107422\n",
      "val loss 2.0809597969055176\n",
      "______________\n",
      "epoch 895 train loss 2.178544282913208\n",
      "val loss 2.080530881881714\n",
      "______________\n",
      "epoch 896 train loss 2.229196548461914\n",
      "val loss 2.0801382064819336\n",
      "______________\n",
      "epoch 897 train loss 2.235283851623535\n",
      "val loss 2.07979154586792\n",
      "______________\n",
      "epoch 898 train loss 2.1226563453674316\n",
      "val loss 2.0794284343719482\n",
      "______________\n",
      "epoch 899 train loss 2.2525651454925537\n",
      "val loss 2.0791096687316895\n",
      "______________\n",
      "epoch 900 train loss 2.234238624572754\n",
      "val loss 2.0788967609405518\n",
      "______________\n",
      "epoch 901 train loss 2.0548713207244873\n",
      "val loss 2.078622817993164\n",
      "______________\n",
      "epoch 902 train loss 2.210648775100708\n",
      "val loss 2.0783309936523438\n",
      "______________\n",
      "epoch 903 train loss 2.1319947242736816\n",
      "val loss 2.078098773956299\n",
      "______________\n",
      "epoch 904 train loss 2.2437007427215576\n",
      "val loss 2.077927350997925\n",
      "______________\n",
      "epoch 905 train loss 2.35774564743042\n",
      "val loss 2.0777761936187744\n",
      "______________\n",
      "epoch 906 train loss 2.3392632007598877\n",
      "val loss 2.077631711959839\n",
      "______________\n",
      "epoch 907 train loss 2.22491717338562\n",
      "val loss 2.0775866508483887\n",
      "______________\n",
      "epoch 908 train loss 2.207226037979126\n",
      "val loss 2.0775675773620605\n",
      "______________\n",
      "epoch 909 train loss 2.163954257965088\n",
      "val loss 2.077483654022217\n",
      "______________\n",
      "epoch 910 train loss 2.155485153198242\n",
      "val loss 2.077298402786255\n",
      "______________\n",
      "epoch 911 train loss 2.166710376739502\n",
      "val loss 2.077033281326294\n",
      "______________\n",
      "epoch 912 train loss 2.29534912109375\n",
      "val loss 2.0767576694488525\n",
      "______________\n",
      "epoch 913 train loss 2.2746615409851074\n",
      "val loss 2.0764105319976807\n",
      "______________\n",
      "epoch 914 train loss 2.117659568786621\n",
      "val loss 2.0760505199432373\n",
      "______________\n",
      "epoch 915 train loss 2.2505900859832764\n",
      "val loss 2.0756936073303223\n",
      "______________\n",
      "epoch 916 train loss 2.1979148387908936\n",
      "val loss 2.075214147567749\n",
      "______________\n",
      "epoch 917 train loss 2.227261543273926\n",
      "val loss 2.074716567993164\n",
      "______________\n",
      "epoch 918 train loss 2.2207818031311035\n",
      "val loss 2.0741918087005615\n",
      "______________\n",
      "epoch 919 train loss 2.0691323280334473\n",
      "val loss 2.0736892223358154\n",
      "______________\n",
      "epoch 920 train loss 2.207073211669922\n",
      "val loss 2.0731492042541504\n",
      "______________\n",
      "epoch 921 train loss 2.206451177597046\n",
      "val loss 2.072638750076294\n",
      "______________\n",
      "epoch 922 train loss 2.198185920715332\n",
      "val loss 2.0721964836120605\n",
      "______________\n",
      "epoch 923 train loss 2.3622913360595703\n",
      "val loss 2.0718321800231934\n",
      "______________\n",
      "epoch 924 train loss 2.229562759399414\n",
      "val loss 2.0714774131774902\n",
      "______________\n",
      "epoch 925 train loss 2.202796697616577\n",
      "val loss 2.071188449859619\n",
      "______________\n",
      "epoch 926 train loss 2.224430561065674\n",
      "val loss 2.070910692214966\n",
      "______________\n",
      "epoch 927 train loss 2.230875253677368\n",
      "val loss 2.070685386657715\n",
      "______________\n",
      "epoch 928 train loss 2.1377415657043457\n",
      "val loss 2.070397138595581\n",
      "______________\n",
      "epoch 929 train loss 2.23860239982605\n",
      "val loss 2.0701379776000977\n",
      "______________\n",
      "epoch 930 train loss 2.2002346515655518\n",
      "val loss 2.0699427127838135\n",
      "______________\n",
      "epoch 931 train loss 2.137986660003662\n",
      "val loss 2.0697433948516846\n",
      "______________\n",
      "epoch 932 train loss 2.2277936935424805\n",
      "val loss 2.0695712566375732\n",
      "______________\n",
      "epoch 933 train loss 2.261343002319336\n",
      "val loss 2.0694010257720947\n",
      "______________\n",
      "epoch 934 train loss 2.26198410987854\n",
      "val loss 2.069192886352539\n",
      "______________\n",
      "epoch 935 train loss 2.255098342895508\n",
      "val loss 2.0689778327941895\n",
      "______________\n",
      "epoch 936 train loss 2.1117899417877197\n",
      "val loss 2.0686397552490234\n",
      "______________\n",
      "epoch 937 train loss 2.295579195022583\n",
      "val loss 2.0683810710906982\n",
      "______________\n",
      "epoch 938 train loss 2.3510992527008057\n",
      "val loss 2.0681183338165283\n",
      "______________\n",
      "epoch 939 train loss 2.1459248065948486\n",
      "val loss 2.0678696632385254\n",
      "______________\n",
      "epoch 940 train loss 2.2892749309539795\n",
      "val loss 2.067706346511841\n",
      "______________\n",
      "epoch 941 train loss 2.3065543174743652\n",
      "val loss 2.06750226020813\n",
      "______________\n",
      "epoch 942 train loss 2.059140205383301\n",
      "val loss 2.067260980606079\n",
      "______________\n",
      "epoch 943 train loss 2.1621718406677246\n",
      "val loss 2.0670602321624756\n",
      "______________\n",
      "epoch 944 train loss 2.195826768875122\n",
      "val loss 2.066838264465332\n",
      "______________\n",
      "epoch 945 train loss 2.1219825744628906\n",
      "val loss 2.0665180683135986\n",
      "______________\n",
      "epoch 946 train loss 2.148452043533325\n",
      "val loss 2.0663130283355713\n",
      "______________\n",
      "epoch 947 train loss 2.166922092437744\n",
      "val loss 2.0661628246307373\n",
      "______________\n",
      "epoch 948 train loss 2.3139328956604004\n",
      "val loss 2.0660831928253174\n",
      "______________\n",
      "epoch 949 train loss 2.2142786979675293\n",
      "val loss 2.0660250186920166\n",
      "______________\n",
      "epoch 950 train loss 2.177516460418701\n",
      "val loss 2.0658838748931885\n",
      "______________\n",
      "epoch 951 train loss 2.2179996967315674\n",
      "val loss 2.0657289028167725\n",
      "______________\n",
      "epoch 952 train loss 2.1451568603515625\n",
      "val loss 2.0655603408813477\n",
      "______________\n",
      "epoch 953 train loss 2.102970600128174\n",
      "val loss 2.065326452255249\n",
      "______________\n",
      "epoch 954 train loss 2.177131175994873\n",
      "val loss 2.0651357173919678\n",
      "______________\n",
      "epoch 955 train loss 2.153120756149292\n",
      "val loss 2.0649242401123047\n",
      "______________\n",
      "epoch 956 train loss 2.230740785598755\n",
      "val loss 2.0646703243255615\n",
      "______________\n",
      "epoch 957 train loss 2.3477115631103516\n",
      "val loss 2.064441204071045\n",
      "______________\n",
      "epoch 958 train loss 2.098691463470459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 2.064159631729126\n",
      "______________\n",
      "epoch 959 train loss 2.1094861030578613\n",
      "val loss 2.0639376640319824\n",
      "______________\n",
      "epoch 960 train loss 2.162257671356201\n",
      "val loss 2.063725471496582\n",
      "______________\n",
      "epoch 961 train loss 2.254152297973633\n",
      "val loss 2.0635952949523926\n",
      "______________\n",
      "epoch 962 train loss 2.2359261512756348\n",
      "val loss 2.06352162361145\n",
      "______________\n",
      "epoch 963 train loss 2.095539093017578\n",
      "val loss 2.0634758472442627\n",
      "______________\n",
      "epoch 964 train loss 2.111147880554199\n",
      "val loss 2.063382863998413\n",
      "______________\n",
      "epoch 965 train loss 2.2358953952789307\n",
      "val loss 2.0633201599121094\n",
      "______________\n",
      "epoch 966 train loss 2.282724380493164\n",
      "val loss 2.0634093284606934\n",
      "______________\n",
      "epoch 967 train loss 2.0360641479492188\n",
      "val loss 2.063382863998413\n",
      "______________\n",
      "epoch 968 train loss 2.182522773742676\n",
      "val loss 2.0633492469787598\n",
      "______________\n",
      "epoch 969 train loss 2.1436967849731445\n",
      "val loss 2.063270330429077\n",
      "______________\n",
      "epoch 970 train loss 2.2676637172698975\n",
      "val loss 2.06318998336792\n",
      "______________\n",
      "epoch 971 train loss 2.1611859798431396\n",
      "val loss 2.063093423843384\n",
      "______________\n",
      "epoch 972 train loss 2.188055992126465\n",
      "val loss 2.0629467964172363\n",
      "______________\n",
      "epoch 973 train loss 2.240060567855835\n",
      "val loss 2.0628206729888916\n",
      "______________\n",
      "epoch 974 train loss 2.0952672958374023\n",
      "val loss 2.0627408027648926\n",
      "______________\n",
      "epoch 975 train loss 2.197843551635742\n",
      "val loss 2.062669277191162\n",
      "______________\n",
      "epoch 976 train loss 2.212578773498535\n",
      "val loss 2.0625734329223633\n",
      "______________\n",
      "epoch 977 train loss 2.1276931762695312\n",
      "val loss 2.0625\n",
      "______________\n",
      "epoch 978 train loss 2.0811798572540283\n",
      "val loss 2.062324285507202\n",
      "______________\n",
      "epoch 979 train loss 2.0808682441711426\n",
      "val loss 2.061981201171875\n",
      "______________\n",
      "epoch 980 train loss 2.1239442825317383\n",
      "val loss 2.061647415161133\n",
      "______________\n",
      "epoch 981 train loss 2.170213460922241\n",
      "val loss 2.061284303665161\n",
      "______________\n",
      "epoch 982 train loss 2.159324884414673\n",
      "val loss 2.06088924407959\n",
      "______________\n",
      "epoch 983 train loss 2.3082339763641357\n",
      "val loss 2.0606157779693604\n",
      "______________\n",
      "epoch 984 train loss 2.1892709732055664\n",
      "val loss 2.060368299484253\n",
      "______________\n",
      "epoch 985 train loss 2.0928523540496826\n",
      "val loss 2.060112476348877\n",
      "______________\n",
      "epoch 986 train loss 2.172717809677124\n",
      "val loss 2.0599448680877686\n",
      "______________\n",
      "epoch 987 train loss 2.18198823928833\n",
      "val loss 2.0598409175872803\n",
      "______________\n",
      "epoch 988 train loss 2.227834463119507\n",
      "val loss 2.0598180294036865\n",
      "______________\n",
      "epoch 989 train loss 2.140763282775879\n",
      "val loss 2.059751272201538\n",
      "______________\n",
      "epoch 990 train loss 2.1175811290740967\n",
      "val loss 2.059443950653076\n",
      "______________\n",
      "epoch 991 train loss 2.1504507064819336\n",
      "val loss 2.0591437816619873\n",
      "______________\n",
      "epoch 992 train loss 2.1833560466766357\n",
      "val loss 2.05879545211792\n",
      "______________\n",
      "epoch 993 train loss 2.053800582885742\n",
      "val loss 2.058342933654785\n",
      "______________\n",
      "epoch 994 train loss 2.1014976501464844\n",
      "val loss 2.057898759841919\n",
      "______________\n",
      "epoch 995 train loss 2.2648422718048096\n",
      "val loss 2.057497262954712\n",
      "______________\n",
      "epoch 996 train loss 2.2152326107025146\n",
      "val loss 2.057135820388794\n",
      "______________\n",
      "epoch 997 train loss 2.153197765350342\n",
      "val loss 2.056824207305908\n",
      "______________\n",
      "epoch 998 train loss 2.0313010215759277\n",
      "val loss 2.0565247535705566\n",
      "______________\n",
      "epoch 999 train loss 2.210550546646118\n",
      "val loss 2.056269645690918\n",
      "______________\n",
      "best loss 2.056269645690918 {'pd': {'accuracy': 0.5164565826330533, 'roc_micro': 0.6913838120104439, 'roc_macro': 0.615764172340734}, 'nd': {'accuracy': 0.5939808266540939, 'roc_micro': 0.7218818916932125, 'roc_macro': 0.6681705975184237}, 'mod': {'accuracy': 0.5939808266540939, 'roc_micro': 0.7218818916932125, 'roc_macro': 0.6681705975184237}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9691780821917808, 'auc': [0.9184149184149184, 0.9521885521885521, 0.9514925373134329, -1, 0.9276595744680851, -1, 0.8976190476190476, -1], 'auc_mean': 0.20592182875050452}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=50, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_state(model=None,\n",
    "                model_args={},\n",
    "                state=1,\n",
    "                split=.7,\n",
    "                lr=.0001,\n",
    "                epochs=1000,\n",
    "                patience=10,\n",
    "                use_attention=True,\n",
    "                weights=[1,1,1,10],\n",
    "                save_path='../data/models/',\n",
    "                use_default_split=True,\n",
    "                use_bagging_split=False,\n",
    "                resample_training=False,#use bootstraping on training data after splitting\n",
    "                n_validation_trainsteps=2,\n",
    "                verbose=True,\n",
    "                use_smote=True,\n",
    "                file_suffix=''):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    if use_smote:\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids)\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "\n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids)\n",
    "    \n",
    "\n",
    "    if not use_attention:\n",
    "        model_args = {k:v for k,v in model_args.items() if 'attention' not in k and 'embed_size' not in k}\n",
    "    if state < 3:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = OutcomeAttentionSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "            else:\n",
    "                model = OutcomeSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "        lfunc = state_loss\n",
    "    else:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = EndpointAttentionSimulator(xtrain.shape[1],**model_args)\n",
    "            else:\n",
    "                model = EndpointSimulator(xtrain.shape[1],**model_args)\n",
    "        weights = weights[:3]\n",
    "        lfunc = outcome_loss\n",
    "        \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    save_file = save_path + 'model_' + model.identifier + '_split' + str(split) + '_resample' + str(resample_training) +  '_hash' + hashcode + file_suffix + '.tar'\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    model.fit_normalizer(xtrain)\n",
    "#     normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "#     unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    last_epoch = False\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(xtrain_sample)\n",
    "        loss = lfunc(ytrain,ypred,weights=weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        if state < 3:\n",
    "            val_metrics = state_metrics(ytest,yval)\n",
    "        else:\n",
    "            val_metrics = outcome_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if verbose:\n",
    "            print('val loss',val_loss.item())\n",
    "            print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    #train one step on validation data\n",
    "    for i in range(n_validation_trainsteps):\n",
    "        model.train()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        val_loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model.state_dict(),save_file)\n",
    "    \n",
    "    model.eval()\n",
    "    return model,  best_val_loss, best_loss_metrics\n",
    "\n",
    "t1_args = {'hidden_layers': [1000], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model1,_,_ = train_state(model_args=t1_args,use_attention=False,use_smote=False)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1a06334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 10.844374656677246\n",
      "val loss 10.376598358154297\n",
      "______________\n",
      "epoch 1 train loss 10.724784851074219\n",
      "val loss 10.22596263885498\n",
      "______________\n",
      "epoch 2 train loss 10.525107383728027\n",
      "val loss 10.082180976867676\n",
      "______________\n",
      "epoch 3 train loss 10.319523811340332\n",
      "val loss 9.94363021850586\n",
      "______________\n",
      "epoch 4 train loss 10.250266075134277\n",
      "val loss 9.809475898742676\n",
      "______________\n",
      "epoch 5 train loss 9.961845397949219\n",
      "val loss 9.679276466369629\n",
      "______________\n",
      "epoch 6 train loss 9.825467109680176\n",
      "val loss 9.552268028259277\n",
      "______________\n",
      "epoch 7 train loss 9.61941146850586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 9.42834758758545\n",
      "______________\n",
      "epoch 8 train loss 9.569151878356934\n",
      "val loss 9.306841850280762\n",
      "______________\n",
      "epoch 9 train loss 9.315780639648438\n",
      "val loss 9.187287330627441\n",
      "______________\n",
      "epoch 10 train loss 9.312115669250488\n",
      "val loss 9.069486618041992\n",
      "______________\n",
      "epoch 11 train loss 9.063375473022461\n",
      "val loss 8.95294189453125\n",
      "______________\n",
      "epoch 12 train loss 8.973291397094727\n",
      "val loss 8.83779525756836\n",
      "______________\n",
      "epoch 13 train loss 8.85146713256836\n",
      "val loss 8.723657608032227\n",
      "______________\n",
      "epoch 14 train loss 8.746414184570312\n",
      "val loss 8.61051082611084\n",
      "______________\n",
      "epoch 15 train loss 8.617608070373535\n",
      "val loss 8.4981050491333\n",
      "______________\n",
      "epoch 16 train loss 8.466524124145508\n",
      "val loss 8.386335372924805\n",
      "______________\n",
      "epoch 17 train loss 8.400378227233887\n",
      "val loss 8.275148391723633\n",
      "______________\n",
      "epoch 18 train loss 8.181365013122559\n",
      "val loss 8.164520263671875\n",
      "______________\n",
      "epoch 19 train loss 8.17809009552002\n",
      "val loss 8.054410934448242\n",
      "______________\n",
      "epoch 20 train loss 8.03363037109375\n",
      "val loss 7.9449615478515625\n",
      "______________\n",
      "epoch 21 train loss 7.858675956726074\n",
      "val loss 7.836215496063232\n",
      "______________\n",
      "epoch 22 train loss 7.6397271156311035\n",
      "val loss 7.727807521820068\n",
      "______________\n",
      "epoch 23 train loss 7.647384166717529\n",
      "val loss 7.619945049285889\n",
      "______________\n",
      "epoch 24 train loss 7.487921237945557\n",
      "val loss 7.512704372406006\n",
      "______________\n",
      "epoch 25 train loss 7.427606582641602\n",
      "val loss 7.406143665313721\n",
      "______________\n",
      "epoch 26 train loss 7.201350212097168\n",
      "val loss 7.300188064575195\n",
      "______________\n",
      "epoch 27 train loss 7.240921974182129\n",
      "val loss 7.1949286460876465\n",
      "______________\n",
      "epoch 28 train loss 7.117316722869873\n",
      "val loss 7.090727806091309\n",
      "______________\n",
      "epoch 29 train loss 7.046900272369385\n",
      "val loss 6.987698078155518\n",
      "______________\n",
      "epoch 30 train loss 7.0222673416137695\n",
      "val loss 6.8858184814453125\n",
      "______________\n",
      "epoch 31 train loss 6.834865570068359\n",
      "val loss 6.7853851318359375\n",
      "______________\n",
      "epoch 32 train loss 6.737785816192627\n",
      "val loss 6.686336994171143\n",
      "______________\n",
      "epoch 33 train loss 6.741597652435303\n",
      "val loss 6.588597774505615\n",
      "______________\n",
      "epoch 34 train loss 6.570941925048828\n",
      "val loss 6.492539882659912\n",
      "______________\n",
      "epoch 35 train loss 6.543216705322266\n",
      "val loss 6.398311138153076\n",
      "______________\n",
      "epoch 36 train loss 6.414637565612793\n",
      "val loss 6.305730819702148\n",
      "______________\n",
      "epoch 37 train loss 6.2647271156311035\n",
      "val loss 6.215084075927734\n",
      "______________\n",
      "epoch 38 train loss 6.167296409606934\n",
      "val loss 6.1262054443359375\n",
      "______________\n",
      "epoch 39 train loss 6.157575607299805\n",
      "val loss 6.039402008056641\n",
      "______________\n",
      "epoch 40 train loss 6.049950122833252\n",
      "val loss 5.954827308654785\n",
      "______________\n",
      "epoch 41 train loss 6.020556926727295\n",
      "val loss 5.872222900390625\n",
      "______________\n",
      "epoch 42 train loss 5.888595104217529\n",
      "val loss 5.791939735412598\n",
      "______________\n",
      "epoch 43 train loss 5.8680739402771\n",
      "val loss 5.714094638824463\n",
      "______________\n",
      "epoch 44 train loss 5.83629035949707\n",
      "val loss 5.638340950012207\n",
      "______________\n",
      "epoch 45 train loss 5.809852123260498\n",
      "val loss 5.56488561630249\n",
      "______________\n",
      "epoch 46 train loss 5.678583145141602\n",
      "val loss 5.493892192840576\n",
      "______________\n",
      "epoch 47 train loss 5.737761497497559\n",
      "val loss 5.425351619720459\n",
      "______________\n",
      "epoch 48 train loss 5.500267505645752\n",
      "val loss 5.358819961547852\n",
      "______________\n",
      "epoch 49 train loss 5.517838478088379\n",
      "val loss 5.2945556640625\n",
      "______________\n",
      "epoch 50 train loss 5.4736504554748535\n",
      "val loss 5.232573509216309\n",
      "______________\n",
      "epoch 51 train loss 5.436333179473877\n",
      "val loss 5.172722339630127\n",
      "______________\n",
      "epoch 52 train loss 5.410581111907959\n",
      "val loss 5.115016460418701\n",
      "______________\n",
      "epoch 53 train loss 5.289875030517578\n",
      "val loss 5.059418678283691\n",
      "______________\n",
      "epoch 54 train loss 5.258647918701172\n",
      "val loss 5.005700588226318\n",
      "______________\n",
      "epoch 55 train loss 5.264798641204834\n",
      "val loss 4.954165935516357\n",
      "______________\n",
      "epoch 56 train loss 5.13468074798584\n",
      "val loss 4.904505252838135\n",
      "______________\n",
      "epoch 57 train loss 5.0484724044799805\n",
      "val loss 4.856597423553467\n",
      "______________\n",
      "epoch 58 train loss 5.31149435043335\n",
      "val loss 4.810725212097168\n",
      "______________\n",
      "epoch 59 train loss 5.022334575653076\n",
      "val loss 4.7664899826049805\n",
      "______________\n",
      "epoch 60 train loss 5.049439907073975\n",
      "val loss 4.723780632019043\n",
      "______________\n",
      "epoch 61 train loss 5.087102890014648\n",
      "val loss 4.682844161987305\n",
      "______________\n",
      "epoch 62 train loss 4.948764324188232\n",
      "val loss 4.6436052322387695\n",
      "______________\n",
      "epoch 63 train loss 4.864608287811279\n",
      "val loss 4.605755805969238\n",
      "______________\n",
      "epoch 64 train loss 4.899506092071533\n",
      "val loss 4.569472312927246\n",
      "______________\n",
      "epoch 65 train loss 4.895163536071777\n",
      "val loss 4.53466272354126\n",
      "______________\n",
      "epoch 66 train loss 4.924319744110107\n",
      "val loss 4.50103759765625\n",
      "______________\n",
      "epoch 67 train loss 4.686473846435547\n",
      "val loss 4.468875408172607\n",
      "______________\n",
      "epoch 68 train loss 4.755214214324951\n",
      "val loss 4.437802314758301\n",
      "______________\n",
      "epoch 69 train loss 4.747920513153076\n",
      "val loss 4.407829761505127\n",
      "______________\n",
      "epoch 70 train loss 4.758978366851807\n",
      "val loss 4.378947734832764\n",
      "______________\n",
      "epoch 71 train loss 4.7260026931762695\n",
      "val loss 4.35099458694458\n",
      "______________\n",
      "epoch 72 train loss 4.658236026763916\n",
      "val loss 4.324236869812012\n",
      "______________\n",
      "epoch 73 train loss 4.605353355407715\n",
      "val loss 4.298340797424316\n",
      "______________\n",
      "epoch 74 train loss 4.750257968902588\n",
      "val loss 4.273473262786865\n",
      "______________\n",
      "epoch 75 train loss 4.468222141265869\n",
      "val loss 4.249550819396973\n",
      "______________\n",
      "epoch 76 train loss 4.709505081176758\n",
      "val loss 4.226789474487305\n",
      "______________\n",
      "epoch 77 train loss 4.6846089363098145\n",
      "val loss 4.205072402954102\n",
      "______________\n",
      "epoch 78 train loss 4.643374443054199\n",
      "val loss 4.184258937835693\n",
      "______________\n",
      "epoch 79 train loss 4.537952423095703\n",
      "val loss 4.164187908172607\n",
      "______________\n",
      "epoch 80 train loss 4.437338829040527\n",
      "val loss 4.144927501678467\n",
      "______________\n",
      "epoch 81 train loss 4.619248867034912\n",
      "val loss 4.126443862915039\n",
      "______________\n",
      "epoch 82 train loss 4.529960632324219\n",
      "val loss 4.108720302581787\n",
      "______________\n",
      "epoch 83 train loss 4.437812328338623\n",
      "val loss 4.091923713684082\n",
      "______________\n",
      "epoch 84 train loss 4.4453020095825195\n",
      "val loss 4.075736999511719\n",
      "______________\n",
      "epoch 85 train loss 4.44804573059082\n",
      "val loss 4.060014247894287\n",
      "______________\n",
      "epoch 86 train loss 4.537969589233398\n",
      "val loss 4.044930458068848\n",
      "______________\n",
      "epoch 87 train loss 4.468859672546387\n",
      "val loss 4.0305328369140625\n",
      "______________\n",
      "epoch 88 train loss 4.444955348968506\n",
      "val loss 4.016565322875977\n",
      "______________\n",
      "epoch 89 train loss 4.586933612823486\n",
      "val loss 4.003120422363281\n",
      "______________\n",
      "epoch 90 train loss 4.418086051940918\n",
      "val loss 3.9900002479553223\n",
      "______________\n",
      "epoch 91 train loss 4.480053901672363\n",
      "val loss 3.977579116821289\n",
      "______________\n",
      "epoch 92 train loss 4.320406913757324\n",
      "val loss 3.965632200241089\n",
      "______________\n",
      "epoch 93 train loss 4.471459865570068\n",
      "val loss 3.9539434909820557\n",
      "______________\n",
      "epoch 94 train loss 4.372234344482422\n",
      "val loss 3.942890167236328\n",
      "______________\n",
      "epoch 95 train loss 4.493626117706299\n",
      "val loss 3.9322891235351562\n",
      "______________\n",
      "epoch 96 train loss 4.327539443969727\n",
      "val loss 3.9219400882720947\n",
      "______________\n",
      "epoch 97 train loss 4.4428911209106445\n",
      "val loss 3.9121060371398926\n",
      "______________\n",
      "epoch 98 train loss 4.364419937133789\n",
      "val loss 3.902714967727661\n",
      "______________\n",
      "epoch 99 train loss 4.363291263580322\n",
      "val loss 3.893505334854126\n",
      "______________\n",
      "epoch 100 train loss 4.242715835571289\n",
      "val loss 3.8843600749969482\n",
      "______________\n",
      "epoch 101 train loss 4.212508678436279\n",
      "val loss 3.8753738403320312\n",
      "______________\n",
      "epoch 102 train loss 4.211004734039307\n",
      "val loss 3.8665037155151367\n",
      "______________\n",
      "epoch 103 train loss 4.32878303527832\n",
      "val loss 3.8578498363494873\n",
      "______________\n",
      "epoch 104 train loss 4.257140636444092\n",
      "val loss 3.849472761154175\n",
      "______________\n",
      "epoch 105 train loss 4.3871941566467285\n",
      "val loss 3.8410637378692627\n",
      "______________\n",
      "epoch 106 train loss 4.426027297973633\n",
      "val loss 3.8330461978912354\n",
      "______________\n",
      "epoch 107 train loss 4.264208793640137\n",
      "val loss 3.8250834941864014\n",
      "______________\n",
      "epoch 108 train loss 4.326849460601807\n",
      "val loss 3.8175723552703857\n",
      "______________\n",
      "epoch 109 train loss 4.275077819824219\n",
      "val loss 3.810112237930298\n",
      "______________\n",
      "epoch 110 train loss 4.338046073913574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.80308198928833\n",
      "______________\n",
      "epoch 111 train loss 4.3055572509765625\n",
      "val loss 3.7962276935577393\n",
      "______________\n",
      "epoch 112 train loss 4.115095138549805\n",
      "val loss 3.789747953414917\n",
      "______________\n",
      "epoch 113 train loss 4.208077907562256\n",
      "val loss 3.783501148223877\n",
      "______________\n",
      "epoch 114 train loss 4.148627758026123\n",
      "val loss 3.7774012088775635\n",
      "______________\n",
      "epoch 115 train loss 4.031924724578857\n",
      "val loss 3.771388530731201\n",
      "______________\n",
      "epoch 116 train loss 4.197422504425049\n",
      "val loss 3.7655134201049805\n",
      "______________\n",
      "epoch 117 train loss 4.120378494262695\n",
      "val loss 3.7597272396087646\n",
      "______________\n",
      "epoch 118 train loss 4.1815032958984375\n",
      "val loss 3.754011869430542\n",
      "______________\n",
      "epoch 119 train loss 4.293508052825928\n",
      "val loss 3.7484607696533203\n",
      "______________\n",
      "epoch 120 train loss 4.0450873374938965\n",
      "val loss 3.742929697036743\n",
      "______________\n",
      "epoch 121 train loss 4.227777004241943\n",
      "val loss 3.7375850677490234\n",
      "______________\n",
      "epoch 122 train loss 4.266199111938477\n",
      "val loss 3.7324271202087402\n",
      "______________\n",
      "epoch 123 train loss 4.11823034286499\n",
      "val loss 3.7274224758148193\n",
      "______________\n",
      "epoch 124 train loss 4.032740116119385\n",
      "val loss 3.7225520610809326\n",
      "______________\n",
      "epoch 125 train loss 4.149197101593018\n",
      "val loss 3.717837333679199\n",
      "______________\n",
      "epoch 126 train loss 4.15692138671875\n",
      "val loss 3.7131824493408203\n",
      "______________\n",
      "epoch 127 train loss 4.0435333251953125\n",
      "val loss 3.7084579467773438\n",
      "______________\n",
      "epoch 128 train loss 4.141664505004883\n",
      "val loss 3.7038426399230957\n",
      "______________\n",
      "epoch 129 train loss 4.083511829376221\n",
      "val loss 3.6993539333343506\n",
      "______________\n",
      "epoch 130 train loss 4.071282863616943\n",
      "val loss 3.694913864135742\n",
      "______________\n",
      "epoch 131 train loss 4.148910999298096\n",
      "val loss 3.6905314922332764\n",
      "______________\n",
      "epoch 132 train loss 4.100502014160156\n",
      "val loss 3.686245918273926\n",
      "______________\n",
      "epoch 133 train loss 3.9676506519317627\n",
      "val loss 3.681976556777954\n",
      "______________\n",
      "epoch 134 train loss 4.10504150390625\n",
      "val loss 3.6779510974884033\n",
      "______________\n",
      "epoch 135 train loss 4.079662322998047\n",
      "val loss 3.6740074157714844\n",
      "______________\n",
      "epoch 136 train loss 3.922058582305908\n",
      "val loss 3.6700992584228516\n",
      "______________\n",
      "epoch 137 train loss 4.00062370300293\n",
      "val loss 3.6662487983703613\n",
      "______________\n",
      "epoch 138 train loss 4.1377739906311035\n",
      "val loss 3.6624715328216553\n",
      "______________\n",
      "epoch 139 train loss 4.021615982055664\n",
      "val loss 3.6586878299713135\n",
      "______________\n",
      "epoch 140 train loss 3.9979100227355957\n",
      "val loss 3.6548314094543457\n",
      "______________\n",
      "epoch 141 train loss 4.044668197631836\n",
      "val loss 3.650864839553833\n",
      "______________\n",
      "epoch 142 train loss 3.9921460151672363\n",
      "val loss 3.6468660831451416\n",
      "______________\n",
      "epoch 143 train loss 3.9027891159057617\n",
      "val loss 3.642934799194336\n",
      "______________\n",
      "epoch 144 train loss 4.022633075714111\n",
      "val loss 3.639247179031372\n",
      "______________\n",
      "epoch 145 train loss 3.9761428833007812\n",
      "val loss 3.6355504989624023\n",
      "______________\n",
      "epoch 146 train loss 3.895326852798462\n",
      "val loss 3.631772756576538\n",
      "______________\n",
      "epoch 147 train loss 3.9437613487243652\n",
      "val loss 3.627993106842041\n",
      "______________\n",
      "epoch 148 train loss 3.9440295696258545\n",
      "val loss 3.6244053840637207\n",
      "______________\n",
      "epoch 149 train loss 3.9516658782958984\n",
      "val loss 3.6209163665771484\n",
      "______________\n",
      "epoch 150 train loss 3.8591208457946777\n",
      "val loss 3.6174750328063965\n",
      "______________\n",
      "epoch 151 train loss 4.004159450531006\n",
      "val loss 3.614206552505493\n",
      "______________\n",
      "epoch 152 train loss 3.9362645149230957\n",
      "val loss 3.6110167503356934\n",
      "______________\n",
      "epoch 153 train loss 3.9239537715911865\n",
      "val loss 3.608025074005127\n",
      "______________\n",
      "epoch 154 train loss 3.9405455589294434\n",
      "val loss 3.604891300201416\n",
      "______________\n",
      "epoch 155 train loss 3.903412103652954\n",
      "val loss 3.6016364097595215\n",
      "______________\n",
      "epoch 156 train loss 3.807953119277954\n",
      "val loss 3.5984201431274414\n",
      "______________\n",
      "epoch 157 train loss 3.928018808364868\n",
      "val loss 3.5951523780822754\n",
      "______________\n",
      "epoch 158 train loss 3.960782051086426\n",
      "val loss 3.5921707153320312\n",
      "______________\n",
      "epoch 159 train loss 3.9374923706054688\n",
      "val loss 3.5893235206604004\n",
      "______________\n",
      "epoch 160 train loss 3.947279691696167\n",
      "val loss 3.586561441421509\n",
      "______________\n",
      "epoch 161 train loss 3.9232115745544434\n",
      "val loss 3.5837132930755615\n",
      "______________\n",
      "epoch 162 train loss 3.8230512142181396\n",
      "val loss 3.58089280128479\n",
      "______________\n",
      "epoch 163 train loss 3.891453504562378\n",
      "val loss 3.578002691268921\n",
      "______________\n",
      "epoch 164 train loss 3.8031978607177734\n",
      "val loss 3.5751616954803467\n",
      "______________\n",
      "epoch 165 train loss 3.9291939735412598\n",
      "val loss 3.5723586082458496\n",
      "______________\n",
      "epoch 166 train loss 3.795372247695923\n",
      "val loss 3.56954288482666\n",
      "______________\n",
      "epoch 167 train loss 3.8007118701934814\n",
      "val loss 3.5667715072631836\n",
      "______________\n",
      "epoch 168 train loss 3.7942612171173096\n",
      "val loss 3.564053535461426\n",
      "______________\n",
      "epoch 169 train loss 3.7718446254730225\n",
      "val loss 3.561405897140503\n",
      "______________\n",
      "epoch 170 train loss 3.843226432800293\n",
      "val loss 3.5588228702545166\n",
      "______________\n",
      "epoch 171 train loss 3.8180577754974365\n",
      "val loss 3.5561864376068115\n",
      "______________\n",
      "epoch 172 train loss 3.8681347370147705\n",
      "val loss 3.5537400245666504\n",
      "______________\n",
      "epoch 173 train loss 3.93827486038208\n",
      "val loss 3.551457166671753\n",
      "______________\n",
      "epoch 174 train loss 3.7634692192077637\n",
      "val loss 3.5489699840545654\n",
      "______________\n",
      "epoch 175 train loss 3.793672561645508\n",
      "val loss 3.5466129779815674\n",
      "______________\n",
      "epoch 176 train loss 3.8433308601379395\n",
      "val loss 3.5441572666168213\n",
      "______________\n",
      "epoch 177 train loss 3.694007158279419\n",
      "val loss 3.5415198802948\n",
      "______________\n",
      "epoch 178 train loss 3.829105854034424\n",
      "val loss 3.5389297008514404\n",
      "______________\n",
      "epoch 179 train loss 3.7125840187072754\n",
      "val loss 3.5362794399261475\n",
      "______________\n",
      "epoch 180 train loss 3.7285895347595215\n",
      "val loss 3.533553123474121\n",
      "______________\n",
      "epoch 181 train loss 3.8755788803100586\n",
      "val loss 3.530872106552124\n",
      "______________\n",
      "epoch 182 train loss 3.7809946537017822\n",
      "val loss 3.528076648712158\n",
      "______________\n",
      "epoch 183 train loss 3.878018617630005\n",
      "val loss 3.525247097015381\n",
      "______________\n",
      "epoch 184 train loss 3.848719835281372\n",
      "val loss 3.522496461868286\n",
      "______________\n",
      "epoch 185 train loss 3.7558248043060303\n",
      "val loss 3.5196526050567627\n",
      "______________\n",
      "epoch 186 train loss 3.7104458808898926\n",
      "val loss 3.5167689323425293\n",
      "______________\n",
      "epoch 187 train loss 3.8446288108825684\n",
      "val loss 3.514038562774658\n",
      "______________\n",
      "epoch 188 train loss 3.737741708755493\n",
      "val loss 3.5112311840057373\n",
      "______________\n",
      "epoch 189 train loss 3.736083984375\n",
      "val loss 3.508436679840088\n",
      "______________\n",
      "epoch 190 train loss 3.782296657562256\n",
      "val loss 3.5057108402252197\n",
      "______________\n",
      "epoch 191 train loss 3.7577011585235596\n",
      "val loss 3.5030267238616943\n",
      "______________\n",
      "epoch 192 train loss 3.7556512355804443\n",
      "val loss 3.5003228187561035\n",
      "______________\n",
      "epoch 193 train loss 3.7624125480651855\n",
      "val loss 3.497702121734619\n",
      "______________\n",
      "epoch 194 train loss 3.7524077892303467\n",
      "val loss 3.4950385093688965\n",
      "______________\n",
      "epoch 195 train loss 3.719557762145996\n",
      "val loss 3.4925343990325928\n",
      "______________\n",
      "epoch 196 train loss 3.70459246635437\n",
      "val loss 3.490058183670044\n",
      "______________\n",
      "epoch 197 train loss 3.68776273727417\n",
      "val loss 3.4876551628112793\n",
      "______________\n",
      "epoch 198 train loss 3.714650869369507\n",
      "val loss 3.4854423999786377\n",
      "______________\n",
      "epoch 199 train loss 3.81965970993042\n",
      "val loss 3.48313045501709\n",
      "______________\n",
      "epoch 200 train loss 3.704059362411499\n",
      "val loss 3.4809563159942627\n",
      "______________\n",
      "epoch 201 train loss 3.6958200931549072\n",
      "val loss 3.4788243770599365\n",
      "______________\n",
      "epoch 202 train loss 3.6995246410369873\n",
      "val loss 3.476778030395508\n",
      "______________\n",
      "epoch 203 train loss 3.718134641647339\n",
      "val loss 3.4749138355255127\n",
      "______________\n",
      "epoch 204 train loss 3.6642303466796875\n",
      "val loss 3.472991466522217\n",
      "______________\n",
      "epoch 205 train loss 3.712609052658081\n",
      "val loss 3.47104811668396\n",
      "______________\n",
      "epoch 206 train loss 3.7126803398132324\n",
      "val loss 3.4692800045013428\n",
      "______________\n",
      "epoch 207 train loss 3.624769926071167\n",
      "val loss 3.4675164222717285\n",
      "______________\n",
      "epoch 208 train loss 3.6680593490600586\n",
      "val loss 3.4657716751098633\n",
      "______________\n",
      "epoch 209 train loss 3.741187810897827\n",
      "val loss 3.4640190601348877\n",
      "______________\n",
      "epoch 210 train loss 3.6922414302825928\n",
      "val loss 3.462362289428711\n",
      "______________\n",
      "epoch 211 train loss 3.693251132965088\n",
      "val loss 3.460860013961792\n",
      "______________\n",
      "epoch 212 train loss 3.6469507217407227\n",
      "val loss 3.459446430206299\n",
      "______________\n",
      "epoch 213 train loss 3.6917760372161865\n",
      "val loss 3.458003520965576\n",
      "______________\n",
      "epoch 214 train loss 3.6831417083740234\n",
      "val loss 3.45640230178833\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 215 train loss 3.658149003982544\n",
      "val loss 3.454775094985962\n",
      "______________\n",
      "epoch 216 train loss 3.580660581588745\n",
      "val loss 3.452946424484253\n",
      "______________\n",
      "epoch 217 train loss 3.718935489654541\n",
      "val loss 3.451059103012085\n",
      "______________\n",
      "epoch 218 train loss 3.6516294479370117\n",
      "val loss 3.449281930923462\n",
      "______________\n",
      "epoch 219 train loss 3.6823983192443848\n",
      "val loss 3.4474222660064697\n",
      "______________\n",
      "epoch 220 train loss 3.617921829223633\n",
      "val loss 3.4455738067626953\n",
      "______________\n",
      "epoch 221 train loss 3.688654661178589\n",
      "val loss 3.4436748027801514\n",
      "______________\n",
      "epoch 222 train loss 3.6806130409240723\n",
      "val loss 3.441771984100342\n",
      "______________\n",
      "epoch 223 train loss 3.7160050868988037\n",
      "val loss 3.4399399757385254\n",
      "______________\n",
      "epoch 224 train loss 3.6901636123657227\n",
      "val loss 3.4381303787231445\n",
      "______________\n",
      "epoch 225 train loss 3.72917103767395\n",
      "val loss 3.4363410472869873\n",
      "______________\n",
      "epoch 226 train loss 3.5759496688842773\n",
      "val loss 3.4345202445983887\n",
      "______________\n",
      "epoch 227 train loss 3.633371114730835\n",
      "val loss 3.4327456951141357\n",
      "______________\n",
      "epoch 228 train loss 3.594621181488037\n",
      "val loss 3.430877208709717\n",
      "______________\n",
      "epoch 229 train loss 3.5679566860198975\n",
      "val loss 3.4290926456451416\n",
      "______________\n",
      "epoch 230 train loss 3.64308762550354\n",
      "val loss 3.427274465560913\n",
      "______________\n",
      "epoch 231 train loss 3.686776638031006\n",
      "val loss 3.425558567047119\n",
      "______________\n",
      "epoch 232 train loss 3.559687852859497\n",
      "val loss 3.4239280223846436\n",
      "______________\n",
      "epoch 233 train loss 3.602719783782959\n",
      "val loss 3.4222755432128906\n",
      "______________\n",
      "epoch 234 train loss 3.5652923583984375\n",
      "val loss 3.420799732208252\n",
      "______________\n",
      "epoch 235 train loss 3.4878644943237305\n",
      "val loss 3.4192419052124023\n",
      "______________\n",
      "epoch 236 train loss 3.5863823890686035\n",
      "val loss 3.4177017211914062\n",
      "______________\n",
      "epoch 237 train loss 3.6466026306152344\n",
      "val loss 3.4161007404327393\n",
      "______________\n",
      "epoch 238 train loss 3.662264108657837\n",
      "val loss 3.414562225341797\n",
      "______________\n",
      "epoch 239 train loss 3.6851963996887207\n",
      "val loss 3.4130301475524902\n",
      "______________\n",
      "epoch 240 train loss 3.6234569549560547\n",
      "val loss 3.411379098892212\n",
      "______________\n",
      "epoch 241 train loss 3.6013805866241455\n",
      "val loss 3.409756898880005\n",
      "______________\n",
      "epoch 242 train loss 3.5194876194000244\n",
      "val loss 3.408054828643799\n",
      "______________\n",
      "epoch 243 train loss 3.602541446685791\n",
      "val loss 3.406311273574829\n",
      "______________\n",
      "epoch 244 train loss 3.5763442516326904\n",
      "val loss 3.4046103954315186\n",
      "______________\n",
      "epoch 245 train loss 3.5811100006103516\n",
      "val loss 3.402853488922119\n",
      "______________\n",
      "epoch 246 train loss 3.6346192359924316\n",
      "val loss 3.4009931087493896\n",
      "______________\n",
      "epoch 247 train loss 3.601217746734619\n",
      "val loss 3.3993160724639893\n",
      "______________\n",
      "epoch 248 train loss 3.4629688262939453\n",
      "val loss 3.397590160369873\n",
      "______________\n",
      "epoch 249 train loss 3.6068191528320312\n",
      "val loss 3.3960628509521484\n",
      "______________\n",
      "epoch 250 train loss 3.6093552112579346\n",
      "val loss 3.39483380317688\n",
      "______________\n",
      "epoch 251 train loss 3.6121826171875\n",
      "val loss 3.393580436706543\n",
      "______________\n",
      "epoch 252 train loss 3.5275914669036865\n",
      "val loss 3.392188549041748\n",
      "______________\n",
      "epoch 253 train loss 3.555142402648926\n",
      "val loss 3.3907644748687744\n",
      "______________\n",
      "epoch 254 train loss 3.4886035919189453\n",
      "val loss 3.389354944229126\n",
      "______________\n",
      "epoch 255 train loss 3.4883055686950684\n",
      "val loss 3.3879785537719727\n",
      "______________\n",
      "epoch 256 train loss 3.455202579498291\n",
      "val loss 3.386347532272339\n",
      "______________\n",
      "epoch 257 train loss 3.580376148223877\n",
      "val loss 3.3847107887268066\n",
      "______________\n",
      "epoch 258 train loss 3.4974281787872314\n",
      "val loss 3.3832576274871826\n",
      "______________\n",
      "epoch 259 train loss 3.580461025238037\n",
      "val loss 3.381669521331787\n",
      "______________\n",
      "epoch 260 train loss 3.5775551795959473\n",
      "val loss 3.380174160003662\n",
      "______________\n",
      "epoch 261 train loss 3.4756252765655518\n",
      "val loss 3.3785293102264404\n",
      "______________\n",
      "epoch 262 train loss 3.5510499477386475\n",
      "val loss 3.3769659996032715\n",
      "______________\n",
      "epoch 263 train loss 3.481049060821533\n",
      "val loss 3.3753154277801514\n",
      "______________\n",
      "epoch 264 train loss 3.5768508911132812\n",
      "val loss 3.373469114303589\n",
      "______________\n",
      "epoch 265 train loss 3.5045177936553955\n",
      "val loss 3.3715696334838867\n",
      "______________\n",
      "epoch 266 train loss 3.580186605453491\n",
      "val loss 3.3699193000793457\n",
      "______________\n",
      "epoch 267 train loss 3.481764078140259\n",
      "val loss 3.368483066558838\n",
      "______________\n",
      "epoch 268 train loss 3.532219648361206\n",
      "val loss 3.3668901920318604\n",
      "______________\n",
      "epoch 269 train loss 3.4849905967712402\n",
      "val loss 3.3652703762054443\n",
      "______________\n",
      "epoch 270 train loss 3.5402889251708984\n",
      "val loss 3.363600254058838\n",
      "______________\n",
      "epoch 271 train loss 3.585209369659424\n",
      "val loss 3.362144708633423\n",
      "______________\n",
      "epoch 272 train loss 3.4820556640625\n",
      "val loss 3.3607852458953857\n",
      "______________\n",
      "epoch 273 train loss 3.44002628326416\n",
      "val loss 3.359262228012085\n",
      "______________\n",
      "epoch 274 train loss 3.5340967178344727\n",
      "val loss 3.357729196548462\n",
      "______________\n",
      "epoch 275 train loss 3.5831761360168457\n",
      "val loss 3.356365919113159\n",
      "______________\n",
      "epoch 276 train loss 3.46933650970459\n",
      "val loss 3.354956865310669\n",
      "______________\n",
      "epoch 277 train loss 3.567303419113159\n",
      "val loss 3.353874683380127\n",
      "______________\n",
      "epoch 278 train loss 3.4121546745300293\n",
      "val loss 3.3527581691741943\n",
      "______________\n",
      "epoch 279 train loss 3.502582550048828\n",
      "val loss 3.3516528606414795\n",
      "______________\n",
      "epoch 280 train loss 3.4377686977386475\n",
      "val loss 3.3505055904388428\n",
      "______________\n",
      "epoch 281 train loss 3.3950326442718506\n",
      "val loss 3.3492846488952637\n",
      "______________\n",
      "epoch 282 train loss 3.4534027576446533\n",
      "val loss 3.3480989933013916\n",
      "______________\n",
      "epoch 283 train loss 3.444066047668457\n",
      "val loss 3.346773862838745\n",
      "______________\n",
      "epoch 284 train loss 3.373800754547119\n",
      "val loss 3.3454339504241943\n",
      "______________\n",
      "epoch 285 train loss 3.3952879905700684\n",
      "val loss 3.3440167903900146\n",
      "______________\n",
      "epoch 286 train loss 3.415208101272583\n",
      "val loss 3.342499256134033\n",
      "______________\n",
      "epoch 287 train loss 3.4816205501556396\n",
      "val loss 3.340991735458374\n",
      "______________\n",
      "epoch 288 train loss 3.473381996154785\n",
      "val loss 3.3395583629608154\n",
      "______________\n",
      "epoch 289 train loss 3.465245246887207\n",
      "val loss 3.338134527206421\n",
      "______________\n",
      "epoch 290 train loss 3.3903093338012695\n",
      "val loss 3.336683988571167\n",
      "______________\n",
      "epoch 291 train loss 3.4640913009643555\n",
      "val loss 3.3351850509643555\n",
      "______________\n",
      "epoch 292 train loss 3.4074394702911377\n",
      "val loss 3.333682060241699\n",
      "______________\n",
      "epoch 293 train loss 3.5003397464752197\n",
      "val loss 3.332170009613037\n",
      "______________\n",
      "epoch 294 train loss 3.455034017562866\n",
      "val loss 3.330564260482788\n",
      "______________\n",
      "epoch 295 train loss 3.4906582832336426\n",
      "val loss 3.3289456367492676\n",
      "______________\n",
      "epoch 296 train loss 3.338210344314575\n",
      "val loss 3.3271992206573486\n",
      "______________\n",
      "epoch 297 train loss 3.406665563583374\n",
      "val loss 3.325450897216797\n",
      "______________\n",
      "epoch 298 train loss 3.440058469772339\n",
      "val loss 3.323910713195801\n",
      "______________\n",
      "epoch 299 train loss 3.3956732749938965\n",
      "val loss 3.3222479820251465\n",
      "______________\n",
      "epoch 300 train loss 3.46644926071167\n",
      "val loss 3.3206045627593994\n",
      "______________\n",
      "epoch 301 train loss 3.421095371246338\n",
      "val loss 3.3191869258880615\n",
      "______________\n",
      "epoch 302 train loss 3.4554269313812256\n",
      "val loss 3.3178179264068604\n",
      "______________\n",
      "epoch 303 train loss 3.4343628883361816\n",
      "val loss 3.3166561126708984\n",
      "______________\n",
      "epoch 304 train loss 3.4057540893554688\n",
      "val loss 3.3155517578125\n",
      "______________\n",
      "epoch 305 train loss 3.458857774734497\n",
      "val loss 3.3144447803497314\n",
      "______________\n",
      "epoch 306 train loss 3.4613566398620605\n",
      "val loss 3.313203811645508\n",
      "______________\n",
      "epoch 307 train loss 3.47379732131958\n",
      "val loss 3.3119380474090576\n",
      "______________\n",
      "epoch 308 train loss 3.349632740020752\n",
      "val loss 3.3105876445770264\n",
      "______________\n",
      "epoch 309 train loss 3.421006202697754\n",
      "val loss 3.309206008911133\n",
      "______________\n",
      "epoch 310 train loss 3.443105936050415\n",
      "val loss 3.30792236328125\n",
      "______________\n",
      "epoch 311 train loss 3.2792675495147705\n",
      "val loss 3.3063385486602783\n",
      "______________\n",
      "epoch 312 train loss 3.3503518104553223\n",
      "val loss 3.3048417568206787\n",
      "______________\n",
      "epoch 313 train loss 3.4636058807373047\n",
      "val loss 3.303495407104492\n",
      "______________\n",
      "epoch 314 train loss 3.4410767555236816\n",
      "val loss 3.302398681640625\n",
      "______________\n",
      "epoch 315 train loss 3.364017963409424\n",
      "val loss 3.301226854324341\n",
      "______________\n",
      "epoch 316 train loss 3.4041686058044434\n",
      "val loss 3.3000454902648926\n",
      "______________\n",
      "epoch 317 train loss 3.404149055480957\n",
      "val loss 3.2989232540130615\n",
      "______________\n",
      "epoch 318 train loss 3.4571924209594727\n",
      "val loss 3.297987699508667\n",
      "______________\n",
      "epoch 319 train loss 3.431056499481201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.2970492839813232\n",
      "______________\n",
      "epoch 320 train loss 3.449652671813965\n",
      "val loss 3.2961435317993164\n",
      "______________\n",
      "epoch 321 train loss 3.439864158630371\n",
      "val loss 3.295297622680664\n",
      "______________\n",
      "epoch 322 train loss 3.362490653991699\n",
      "val loss 3.294382333755493\n",
      "______________\n",
      "epoch 323 train loss 3.387547492980957\n",
      "val loss 3.2936017513275146\n",
      "______________\n",
      "epoch 324 train loss 3.3449220657348633\n",
      "val loss 3.2927448749542236\n",
      "______________\n",
      "epoch 325 train loss 3.3294546604156494\n",
      "val loss 3.291825532913208\n",
      "______________\n",
      "epoch 326 train loss 3.3647406101226807\n",
      "val loss 3.2908735275268555\n",
      "______________\n",
      "epoch 327 train loss 3.3525094985961914\n",
      "val loss 3.289863109588623\n",
      "______________\n",
      "epoch 328 train loss 3.309746265411377\n",
      "val loss 3.288764715194702\n",
      "______________\n",
      "epoch 329 train loss 3.402501344680786\n",
      "val loss 3.287614583969116\n",
      "______________\n",
      "epoch 330 train loss 3.3374152183532715\n",
      "val loss 3.2864725589752197\n",
      "______________\n",
      "epoch 331 train loss 3.407655715942383\n",
      "val loss 3.285360097885132\n",
      "______________\n",
      "epoch 332 train loss 3.304387092590332\n",
      "val loss 3.2844011783599854\n",
      "______________\n",
      "epoch 333 train loss 3.3013358116149902\n",
      "val loss 3.2833847999572754\n",
      "______________\n",
      "epoch 334 train loss 3.361640691757202\n",
      "val loss 3.282341957092285\n",
      "______________\n",
      "epoch 335 train loss 3.3460593223571777\n",
      "val loss 3.2813799381256104\n",
      "______________\n",
      "epoch 336 train loss 3.3898377418518066\n",
      "val loss 3.280515193939209\n",
      "______________\n",
      "epoch 337 train loss 3.3761940002441406\n",
      "val loss 3.279750347137451\n",
      "______________\n",
      "epoch 338 train loss 3.356247663497925\n",
      "val loss 3.278801202774048\n",
      "______________\n",
      "epoch 339 train loss 3.363534927368164\n",
      "val loss 3.277859926223755\n",
      "______________\n",
      "epoch 340 train loss 3.3091588020324707\n",
      "val loss 3.277170419692993\n",
      "______________\n",
      "epoch 341 train loss 3.397456169128418\n",
      "val loss 3.276491641998291\n",
      "______________\n",
      "epoch 342 train loss 3.3550329208374023\n",
      "val loss 3.275899887084961\n",
      "______________\n",
      "epoch 343 train loss 3.3745408058166504\n",
      "val loss 3.2753400802612305\n",
      "______________\n",
      "epoch 344 train loss 3.3137712478637695\n",
      "val loss 3.274662494659424\n",
      "______________\n",
      "epoch 345 train loss 3.3767404556274414\n",
      "val loss 3.273847818374634\n",
      "______________\n",
      "epoch 346 train loss 3.3714230060577393\n",
      "val loss 3.27312970161438\n",
      "______________\n",
      "epoch 347 train loss 3.288363218307495\n",
      "val loss 3.272256851196289\n",
      "______________\n",
      "epoch 348 train loss 3.2992093563079834\n",
      "val loss 3.271364688873291\n",
      "______________\n",
      "epoch 349 train loss 3.229757785797119\n",
      "val loss 3.2703914642333984\n",
      "______________\n",
      "epoch 350 train loss 3.304678201675415\n",
      "val loss 3.269408941268921\n",
      "______________\n",
      "epoch 351 train loss 3.3340816497802734\n",
      "val loss 3.2686691284179688\n",
      "______________\n",
      "epoch 352 train loss 3.344167947769165\n",
      "val loss 3.2677714824676514\n",
      "______________\n",
      "epoch 353 train loss 3.303375482559204\n",
      "val loss 3.267066240310669\n",
      "______________\n",
      "epoch 354 train loss 3.3817594051361084\n",
      "val loss 3.266371488571167\n",
      "______________\n",
      "epoch 355 train loss 3.255021572113037\n",
      "val loss 3.26564621925354\n",
      "______________\n",
      "epoch 356 train loss 3.3113460540771484\n",
      "val loss 3.264697551727295\n",
      "______________\n",
      "epoch 357 train loss 3.332456588745117\n",
      "val loss 3.2638704776763916\n",
      "______________\n",
      "epoch 358 train loss 3.3369674682617188\n",
      "val loss 3.2629106044769287\n",
      "______________\n",
      "epoch 359 train loss 3.301987886428833\n",
      "val loss 3.261880397796631\n",
      "______________\n",
      "epoch 360 train loss 3.399195671081543\n",
      "val loss 3.2610819339752197\n",
      "______________\n",
      "epoch 361 train loss 3.3387627601623535\n",
      "val loss 3.260430097579956\n",
      "______________\n",
      "epoch 362 train loss 3.314990520477295\n",
      "val loss 3.2599143981933594\n",
      "______________\n",
      "epoch 363 train loss 3.247260570526123\n",
      "val loss 3.2593958377838135\n",
      "______________\n",
      "epoch 364 train loss 3.3548145294189453\n",
      "val loss 3.258899211883545\n",
      "______________\n",
      "epoch 365 train loss 3.268779993057251\n",
      "val loss 3.2584009170532227\n",
      "______________\n",
      "epoch 366 train loss 3.405747652053833\n",
      "val loss 3.25795578956604\n",
      "______________\n",
      "epoch 367 train loss 3.3049936294555664\n",
      "val loss 3.2573611736297607\n",
      "______________\n",
      "epoch 368 train loss 3.282869338989258\n",
      "val loss 3.256728410720825\n",
      "______________\n",
      "epoch 369 train loss 3.311215877532959\n",
      "val loss 3.2560088634490967\n",
      "______________\n",
      "epoch 370 train loss 3.218007802963257\n",
      "val loss 3.255251169204712\n",
      "______________\n",
      "epoch 371 train loss 3.391772747039795\n",
      "val loss 3.254298210144043\n",
      "______________\n",
      "epoch 372 train loss 3.2880361080169678\n",
      "val loss 3.253183603286743\n",
      "______________\n",
      "epoch 373 train loss 3.320010185241699\n",
      "val loss 3.252105712890625\n",
      "______________\n",
      "epoch 374 train loss 3.200718879699707\n",
      "val loss 3.2510948181152344\n",
      "______________\n",
      "epoch 375 train loss 3.270311117172241\n",
      "val loss 3.250070571899414\n",
      "______________\n",
      "epoch 376 train loss 3.2608211040496826\n",
      "val loss 3.2489442825317383\n",
      "______________\n",
      "epoch 377 train loss 3.2546262741088867\n",
      "val loss 3.247757911682129\n",
      "______________\n",
      "epoch 378 train loss 3.289181709289551\n",
      "val loss 3.2464938163757324\n",
      "______________\n",
      "epoch 379 train loss 3.217402696609497\n",
      "val loss 3.2452423572540283\n",
      "______________\n",
      "epoch 380 train loss 3.267214059829712\n",
      "val loss 3.244070529937744\n",
      "______________\n",
      "epoch 381 train loss 3.306166648864746\n",
      "val loss 3.2429487705230713\n",
      "______________\n",
      "epoch 382 train loss 3.2144241333007812\n",
      "val loss 3.241762638092041\n",
      "______________\n",
      "epoch 383 train loss 3.2751431465148926\n",
      "val loss 3.24043869972229\n",
      "______________\n",
      "epoch 384 train loss 3.333613157272339\n",
      "val loss 3.2392561435699463\n",
      "______________\n",
      "epoch 385 train loss 3.34761381149292\n",
      "val loss 3.2382562160491943\n",
      "______________\n",
      "epoch 386 train loss 3.204653024673462\n",
      "val loss 3.2372334003448486\n",
      "______________\n",
      "epoch 387 train loss 3.3481669425964355\n",
      "val loss 3.236311197280884\n",
      "______________\n",
      "epoch 388 train loss 3.3335886001586914\n",
      "val loss 3.235518217086792\n",
      "______________\n",
      "epoch 389 train loss 3.2370221614837646\n",
      "val loss 3.234894037246704\n",
      "______________\n",
      "epoch 390 train loss 3.154207229614258\n",
      "val loss 3.2341349124908447\n",
      "______________\n",
      "epoch 391 train loss 3.333465576171875\n",
      "val loss 3.233342409133911\n",
      "______________\n",
      "epoch 392 train loss 3.313371181488037\n",
      "val loss 3.2325432300567627\n",
      "______________\n",
      "epoch 393 train loss 3.164140462875366\n",
      "val loss 3.231773853302002\n",
      "______________\n",
      "epoch 394 train loss 3.283205032348633\n",
      "val loss 3.2311484813690186\n",
      "______________\n",
      "epoch 395 train loss 3.2886648178100586\n",
      "val loss 3.2306554317474365\n",
      "______________\n",
      "epoch 396 train loss 3.206098794937134\n",
      "val loss 3.2301669120788574\n",
      "______________\n",
      "epoch 397 train loss 3.2545018196105957\n",
      "val loss 3.2296228408813477\n",
      "______________\n",
      "epoch 398 train loss 3.3363382816314697\n",
      "val loss 3.2289137840270996\n",
      "______________\n",
      "epoch 399 train loss 3.2057464122772217\n",
      "val loss 3.2281129360198975\n",
      "______________\n",
      "epoch 400 train loss 3.198624849319458\n",
      "val loss 3.2273170948028564\n",
      "______________\n",
      "epoch 401 train loss 3.251194477081299\n",
      "val loss 3.2266104221343994\n",
      "______________\n",
      "epoch 402 train loss 3.2724080085754395\n",
      "val loss 3.2257778644561768\n",
      "______________\n",
      "epoch 403 train loss 3.2420549392700195\n",
      "val loss 3.22489333152771\n",
      "______________\n",
      "epoch 404 train loss 3.2040789127349854\n",
      "val loss 3.223947286605835\n",
      "______________\n",
      "epoch 405 train loss 3.3913753032684326\n",
      "val loss 3.223071813583374\n",
      "______________\n",
      "epoch 406 train loss 3.2039334774017334\n",
      "val loss 3.222379207611084\n",
      "______________\n",
      "epoch 407 train loss 3.3069522380828857\n",
      "val loss 3.2217421531677246\n",
      "______________\n",
      "epoch 408 train loss 3.24991512298584\n",
      "val loss 3.2210958003997803\n",
      "______________\n",
      "epoch 409 train loss 3.2587943077087402\n",
      "val loss 3.220282793045044\n",
      "______________\n",
      "epoch 410 train loss 3.1851577758789062\n",
      "val loss 3.2195682525634766\n",
      "______________\n",
      "epoch 411 train loss 3.249375104904175\n",
      "val loss 3.2189011573791504\n",
      "______________\n",
      "epoch 412 train loss 3.328871250152588\n",
      "val loss 3.218240737915039\n",
      "______________\n",
      "epoch 413 train loss 3.280791997909546\n",
      "val loss 3.2175710201263428\n",
      "______________\n",
      "epoch 414 train loss 3.2949273586273193\n",
      "val loss 3.216862678527832\n",
      "______________\n",
      "epoch 415 train loss 3.2281341552734375\n",
      "val loss 3.2162601947784424\n",
      "______________\n",
      "epoch 416 train loss 3.164046049118042\n",
      "val loss 3.2156484127044678\n",
      "______________\n",
      "epoch 417 train loss 3.2486844062805176\n",
      "val loss 3.2151107788085938\n",
      "______________\n",
      "epoch 418 train loss 3.2900943756103516\n",
      "val loss 3.214684009552002\n",
      "______________\n",
      "epoch 419 train loss 3.272228479385376\n",
      "val loss 3.2141666412353516\n",
      "______________\n",
      "epoch 420 train loss 3.217617988586426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.2134628295898438\n",
      "______________\n",
      "epoch 421 train loss 3.244910717010498\n",
      "val loss 3.212829351425171\n",
      "______________\n",
      "epoch 422 train loss 3.1761891841888428\n",
      "val loss 3.212137460708618\n",
      "______________\n",
      "epoch 423 train loss 3.1550159454345703\n",
      "val loss 3.211280345916748\n",
      "______________\n",
      "epoch 424 train loss 3.1989967823028564\n",
      "val loss 3.210329294204712\n",
      "______________\n",
      "epoch 425 train loss 3.2992453575134277\n",
      "val loss 3.209467649459839\n",
      "______________\n",
      "epoch 426 train loss 3.1627585887908936\n",
      "val loss 3.2086548805236816\n",
      "______________\n",
      "epoch 427 train loss 3.2535293102264404\n",
      "val loss 3.2078168392181396\n",
      "______________\n",
      "epoch 428 train loss 3.2041923999786377\n",
      "val loss 3.2070600986480713\n",
      "______________\n",
      "epoch 429 train loss 3.164231777191162\n",
      "val loss 3.2062439918518066\n",
      "______________\n",
      "epoch 430 train loss 3.1740477085113525\n",
      "val loss 3.2053277492523193\n",
      "______________\n",
      "epoch 431 train loss 3.151127815246582\n",
      "val loss 3.2044055461883545\n",
      "______________\n",
      "epoch 432 train loss 3.2234392166137695\n",
      "val loss 3.2034332752227783\n",
      "______________\n",
      "epoch 433 train loss 3.1465349197387695\n",
      "val loss 3.202540159225464\n",
      "______________\n",
      "epoch 434 train loss 3.1397294998168945\n",
      "val loss 3.201664447784424\n",
      "______________\n",
      "epoch 435 train loss 3.310124635696411\n",
      "val loss 3.2010626792907715\n",
      "______________\n",
      "epoch 436 train loss 3.1634819507598877\n",
      "val loss 3.2004997730255127\n",
      "______________\n",
      "epoch 437 train loss 3.190075397491455\n",
      "val loss 3.1999261379241943\n",
      "______________\n",
      "epoch 438 train loss 3.123732566833496\n",
      "val loss 3.199453592300415\n",
      "______________\n",
      "epoch 439 train loss 3.19651198387146\n",
      "val loss 3.199056625366211\n",
      "______________\n",
      "epoch 440 train loss 3.131859302520752\n",
      "val loss 3.1984524726867676\n",
      "______________\n",
      "epoch 441 train loss 3.189663887023926\n",
      "val loss 3.1979312896728516\n",
      "______________\n",
      "epoch 442 train loss 3.2192811965942383\n",
      "val loss 3.1973111629486084\n",
      "______________\n",
      "epoch 443 train loss 3.1076102256774902\n",
      "val loss 3.196497678756714\n",
      "______________\n",
      "epoch 444 train loss 3.218569278717041\n",
      "val loss 3.195589780807495\n",
      "______________\n",
      "epoch 445 train loss 3.209975481033325\n",
      "val loss 3.1946938037872314\n",
      "______________\n",
      "epoch 446 train loss 3.2548062801361084\n",
      "val loss 3.1938514709472656\n",
      "______________\n",
      "epoch 447 train loss 3.2513504028320312\n",
      "val loss 3.193100929260254\n",
      "______________\n",
      "epoch 448 train loss 3.158353805541992\n",
      "val loss 3.192424774169922\n",
      "______________\n",
      "epoch 449 train loss 3.1942057609558105\n",
      "val loss 3.1919171810150146\n",
      "______________\n",
      "epoch 450 train loss 3.2778165340423584\n",
      "val loss 3.1913559436798096\n",
      "______________\n",
      "epoch 451 train loss 3.1825757026672363\n",
      "val loss 3.1907083988189697\n",
      "______________\n",
      "epoch 452 train loss 3.197666883468628\n",
      "val loss 3.1901772022247314\n",
      "______________\n",
      "epoch 453 train loss 3.2791926860809326\n",
      "val loss 3.189707040786743\n",
      "______________\n",
      "epoch 454 train loss 3.201892614364624\n",
      "val loss 3.1891653537750244\n",
      "______________\n",
      "epoch 455 train loss 3.2345776557922363\n",
      "val loss 3.1886980533599854\n",
      "______________\n",
      "epoch 456 train loss 3.2339086532592773\n",
      "val loss 3.1882851123809814\n",
      "______________\n",
      "epoch 457 train loss 3.1224265098571777\n",
      "val loss 3.187755823135376\n",
      "______________\n",
      "epoch 458 train loss 3.2168641090393066\n",
      "val loss 3.1872475147247314\n",
      "______________\n",
      "epoch 459 train loss 3.172689914703369\n",
      "val loss 3.1868185997009277\n",
      "______________\n",
      "epoch 460 train loss 3.162646770477295\n",
      "val loss 3.1864655017852783\n",
      "______________\n",
      "epoch 461 train loss 3.1895666122436523\n",
      "val loss 3.1859796047210693\n",
      "______________\n",
      "epoch 462 train loss 3.1644556522369385\n",
      "val loss 3.1854565143585205\n",
      "______________\n",
      "epoch 463 train loss 3.2974700927734375\n",
      "val loss 3.1849710941314697\n",
      "______________\n",
      "epoch 464 train loss 3.179447650909424\n",
      "val loss 3.1845786571502686\n",
      "______________\n",
      "epoch 465 train loss 3.1924939155578613\n",
      "val loss 3.1843817234039307\n",
      "______________\n",
      "epoch 466 train loss 3.1842782497406006\n",
      "val loss 3.1839051246643066\n",
      "______________\n",
      "epoch 467 train loss 3.219230890274048\n",
      "val loss 3.1834940910339355\n",
      "______________\n",
      "epoch 468 train loss 3.0733418464660645\n",
      "val loss 3.1829569339752197\n",
      "______________\n",
      "epoch 469 train loss 3.2156145572662354\n",
      "val loss 3.18245005607605\n",
      "______________\n",
      "epoch 470 train loss 3.1109187602996826\n",
      "val loss 3.1820011138916016\n",
      "______________\n",
      "epoch 471 train loss 3.1084327697753906\n",
      "val loss 3.181558847427368\n",
      "______________\n",
      "epoch 472 train loss 3.248445510864258\n",
      "val loss 3.1814537048339844\n",
      "______________\n",
      "epoch 473 train loss 3.205995559692383\n",
      "val loss 3.181377649307251\n",
      "______________\n",
      "epoch 474 train loss 3.2160086631774902\n",
      "val loss 3.1812777519226074\n",
      "______________\n",
      "epoch 475 train loss 3.212677001953125\n",
      "val loss 3.1810638904571533\n",
      "______________\n",
      "epoch 476 train loss 3.150369644165039\n",
      "val loss 3.180605173110962\n",
      "______________\n",
      "epoch 477 train loss 3.2275147438049316\n",
      "val loss 3.18002986907959\n",
      "______________\n",
      "epoch 478 train loss 3.2003629207611084\n",
      "val loss 3.1795167922973633\n",
      "______________\n",
      "epoch 479 train loss 3.1147360801696777\n",
      "val loss 3.179108142852783\n",
      "______________\n",
      "epoch 480 train loss 3.1646132469177246\n",
      "val loss 3.17875599861145\n",
      "______________\n",
      "epoch 481 train loss 3.146092414855957\n",
      "val loss 3.1785080432891846\n",
      "______________\n",
      "epoch 482 train loss 3.110536575317383\n",
      "val loss 3.178239107131958\n",
      "______________\n",
      "epoch 483 train loss 3.078996181488037\n",
      "val loss 3.1781275272369385\n",
      "______________\n",
      "epoch 484 train loss 3.1224982738494873\n",
      "val loss 3.1778564453125\n",
      "______________\n",
      "epoch 485 train loss 3.1064436435699463\n",
      "val loss 3.1774959564208984\n",
      "______________\n",
      "epoch 486 train loss 3.0986533164978027\n",
      "val loss 3.1769964694976807\n",
      "______________\n",
      "epoch 487 train loss 3.218273401260376\n",
      "val loss 3.1763832569122314\n",
      "______________\n",
      "epoch 488 train loss 3.14636492729187\n",
      "val loss 3.1757733821868896\n",
      "______________\n",
      "epoch 489 train loss 3.1154189109802246\n",
      "val loss 3.175046920776367\n",
      "______________\n",
      "epoch 490 train loss 3.104224920272827\n",
      "val loss 3.1742947101593018\n",
      "______________\n",
      "epoch 491 train loss 3.236727237701416\n",
      "val loss 3.173635482788086\n",
      "______________\n",
      "epoch 492 train loss 3.236392021179199\n",
      "val loss 3.173008441925049\n",
      "______________\n",
      "epoch 493 train loss 3.0933890342712402\n",
      "val loss 3.1723480224609375\n",
      "______________\n",
      "epoch 494 train loss 3.177058219909668\n",
      "val loss 3.171834707260132\n",
      "______________\n",
      "epoch 495 train loss 3.187483072280884\n",
      "val loss 3.171534776687622\n",
      "______________\n",
      "epoch 496 train loss 3.201232433319092\n",
      "val loss 3.17126727104187\n",
      "______________\n",
      "epoch 497 train loss 3.2720730304718018\n",
      "val loss 3.1712231636047363\n",
      "______________\n",
      "epoch 498 train loss 3.1222610473632812\n",
      "val loss 3.1711418628692627\n",
      "______________\n",
      "epoch 499 train loss 3.1529111862182617\n",
      "val loss 3.1710662841796875\n",
      "______________\n",
      "epoch 500 train loss 3.222545862197876\n",
      "val loss 3.170917510986328\n",
      "______________\n",
      "epoch 501 train loss 3.1218743324279785\n",
      "val loss 3.1705965995788574\n",
      "______________\n",
      "epoch 502 train loss 3.113710641860962\n",
      "val loss 3.1701717376708984\n",
      "______________\n",
      "epoch 503 train loss 3.2016890048980713\n",
      "val loss 3.169834852218628\n",
      "______________\n",
      "epoch 504 train loss 3.109907865524292\n",
      "val loss 3.1694812774658203\n",
      "______________\n",
      "epoch 505 train loss 3.1457509994506836\n",
      "val loss 3.1691272258758545\n",
      "______________\n",
      "epoch 506 train loss 3.1538970470428467\n",
      "val loss 3.168752670288086\n",
      "______________\n",
      "epoch 507 train loss 3.0781641006469727\n",
      "val loss 3.1683590412139893\n",
      "______________\n",
      "epoch 508 train loss 3.1465160846710205\n",
      "val loss 3.168022394180298\n",
      "______________\n",
      "epoch 509 train loss 3.1984035968780518\n",
      "val loss 3.167663812637329\n",
      "______________\n",
      "epoch 510 train loss 3.0925955772399902\n",
      "val loss 3.1672582626342773\n",
      "______________\n",
      "epoch 511 train loss 3.137476921081543\n",
      "val loss 3.1667346954345703\n",
      "______________\n",
      "epoch 512 train loss 3.1075844764709473\n",
      "val loss 3.1661455631256104\n",
      "______________\n",
      "epoch 513 train loss 3.270711898803711\n",
      "val loss 3.1659483909606934\n",
      "______________\n",
      "epoch 514 train loss 3.0342116355895996\n",
      "val loss 3.165680170059204\n",
      "______________\n",
      "epoch 515 train loss 3.032043695449829\n",
      "val loss 3.165358304977417\n",
      "______________\n",
      "epoch 516 train loss 3.1142027378082275\n",
      "val loss 3.1650264263153076\n",
      "______________\n",
      "epoch 517 train loss 3.0785229206085205\n",
      "val loss 3.1646478176116943\n",
      "______________\n",
      "epoch 518 train loss 3.087569236755371\n",
      "val loss 3.1643030643463135\n",
      "______________\n",
      "epoch 519 train loss 3.2433931827545166\n",
      "val loss 3.1639597415924072\n",
      "______________\n",
      "epoch 520 train loss 3.127847671508789\n",
      "val loss 3.1634726524353027\n",
      "______________\n",
      "epoch 521 train loss 3.1448147296905518\n",
      "val loss 3.1629526615142822\n",
      "______________\n",
      "epoch 522 train loss 3.1152760982513428\n",
      "val loss 3.1624205112457275\n",
      "______________\n",
      "epoch 523 train loss 3.1173458099365234\n",
      "val loss 3.1621642112731934\n",
      "______________\n",
      "epoch 524 train loss 3.176868200302124\n",
      "val loss 3.161771059036255\n",
      "______________\n",
      "epoch 525 train loss 3.1884026527404785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.1613035202026367\n",
      "______________\n",
      "epoch 526 train loss 3.1454951763153076\n",
      "val loss 3.160902738571167\n",
      "______________\n",
      "epoch 527 train loss 3.1057627201080322\n",
      "val loss 3.1603498458862305\n",
      "______________\n",
      "epoch 528 train loss 3.1376500129699707\n",
      "val loss 3.1599783897399902\n",
      "______________\n",
      "epoch 529 train loss 3.0357484817504883\n",
      "val loss 3.1595938205718994\n",
      "______________\n",
      "epoch 530 train loss 3.125753164291382\n",
      "val loss 3.1591968536376953\n",
      "______________\n",
      "epoch 531 train loss 3.1871085166931152\n",
      "val loss 3.1588706970214844\n",
      "______________\n",
      "epoch 532 train loss 3.1742355823516846\n",
      "val loss 3.1585476398468018\n",
      "______________\n",
      "epoch 533 train loss 3.1305651664733887\n",
      "val loss 3.158234119415283\n",
      "______________\n",
      "epoch 534 train loss 3.1239283084869385\n",
      "val loss 3.1580350399017334\n",
      "______________\n",
      "epoch 535 train loss 3.1286399364471436\n",
      "val loss 3.1577892303466797\n",
      "______________\n",
      "epoch 536 train loss 3.1549975872039795\n",
      "val loss 3.15753436088562\n",
      "______________\n",
      "epoch 537 train loss 3.0589611530303955\n",
      "val loss 3.1572489738464355\n",
      "______________\n",
      "epoch 538 train loss 3.1076841354370117\n",
      "val loss 3.157029867172241\n",
      "______________\n",
      "epoch 539 train loss 3.17297101020813\n",
      "val loss 3.156780481338501\n",
      "______________\n",
      "epoch 540 train loss 3.1373448371887207\n",
      "val loss 3.1565709114074707\n",
      "______________\n",
      "epoch 541 train loss 2.9988951683044434\n",
      "val loss 3.1563620567321777\n",
      "______________\n",
      "epoch 542 train loss 3.058840036392212\n",
      "val loss 3.1562232971191406\n",
      "______________\n",
      "epoch 543 train loss 3.0891053676605225\n",
      "val loss 3.155900239944458\n",
      "______________\n",
      "epoch 544 train loss 3.1216983795166016\n",
      "val loss 3.1556732654571533\n",
      "______________\n",
      "epoch 545 train loss 3.1130521297454834\n",
      "val loss 3.1553778648376465\n",
      "______________\n",
      "epoch 546 train loss 3.1102428436279297\n",
      "val loss 3.1551809310913086\n",
      "______________\n",
      "epoch 547 train loss 3.14013409614563\n",
      "val loss 3.155062675476074\n",
      "______________\n",
      "epoch 548 train loss 3.131051540374756\n",
      "val loss 3.1550095081329346\n",
      "______________\n",
      "epoch 549 train loss 3.152101993560791\n",
      "val loss 3.15496826171875\n",
      "______________\n",
      "epoch 550 train loss 3.115617275238037\n",
      "val loss 3.1547951698303223\n",
      "______________\n",
      "epoch 551 train loss 3.147045373916626\n",
      "val loss 3.1546266078948975\n",
      "______________\n",
      "epoch 552 train loss 3.1085622310638428\n",
      "val loss 3.1545536518096924\n",
      "______________\n",
      "epoch 553 train loss 3.0625579357147217\n",
      "val loss 3.1546504497528076\n",
      "______________\n",
      "epoch 554 train loss 3.015610694885254\n",
      "val loss 3.154665470123291\n",
      "______________\n",
      "epoch 555 train loss 3.043259382247925\n",
      "val loss 3.1546335220336914\n",
      "______________\n",
      "epoch 556 train loss 3.1267359256744385\n",
      "val loss 3.154536247253418\n",
      "______________\n",
      "epoch 557 train loss 3.145155429840088\n",
      "val loss 3.1543900966644287\n",
      "______________\n",
      "epoch 558 train loss 3.0964109897613525\n",
      "val loss 3.154085636138916\n",
      "______________\n",
      "epoch 559 train loss 3.1235110759735107\n",
      "val loss 3.153817892074585\n",
      "______________\n",
      "epoch 560 train loss 3.0833911895751953\n",
      "val loss 3.153421640396118\n",
      "______________\n",
      "epoch 561 train loss 3.1610958576202393\n",
      "val loss 3.1530697345733643\n",
      "______________\n",
      "epoch 562 train loss 3.1291956901550293\n",
      "val loss 3.1528024673461914\n",
      "______________\n",
      "epoch 563 train loss 3.119135618209839\n",
      "val loss 3.1525893211364746\n",
      "______________\n",
      "epoch 564 train loss 3.085254430770874\n",
      "val loss 3.1523561477661133\n",
      "______________\n",
      "epoch 565 train loss 3.1803746223449707\n",
      "val loss 3.1520438194274902\n",
      "______________\n",
      "epoch 566 train loss 3.0729525089263916\n",
      "val loss 3.1517982482910156\n",
      "______________\n",
      "epoch 567 train loss 3.0344812870025635\n",
      "val loss 3.1514575481414795\n",
      "______________\n",
      "epoch 568 train loss 3.1004421710968018\n",
      "val loss 3.1512129306793213\n",
      "______________\n",
      "epoch 569 train loss 3.059640884399414\n",
      "val loss 3.1509974002838135\n",
      "______________\n",
      "epoch 570 train loss 3.028362989425659\n",
      "val loss 3.1506288051605225\n",
      "______________\n",
      "epoch 571 train loss 3.063840389251709\n",
      "val loss 3.1502952575683594\n",
      "______________\n",
      "epoch 572 train loss 3.052485942840576\n",
      "val loss 3.150064468383789\n",
      "______________\n",
      "epoch 573 train loss 3.145390748977661\n",
      "val loss 3.149848222732544\n",
      "______________\n",
      "epoch 574 train loss 3.0382659435272217\n",
      "val loss 3.1494786739349365\n",
      "______________\n",
      "epoch 575 train loss 3.0623481273651123\n",
      "val loss 3.149043083190918\n",
      "______________\n",
      "epoch 576 train loss 3.0222747325897217\n",
      "val loss 3.1486146450042725\n",
      "______________\n",
      "epoch 577 train loss 3.099848985671997\n",
      "val loss 3.1482274532318115\n",
      "______________\n",
      "epoch 578 train loss 3.0428154468536377\n",
      "val loss 3.1477510929107666\n",
      "______________\n",
      "epoch 579 train loss 3.030994176864624\n",
      "val loss 3.147240400314331\n",
      "______________\n",
      "epoch 580 train loss 3.027733087539673\n",
      "val loss 3.1465702056884766\n",
      "______________\n",
      "epoch 581 train loss 3.0542562007904053\n",
      "val loss 3.1458723545074463\n",
      "______________\n",
      "epoch 582 train loss 3.0663204193115234\n",
      "val loss 3.1452157497406006\n",
      "______________\n",
      "epoch 583 train loss 3.0161421298980713\n",
      "val loss 3.1445701122283936\n",
      "______________\n",
      "epoch 584 train loss 3.0918095111846924\n",
      "val loss 3.1440277099609375\n",
      "______________\n",
      "epoch 585 train loss 3.0586512088775635\n",
      "val loss 3.143557071685791\n",
      "______________\n",
      "epoch 586 train loss 3.05615496635437\n",
      "val loss 3.143120765686035\n",
      "______________\n",
      "epoch 587 train loss 3.0499463081359863\n",
      "val loss 3.142674684524536\n",
      "______________\n",
      "epoch 588 train loss 3.127225399017334\n",
      "val loss 3.142268180847168\n",
      "______________\n",
      "epoch 589 train loss 3.0811877250671387\n",
      "val loss 3.141951084136963\n",
      "______________\n",
      "epoch 590 train loss 3.0035810470581055\n",
      "val loss 3.141784191131592\n",
      "______________\n",
      "epoch 591 train loss 3.0427474975585938\n",
      "val loss 3.141767978668213\n",
      "______________\n",
      "epoch 592 train loss 3.0909206867218018\n",
      "val loss 3.141676425933838\n",
      "______________\n",
      "epoch 593 train loss 3.0295140743255615\n",
      "val loss 3.1414594650268555\n",
      "______________\n",
      "epoch 594 train loss 3.0583558082580566\n",
      "val loss 3.141170024871826\n",
      "______________\n",
      "epoch 595 train loss 3.0695090293884277\n",
      "val loss 3.1409432888031006\n",
      "______________\n",
      "epoch 596 train loss 3.0658459663391113\n",
      "val loss 3.1406099796295166\n",
      "______________\n",
      "epoch 597 train loss 3.0737502574920654\n",
      "val loss 3.1401779651641846\n",
      "______________\n",
      "epoch 598 train loss 3.0571095943450928\n",
      "val loss 3.1395716667175293\n",
      "______________\n",
      "epoch 599 train loss 3.0069258213043213\n",
      "val loss 3.1388399600982666\n",
      "______________\n",
      "epoch 600 train loss 3.0958199501037598\n",
      "val loss 3.1380467414855957\n",
      "______________\n",
      "epoch 601 train loss 2.998311996459961\n",
      "val loss 3.1372084617614746\n",
      "______________\n",
      "epoch 602 train loss 3.021841287612915\n",
      "val loss 3.13639497756958\n",
      "______________\n",
      "epoch 603 train loss 3.0153849124908447\n",
      "val loss 3.135840892791748\n",
      "______________\n",
      "epoch 604 train loss 3.005845069885254\n",
      "val loss 3.1352574825286865\n",
      "______________\n",
      "epoch 605 train loss 3.122023582458496\n",
      "val loss 3.134488582611084\n",
      "______________\n",
      "epoch 606 train loss 3.084153890609741\n",
      "val loss 3.133819341659546\n",
      "______________\n",
      "epoch 607 train loss 3.1662838459014893\n",
      "val loss 3.1332814693450928\n",
      "______________\n",
      "epoch 608 train loss 2.9936699867248535\n",
      "val loss 3.132866859436035\n",
      "______________\n",
      "epoch 609 train loss 2.992293357849121\n",
      "val loss 3.132401943206787\n",
      "______________\n",
      "epoch 610 train loss 2.9987576007843018\n",
      "val loss 3.1320035457611084\n",
      "______________\n",
      "epoch 611 train loss 2.9628937244415283\n",
      "val loss 3.131730556488037\n",
      "______________\n",
      "epoch 612 train loss 3.0583655834198\n",
      "val loss 3.1315228939056396\n",
      "______________\n",
      "epoch 613 train loss 3.0193347930908203\n",
      "val loss 3.131303548812866\n",
      "______________\n",
      "epoch 614 train loss 3.1566474437713623\n",
      "val loss 3.131281614303589\n",
      "______________\n",
      "epoch 615 train loss 3.1375410556793213\n",
      "val loss 3.1313388347625732\n",
      "______________\n",
      "epoch 616 train loss 3.1214399337768555\n",
      "val loss 3.1313369274139404\n",
      "______________\n",
      "epoch 617 train loss 3.0099663734436035\n",
      "val loss 3.1313889026641846\n",
      "______________\n",
      "epoch 618 train loss 2.9715089797973633\n",
      "val loss 3.131582736968994\n",
      "______________\n",
      "epoch 619 train loss 2.963371515274048\n",
      "val loss 3.131545305252075\n",
      "______________\n",
      "epoch 620 train loss 3.0040442943573\n",
      "val loss 3.1315605640411377\n",
      "______________\n",
      "epoch 621 train loss 3.0191993713378906\n",
      "val loss 3.1315793991088867\n",
      "______________\n",
      "epoch 622 train loss 3.0418944358825684\n",
      "val loss 3.131589651107788\n",
      "______________\n",
      "epoch 623 train loss 3.089101552963257\n",
      "val loss 3.13161563873291\n",
      "______________\n",
      "epoch 624 train loss 3.033050775527954\n",
      "val loss 3.1315932273864746\n",
      "______________\n",
      "epoch 625 train loss 3.0652389526367188\n",
      "val loss 3.131505012512207\n",
      "______________\n",
      "best loss 3.131281614303589 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9403342420291573, 'roc_macro': -1}, 'nd': {'accuracy': 0.34012394514767935, 'roc_micro': 0.7368927600394601, 'roc_macro': 0.5674594902872342}, 'mod': {'accuracy': 0.34012394514767935, 'roc_micro': 0.7368927600394601, 'roc_macro': 0.5674594902872342}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.289044289044289, 0.7338308457711443, 0.6670092497430626, -1, 0.47092198581560285, -1, 0.5829787234042554, -1], 'auc_mean': -0.03202686327770571}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=72, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (disease_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=500, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=500, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_args = {'hidden_layers': [500, 500], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model2,_,_ = train_state(model_args=t2_args,state=2,use_attention=False,use_smote=False)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7e7ebb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss 2.2618024349212646\n",
      "val loss 2.143848419189453\n",
      "______________\n",
      "epoch 1 train loss 2.2406535148620605\n",
      "val loss 2.1115522384643555\n",
      "______________\n",
      "epoch 2 train loss 2.159592628479004\n",
      "val loss 2.080714702606201\n",
      "______________\n",
      "epoch 3 train loss 2.0866901874542236\n",
      "val loss 2.0511999130249023\n",
      "______________\n",
      "epoch 4 train loss 2.091585636138916\n",
      "val loss 2.023052453994751\n",
      "______________\n",
      "epoch 5 train loss 2.0663974285125732\n",
      "val loss 1.9962196350097656\n",
      "______________\n",
      "epoch 6 train loss 1.9959940910339355\n",
      "val loss 1.9704458713531494\n",
      "______________\n",
      "epoch 7 train loss 1.9626026153564453\n",
      "val loss 1.9457974433898926\n",
      "______________\n",
      "epoch 8 train loss 1.9203476905822754\n",
      "val loss 1.9220383167266846\n",
      "______________\n",
      "epoch 9 train loss 1.8915472030639648\n",
      "val loss 1.8990752696990967\n",
      "______________\n",
      "epoch 10 train loss 1.8611359596252441\n",
      "val loss 1.8769221305847168\n",
      "______________\n",
      "epoch 11 train loss 1.862541675567627\n",
      "val loss 1.8556615114212036\n",
      "______________\n",
      "epoch 12 train loss 1.813774585723877\n",
      "val loss 1.8353416919708252\n",
      "______________\n",
      "epoch 13 train loss 1.8340375423431396\n",
      "val loss 1.8159586191177368\n",
      "______________\n",
      "epoch 14 train loss 1.759938359260559\n",
      "val loss 1.7974011898040771\n",
      "______________\n",
      "epoch 15 train loss 1.7801076173782349\n",
      "val loss 1.779634952545166\n",
      "______________\n",
      "epoch 16 train loss 1.7633389234542847\n",
      "val loss 1.7626352310180664\n",
      "______________\n",
      "epoch 17 train loss 1.7254152297973633\n",
      "val loss 1.746382236480713\n",
      "______________\n",
      "epoch 18 train loss 1.7224971055984497\n",
      "val loss 1.7307662963867188\n",
      "______________\n",
      "epoch 19 train loss 1.687667727470398\n",
      "val loss 1.7158008813858032\n",
      "______________\n",
      "epoch 20 train loss 1.6605757474899292\n",
      "val loss 1.7014648914337158\n",
      "______________\n",
      "epoch 21 train loss 1.6949552297592163\n",
      "val loss 1.6877188682556152\n",
      "______________\n",
      "epoch 22 train loss 1.6901698112487793\n",
      "val loss 1.6746604442596436\n",
      "______________\n",
      "epoch 23 train loss 1.6493141651153564\n",
      "val loss 1.6621923446655273\n",
      "______________\n",
      "epoch 24 train loss 1.6616454124450684\n",
      "val loss 1.6503534317016602\n",
      "______________\n",
      "epoch 25 train loss 1.6559584140777588\n",
      "val loss 1.6390882730484009\n",
      "______________\n",
      "epoch 26 train loss 1.623307704925537\n",
      "val loss 1.6284282207489014\n",
      "______________\n",
      "epoch 27 train loss 1.6279486417770386\n",
      "val loss 1.6183042526245117\n",
      "______________\n",
      "epoch 28 train loss 1.5909206867218018\n",
      "val loss 1.608695387840271\n",
      "______________\n",
      "epoch 29 train loss 1.592806100845337\n",
      "val loss 1.5995595455169678\n",
      "______________\n",
      "epoch 30 train loss 1.5845211744308472\n",
      "val loss 1.5908615589141846\n",
      "______________\n",
      "epoch 31 train loss 1.6262283325195312\n",
      "val loss 1.5826644897460938\n",
      "______________\n",
      "epoch 32 train loss 1.589493751525879\n",
      "val loss 1.5749480724334717\n",
      "______________\n",
      "epoch 33 train loss 1.5743942260742188\n",
      "val loss 1.5677125453948975\n",
      "______________\n",
      "epoch 34 train loss 1.5799680948257446\n",
      "val loss 1.5608749389648438\n",
      "______________\n",
      "epoch 35 train loss 1.5572967529296875\n",
      "val loss 1.554382562637329\n",
      "______________\n",
      "epoch 36 train loss 1.5701055526733398\n",
      "val loss 1.54826021194458\n",
      "______________\n",
      "epoch 37 train loss 1.5624183416366577\n",
      "val loss 1.5424208641052246\n",
      "______________\n",
      "epoch 38 train loss 1.5557043552398682\n",
      "val loss 1.5369172096252441\n",
      "______________\n",
      "epoch 39 train loss 1.5357112884521484\n",
      "val loss 1.5316789150238037\n",
      "______________\n",
      "epoch 40 train loss 1.5572826862335205\n",
      "val loss 1.5266571044921875\n",
      "______________\n",
      "epoch 41 train loss 1.5489490032196045\n",
      "val loss 1.521818995475769\n",
      "______________\n",
      "epoch 42 train loss 1.5362207889556885\n",
      "val loss 1.5172152519226074\n",
      "______________\n",
      "epoch 43 train loss 1.5537129640579224\n",
      "val loss 1.5128262042999268\n",
      "______________\n",
      "epoch 44 train loss 1.5688573122024536\n",
      "val loss 1.508679986000061\n",
      "______________\n",
      "epoch 45 train loss 1.4968045949935913\n",
      "val loss 1.5047099590301514\n",
      "______________\n",
      "epoch 46 train loss 1.5123178958892822\n",
      "val loss 1.500877857208252\n",
      "______________\n",
      "epoch 47 train loss 1.5271425247192383\n",
      "val loss 1.4972174167633057\n",
      "______________\n",
      "epoch 48 train loss 1.483454942703247\n",
      "val loss 1.4936673641204834\n",
      "______________\n",
      "epoch 49 train loss 1.4994189739227295\n",
      "val loss 1.4903717041015625\n",
      "______________\n",
      "epoch 50 train loss 1.5289485454559326\n",
      "val loss 1.4872663021087646\n",
      "______________\n",
      "epoch 51 train loss 1.4855918884277344\n",
      "val loss 1.4842569828033447\n",
      "______________\n",
      "epoch 52 train loss 1.5278172492980957\n",
      "val loss 1.4813809394836426\n",
      "______________\n",
      "epoch 53 train loss 1.502448320388794\n",
      "val loss 1.4785860776901245\n",
      "______________\n",
      "epoch 54 train loss 1.4783174991607666\n",
      "val loss 1.475855827331543\n",
      "______________\n",
      "epoch 55 train loss 1.4940438270568848\n",
      "val loss 1.473253846168518\n",
      "______________\n",
      "epoch 56 train loss 1.4841656684875488\n",
      "val loss 1.4707375764846802\n",
      "______________\n",
      "epoch 57 train loss 1.5004596710205078\n",
      "val loss 1.468258023262024\n",
      "______________\n",
      "epoch 58 train loss 1.5767409801483154\n",
      "val loss 1.4659223556518555\n",
      "______________\n",
      "epoch 59 train loss 1.4658958911895752\n",
      "val loss 1.4635934829711914\n",
      "______________\n",
      "epoch 60 train loss 1.4862697124481201\n",
      "val loss 1.4613533020019531\n",
      "______________\n",
      "epoch 61 train loss 1.505720615386963\n",
      "val loss 1.459172010421753\n",
      "______________\n",
      "epoch 62 train loss 1.4749743938446045\n",
      "val loss 1.4570438861846924\n",
      "______________\n",
      "epoch 63 train loss 1.465419054031372\n",
      "val loss 1.4549496173858643\n",
      "______________\n",
      "epoch 64 train loss 1.4164788722991943\n",
      "val loss 1.4527561664581299\n",
      "______________\n",
      "epoch 65 train loss 1.4952876567840576\n",
      "val loss 1.4505789279937744\n",
      "______________\n",
      "epoch 66 train loss 1.453993320465088\n",
      "val loss 1.4483742713928223\n",
      "______________\n",
      "epoch 67 train loss 1.4754512310028076\n",
      "val loss 1.446218490600586\n",
      "______________\n",
      "epoch 68 train loss 1.4546349048614502\n",
      "val loss 1.4441471099853516\n",
      "______________\n",
      "epoch 69 train loss 1.423966884613037\n",
      "val loss 1.4420632123947144\n",
      "______________\n",
      "epoch 70 train loss 1.46451997756958\n",
      "val loss 1.4400362968444824\n",
      "______________\n",
      "epoch 71 train loss 1.4527523517608643\n",
      "val loss 1.4379644393920898\n",
      "______________\n",
      "epoch 72 train loss 1.4587817192077637\n",
      "val loss 1.435899019241333\n",
      "______________\n",
      "epoch 73 train loss 1.4665619134902954\n",
      "val loss 1.4338737726211548\n",
      "______________\n",
      "epoch 74 train loss 1.4541168212890625\n",
      "val loss 1.431884527206421\n",
      "______________\n",
      "epoch 75 train loss 1.4133331775665283\n",
      "val loss 1.4298845529556274\n",
      "______________\n",
      "epoch 76 train loss 1.486931324005127\n",
      "val loss 1.4279241561889648\n",
      "______________\n",
      "epoch 77 train loss 1.4392421245574951\n",
      "val loss 1.4259058237075806\n",
      "______________\n",
      "epoch 78 train loss 1.405194640159607\n",
      "val loss 1.4238609075546265\n",
      "______________\n",
      "epoch 79 train loss 1.4207149744033813\n",
      "val loss 1.4217958450317383\n",
      "______________\n",
      "epoch 80 train loss 1.3818546533584595\n",
      "val loss 1.4197088479995728\n",
      "______________\n",
      "epoch 81 train loss 1.4129371643066406\n",
      "val loss 1.4175654649734497\n",
      "______________\n",
      "epoch 82 train loss 1.4113179445266724\n",
      "val loss 1.4153755903244019\n",
      "______________\n",
      "epoch 83 train loss 1.4549438953399658\n",
      "val loss 1.4132064580917358\n",
      "______________\n",
      "epoch 84 train loss 1.3933782577514648\n",
      "val loss 1.4110344648361206\n",
      "______________\n",
      "epoch 85 train loss 1.4238767623901367\n",
      "val loss 1.4088919162750244\n",
      "______________\n",
      "epoch 86 train loss 1.4052711725234985\n",
      "val loss 1.4068279266357422\n",
      "______________\n",
      "epoch 87 train loss 1.4067249298095703\n",
      "val loss 1.4047565460205078\n",
      "______________\n",
      "epoch 88 train loss 1.4248905181884766\n",
      "val loss 1.402768850326538\n",
      "______________\n",
      "epoch 89 train loss 1.4224178791046143\n",
      "val loss 1.400864839553833\n",
      "______________\n",
      "epoch 90 train loss 1.4093290567398071\n",
      "val loss 1.3989667892456055\n",
      "______________\n",
      "epoch 91 train loss 1.3868346214294434\n",
      "val loss 1.3969978094100952\n",
      "______________\n",
      "epoch 92 train loss 1.4030730724334717\n",
      "val loss 1.395012378692627\n",
      "______________\n",
      "epoch 93 train loss 1.4042181968688965\n",
      "val loss 1.3930048942565918\n",
      "______________\n",
      "epoch 94 train loss 1.4185434579849243\n",
      "val loss 1.3910077810287476\n",
      "______________\n",
      "epoch 95 train loss 1.3867708444595337\n",
      "val loss 1.3890697956085205\n",
      "______________\n",
      "epoch 96 train loss 1.389738917350769\n",
      "val loss 1.3871721029281616\n",
      "______________\n",
      "epoch 97 train loss 1.4150075912475586\n",
      "val loss 1.385288953781128\n",
      "______________\n",
      "epoch 98 train loss 1.3818776607513428\n",
      "val loss 1.3833329677581787\n",
      "______________\n",
      "epoch 99 train loss 1.3468332290649414\n",
      "val loss 1.3812874555587769\n",
      "______________\n",
      "epoch 100 train loss 1.3801898956298828\n",
      "val loss 1.3792757987976074\n",
      "______________\n",
      "epoch 101 train loss 1.3678961992263794\n",
      "val loss 1.3772882223129272\n",
      "______________\n",
      "epoch 102 train loss 1.3716983795166016\n",
      "val loss 1.3752915859222412\n",
      "______________\n",
      "epoch 103 train loss 1.3273645639419556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.3732812404632568\n",
      "______________\n",
      "epoch 104 train loss 1.3399834632873535\n",
      "val loss 1.3712007999420166\n",
      "______________\n",
      "epoch 105 train loss 1.3930026292800903\n",
      "val loss 1.369257926940918\n",
      "______________\n",
      "epoch 106 train loss 1.3601747751235962\n",
      "val loss 1.367357850074768\n",
      "______________\n",
      "epoch 107 train loss 1.3442729711532593\n",
      "val loss 1.3654862642288208\n",
      "______________\n",
      "epoch 108 train loss 1.3501203060150146\n",
      "val loss 1.3636412620544434\n",
      "______________\n",
      "epoch 109 train loss 1.377656102180481\n",
      "val loss 1.361830711364746\n",
      "______________\n",
      "epoch 110 train loss 1.371109962463379\n",
      "val loss 1.3601478338241577\n",
      "______________\n",
      "epoch 111 train loss 1.352440595626831\n",
      "val loss 1.3584325313568115\n",
      "______________\n",
      "epoch 112 train loss 1.311982274055481\n",
      "val loss 1.3567085266113281\n",
      "______________\n",
      "epoch 113 train loss 1.3158514499664307\n",
      "val loss 1.3548954725265503\n",
      "______________\n",
      "epoch 114 train loss 1.3635830879211426\n",
      "val loss 1.3531363010406494\n",
      "______________\n",
      "epoch 115 train loss 1.3940324783325195\n",
      "val loss 1.351474642753601\n",
      "______________\n",
      "epoch 116 train loss 1.3636491298675537\n",
      "val loss 1.3498826026916504\n",
      "______________\n",
      "epoch 117 train loss 1.3783550262451172\n",
      "val loss 1.348388910293579\n",
      "______________\n",
      "epoch 118 train loss 1.3294544219970703\n",
      "val loss 1.3469057083129883\n",
      "______________\n",
      "epoch 119 train loss 1.3379589319229126\n",
      "val loss 1.3453902006149292\n",
      "______________\n",
      "epoch 120 train loss 1.380232810974121\n",
      "val loss 1.3440123796463013\n",
      "______________\n",
      "epoch 121 train loss 1.3285958766937256\n",
      "val loss 1.3425943851470947\n",
      "______________\n",
      "epoch 122 train loss 1.3539456129074097\n",
      "val loss 1.3412830829620361\n",
      "______________\n",
      "epoch 123 train loss 1.3091769218444824\n",
      "val loss 1.339874267578125\n",
      "______________\n",
      "epoch 124 train loss 1.3430439233779907\n",
      "val loss 1.3384181261062622\n",
      "______________\n",
      "epoch 125 train loss 1.3171577453613281\n",
      "val loss 1.3369923830032349\n",
      "______________\n",
      "epoch 126 train loss 1.3153259754180908\n",
      "val loss 1.3355847597122192\n",
      "______________\n",
      "epoch 127 train loss 1.329237461090088\n",
      "val loss 1.3342443704605103\n",
      "______________\n",
      "epoch 128 train loss 1.3246427774429321\n",
      "val loss 1.3329154253005981\n",
      "______________\n",
      "epoch 129 train loss 1.3511725664138794\n",
      "val loss 1.331668734550476\n",
      "______________\n",
      "epoch 130 train loss 1.2999870777130127\n",
      "val loss 1.3303520679473877\n",
      "______________\n",
      "epoch 131 train loss 1.3656678199768066\n",
      "val loss 1.3290581703186035\n",
      "______________\n",
      "epoch 132 train loss 1.3447604179382324\n",
      "val loss 1.3277896642684937\n",
      "______________\n",
      "epoch 133 train loss 1.332994818687439\n",
      "val loss 1.326526165008545\n",
      "______________\n",
      "epoch 134 train loss 1.3653310537338257\n",
      "val loss 1.3252791166305542\n",
      "______________\n",
      "epoch 135 train loss 1.3335154056549072\n",
      "val loss 1.3241066932678223\n",
      "______________\n",
      "epoch 136 train loss 1.29417085647583\n",
      "val loss 1.3228700160980225\n",
      "______________\n",
      "epoch 137 train loss 1.324922800064087\n",
      "val loss 1.3216885328292847\n",
      "______________\n",
      "epoch 138 train loss 1.3008053302764893\n",
      "val loss 1.3204506635665894\n",
      "______________\n",
      "epoch 139 train loss 1.3195149898529053\n",
      "val loss 1.3192131519317627\n",
      "______________\n",
      "epoch 140 train loss 1.3236238956451416\n",
      "val loss 1.3180419206619263\n",
      "______________\n",
      "epoch 141 train loss 1.3070214986801147\n",
      "val loss 1.316928505897522\n",
      "______________\n",
      "epoch 142 train loss 1.2666685581207275\n",
      "val loss 1.3157739639282227\n",
      "______________\n",
      "epoch 143 train loss 1.294500470161438\n",
      "val loss 1.3146686553955078\n",
      "______________\n",
      "epoch 144 train loss 1.3064066171646118\n",
      "val loss 1.3135602474212646\n",
      "______________\n",
      "epoch 145 train loss 1.2677098512649536\n",
      "val loss 1.312381386756897\n",
      "______________\n",
      "epoch 146 train loss 1.336732268333435\n",
      "val loss 1.3113007545471191\n",
      "______________\n",
      "epoch 147 train loss 1.2946668863296509\n",
      "val loss 1.3101531267166138\n",
      "______________\n",
      "epoch 148 train loss 1.3069801330566406\n",
      "val loss 1.3091163635253906\n",
      "______________\n",
      "epoch 149 train loss 1.2948412895202637\n",
      "val loss 1.3080593347549438\n",
      "______________\n",
      "epoch 150 train loss 1.287578821182251\n",
      "val loss 1.3069990873336792\n",
      "______________\n",
      "epoch 151 train loss 1.3138165473937988\n",
      "val loss 1.3059827089309692\n",
      "______________\n",
      "epoch 152 train loss 1.344664454460144\n",
      "val loss 1.3050028085708618\n",
      "______________\n",
      "epoch 153 train loss 1.2802252769470215\n",
      "val loss 1.3039497137069702\n",
      "______________\n",
      "epoch 154 train loss 1.2715249061584473\n",
      "val loss 1.3028321266174316\n",
      "______________\n",
      "epoch 155 train loss 1.2905235290527344\n",
      "val loss 1.3017613887786865\n",
      "______________\n",
      "epoch 156 train loss 1.2966461181640625\n",
      "val loss 1.300707459449768\n",
      "______________\n",
      "epoch 157 train loss 1.3177366256713867\n",
      "val loss 1.2996879816055298\n",
      "______________\n",
      "epoch 158 train loss 1.2562830448150635\n",
      "val loss 1.29861319065094\n",
      "______________\n",
      "epoch 159 train loss 1.2636878490447998\n",
      "val loss 1.2974717617034912\n",
      "______________\n",
      "epoch 160 train loss 1.3305082321166992\n",
      "val loss 1.296386480331421\n",
      "______________\n",
      "epoch 161 train loss 1.290442943572998\n",
      "val loss 1.2953217029571533\n",
      "______________\n",
      "epoch 162 train loss 1.2977705001831055\n",
      "val loss 1.2943154573440552\n",
      "______________\n",
      "epoch 163 train loss 1.2385659217834473\n",
      "val loss 1.29331374168396\n",
      "______________\n",
      "epoch 164 train loss 1.2693026065826416\n",
      "val loss 1.292317509651184\n",
      "______________\n",
      "epoch 165 train loss 1.2411527633666992\n",
      "val loss 1.2912964820861816\n",
      "______________\n",
      "epoch 166 train loss 1.2687219381332397\n",
      "val loss 1.2902965545654297\n",
      "______________\n",
      "epoch 167 train loss 1.279719352722168\n",
      "val loss 1.2893149852752686\n",
      "______________\n",
      "epoch 168 train loss 1.2614171504974365\n",
      "val loss 1.2884272336959839\n",
      "______________\n",
      "epoch 169 train loss 1.2618094682693481\n",
      "val loss 1.2875111103057861\n",
      "______________\n",
      "epoch 170 train loss 1.2614483833312988\n",
      "val loss 1.286657691001892\n",
      "______________\n",
      "epoch 171 train loss 1.2243050336837769\n",
      "val loss 1.2858364582061768\n",
      "______________\n",
      "epoch 172 train loss 1.2838852405548096\n",
      "val loss 1.285099983215332\n",
      "______________\n",
      "epoch 173 train loss 1.232236385345459\n",
      "val loss 1.2843282222747803\n",
      "______________\n",
      "epoch 174 train loss 1.2641971111297607\n",
      "val loss 1.283571481704712\n",
      "______________\n",
      "epoch 175 train loss 1.2500988245010376\n",
      "val loss 1.2828530073165894\n",
      "______________\n",
      "epoch 176 train loss 1.2439700365066528\n",
      "val loss 1.2821167707443237\n",
      "______________\n",
      "epoch 177 train loss 1.2533657550811768\n",
      "val loss 1.281455397605896\n",
      "______________\n",
      "epoch 178 train loss 1.2463665008544922\n",
      "val loss 1.280901312828064\n",
      "______________\n",
      "epoch 179 train loss 1.2433218955993652\n",
      "val loss 1.2803981304168701\n",
      "______________\n",
      "epoch 180 train loss 1.2899460792541504\n",
      "val loss 1.2798973321914673\n",
      "______________\n",
      "epoch 181 train loss 1.2415754795074463\n",
      "val loss 1.279421329498291\n",
      "______________\n",
      "epoch 182 train loss 1.2213810682296753\n",
      "val loss 1.278906226158142\n",
      "______________\n",
      "epoch 183 train loss 1.2657761573791504\n",
      "val loss 1.2783879041671753\n",
      "______________\n",
      "epoch 184 train loss 1.2750890254974365\n",
      "val loss 1.2779254913330078\n",
      "______________\n",
      "epoch 185 train loss 1.2686185836791992\n",
      "val loss 1.2774450778961182\n",
      "______________\n",
      "epoch 186 train loss 1.2852728366851807\n",
      "val loss 1.2770644426345825\n",
      "______________\n",
      "epoch 187 train loss 1.2649040222167969\n",
      "val loss 1.276647686958313\n",
      "______________\n",
      "epoch 188 train loss 1.2887020111083984\n",
      "val loss 1.2762796878814697\n",
      "______________\n",
      "epoch 189 train loss 1.2868695259094238\n",
      "val loss 1.2759162187576294\n",
      "______________\n",
      "epoch 190 train loss 1.2269610166549683\n",
      "val loss 1.2754919528961182\n",
      "______________\n",
      "epoch 191 train loss 1.2304612398147583\n",
      "val loss 1.274970531463623\n",
      "______________\n",
      "epoch 192 train loss 1.2507587671279907\n",
      "val loss 1.274418830871582\n",
      "______________\n",
      "epoch 193 train loss 1.2404141426086426\n",
      "val loss 1.2739014625549316\n",
      "______________\n",
      "epoch 194 train loss 1.235525131225586\n",
      "val loss 1.2734090089797974\n",
      "______________\n",
      "epoch 195 train loss 1.2405325174331665\n",
      "val loss 1.2728664875030518\n",
      "______________\n",
      "epoch 196 train loss 1.2613400220870972\n",
      "val loss 1.2723355293273926\n",
      "______________\n",
      "epoch 197 train loss 1.2249724864959717\n",
      "val loss 1.2717887163162231\n",
      "______________\n",
      "epoch 198 train loss 1.2265039682388306\n",
      "val loss 1.2711303234100342\n",
      "______________\n",
      "epoch 199 train loss 1.2386404275894165\n",
      "val loss 1.270462989807129\n",
      "______________\n",
      "epoch 200 train loss 1.277125597000122\n",
      "val loss 1.269939661026001\n",
      "______________\n",
      "epoch 201 train loss 1.244282603263855\n",
      "val loss 1.2694697380065918\n",
      "______________\n",
      "epoch 202 train loss 1.2180137634277344\n",
      "val loss 1.2689540386199951\n",
      "______________\n",
      "epoch 203 train loss 1.2285817861557007\n",
      "val loss 1.2684383392333984\n",
      "______________\n",
      "epoch 204 train loss 1.2181916236877441\n",
      "val loss 1.2679544687271118\n",
      "______________\n",
      "epoch 205 train loss 1.2283987998962402\n",
      "val loss 1.2674615383148193\n",
      "______________\n",
      "epoch 206 train loss 1.2375478744506836\n",
      "val loss 1.2670857906341553\n",
      "______________\n",
      "epoch 207 train loss 1.230346441268921\n",
      "val loss 1.2666170597076416\n",
      "______________\n",
      "epoch 208 train loss 1.22604501247406\n",
      "val loss 1.2661629915237427\n",
      "______________\n",
      "epoch 209 train loss 1.2509433031082153\n",
      "val loss 1.265812873840332\n",
      "______________\n",
      "epoch 210 train loss 1.2152594327926636\n",
      "val loss 1.2654399871826172\n",
      "______________\n",
      "epoch 211 train loss 1.2267355918884277\n",
      "val loss 1.2650988101959229\n",
      "______________\n",
      "epoch 212 train loss 1.2199565172195435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.2647268772125244\n",
      "______________\n",
      "epoch 213 train loss 1.2452644109725952\n",
      "val loss 1.2643617391586304\n",
      "______________\n",
      "epoch 214 train loss 1.242777943611145\n",
      "val loss 1.2640572786331177\n",
      "______________\n",
      "epoch 215 train loss 1.233198881149292\n",
      "val loss 1.2637630701065063\n",
      "______________\n",
      "epoch 216 train loss 1.2229982614517212\n",
      "val loss 1.2634495496749878\n",
      "______________\n",
      "epoch 217 train loss 1.2289142608642578\n",
      "val loss 1.263178825378418\n",
      "______________\n",
      "epoch 218 train loss 1.2482945919036865\n",
      "val loss 1.2629578113555908\n",
      "______________\n",
      "epoch 219 train loss 1.237855076789856\n",
      "val loss 1.262730360031128\n",
      "______________\n",
      "epoch 220 train loss 1.241115927696228\n",
      "val loss 1.2625415325164795\n",
      "______________\n",
      "epoch 221 train loss 1.2059739828109741\n",
      "val loss 1.2623170614242554\n",
      "______________\n",
      "epoch 222 train loss 1.2172269821166992\n",
      "val loss 1.2620867490768433\n",
      "______________\n",
      "epoch 223 train loss 1.2195500135421753\n",
      "val loss 1.2618577480316162\n",
      "______________\n",
      "epoch 224 train loss 1.2369847297668457\n",
      "val loss 1.261680245399475\n",
      "______________\n",
      "epoch 225 train loss 1.2080473899841309\n",
      "val loss 1.2614765167236328\n",
      "______________\n",
      "epoch 226 train loss 1.2006937265396118\n",
      "val loss 1.2612695693969727\n",
      "______________\n",
      "epoch 227 train loss 1.2111873626708984\n",
      "val loss 1.2610478401184082\n",
      "______________\n",
      "epoch 228 train loss 1.2290549278259277\n",
      "val loss 1.2608376741409302\n",
      "______________\n",
      "epoch 229 train loss 1.2385179996490479\n",
      "val loss 1.2606868743896484\n",
      "______________\n",
      "epoch 230 train loss 1.2017512321472168\n",
      "val loss 1.2605321407318115\n",
      "______________\n",
      "epoch 231 train loss 1.2057527303695679\n",
      "val loss 1.2603776454925537\n",
      "______________\n",
      "epoch 232 train loss 1.273874044418335\n",
      "val loss 1.2603480815887451\n",
      "______________\n",
      "epoch 233 train loss 1.186018943786621\n",
      "val loss 1.2602133750915527\n",
      "______________\n",
      "epoch 234 train loss 1.2143735885620117\n",
      "val loss 1.2600393295288086\n",
      "______________\n",
      "epoch 235 train loss 1.1873977184295654\n",
      "val loss 1.2597888708114624\n",
      "______________\n",
      "epoch 236 train loss 1.2145541906356812\n",
      "val loss 1.2595667839050293\n",
      "______________\n",
      "epoch 237 train loss 1.2399801015853882\n",
      "val loss 1.2593810558319092\n",
      "______________\n",
      "epoch 238 train loss 1.2126190662384033\n",
      "val loss 1.259216547012329\n",
      "______________\n",
      "epoch 239 train loss 1.2057496309280396\n",
      "val loss 1.2590181827545166\n",
      "______________\n",
      "epoch 240 train loss 1.223370909690857\n",
      "val loss 1.2588520050048828\n",
      "______________\n",
      "epoch 241 train loss 1.204119086265564\n",
      "val loss 1.2586802244186401\n",
      "______________\n",
      "epoch 242 train loss 1.187806248664856\n",
      "val loss 1.2585022449493408\n",
      "______________\n",
      "epoch 243 train loss 1.1788240671157837\n",
      "val loss 1.2582451105117798\n",
      "______________\n",
      "epoch 244 train loss 1.2403950691223145\n",
      "val loss 1.2579782009124756\n",
      "______________\n",
      "epoch 245 train loss 1.210369348526001\n",
      "val loss 1.2576932907104492\n",
      "______________\n",
      "epoch 246 train loss 1.1809685230255127\n",
      "val loss 1.2573344707489014\n",
      "______________\n",
      "epoch 247 train loss 1.2080061435699463\n",
      "val loss 1.256955623626709\n",
      "______________\n",
      "epoch 248 train loss 1.2273426055908203\n",
      "val loss 1.2565438747406006\n",
      "______________\n",
      "epoch 249 train loss 1.1740641593933105\n",
      "val loss 1.2560994625091553\n",
      "______________\n",
      "epoch 250 train loss 1.175339937210083\n",
      "val loss 1.2556953430175781\n",
      "______________\n",
      "epoch 251 train loss 1.180330753326416\n",
      "val loss 1.2552847862243652\n",
      "______________\n",
      "epoch 252 train loss 1.200700044631958\n",
      "val loss 1.25490403175354\n",
      "______________\n",
      "epoch 253 train loss 1.2298908233642578\n",
      "val loss 1.254551649093628\n",
      "______________\n",
      "epoch 254 train loss 1.2073161602020264\n",
      "val loss 1.2542132139205933\n",
      "______________\n",
      "epoch 255 train loss 1.2106385231018066\n",
      "val loss 1.2538690567016602\n",
      "______________\n",
      "epoch 256 train loss 1.1968750953674316\n",
      "val loss 1.2534775733947754\n",
      "______________\n",
      "epoch 257 train loss 1.1932119131088257\n",
      "val loss 1.2530772686004639\n",
      "______________\n",
      "epoch 258 train loss 1.2036519050598145\n",
      "val loss 1.252678632736206\n",
      "______________\n",
      "epoch 259 train loss 1.2517545223236084\n",
      "val loss 1.2522929906845093\n",
      "______________\n",
      "epoch 260 train loss 1.226130485534668\n",
      "val loss 1.2519601583480835\n",
      "______________\n",
      "epoch 261 train loss 1.1923397779464722\n",
      "val loss 1.2516398429870605\n",
      "______________\n",
      "epoch 262 train loss 1.1646716594696045\n",
      "val loss 1.2513115406036377\n",
      "______________\n",
      "epoch 263 train loss 1.1767743825912476\n",
      "val loss 1.250997543334961\n",
      "______________\n",
      "epoch 264 train loss 1.1628845930099487\n",
      "val loss 1.2506935596466064\n",
      "______________\n",
      "epoch 265 train loss 1.1747245788574219\n",
      "val loss 1.2503052949905396\n",
      "______________\n",
      "epoch 266 train loss 1.2621763944625854\n",
      "val loss 1.2500219345092773\n",
      "______________\n",
      "epoch 267 train loss 1.1764063835144043\n",
      "val loss 1.2497007846832275\n",
      "______________\n",
      "epoch 268 train loss 1.2082663774490356\n",
      "val loss 1.249464988708496\n",
      "______________\n",
      "epoch 269 train loss 1.187474250793457\n",
      "val loss 1.2492862939834595\n",
      "______________\n",
      "epoch 270 train loss 1.137508511543274\n",
      "val loss 1.2489988803863525\n",
      "______________\n",
      "epoch 271 train loss 1.1899981498718262\n",
      "val loss 1.2487003803253174\n",
      "______________\n",
      "epoch 272 train loss 1.203346848487854\n",
      "val loss 1.248410940170288\n",
      "______________\n",
      "epoch 273 train loss 1.239454746246338\n",
      "val loss 1.2481786012649536\n",
      "______________\n",
      "epoch 274 train loss 1.1947276592254639\n",
      "val loss 1.2479681968688965\n",
      "______________\n",
      "epoch 275 train loss 1.1725982427597046\n",
      "val loss 1.2477014064788818\n",
      "______________\n",
      "epoch 276 train loss 1.1724610328674316\n",
      "val loss 1.247366189956665\n",
      "______________\n",
      "epoch 277 train loss 1.17208731174469\n",
      "val loss 1.2470706701278687\n",
      "______________\n",
      "epoch 278 train loss 1.2181353569030762\n",
      "val loss 1.2468128204345703\n",
      "______________\n",
      "epoch 279 train loss 1.183330774307251\n",
      "val loss 1.2465312480926514\n",
      "______________\n",
      "epoch 280 train loss 1.2002840042114258\n",
      "val loss 1.2463204860687256\n",
      "______________\n",
      "epoch 281 train loss 1.1650716066360474\n",
      "val loss 1.246114730834961\n",
      "______________\n",
      "epoch 282 train loss 1.1968238353729248\n",
      "val loss 1.245827317237854\n",
      "______________\n",
      "epoch 283 train loss 1.147566795349121\n",
      "val loss 1.2454969882965088\n",
      "______________\n",
      "epoch 284 train loss 1.1959117650985718\n",
      "val loss 1.2452154159545898\n",
      "______________\n",
      "epoch 285 train loss 1.175819754600525\n",
      "val loss 1.2449456453323364\n",
      "______________\n",
      "epoch 286 train loss 1.207529902458191\n",
      "val loss 1.244742751121521\n",
      "______________\n",
      "epoch 287 train loss 1.1834778785705566\n",
      "val loss 1.244494915008545\n",
      "______________\n",
      "epoch 288 train loss 1.1640491485595703\n",
      "val loss 1.24428129196167\n",
      "______________\n",
      "epoch 289 train loss 1.1853251457214355\n",
      "val loss 1.2441892623901367\n",
      "______________\n",
      "epoch 290 train loss 1.1807265281677246\n",
      "val loss 1.244077444076538\n",
      "______________\n",
      "epoch 291 train loss 1.1876654624938965\n",
      "val loss 1.243906855583191\n",
      "______________\n",
      "epoch 292 train loss 1.2000617980957031\n",
      "val loss 1.2436959743499756\n",
      "______________\n",
      "epoch 293 train loss 1.2138559818267822\n",
      "val loss 1.2434738874435425\n",
      "______________\n",
      "epoch 294 train loss 1.1924653053283691\n",
      "val loss 1.243340015411377\n",
      "______________\n",
      "epoch 295 train loss 1.166139006614685\n",
      "val loss 1.2431389093399048\n",
      "______________\n",
      "epoch 296 train loss 1.178109049797058\n",
      "val loss 1.2429548501968384\n",
      "______________\n",
      "epoch 297 train loss 1.218632698059082\n",
      "val loss 1.2428250312805176\n",
      "______________\n",
      "epoch 298 train loss 1.2406926155090332\n",
      "val loss 1.2427922487258911\n",
      "______________\n",
      "epoch 299 train loss 1.1583268642425537\n",
      "val loss 1.2427241802215576\n",
      "______________\n",
      "epoch 300 train loss 1.152788758277893\n",
      "val loss 1.2426230907440186\n",
      "______________\n",
      "epoch 301 train loss 1.1694395542144775\n",
      "val loss 1.2425563335418701\n",
      "______________\n",
      "epoch 302 train loss 1.2160223722457886\n",
      "val loss 1.2424843311309814\n",
      "______________\n",
      "epoch 303 train loss 1.14309561252594\n",
      "val loss 1.2423819303512573\n",
      "______________\n",
      "epoch 304 train loss 1.1426820755004883\n",
      "val loss 1.2422422170639038\n",
      "______________\n",
      "epoch 305 train loss 1.1597214937210083\n",
      "val loss 1.2420846223831177\n",
      "______________\n",
      "epoch 306 train loss 1.1582074165344238\n",
      "val loss 1.241903305053711\n",
      "______________\n",
      "epoch 307 train loss 1.099316120147705\n",
      "val loss 1.2417495250701904\n",
      "______________\n",
      "epoch 308 train loss 1.1783888339996338\n",
      "val loss 1.241611123085022\n",
      "______________\n",
      "epoch 309 train loss 1.1957013607025146\n",
      "val loss 1.2414088249206543\n",
      "______________\n",
      "epoch 310 train loss 1.217827558517456\n",
      "val loss 1.2412924766540527\n",
      "______________\n",
      "epoch 311 train loss 1.1497106552124023\n",
      "val loss 1.2411999702453613\n",
      "______________\n",
      "epoch 312 train loss 1.1641762256622314\n",
      "val loss 1.2410969734191895\n",
      "______________\n",
      "epoch 313 train loss 1.2119801044464111\n",
      "val loss 1.2411140203475952\n",
      "______________\n",
      "epoch 314 train loss 1.163152813911438\n",
      "val loss 1.2411282062530518\n",
      "______________\n",
      "epoch 315 train loss 1.1567754745483398\n",
      "val loss 1.2411037683486938\n",
      "______________\n",
      "epoch 316 train loss 1.1708221435546875\n",
      "val loss 1.241052269935608\n",
      "______________\n",
      "epoch 317 train loss 1.1766438484191895\n",
      "val loss 1.241007924079895\n",
      "______________\n",
      "epoch 318 train loss 1.1377921104431152\n",
      "val loss 1.240966558456421\n",
      "______________\n",
      "epoch 319 train loss 1.150407314300537\n",
      "val loss 1.2409080266952515\n",
      "______________\n",
      "epoch 320 train loss 1.193274974822998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.2408045530319214\n",
      "______________\n",
      "epoch 321 train loss 1.183243751525879\n",
      "val loss 1.2407293319702148\n",
      "______________\n",
      "epoch 322 train loss 1.164512276649475\n",
      "val loss 1.2406764030456543\n",
      "______________\n",
      "epoch 323 train loss 1.198918342590332\n",
      "val loss 1.2406634092330933\n",
      "______________\n",
      "epoch 324 train loss 1.1977900266647339\n",
      "val loss 1.2406835556030273\n",
      "______________\n",
      "epoch 325 train loss 1.137998342514038\n",
      "val loss 1.2407160997390747\n",
      "______________\n",
      "epoch 326 train loss 1.1934255361557007\n",
      "val loss 1.2407705783843994\n",
      "______________\n",
      "epoch 327 train loss 1.186288595199585\n",
      "val loss 1.2408310174942017\n",
      "______________\n",
      "epoch 328 train loss 1.161870002746582\n",
      "val loss 1.2408814430236816\n",
      "______________\n",
      "epoch 329 train loss 1.201947569847107\n",
      "val loss 1.2408894300460815\n",
      "______________\n",
      "epoch 330 train loss 1.135907769203186\n",
      "val loss 1.2408902645111084\n",
      "______________\n",
      "epoch 331 train loss 1.1495435237884521\n",
      "val loss 1.2408567667007446\n",
      "______________\n",
      "epoch 332 train loss 1.1719534397125244\n",
      "val loss 1.2408909797668457\n",
      "______________\n",
      "epoch 333 train loss 1.1483314037322998\n",
      "val loss 1.2408850193023682\n",
      "______________\n",
      "epoch 334 train loss 1.1436834335327148\n",
      "val loss 1.2408418655395508\n",
      "______________\n",
      "best loss 1.2406634092330933 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.10916822, 'auc': 0.6346153846153846}, 'FT': {'accuracy': -1, 'mse': 0.15713833, 'auc': 0.7138157894736843}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.123939276, 'auc': 0.8125}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EndpointSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=70, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (outcome_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3_args = {'hidden_layers': [500, 500], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model3,_,_ = train_state(model_args=t3_args,state=3,use_attention=False,use_smote=False)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0a9536fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.764965534210205 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6839781628293378, 'roc_macro': 0.6330226813097114}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9510489510489512, 0.9313131313131313, 0.9527363184079602, -1, 0.9092198581560285, -1, 0.9333333333333333, -1], 'auc_mean': 0.20970644903242558}}\n",
      "done 0 2.764965534210205\n",
      "_++++++++++New Best++++____\n",
      "2.764965534210205\n",
      "{'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6839781628293378, 'roc_macro': 0.6330226813097114}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9510489510489512, 0.9313131313131313, 0.9527363184079602, -1, 0.9092198581560285, -1, 0.9333333333333333, -1], 'auc_mean': 0.20970644903242558}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 4.025295257568359 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6755281272252552, 'roc_macro': 0.6340827355168788}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5679000245037981, 'roc_macro': 0.559701470027557}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5679000245037981, 'roc_macro': 0.559701470027557}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.766899766899767, 0.8424242424242425, 0.7170398009950248, -1, 0.75177304964539, -1, 0.8880952380952382, -1], 'auc_mean': 0.12077901225745781}}\n",
      "done 1 4.025295257568359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.001817226409912 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6632328507002136, 'roc_macro': 0.5835680340959767}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6071551090419015, 'roc_macro': 0.6562513573383139}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6071551090419015, 'roc_macro': 0.6562513573383139}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9696969696969696, 0.8915824915824916, 0.9427860696517413, -1, 0.9163120567375886, -1, 0.7916666666666667, -1], 'auc_mean': 0.18900553179193225}}\n",
      "done 2 3.001817226409912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.5316758155822754 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6843104676002848, 'roc_macro': 0.6333873764750005}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9582491582491582, 0.9191542288557214, -1, 0.9546099290780142, -1, 0.9392857142857143, -1], 'auc_mean': 0.20538673778293498}}\n",
      "done 3 2.5316758155822754\n",
      "_++++++++++New Best++++____\n",
      "2.5316758155822754\n",
      "{'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6843104676002848, 'roc_macro': 0.6333873764750005}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9582491582491582, 0.9191542288557214, -1, 0.9546099290780142, -1, 0.9392857142857143, -1], 'auc_mean': 0.20538673778293498}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.395699977874756 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6678851174934726, 'roc_macro': 0.5876957699624655}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6026954177897574, 'roc_macro': 0.638124254972081}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6026954177897574, 'roc_macro': 0.638124254972081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.7226107226107225, 0.8249158249158249, 0.8575870646766169, -1, 0.9304964539007092, -1, 0.9333333333333333, -1], 'auc_mean': 0.15861792492965085}}\n",
      "done 4 3.395699977874756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.398782730102539 {'pd': {'accuracy': 0.4304388422035481, 'roc_micro': 0.6791834797056728, 'roc_macro': 0.6171084583982819}, 'nd': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'mod': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9207459207459208, 0.901010101010101, 0.9079601990049752, -1, 0.9361702127659575, -1, 0.7976190476190477, -1], 'auc_mean': 0.18293818514325025}}\n",
      "done 5 2.398782730102539\n",
      "_++++++++++New Best++++____\n",
      "2.398782730102539\n",
      "{'pd': {'accuracy': 0.4304388422035481, 'roc_micro': 0.6791834797056728, 'roc_macro': 0.6171084583982819}, 'nd': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'mod': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9207459207459208, 0.901010101010101, 0.9079601990049752, -1, 0.9361702127659575, -1, 0.7976190476190477, -1], 'auc_mean': 0.18293818514325025}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.251129150390625 {'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "done 6 2.251129150390625\n",
      "_++++++++++New Best++++____\n",
      "2.251129150390625\n",
      "{'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.520254611968994 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.68112983622122, 'roc_macro': 0.6464487590447383}, 'nd': {'accuracy': 0.4504164702184504, 'roc_micro': 0.6337172261700563, 'roc_macro': 0.6634349949567341}, 'mod': {'accuracy': 0.4504164702184504, 'roc_micro': 0.6337172261700563, 'roc_macro': 0.6634349949567341}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8764568764568764, 0.9481481481481482, 0.9253731343283582, -1, 0.9276595744680851, -1, 0.9369047619047619, -1], 'auc_mean': 0.20181781191327874}}\n",
      "done 7 2.520254611968994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.279262065887451 {'pd': {'accuracy': 0.4637021475256769, 'roc_micro': 0.6813197246617612, 'roc_macro': 0.5885267481288077}, 'nd': {'accuracy': 0.49607103567499605, 'roc_micro': 0.6965449644694928, 'roc_macro': 0.6838083414170372}, 'mod': {'accuracy': 0.49607103567499605, 'roc_micro': 0.6965449644694928, 'roc_macro': 0.6838083414170372}, 'dlts': {'accuracy': [0.9794520547945206, 0.9315068493150684, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9691780821917808, 'auc': [0.9090909090909091, 0.9144781144781146, 0.9104477611940298, -1, 0.9304964539007092, -1, 0.8178571428571428, -1], 'auc_mean': 0.1852962976901132}}\n",
      "done 8 2.279262065887451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.997028350830078 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6793733681462141, 'roc_macro': 0.6386482250527823}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6114677775055133, 'roc_macro': 0.6717222994396908}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6114677775055133, 'roc_macro': 0.6717222994396908}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9533799533799533, 0.9750841750841751, 0.9216417910447761, -1, 0.9049645390070922, -1, 0.8928571428571429, -1], 'auc_mean': 0.20599095017164243}}\n",
      "done 9 2.997028350830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.8466691970825195 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.681604557322573, 'roc_macro': 0.594717942463165}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5880421465327126, 'roc_macro': 0.6352678118982467}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5880421465327126, 'roc_macro': 0.6352678118982467}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8228438228438228, 0.8471380471380472, 0.8550995024875622, -1, 0.8028368794326242, -1, 0.8857142857142857, -1], 'auc_mean': 0.15170406720204277}}\n",
      "done 10 3.8466691970825195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.0380520820617676 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6543080939947781, 'roc_macro': 0.5598462107334532}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6016662582700318, 'roc_macro': 0.6464426274208882}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6016662582700318, 'roc_macro': 0.6464426274208882}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9347319347319346, 0.898989898989899, 0.9378109452736317, -1, 0.9078014184397163, -1, 0.7642857142857142, -1], 'auc_mean': 0.18045248896511196}}\n",
      "done 11 3.0380520820617676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.413274049758911 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6775694279610729, 'roc_macro': 0.6172972181937416}, 'nd': {'accuracy': 0.4266069464089266, 'roc_micro': 0.6321489830923793, 'roc_macro': 0.6658383886644756}, 'mod': {'accuracy': 0.4266069464089266, 'roc_micro': 0.6321489830923793, 'roc_macro': 0.6658383886644756}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079254, 0.9723905723905725, 0.9446517412935324, -1, 0.8921985815602836, -1, 0.9166666666666666, -1], 'auc_mean': 0.20641443591487255}}\n",
      "done 12 2.413274049758911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.300992012023926 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6804177545691906, 'roc_macro': 0.6252601804380816}, 'nd': {'accuracy': 0.4596888260254597, 'roc_micro': 0.6478804214653271, 'roc_macro': 0.6664790523486176}, 'mod': {'accuracy': 0.4596888260254597, 'roc_micro': 0.6478804214653271, 'roc_macro': 0.6664790523486176}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909092, 0.977104377104377, 0.9458955223880597, -1, 0.9177304964539007, -1, 0.8928571428571429, -1], 'auc_mean': 0.2053348059867987}}\n",
      "done 13 2.300992012023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3748905658721924 {'pd': {'accuracy': 0.4165499533146592, 'roc_micro': 0.6802753382387846, 'roc_macro': 0.5898411170141197}, 'nd': {'accuracy': 0.5026716957410027, 'roc_micro': 0.6737074246508209, 'roc_macro': 0.6798814108596717}, 'mod': {'accuracy': 0.5026716957410027, 'roc_micro': 0.6737074246508209, 'roc_macro': 0.6798814108596717}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079254, 0.9232323232323232, 0.8961442786069652, -1, 0.9446808510638298, -1, 0.7869047619047619, -1], 'auc_mean': 0.18454626752697567}}\n",
      "done 14 2.3748905658721924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3364131450653076 {'pd': {'accuracy': 0.3776844070961718, 'roc_micro': 0.6820792784239259, 'roc_macro': 0.6339983152842792}, 'nd': {'accuracy': 0.4676253339619676, 'roc_micro': 0.657730948296986, 'roc_macro': 0.6735513882253011}, 'mod': {'accuracy': 0.4676253339619676, 'roc_micro': 0.657730948296986, 'roc_macro': 0.6735513882253011}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079255, 0.9622895622895623, 0.9440298507462687, -1, 0.9177304964539007, -1, 0.9023809523809523, -1], 'auc_mean': 0.2064798484098262}}\n",
      "done 15 2.3364131450653076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.2603046894073486 {'pd': {'accuracy': 0.35830999066293184, 'roc_micro': 0.6845478281509614, 'roc_macro': 0.6269651718063419}, 'nd': {'accuracy': 0.48349834983498347, 'roc_micro': 0.6686596422445479, 'roc_macro': 0.6666898922333705}, 'mod': {'accuracy': 0.48349834983498347, 'roc_micro': 0.6686596422445479, 'roc_macro': 0.6666898922333705}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8787878787878788, 0.9696969696969696, 0.9452736318407959, -1, 0.902127659574468, -1, 0.9083333333333334, -1], 'auc_mean': 0.20052743415418073}}\n",
      "done 16 2.2603046894073486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.298572063446045 {'pd': {'accuracy': 0.5053688141923436, 'roc_micro': 0.6820318063137907, 'roc_macro': 0.5856912400747091}, 'nd': {'accuracy': 0.5278170674210277, 'roc_micro': 0.7020828228375398, 'roc_macro': 0.6787409450452929}, 'mod': {'accuracy': 0.5278170674210277, 'roc_micro': 0.7020828228375398, 'roc_macro': 0.6787409450452929}, 'dlts': {'accuracy': [0.9794520547945206, 0.9315068493150684, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9700342465753424, 'auc': [0.8648018648018648, 0.9124579124579125, 0.907960199004975, -1, 0.9319148936170213, -1, 0.8190476190476191, -1], 'auc_mean': 0.1795228111161741}}\n",
      "done 17 2.298572063446045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.4547085762023926 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6776643721813435, 'roc_macro': 0.6204213177441975}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.601568243077677, 'roc_macro': 0.6528773159207941}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.601568243077677, 'roc_macro': 0.6528773159207941}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8811188811188811, 0.9441077441077441, 0.9322139303482587, -1, 0.9148936170212766, -1, 0.9130952380952381, -1], 'auc_mean': 0.19817867633642486}}\n",
      "done 18 3.4547085762023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.4677934646606445 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6800854497982436, 'roc_macro': 0.6314613501574468}, 'nd': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6250918892428327, 'roc_macro': 0.658987148117583}, 'mod': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6250918892428327, 'roc_macro': 0.658987148117583}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8951048951048951, 0.9575757575757575, 0.9247512437810945, -1, 0.9375886524822695, -1, 0.930952380952381, -1], 'auc_mean': 0.2057466162370497}}\n",
      "done 19 2.4677934646606445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6515095233917236 {'pd': {'accuracy': 0.3277310924369748, 'roc_micro': 0.6747211013529552, 'roc_macro': 0.6275076423156724}, 'nd': {'accuracy': 0.3631148829168631, 'roc_micro': 0.6184268561627052, 'roc_macro': 0.6478768815725338}, 'mod': {'accuracy': 0.3631148829168631, 'roc_micro': 0.6184268561627052, 'roc_macro': 0.6478768815725338}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8671328671328671, 0.931986531986532, 0.9353233830845771, -1, 0.9234042553191489, -1, 0.9416666666666668, -1], 'auc_mean': 0.19993921302372397}}\n",
      "done 20 2.6515095233917236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.5779154300689697 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6768098741989081, 'roc_macro': 0.6113316490128552}, 'nd': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6195050232786081, 'roc_macro': 0.656675450153711}, 'mod': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6195050232786081, 'roc_macro': 0.656675450153711}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8601398601398601, 0.9292929292929293, 0.9253731343283582, -1, 0.9560283687943262, -1, 0.9476190476190477, -1], 'auc_mean': 0.2023066675218152}}\n",
      "done 21 2.5779154300689697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.593141794204712 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.676619985758367, 'roc_macro': 0.6053695307193232}, 'nd': {'accuracy': 0.3426056891403426, 'roc_micro': 0.6117618230825779, 'roc_macro': 0.6490095049877659}, 'mod': {'accuracy': 0.3426056891403426, 'roc_micro': 0.6117618230825779, 'roc_macro': 0.6490095049877659}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9791245791245792, 0.9409203980099502, -1, 0.9460992907801419, -1, 0.9214285714285715, -1], 'auc_mean': 0.20742096389226428}}\n",
      "done 22 2.593141794204712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.356215476989746 {'pd': {'accuracy': 0.4830765639589169, 'roc_micro': 0.6858295751246143, 'roc_macro': 0.6286025078168812}, 'nd': {'accuracy': 0.5119440515480119, 'roc_micro': 0.7045822102425876, 'roc_macro': 0.6924503636460159}, 'mod': {'accuracy': 0.5119440515480119, 'roc_micro': 0.7045822102425876, 'roc_macro': 0.6924503636460159}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8974358974358974, 0.9595959595959596, 0.9291044776119403, -1, 0.9333333333333333, -1, 0.8904761904761904, -1], 'auc_mean': 0.2012432323066651}}\n",
      "done 23 2.356215476989746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.9129796028137207 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6745786850225493, 'roc_macro': 0.607016177388629}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6130360205831904, 'roc_macro': 0.6548680787811222}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6130360205831904, 'roc_macro': 0.6548680787811222}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8974358974358975, 0.936026936026936, 0.9235074626865672, -1, 0.9163120567375886, -1, 0.9107142857142857, -1], 'auc_mean': 0.19799957982515937}}\n",
      "done 24 2.9129796028137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.988474130630493 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6667932589603608, 'roc_macro': 0.5469005279579185}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5748100955648126, 'roc_macro': 0.5464107148889757}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5748100955648126, 'roc_macro': 0.5464107148889757}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.45687645687645684, 0.6249158249158249, 0.6921641791044777, -1, 0.7943262411347518, -1, 0.8166666666666668, -1], 'auc_mean': 0.04811867108727223}}\n",
      "done 25 3.988474130630493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6778604984283447 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6774270116306671, 'roc_macro': 0.6261786719100272}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6202401372212692, 'roc_macro': 0.6533659577137838}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6202401372212692, 'roc_macro': 0.6533659577137838}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8741258741258741, 0.9616161616161616, 0.9378109452736318, -1, 0.9163120567375886, -1, 0.9178571428571428, -1], 'auc_mean': 0.20096527257629987}}\n",
      "done 26 2.6778604984283447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6250922679901123 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.673249465938761, 'roc_macro': 0.6176413083426929}, 'nd': {'accuracy': 0.3855885588558856, 'roc_micro': 0.6152903700073511, 'roc_macro': 0.6553892966936444}, 'mod': {'accuracy': 0.3855885588558856, 'roc_micro': 0.6152903700073511, 'roc_macro': 0.6553892966936444}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8927738927738927, 0.9542087542087542, 0.9539800995024875, -1, 0.899290780141844, -1, 0.9273809523809523, -1], 'auc_mean': 0.20345430987599133}}\n",
      "done 27 2.6250922679901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.7161152362823486 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6835509138381202, 'roc_macro': 0.6361547246381728}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6163195295270767, 'roc_macro': 0.6741712393886307}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6163195295270767, 'roc_macro': 0.6741712393886307}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9137529137529138, 0.9683501683501683, 0.9359452736318408, -1, 0.9304964539007092, -1, 0.9011904761904762, -1], 'auc_mean': 0.20621691072826354}}\n",
      "done 28 2.7161152362823486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3858258724212646 {'pd': {'accuracy': 0.4969654528478058, 'roc_micro': 0.6851174934725849, 'roc_macro': 0.6237181607808212}, 'nd': {'accuracy': 0.5198805594845198, 'roc_micro': 0.7011026709139917, 'roc_macro': 0.6828778105952019}, 'mod': {'accuracy': 0.5198805594845198, 'roc_micro': 0.7011026709139917, 'roc_macro': 0.6828778105952019}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8951048951048951, 0.9555555555555556, 0.9253731343283582, -1, 0.9432624113475176, -1, 0.8952380952380953, -1], 'auc_mean': 0.20181676144680272}}\n",
      "done 29 2.3858258724212646\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 2.251129150390625\n",
      "{'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeAttentionSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=1000, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (resize_layer): Linear(in_features=63, out_features=100, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gridsearch_attention_transition_models(state=1,attentions=[True,False]):\n",
    "    model_arglist = [\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for use_attention in attentions:\n",
    "            embed_sizes = [200,400] if use_attention else [0]\n",
    "            for embed_size in embed_sizes:\n",
    "                args['embed_size'] = embed_size\n",
    "                for dropout in [.9,]:\n",
    "                    args['dropout'] = dropout\n",
    "                    for input_dropout in [.5]:\n",
    "                        args['input_dropout'] = input_dropout\n",
    "                    \n",
    "                        model,m_loss,m_metrics = train_state(model_args=args,state=state,use_attention=use_attention,verbose=False)\n",
    "                        print('done',k,m_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print(use_attention)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "# model1 = gridsearch_attention_transition_models(1)\n",
    "# model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "27cdf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.808809757232666 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9072182055232902, 'roc_macro': -1}, 'nd': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'mod': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2564102564102564, 0.5926616915422885, 0.60431654676259, -1, 0.5035460992907801, -1, 0.5943262411347519, -1], 'auc_mean': -0.05609239560741665}}\n",
      "done 0 3.808809757232666\n",
      "_++++++++++New Best++++____\n",
      "3.808809757232666\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9072182055232902, 'roc_macro': -1}, 'nd': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'mod': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2564102564102564, 0.5926616915422885, 0.60431654676259, -1, 0.5035460992907801, -1, 0.5943262411347519, -1], 'auc_mean': -0.05609239560741665}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.824561595916748 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9132867132867133, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7394432280262747, 'roc_macro': 0.6098472283685697}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7394432280262747, 'roc_macro': 0.6098472283685697}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.20046620046620045, 0.6057213930348259, 0.48612538540596095, -1, 0.46808510638297873, -1, 0.37163120567375885, -1], 'auc_mean': -0.10849633862953441}}\n",
      "done 1 3.824561595916748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8581931591033936 {'pd': {'accuracy': 0.5, 'roc_micro': 0.934313144482636, 'roc_macro': -1}, 'nd': {'accuracy': 0.3314873417721519, 'roc_micro': 0.7344625971463632, 'roc_macro': 0.5642928287745361}, 'mod': {'accuracy': 0.3314873417721519, 'roc_micro': 0.7344625971463632, 'roc_macro': 0.5642928287745361}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3333333333333333, 0.5174129353233832, 0.6145940390544706, -1, 0.4907801418439717, -1, 0.49503546099290785, -1], 'auc_mean': -0.06860551118149166}}\n",
      "done 2 3.8581931591033936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8618290424346924 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9207775275571886, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7238035658429778, 'roc_macro': 0.5260440382391601}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7238035658429778, 'roc_macro': 0.5260440382391601}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5151515151515151, 0.6822139303482586, 0.5642343268242549, -1, 0.4581560283687944, -1, 0.5829787234042554, -1], 'auc_mean': -0.024658184487865192}}\n",
      "done 3 3.8618290424346924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.7894489765167236 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9281972265023112, 'roc_macro': -1}, 'nd': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'mod': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.543123543123543, 0.4527363184079602, 0.4049331963001027, -1, 0.45390070921985815, -1, 0.33333333333333326, -1], 'auc_mean': -0.10149661245190032}}\n",
      "done 4 3.7894489765167236\n",
      "_++++++++++New Best++++____\n",
      "3.7894489765167236\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9281972265023112, 'roc_macro': -1}, 'nd': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'mod': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.543123543123543, 0.4527363184079602, 0.4049331963001027, -1, 0.45390070921985815, -1, 0.33333333333333326, -1], 'auc_mean': -0.10149661245190032}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6160809993743896 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9404053573545099, 'roc_macro': -1}, 'nd': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'mod': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3356643356643356, 0.5522388059701493, 0.5878725590955807, -1, 0.6524822695035462, -1, 0.5049645390070923, -1], 'auc_mean': -0.045847186344912}}\n",
      "done 5 3.6160809993743896\n",
      "_++++++++++New Best++++____\n",
      "3.6160809993743896\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9404053573545099, 'roc_macro': -1}, 'nd': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'mod': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3356643356643356, 0.5522388059701493, 0.5878725590955807, -1, 0.6524822695035462, -1, 0.5049645390070923, -1], 'auc_mean': -0.045847186344912}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.81306529045105 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9322745051558612, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7073698900411444, 'roc_macro': 0.5147629160586478}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7073698900411444, 'roc_macro': 0.5147629160586478}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.599067599067599, 0.6411691542288558, 0.763617677286742, -1, 0.4836879432624114, -1, 0.15886524822695036, -1], 'auc_mean': -0.044199047240930184}}\n",
      "done 6 3.81306529045105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8622279167175293 {'pd': {'accuracy': 0.5, 'roc_micro': 0.8979732132274505, 'roc_macro': -1}, 'nd': {'accuracy': 0.33419040084388185, 'roc_micro': 0.7286879526479151, 'roc_macro': 0.5092026416340439}, 'mod': {'accuracy': 0.33419040084388185, 'roc_micro': 0.7286879526479151, 'roc_macro': 0.5092026416340439}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7692307692307692, 0.5062189054726368, 0.5817060637204522, -1, 0.5163120567375886, -1, 0.5531914893617021, -1], 'auc_mean': -0.009167589434606369}}\n",
      "done 7 3.8622279167175293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6245648860931396 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9408320493066256, 'roc_macro': -1}, 'nd': {'accuracy': 0.31955432489451474, 'roc_micro': 0.7354972209523352, 'roc_macro': 0.5626309446812496}, 'mod': {'accuracy': 0.31955432489451474, 'roc_micro': 0.7354972209523352, 'roc_macro': 0.5626309446812496}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2913752913752914, 0.5453980099502488, 0.5971223021582733, -1, 0.6425531914893617, -1, 0.526241134751773, -1], 'auc_mean': -0.049663758784381465}}\n",
      "done 8 3.6245648860931396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.7966322898864746 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9020030816640987, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7119655446211592, 'roc_macro': 0.5892248169306097}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7119655446211592, 'roc_macro': 0.5892248169306097}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.62004662004662, 0.47325870646766177, 0.2744090441932169, -1, 0.49503546099290785, -1, 0.3929078014184397, -1], 'auc_mean': -0.0930427958601442}}\n",
      "done 9 3.7966322898864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8089020252227783 {'pd': {'accuracy': 0.5, 'roc_micro': 0.924594050017779, 'roc_macro': -1}, 'nd': {'accuracy': 0.328125, 'roc_micro': 0.7050119102042781, 'roc_macro': 0.5038980875490021}, 'mod': {'accuracy': 0.328125, 'roc_micro': 0.7050119102042781, 'roc_macro': 0.5038980875490021}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.49883449883449876, 0.5926616915422886, 0.42754367934224047, -1, 0.5078014184397164, -1, 0.4595744680851064, -1], 'auc_mean': -0.06419803046951866}}\n",
      "done 10 3.8089020252227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.9345345497131348 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9310181344079649, 'roc_macro': -1}, 'nd': {'accuracy': 0.314543776371308, 'roc_micro': 0.7163446500324824, 'roc_macro': 0.5882717422351568}, 'mod': {'accuracy': 0.314543776371308, 'roc_micro': 0.7163446500324824, 'roc_macro': 0.5882717422351568}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.527363184079602, 0.5775950668036999, -1, 0.5517730496453901, -1, 0.6070921985815603, -1], 'auc_mean': -0.044819265408421266}}\n",
      "done 11 3.9345345497131348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8231570720672607 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9286713286713287, 'roc_macro': -1}, 'nd': {'accuracy': 0.3422336497890295, 'roc_micro': 0.7420658790693199, 'roc_macro': 0.4140939960299716}, 'mod': {'accuracy': 0.3422336497890295, 'roc_micro': 0.7420658790693199, 'roc_macro': 0.4140939960299716}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4242424242424242, 0.47450248756218905, 0.6197327852004111, -1, 0.3773049645390071, -1, 0.7078014184397163, -1], 'auc_mean': -0.04955199000203153}}\n",
      "done 12 3.8231570720672607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.9054479598999023 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9255422543558136, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7711797117489956, 'roc_macro': 0.570120584030645}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7711797117489956, 'roc_macro': 0.570120584030645}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7808857808857809, 0.47512437810945274, 0.39465570400822203, -1, 0.4936170212765958, -1, 0.4865248226950355, -1], 'auc_mean': -0.04614903662811411}}\n",
      "done 13 3.9054479598999023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.642094135284424 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9356406305558849, 'roc_macro': -1}, 'nd': {'accuracy': 0.34487078059071735, 'roc_micro': 0.7490916965424316, 'roc_macro': 0.5605770521929059}, 'mod': {'accuracy': 0.34487078059071735, 'roc_micro': 0.7490916965424316, 'roc_macro': 0.5605770521929059}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.32167832167832167, 0.5292288557213931, 0.6063720452209661, -1, 0.6028368794326242, -1, 0.5943262411347519, -1], 'auc_mean': -0.04319470710149288}}\n",
      "done 14 3.642094135284424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8308892250061035 {'pd': {'accuracy': 0.5, 'roc_micro': 0.925115562403698, 'roc_macro': -1}, 'nd': {'accuracy': 0.3447389240506329, 'roc_micro': 0.74370202834388, 'roc_macro': 0.484826693858706}, 'mod': {'accuracy': 0.3447389240506329, 'roc_micro': 0.74370202834388, 'roc_macro': 0.484826693858706}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4662004662004662, 0.5, 0.5118191161356629, -1, 0.5460992907801419, -1, 0.4836879432624114, -1], 'auc_mean': -0.06152414795266471}}\n",
      "done 15 3.8308892250061035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.805161714553833 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9211805144008534, 'roc_macro': -1}, 'nd': {'accuracy': 0.3704509493670886, 'roc_micro': 0.7719256033300449, 'roc_macro': 0.612286278635364}, 'mod': {'accuracy': 0.3704509493670886, 'roc_micro': 0.7719256033300449, 'roc_macro': 0.612286278635364}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5174825174825175, 0.6679104477611941, 0.32476875642343267, -1, 0.5929078014184397, -1, 0.5503546099290781, -1], 'auc_mean': -0.04332198337316723}}\n",
      "done 16 3.805161714553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.622523069381714 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9383430129192842, 'roc_macro': -1}, 'nd': {'accuracy': 0.3371571729957806, 'roc_micro': 0.7438704554750848, 'roc_macro': 0.6040446960797571}, 'mod': {'accuracy': 0.3371571729957806, 'roc_micro': 0.7438704554750848, 'roc_macro': 0.6040446960797571}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2540792540792541, 0.5180348258706469, 0.5981500513874615, -1, 0.6326241134751773, -1, 0.4539007092198582, -1], 'auc_mean': -0.06790138074595027}}\n",
      "done 17 3.622523069381714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8256046772003174 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9312551854924735, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7060224729915064, 'roc_macro': 0.514530854088781}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7060224729915064, 'roc_macro': 0.514530854088781}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.47319347319347316, 0.6853233830845771, 0.4285714285714286, -1, 0.44680851063829785, -1, 0.3290780141843972, -1], 'auc_mean': -0.07962814879097826}}\n",
      "done 18 3.8256046772003174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.86962890625 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9141163920824937, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7208440605375233, 'roc_macro': 0.5675430341969976}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7208440605375233, 'roc_macro': 0.5675430341969976}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5897435897435898, 0.724502487562189, 0.5724563206577594, -1, 0.44539007092198585, -1, 0.41276595744680855, -1], 'auc_mean': -0.031892696708458415}}\n",
      "done 19 3.86962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6590921878814697 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9298328789854214, 'roc_macro': -1}, 'nd': {'accuracy': 0.3386075949367089, 'roc_micro': 0.7410071942446044, 'roc_macro': 0.577001234775625}, 'mod': {'accuracy': 0.3386075949367089, 'roc_micro': 0.7410071942446044, 'roc_macro': 0.577001234775625}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4405594405594405, 0.6131840796019901, 0.6762589928057554, -1, 0.526241134751773, -1, 0.4794326241134752, -1], 'auc_mean': -0.03304046602094571}}\n",
      "done 20 3.6590921878814697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8690803050994873 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9332227094938959, 'roc_macro': -1}, 'nd': {'accuracy': 0.3358386075949367, 'roc_micro': 0.7272683525420467, 'roc_macro': 0.5248340080657155}, 'mod': {'accuracy': 0.3358386075949367, 'roc_micro': 0.7272683525420467, 'roc_macro': 0.5248340080657155}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7715617715617715, 0.470771144278607, 0.4295991778006166, -1, 0.5219858156028369, -1, 0.4964539007092199, -1], 'auc_mean': -0.038703523755868524}}\n",
      "done 21 3.8690803050994873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8235793113708496 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9218916676543795, 'roc_macro': -1}, 'nd': {'accuracy': 0.32733386075949367, 'roc_micro': 0.7462284353119512, 'roc_macro': 0.5123345418696029}, 'mod': {'accuracy': 0.32733386075949367, 'roc_micro': 0.7462284353119512, 'roc_macro': 0.5123345418696029}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.20279720279720279, 0.6635572139303483, 0.5704008221993833, -1, 0.44255319148936173, -1, 0.5602836879432624, -1], 'auc_mean': -0.07005098520505519}}\n",
      "done 22 3.8235793113708496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.4627208709716797 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9355458101220813, 'roc_macro': -1}, 'nd': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'mod': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.37296037296037293, 0.5746268656716418, 0.5981500513874615, -1, 0.6397163120567376, -1, 0.38865248226950355, -1], 'auc_mean': -0.05323673945678532}}\n",
      "done 23 3.4627208709716797\n",
      "_++++++++++New Best++++____\n",
      "3.4627208709716797\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9355458101220813, 'roc_macro': -1}, 'nd': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'mod': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.37296037296037293, 0.5746268656716418, 0.5981500513874615, -1, 0.6397163120567376, -1, 0.38865248226950355, -1], 'auc_mean': -0.05323673945678532}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [10, 10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8075175285339355 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9022164276401564, 'roc_macro': -1}, 'nd': {'accuracy': 0.3323444092827004, 'roc_micro': 0.721265128365535, 'roc_macro': 0.4738785728686643}, 'mod': {'accuracy': 0.3323444092827004, 'roc_micro': 0.721265128365535, 'roc_macro': 0.4738785728686643}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.62004662004662, 0.375, 0.328879753340185, -1, 0.5234042553191489, -1, 0.35602836879432626, -1], 'auc_mean': -0.09958012531246498}}\n",
      "done 24 3.8075175285339355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8069398403167725 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9147327249022166, 'roc_macro': -1}, 'nd': {'accuracy': 0.3229166666666667, 'roc_micro': 0.7139746396862443, 'roc_macro': 0.5077768110351952}, 'mod': {'accuracy': 0.3229166666666667, 'roc_micro': 0.7139746396862443, 'roc_macro': 0.5077768110351952}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.8648018648018647, 0.44340796019900497, 0.40493319630010277, -1, 0.624113475177305, -1, 0.33333333333333337, -1], 'auc_mean': -0.04117627127354864}}\n",
      "done 25 3.8069398403167725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6829874515533447 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9322982102643119, 'roc_macro': -1}, 'nd': {'accuracy': 0.3604298523206751, 'roc_micro': 0.7450013233560309, 'roc_macro': 0.5937424811281519}, 'mod': {'accuracy': 0.3604298523206751, 'roc_micro': 0.7450013233560309, 'roc_macro': 0.5937424811281519}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4662004662004662, 0.5764925373134329, 0.6485097636176773, -1, 0.5475177304964539, -1, 0.4269503546099291, -1], 'auc_mean': -0.04179114347025506}}\n",
      "done 26 3.6829874515533447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.85282564163208 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9084982813796374, 'roc_macro': -1}, 'nd': {'accuracy': 0.36089135021097046, 'roc_micro': 0.7526767883352181, 'roc_macro': 0.6454314411631485}, 'mod': {'accuracy': 0.36089135021097046, 'roc_micro': 0.7526767883352181, 'roc_macro': 0.6454314411631485}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.45454545454545453, 0.6598258706467661, 0.4840698869475848, -1, 0.4794326241134752, -1, 0.5319148936170213, -1], 'auc_mean': -0.048776408766212254}}\n",
      "done 27 3.85282564163208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8991506099700928 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9260874718501837, 'roc_macro': -1}, 'nd': {'accuracy': 0.32383966244725737, 'roc_micro': 0.7193041553379371, 'roc_macro': 0.484346802563266}, 'mod': {'accuracy': 0.32383966244725737, 'roc_micro': 0.7193041553379371, 'roc_macro': 0.484346802563266}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.48717948717948717, 0.5690298507462687, 0.4696813977389517, -1, 0.5397163120567376, -1, 0.3588652482269504, -1], 'auc_mean': -0.07194096300645057}}\n",
      "done 28 3.8991506099700928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.4415688514709473 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "done 29 3.4415688514709473\n",
      "_++++++++++New Best++++____\n",
      "3.4415688514709473\n",
      "{'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 3.4415688514709473\n",
      "{'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# model2 = gridsearch_atten/.tion_transition_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c33d908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9533352851867676 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22294936, 'auc': 0.61875}, 'FT': {'accuracy': -1, 'mse': 0.22988118, 'auc': 0.6208881578947368}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.23439899, 'auc': 0.7096153846153845}}\n",
      "done 0 1.9533352851867676\n",
      "_++++++++++New Best++++____\n",
      "1.9533352851867676\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22294936, 'auc': 0.61875}, 'FT': {'accuracy': -1, 'mse': 0.22988118, 'auc': 0.6208881578947368}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.23439899, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9169039726257324 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.23428532, 'auc': 0.5783653846153846}, 'FT': {'accuracy': -1, 'mse': 0.21831562, 'auc': 0.6165021929824561}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.21789795, 'auc': 0.7125}}\n",
      "done 1 1.9169039726257324\n",
      "_++++++++++New Best++++____\n",
      "1.9169039726257324\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.23428532, 'auc': 0.5783653846153846}, 'FT': {'accuracy': -1, 'mse': 0.21831562, 'auc': 0.6165021929824561}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.21789795, 'auc': 0.7125}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5414049625396729 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1648547, 'auc': 0.6644230769230769}, 'FT': {'accuracy': -1, 'mse': 0.18985225, 'auc': 0.6170504385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1474471, 'auc': 0.7243589743589743}}\n",
      "done 2 1.5414049625396729\n",
      "_++++++++++New Best++++____\n",
      "1.5414049625396729\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1648547, 'auc': 0.6644230769230769}, 'FT': {'accuracy': -1, 'mse': 0.18985225, 'auc': 0.6170504385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1474471, 'auc': 0.7243589743589743}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.674856424331665 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.19408122, 'auc': 0.6682692307692308}, 'FT': {'accuracy': -1, 'mse': 0.19684686, 'auc': 0.6022478070175439}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16715875, 'auc': 0.7548076923076923}}\n",
      "done 3 1.674856424331665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.518134355545044 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14513706, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20396616, 'auc': 0.5858004385964913}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14681251, 'auc': 0.7025641025641025}}\n",
      "done 4 1.518134355545044\n",
      "_++++++++++New Best++++____\n",
      "1.518134355545044\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14513706, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20396616, 'auc': 0.5858004385964913}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14681251, 'auc': 0.7025641025641025}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5087974071502686 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13931565, 'auc': 0.6211538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20392582, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14429918, 'auc': 0.7108974358974359}}\n",
      "done 5 1.5087974071502686\n",
      "_++++++++++New Best++++____\n",
      "1.5087974071502686\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13931565, 'auc': 0.6211538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20392582, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14429918, 'auc': 0.7108974358974359}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.483170509338379 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1349846, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20205373, 'auc': 0.603344298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14491129, 'auc': 0.7314102564102564}}\n",
      "done 6 1.483170509338379\n",
      "_++++++++++New Best++++____\n",
      "1.483170509338379\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1349846, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20205373, 'auc': 0.603344298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14491129, 'auc': 0.7314102564102564}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5140568017959595 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1465887, 'auc': 0.6384615384615385}, 'FT': {'accuracy': -1, 'mse': 0.20255052, 'auc': 0.6222587719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14903975, 'auc': 0.7525641025641026}}\n",
      "done 7 1.5140568017959595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4785480499267578 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12899454, 'auc': 0.6235576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20520449, 'auc': 0.6060855263157896}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14056323, 'auc': 0.7285256410256411}}\n",
      "done 8 1.4785480499267578\n",
      "_++++++++++New Best++++____\n",
      "1.4785480499267578\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12899454, 'auc': 0.6235576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20520449, 'auc': 0.6060855263157896}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14056323, 'auc': 0.7285256410256411}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.887725830078125 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22325234, 'auc': 0.5134615384615385}, 'FT': {'accuracy': -1, 'mse': 0.22919208, 'auc': 0.6014254385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.20300515, 'auc': 0.7384615384615385}}\n",
      "done 9 1.887725830078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9279515743255615 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.21030568, 'auc': 0.6495192307692308}, 'FT': {'accuracy': -1, 'mse': 0.24050061, 'auc': 0.5531798245614035}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.2241059, 'auc': 0.6698717948717948}}\n",
      "done 10 1.9279515743255615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.555857539176941 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16066353, 'auc': 0.6274038461538461}, 'FT': {'accuracy': -1, 'mse': 0.1991347, 'auc': 0.5932017543859649}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14868976, 'auc': 0.7035256410256411}}\n",
      "done 11 1.555857539176941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5066845417022705 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14507481, 'auc': 0.5649038461538461}, 'FT': {'accuracy': -1, 'mse': 0.19716617, 'auc': 0.602796052631579}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.15009356, 'auc': 0.710576923076923}}\n",
      "done 12 1.5066845417022705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.589341640472412 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.17413948, 'auc': 0.5586538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20374537, 'auc': 0.5951206140350878}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14826688, 'auc': 0.7544871794871795}}\n",
      "done 13 1.589341640472412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4861150979995728 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13306338, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20490709, 'auc': 0.600328947368421}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1420104, 'auc': 0.7141025641025641}}\n",
      "done 14 1.4861150979995728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.506028652191162 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14841402, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20488185, 'auc': 0.5877192982456141}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13998102, 'auc': 0.7483974358974359}}\n",
      "done 15 1.506028652191162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5576770305633545 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.154363, 'auc': 0.5822115384615385}, 'FT': {'accuracy': -1, 'mse': 0.21026096, 'auc': 0.5879934210526315}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.15049165, 'auc': 0.7298076923076924}}\n",
      "done 16 1.5576770305633545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5055675506591797 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13160379, 'auc': 0.6264423076923077}, 'FT': {'accuracy': -1, 'mse': 0.2073938, 'auc': 0.581140350877193}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14211161, 'auc': 0.7141025641025642}}\n",
      "done 17 1.5055675506591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.637538194656372 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16827497, 'auc': 0.48413461538461544}, 'FT': {'accuracy': -1, 'mse': 0.21037889, 'auc': 0.5635964912280702}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16129254, 'auc': 0.717948717948718}}\n",
      "done 18 1.637538194656372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9545180797576904 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22068177, 'auc': 0.45240384615384616}, 'FT': {'accuracy': -1, 'mse': 0.238595, 'auc': 0.5356359649122807}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.22857483, 'auc': 0.705448717948718}}\n",
      "done 19 1.9545180797576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4690238237380981 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14176321, 'auc': 0.6177884615384615}, 'FT': {'accuracy': -1, 'mse': 0.20021597, 'auc': 0.6066337719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13276392, 'auc': 0.7487179487179487}}\n",
      "done 20 1.4690238237380981\n",
      "_++++++++++New Best++++____\n",
      "1.4690238237380981\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14176321, 'auc': 0.6177884615384615}, 'FT': {'accuracy': -1, 'mse': 0.20021597, 'auc': 0.6066337719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13276392, 'auc': 0.7487179487179487}}\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [10, 10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4727905988693237 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13137068, 'auc': 0.6495192307692308}, 'FT': {'accuracy': -1, 'mse': 0.20992997, 'auc': 0.6019736842105263}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13884372, 'auc': 0.7480769230769231}}\n",
      "done 21 1.4727905988693237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.515777587890625 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.15018119, 'auc': 0.6610576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20404501, 'auc': 0.6041666666666666}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13985752, 'auc': 0.7352564102564103}}\n",
      "done 22 1.515777587890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5039113759994507 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1309246, 'auc': 0.626923076923077}, 'FT': {'accuracy': -1, 'mse': 0.20764191, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14242676, 'auc': 0.7169871794871795}}\n",
      "done 23 1.5039113759994507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.6280651092529297 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16924354, 'auc': 0.6264423076923078}, 'FT': {'accuracy': -1, 'mse': 0.20434348, 'auc': 0.6101973684210527}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16036619, 'auc': 0.7737179487179487}}\n",
      "done 24 1.6280651092529297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.014167547225952 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.2509568, 'auc': 0.5038461538461538}, 'FT': {'accuracy': -1, 'mse': 0.23930772, 'auc': 0.5400219298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.22724013, 'auc': 0.42275641025641025}}\n",
      "done 25 2.014167547225952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4920299053192139 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14099866, 'auc': 0.6514423076923077}, 'FT': {'accuracy': -1, 'mse': 0.19876012, 'auc': 0.5901864035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14173688, 'auc': 0.7227564102564102}}\n",
      "done 26 1.4920299053192139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.513304352760315 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.15192407, 'auc': 0.6110576923076922}, 'FT': {'accuracy': -1, 'mse': 0.19458365, 'auc': 0.5923793859649122}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14482027, 'auc': 0.7080128205128204}}\n",
      "done 27 1.513304352760315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.455763339996338 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "done 28 1.455763339996338\n",
      "_++++++++++New Best++++____\n",
      "1.455763339996338\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4676107168197632 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12858523, 'auc': 0.6384615384615384}, 'FT': {'accuracy': -1, 'mse': 0.19938947, 'auc': 0.6077302631578947}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13879225, 'auc': 0.7153846153846154}}\n",
      "done 29 1.4676107168197632\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 1.455763339996338\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# model3 = gridsearch_attention_transition_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2937b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models():\n",
    "    files = Const.tuned_transition_models\n",
    "    decision_file = Const.tuned_decision_model\n",
    "    [model1,model2,model3] = [torch.load(file) for file in files]\n",
    "    decision_model = torch.load(decision_file)\n",
    "    return decision_model, model1,model2,model3\n",
    "_, model1, model2, model3 =load_trained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8af5c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "______epoch 0 _____\n",
      "train imitation 2.206021547317505 reward 2.491159677505493\n",
      "val imitation 2.1344025135040283 reward 1.8243277072906494\n",
      "val loss 3.9587302207946777 1000000000.0\n",
      "[{'decision': 0, 'accuracy': 0.3356164383561644, 'auc': 0.6951923076923078}, {'decision': 1, 'accuracy': 0.363013698630137, 'auc': 0.48300438596491224}, {'decision': 2, 'accuracy': 0.5136986301369864, 'auc': 0.6221153846153846}]\n",
      "______epoch 1 _____\n",
      "train imitation 2.191789150238037 reward 2.4916346073150635\n",
      "val imitation 2.09209942817688 reward 1.8282902240753174\n",
      "val loss 3.9203896522521973 3.9587302207946777\n",
      "[{'decision': 0, 'accuracy': 0.3698630136986301, 'auc': 0.701923076923077}, {'decision': 1, 'accuracy': 0.4315068493150685, 'auc': 0.5098684210526316}, {'decision': 2, 'accuracy': 0.6232876712328768, 'auc': 0.6842948717948718}]\n",
      "______epoch 2 _____\n",
      "train imitation 2.174431562423706 reward 2.4919028282165527\n",
      "val imitation 2.0585765838623047 reward 1.8293774127960205\n",
      "val loss 3.887953996658325 3.9203896522521973\n",
      "[{'decision': 0, 'accuracy': 0.4657534246575342, 'auc': 0.7}, {'decision': 1, 'accuracy': 0.541095890410959, 'auc': 0.5328947368421052}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7288461538461538}]\n",
      "______epoch 3 _____\n",
      "train imitation 2.1561174392700195 reward 2.490971803665161\n",
      "val imitation 2.034191608428955 reward 1.8288648128509521\n",
      "val loss 3.8630564212799072 3.887953996658325\n",
      "[{'decision': 0, 'accuracy': 0.547945205479452, 'auc': 0.6961538461538461}, {'decision': 1, 'accuracy': 0.589041095890411, 'auc': 0.5466008771929824}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.7583333333333333}]\n",
      "______epoch 4 _____\n",
      "train imitation 2.1233973503112793 reward 2.4924299716949463\n",
      "val imitation 2.0153942108154297 reward 1.829373836517334\n",
      "val loss 3.8447680473327637 3.8630564212799072\n",
      "[{'decision': 0, 'accuracy': 0.6095890410958904, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.5958904109589042, 'auc': 0.5619517543859649}, {'decision': 2, 'accuracy': 0.7465753424657534, 'auc': 0.7826923076923078}]\n",
      "______epoch 5 _____\n",
      "train imitation 2.1100046634674072 reward 2.4918909072875977\n",
      "val imitation 2.000598430633545 reward 1.8311679363250732\n",
      "val loss 3.831766366958618 3.8447680473327637\n",
      "[{'decision': 0, 'accuracy': 0.636986301369863, 'auc': 0.6788461538461539}, {'decision': 1, 'accuracy': 0.6095890410958904, 'auc': 0.5794956140350878}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.8012820512820512}]\n",
      "______epoch 6 _____\n",
      "train imitation 2.106778621673584 reward 2.4870259761810303\n",
      "val imitation 1.9890010356903076 reward 1.8310320377349854\n",
      "val loss 3.820033073425293 3.831766366958618\n",
      "[{'decision': 0, 'accuracy': 0.6438356164383562, 'auc': 0.6778846153846154}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.5896381578947368}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8083333333333333}]\n",
      "______epoch 7 _____\n",
      "train imitation 2.0893402099609375 reward 2.4908833503723145\n",
      "val imitation 1.9813485145568848 reward 1.8313124179840088\n",
      "val loss 3.8126609325408936 3.820033073425293\n",
      "[{'decision': 0, 'accuracy': 0.6575342465753424, 'auc': 0.6740384615384615}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.5995065789473684}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8173076923076923}]\n",
      "______epoch 8 _____\n",
      "train imitation 2.081341505050659 reward 2.4902243614196777\n",
      "val imitation 1.976462483406067 reward 1.8320754766464233\n",
      "val loss 3.8085379600524902 3.8126609325408936\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.6668269230769232}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6082785087719297}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8233974358974359}]\n",
      "______epoch 9 _____\n",
      "train imitation 2.0710432529449463 reward 2.4939701557159424\n",
      "val imitation 1.9731402397155762 reward 1.8315621614456177\n",
      "val loss 3.8047022819519043 3.8085379600524902\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6156798245614036}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8294871794871794}]\n",
      "______epoch 10 _____\n",
      "train imitation 2.057062864303589 reward 2.4904961585998535\n",
      "val imitation 1.9717128276824951 reward 1.8311080932617188\n",
      "val loss 3.802820920944214 3.8047022819519043\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6236293859649122}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.8349358974358975}]\n",
      "______epoch 11 _____\n",
      "train imitation 2.0575242042541504 reward 2.4905333518981934\n",
      "val imitation 1.9720783233642578 reward 1.8306081295013428\n",
      "val loss 3.8026864528656006 3.802820920944214\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.6442307692307692}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6288377192982456}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.8400641025641026}]\n",
      "______epoch 12 _____\n",
      "train imitation 2.0573410987854004 reward 2.491533041000366\n",
      "val imitation 1.972062587738037 reward 1.83027982711792\n",
      "val loss 3.802342414855957 3.8026864528656006\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.6375}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6356907894736842}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8407051282051282}]\n",
      "______epoch 13 _____\n",
      "train imitation 2.0461175441741943 reward 2.4911036491394043\n",
      "val imitation 1.9715285301208496 reward 1.8297386169433594\n",
      "val loss 3.801267147064209 3.802342414855957\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.6336538461538461}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6378837719298245}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.8419871794871795}]\n",
      "______epoch 14 _____\n",
      "train imitation 2.0346388816833496 reward 2.490180253982544\n",
      "val imitation 1.9685478210449219 reward 1.8304566144943237\n",
      "val loss 3.799004554748535 3.801267147064209\n",
      "[{'decision': 0, 'accuracy': 0.6575342465753424, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.644188596491228}, {'decision': 2, 'accuracy': 0.7602739726027398, 'auc': 0.8432692307692308}]\n",
      "______epoch 15 _____\n",
      "train imitation 2.0449788570404053 reward 2.490612506866455\n",
      "val imitation 1.9650113582611084 reward 1.8309855461120605\n",
      "val loss 3.795996904373169 3.799004554748535\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.6235576923076922}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6458333333333334}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.8442307692307692}]\n",
      "______epoch 16 _____\n",
      "train imitation 2.0223171710968018 reward 2.490412712097168\n",
      "val imitation 1.9600481986999512 reward 1.8299051523208618\n",
      "val loss 3.7899532318115234 3.795996904373169\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.6173076923076923}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6499451754385965}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.842948717948718}]\n",
      "______epoch 17 _____\n",
      "train imitation 2.0177223682403564 reward 2.4923434257507324\n",
      "val imitation 1.954244613647461 reward 1.8306488990783691\n",
      "val loss 3.78489351272583 3.7899532318115234\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.6163461538461539}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6507675438596492}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8423076923076923}]\n",
      "______epoch 18 _____\n",
      "train imitation 2.0216305255889893 reward 2.4909868240356445\n",
      "val imitation 1.9468265771865845 reward 1.8327605724334717\n",
      "val loss 3.7795872688293457 3.78489351272583\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6546052631578947}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8403846153846154}]\n",
      "______epoch 19 _____\n",
      "train imitation 2.0152676105499268 reward 2.49192214012146\n",
      "val imitation 1.9391822814941406 reward 1.832737684249878\n",
      "val loss 3.7719199657440186 3.7795872688293457\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.6139423076923076}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6551535087719298}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8387820512820513}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 20 _____\n",
      "train imitation 2.0111188888549805 reward 2.493630886077881\n",
      "val imitation 1.930152177810669 reward 1.833322286605835\n",
      "val loss 3.763474464416504 3.7719199657440186\n",
      "[{'decision': 0, 'accuracy': 0.7054794520547946, 'auc': 0.6153846153846154}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6554276315789473}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8358974358974358}]\n",
      "______epoch 21 _____\n",
      "train imitation 2.013956308364868 reward 2.493551731109619\n",
      "val imitation 1.9202048778533936 reward 1.8355802297592163\n",
      "val loss 3.7557849884033203 3.763474464416504\n",
      "[{'decision': 0, 'accuracy': 0.7191780821917808, 'auc': 0.6134615384615385}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6559758771929824}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8349358974358975}]\n",
      "______epoch 22 _____\n",
      "train imitation 2.013810157775879 reward 2.4933156967163086\n",
      "val imitation 1.9114313125610352 reward 1.836445689201355\n",
      "val loss 3.7478771209716797 3.7557849884033203\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.6096153846153847}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6578947368421053}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8333333333333333}]\n",
      "______epoch 23 _____\n",
      "train imitation 2.0000014305114746 reward 2.490692615509033\n",
      "val imitation 1.9032714366912842 reward 1.8374098539352417\n",
      "val loss 3.7406811714172363 3.7478771209716797\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.6072115384615385}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6600877192982456}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8323717948717949}]\n",
      "______epoch 24 _____\n",
      "train imitation 2.010221242904663 reward 2.493584156036377\n",
      "val imitation 1.894156575202942 reward 1.836763858795166\n",
      "val loss 3.7309203147888184 3.7406811714172363\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.6072115384615384}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6606359649122806}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8320512820512821}]\n",
      "______epoch 25 _____\n",
      "train imitation 1.9968085289001465 reward 2.4930713176727295\n",
      "val imitation 1.8854457139968872 reward 1.836855173110962\n",
      "val loss 3.7223010063171387 3.7309203147888184\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.6052884615384615}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6614583333333334}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8307692307692307}]\n",
      "______epoch 26 _____\n",
      "train imitation 1.9900195598602295 reward 2.4950413703918457\n",
      "val imitation 1.877955675125122 reward 1.8368399143218994\n",
      "val loss 3.7147955894470215 3.7223010063171387\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.6043269230769232}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6631030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8282051282051283}]\n",
      "______epoch 27 _____\n",
      "train imitation 1.9929931163787842 reward 2.494145154953003\n",
      "val imitation 1.8705317974090576 reward 1.838521957397461\n",
      "val loss 3.7090537548065186 3.7147955894470215\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.6004807692307692}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6636513157894737}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8278846153846153}]\n",
      "______epoch 28 _____\n",
      "train imitation 1.9878859519958496 reward 2.4954371452331543\n",
      "val imitation 1.86318838596344 reward 1.8409392833709717\n",
      "val loss 3.704127788543701 3.7090537548065186\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5975961538461538}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6636513157894737}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8275641025641025}]\n",
      "______epoch 29 _____\n",
      "train imitation 1.983303427696228 reward 2.496771812438965\n",
      "val imitation 1.8546773195266724 reward 1.8435025215148926\n",
      "val loss 3.6981797218322754 3.704127788543701\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5951923076923076}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6672149122807017}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.825}]\n",
      "______epoch 30 _____\n",
      "train imitation 1.9743165969848633 reward 2.493924140930176\n",
      "val imitation 1.8455655574798584 reward 1.8449515104293823\n",
      "val loss 3.690516948699951 3.6981797218322754\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5889423076923077}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6688596491228072}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8250000000000001}]\n",
      "______epoch 31 _____\n",
      "train imitation 1.969831943511963 reward 2.49389386177063\n",
      "val imitation 1.8365049362182617 reward 1.8445513248443604\n",
      "val loss 3.681056261062622 3.690516948699951\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5850961538461539}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6694078947368421}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8233974358974359}]\n",
      "______epoch 32 _____\n",
      "train imitation 1.9735610485076904 reward 2.4955830574035645\n",
      "val imitation 1.8262863159179688 reward 1.844857931137085\n",
      "val loss 3.6711442470550537 3.681056261062622\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5812499999999999}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6705043859649122}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8227564102564102}]\n",
      "______epoch 33 _____\n",
      "train imitation 1.9571040868759155 reward 2.495180130004883\n",
      "val imitation 1.8151342868804932 reward 1.8476020097732544\n",
      "val loss 3.662736415863037 3.6711442470550537\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5812499999999999}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6702302631578947}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8237179487179487}]\n",
      "______epoch 34 _____\n",
      "train imitation 1.9544007778167725 reward 2.4948737621307373\n",
      "val imitation 1.8049743175506592 reward 1.8479098081588745\n",
      "val loss 3.652884006500244 3.662736415863037\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.579326923076923}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6710526315789473}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8237179487179487}]\n",
      "______epoch 35 _____\n",
      "train imitation 1.9570393562316895 reward 2.49772572517395\n",
      "val imitation 1.796583652496338 reward 1.8486576080322266\n",
      "val loss 3.6452412605285645 3.652884006500244\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5788461538461539}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6710526315789473}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.825}]\n",
      "______epoch 36 _____\n",
      "train imitation 1.9398607015609741 reward 2.498457431793213\n",
      "val imitation 1.7871732711791992 reward 1.8461582660675049\n",
      "val loss 3.633331537246704 3.6452412605285645\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5764423076923076}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6724232456140351}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.8253205128205129}]\n",
      "______epoch 37 _____\n",
      "train imitation 1.9553736448287964 reward 2.4947290420532227\n",
      "val imitation 1.7805269956588745 reward 1.8456761837005615\n",
      "val loss 3.6262030601501465 3.633331537246704\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5759615384615385}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6746162280701755}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.825}]\n",
      "______epoch 38 _____\n",
      "train imitation 1.9448845386505127 reward 2.4979593753814697\n",
      "val imitation 1.7740604877471924 reward 1.845260500907898\n",
      "val loss 3.619320869445801 3.6262030601501465\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5754807692307693}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6743421052631579}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8243589743589743}]\n",
      "______epoch 39 _____\n",
      "train imitation 1.9300181865692139 reward 2.497803211212158\n",
      "val imitation 1.7670029401779175 reward 1.8454383611679077\n",
      "val loss 3.612441301345825 3.619320869445801\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.576923076923077}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6754385964912281}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8240384615384615}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 40 _____\n",
      "train imitation 1.9267195463180542 reward 2.496753454208374\n",
      "val imitation 1.759631872177124 reward 1.8455004692077637\n",
      "val loss 3.6051323413848877 3.612441301345825\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.575}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6759868421052633}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.823076923076923}]\n",
      "______epoch 41 _____\n",
      "train imitation 1.9307422637939453 reward 2.4959752559661865\n",
      "val imitation 1.7474699020385742 reward 1.846486210823059\n",
      "val loss 3.5939559936523438 3.6051323413848877\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5750000000000001}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6759868421052632}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8227564102564102}]\n",
      "______epoch 42 _____\n",
      "train imitation 1.9262444972991943 reward 2.4975411891937256\n",
      "val imitation 1.7365131378173828 reward 1.844804286956787\n",
      "val loss 3.58131742477417 3.5939559936523438\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5735576923076924}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6770833333333333}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8230769230769232}]\n",
      "______epoch 43 _____\n",
      "train imitation 1.9141743183135986 reward 2.496020793914795\n",
      "val imitation 1.7244948148727417 reward 1.8444679975509644\n",
      "val loss 3.568962812423706 3.58131742477417\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.570673076923077}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6798245614035088}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8214743589743589}]\n",
      "______epoch 44 _____\n",
      "train imitation 1.911386251449585 reward 2.4956717491149902\n",
      "val imitation 1.7102255821228027 reward 1.842787265777588\n",
      "val loss 3.5530128479003906 3.568962812423706\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5692307692307692}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.681469298245614}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.8205128205128205}]\n",
      "______epoch 45 _____\n",
      "train imitation 1.9093036651611328 reward 2.4946205615997314\n",
      "val imitation 1.6945586204528809 reward 1.8431789875030518\n",
      "val loss 3.5377376079559326 3.5530128479003906\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5701923076923077}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.680921052631579}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8205128205128205}]\n",
      "______epoch 46 _____\n",
      "train imitation 1.9045758247375488 reward 2.4973437786102295\n",
      "val imitation 1.681840181350708 reward 1.843117117881775\n",
      "val loss 3.5249571800231934 3.5377376079559326\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5692307692307692}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6817434210526316}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8205128205128205}]\n",
      "______epoch 47 _____\n",
      "train imitation 1.8924908638000488 reward 2.4976069927215576\n",
      "val imitation 1.6698553562164307 reward 1.843977689743042\n",
      "val loss 3.5138330459594727 3.5249571800231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5682692307692307}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6828399122807018}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.819551282051282}]\n",
      "______epoch 48 _____\n",
      "train imitation 1.8917937278747559 reward 2.4969513416290283\n",
      "val imitation 1.6580144166946411 reward 1.8438791036605835\n",
      "val loss 3.5018935203552246 3.5138330459594727\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5682692307692307}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6839364035087719}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8185897435897436}]\n",
      "______epoch 49 _____\n",
      "train imitation 1.9080363512039185 reward 2.497688055038452\n",
      "val imitation 1.6480411291122437 reward 1.8447569608688354\n",
      "val loss 3.492798089981079 3.5018935203552246\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5682692307692307}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6842105263157894}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8185897435897436}]\n",
      "______epoch 50 _____\n",
      "train imitation 1.8932082653045654 reward 2.496107816696167\n",
      "val imitation 1.6372065544128418 reward 1.844957947731018\n",
      "val loss 3.4821643829345703 3.492798089981079\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5682692307692307}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6866776315789475}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8192307692307692}]\n",
      "______epoch 51 _____\n",
      "train imitation 1.8981356620788574 reward 2.4969589710235596\n",
      "val imitation 1.6259864568710327 reward 1.8470299243927002\n",
      "val loss 3.4730162620544434 3.4821643829345703\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5697115384615384}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6874999999999999}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.819551282051282}]\n",
      "______epoch 52 _____\n",
      "train imitation 1.8837611675262451 reward 2.4974982738494873\n",
      "val imitation 1.615830898284912 reward 1.8469386100769043\n",
      "val loss 3.4627695083618164 3.4730162620544434\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5721153846153846}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6872258771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.819551282051282}]\n",
      "______epoch 53 _____\n",
      "train imitation 1.8782680034637451 reward 2.497366189956665\n",
      "val imitation 1.6107745170593262 reward 1.8473992347717285\n",
      "val loss 3.4581737518310547 3.4627695083618164\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5745192307692308}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6861293859649124}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8198717948717948}]\n",
      "______epoch 54 _____\n",
      "train imitation 1.8852537870407104 reward 2.499736785888672\n",
      "val imitation 1.6080193519592285 reward 1.8490653038024902\n",
      "val loss 3.4570846557617188 3.4581737518310547\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5735576923076924}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6872258771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8185897435897436}]\n",
      "______epoch 55 _____\n",
      "train imitation 1.8692238330841064 reward 2.4977190494537354\n",
      "val imitation 1.6053472757339478 reward 1.8492029905319214\n",
      "val loss 3.454550266265869 3.4570846557617188\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5740384615384615}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6866776315789475}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8182692307692307}]\n",
      "______epoch 56 _____\n",
      "train imitation 1.8539478778839111 reward 2.4986681938171387\n",
      "val imitation 1.600229263305664 reward 1.8494539260864258\n",
      "val loss 3.44968318939209 3.454550266265869\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5721153846153846}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8182692307692307}]\n",
      "______epoch 57 _____\n",
      "train imitation 1.8649450540542603 reward 2.4993185997009277\n",
      "val imitation 1.5955220460891724 reward 1.8507006168365479\n",
      "val loss 3.4462227821350098 3.44968318939209\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5668269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6864035087719298}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8176282051282051}]\n",
      "______epoch 58 _____\n",
      "train imitation 1.8595130443572998 reward 2.4988956451416016\n",
      "val imitation 1.589910864830017 reward 1.8509081602096558\n",
      "val loss 3.440819025039673 3.4462227821350098\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5625000000000001}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6864035087719299}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8157051282051282}]\n",
      "______epoch 59 _____\n",
      "train imitation 1.8581197261810303 reward 2.4983019828796387\n",
      "val imitation 1.5854763984680176 reward 1.8511316776275635\n",
      "val loss 3.436608076095581 3.440819025039673\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5605769230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8166666666666667}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 60 _____\n",
      "train imitation 1.853175163269043 reward 2.498384475708008\n",
      "val imitation 1.583315372467041 reward 1.8504291772842407\n",
      "val loss 3.433744430541992 3.436608076095581\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5615384615384615}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8173076923076923}]\n",
      "______epoch 61 _____\n",
      "train imitation 1.8535605669021606 reward 2.4979989528656006\n",
      "val imitation 1.5808353424072266 reward 1.8510133028030396\n",
      "val loss 3.4318485260009766 3.433744430541992\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5615384615384615}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8176282051282051}]\n",
      "______epoch 62 _____\n",
      "train imitation 1.8503973484039307 reward 2.497927188873291\n",
      "val imitation 1.576523780822754 reward 1.8510133028030396\n",
      "val loss 3.427536964416504 3.4318485260009766\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5615384615384615}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6899671052631579}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8176282051282051}]\n",
      "______epoch 63 _____\n",
      "train imitation 1.8434240818023682 reward 2.497007131576538\n",
      "val imitation 1.570784091949463 reward 1.8516895771026611\n",
      "val loss 3.422473669052124 3.427536964416504\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5591346153846154}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6918859649122807}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8176282051282051}]\n",
      "______epoch 64 _____\n",
      "train imitation 1.8274719715118408 reward 2.498020648956299\n",
      "val imitation 1.5626788139343262 reward 1.8511549234390259\n",
      "val loss 3.4138336181640625 3.422473669052124\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5572115384615385}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6916118421052632}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8169871794871795}]\n",
      "______epoch 65 _____\n",
      "train imitation 1.8360493183135986 reward 2.4997708797454834\n",
      "val imitation 1.5528351068496704 reward 1.851898431777954\n",
      "val loss 3.404733657836914 3.4138336181640625\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5572115384615385}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6913377192982456}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8179487179487179}]\n",
      "______epoch 66 _____\n",
      "train imitation 1.8329066038131714 reward 2.497541904449463\n",
      "val imitation 1.547363519668579 reward 1.8511977195739746\n",
      "val loss 3.3985612392425537 3.404733657836914\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.691611842105263}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8189102564102564}]\n",
      "______epoch 67 _____\n",
      "train imitation 1.8366663455963135 reward 2.49946665763855\n",
      "val imitation 1.5449597835540771 reward 1.852919101715088\n",
      "val loss 3.397878885269165 3.3985612392425537\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5528846153846154}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6913377192982456}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8189102564102564}]\n",
      "______epoch 68 _____\n",
      "train imitation 1.824026107788086 reward 2.496875762939453\n",
      "val imitation 1.5421444177627563 reward 1.8532205820083618\n",
      "val loss 3.395364999771118 3.397878885269165\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5504807692307693}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6921600877192983}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8198717948717948}]\n",
      "______epoch 69 _____\n",
      "train imitation 1.8066588640213013 reward 2.499702215194702\n",
      "val imitation 1.5405817031860352 reward 1.8525564670562744\n",
      "val loss 3.3931381702423096 3.395364999771118\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5514423076923077}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6932565789473684}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8192307692307692}]\n",
      "______epoch 70 _____\n",
      "train imitation 1.8091139793395996 reward 2.4989912509918213\n",
      "val imitation 1.5375438928604126 reward 1.8529722690582275\n",
      "val loss 3.3905162811279297 3.3931381702423096\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5514423076923077}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6932565789473684}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8192307692307692}]\n",
      "______epoch 71 _____\n",
      "train imitation 1.7932422161102295 reward 2.4995548725128174\n",
      "val imitation 1.534264326095581 reward 1.8537614345550537\n",
      "val loss 3.3880257606506348 3.3905162811279297\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6929824561403509}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8189102564102564}]\n",
      "______epoch 72 _____\n",
      "train imitation 1.7975488901138306 reward 2.499932289123535\n",
      "val imitation 1.527953028678894 reward 1.8538355827331543\n",
      "val loss 3.381788730621338 3.3880257606506348\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5528846153846154}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6932565789473684}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8192307692307692}]\n",
      "______epoch 73 _____\n",
      "train imitation 1.8240896463394165 reward 2.503269672393799\n",
      "val imitation 1.5221731662750244 reward 1.8538342714309692\n",
      "val loss 3.376007556915283 3.381788730621338\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.551923076923077}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6938048245614035}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8189102564102564}]\n",
      "______epoch 74 _____\n",
      "train imitation 1.7981438636779785 reward 2.4991347789764404\n",
      "val imitation 1.5175219774246216 reward 1.8537280559539795\n",
      "val loss 3.3712501525878906 3.376007556915283\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8185897435897436}]\n",
      "______epoch 75 _____\n",
      "train imitation 1.819718837738037 reward 2.501241683959961\n",
      "val imitation 1.5117297172546387 reward 1.8536503314971924\n",
      "val loss 3.365380048751831 3.3712501525878906\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.551923076923077}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8189102564102564}]\n",
      "______epoch 76 _____\n",
      "train imitation 1.7953014373779297 reward 2.4973957538604736\n",
      "val imitation 1.5040955543518066 reward 1.8535346984863281\n",
      "val loss 3.3576302528381348 3.365380048751831\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8192307692307692}]\n",
      "______epoch 77 _____\n",
      "train imitation 1.802079200744629 reward 2.5014514923095703\n",
      "val imitation 1.4995259046554565 reward 1.854347586631775\n",
      "val loss 3.3538734912872314 3.3576302528381348\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8189102564102564}]\n",
      "______epoch 78 _____\n",
      "train imitation 1.794877290725708 reward 2.49904465675354\n",
      "val imitation 1.4954524040222168 reward 1.8543815612792969\n",
      "val loss 3.3498339653015137 3.3538734912872314\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6973684210526316}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8198717948717948}]\n",
      "______epoch 79 _____\n",
      "train imitation 1.7923130989074707 reward 2.498985767364502\n",
      "val imitation 1.4890282154083252 reward 1.8533841371536255\n",
      "val loss 3.3424124717712402 3.3498339653015137\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6962719298245614}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8198717948717948}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 80 _____\n",
      "train imitation 1.791233777999878 reward 2.499624729156494\n",
      "val imitation 1.4829208850860596 reward 1.8540877103805542\n",
      "val loss 3.337008476257324 3.3424124717712402\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6962719298245614}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8198717948717948}]\n",
      "______epoch 81 _____\n",
      "train imitation 1.7691264152526855 reward 2.4982500076293945\n",
      "val imitation 1.4786710739135742 reward 1.8539334535598755\n",
      "val loss 3.33260440826416 3.337008476257324\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6957236842105263}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8189102564102565}]\n",
      "______epoch 82 _____\n",
      "train imitation 1.7823193073272705 reward 2.4983677864074707\n",
      "val imitation 1.4739822149276733 reward 1.8541843891143799\n",
      "val loss 3.3281664848327637 3.33260440826416\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5528846153846154}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6962719298245614}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8192307692307693}]\n",
      "______epoch 83 _____\n",
      "train imitation 1.787705898284912 reward 2.498119354248047\n",
      "val imitation 1.4722323417663574 reward 1.8535674810409546\n",
      "val loss 3.3257999420166016 3.3281664848327637\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8189102564102564}]\n",
      "______epoch 84 _____\n",
      "train imitation 1.7923203706741333 reward 2.500049591064453\n",
      "val imitation 1.4647767543792725 reward 1.8534549474716187\n",
      "val loss 3.3182315826416016 3.3257999420166016\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6951754385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.819551282051282}]\n",
      "______epoch 85 _____\n",
      "train imitation 1.776859998703003 reward 2.500501871109009\n",
      "val imitation 1.460679054260254 reward 1.8539154529571533\n",
      "val loss 3.3145945072174072 3.3182315826416016\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6954495614035088}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.819551282051282}]\n",
      "______epoch 86 _____\n",
      "train imitation 1.7567071914672852 reward 2.4994513988494873\n",
      "val imitation 1.4564815759658813 reward 1.853557825088501\n",
      "val loss 3.310039520263672 3.3145945072174072\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5548076923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6951754385964912}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8192307692307692}]\n",
      "______epoch 87 _____\n",
      "train imitation 1.7479236125946045 reward 2.499628782272339\n",
      "val imitation 1.4538885354995728 reward 1.8542160987854004\n",
      "val loss 3.3081045150756836 3.310039520263672\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6940789473684211}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8189102564102564}]\n",
      "______epoch 88 _____\n",
      "train imitation 1.762840747833252 reward 2.4980998039245605\n",
      "val imitation 1.4543378353118896 reward 1.8544710874557495\n",
      "val loss 3.3088088035583496 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5533653846153845}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.693530701754386}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.819871794871795}]\n",
      "______epoch 89 _____\n",
      "train imitation 1.7522327899932861 reward 2.497387409210205\n",
      "val imitation 1.457422137260437 reward 1.8543344736099243\n",
      "val loss 3.3117566108703613 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5533653846153845}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6949013157894737}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8201923076923078}]\n",
      "______epoch 90 _____\n",
      "train imitation 1.773850917816162 reward 2.4974045753479004\n",
      "val imitation 1.4596668481826782 reward 1.8536665439605713\n",
      "val loss 3.313333511352539 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6949013157894737}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.819871794871795}]\n",
      "______epoch 91 _____\n",
      "train imitation 1.759235143661499 reward 2.501359224319458\n",
      "val imitation 1.4610693454742432 reward 1.8534181118011475\n",
      "val loss 3.3144874572753906 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5548076923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.819551282051282}]\n",
      "______epoch 92 _____\n",
      "train imitation 1.7473222017288208 reward 2.4962005615234375\n",
      "val imitation 1.4615763425827026 reward 1.8528823852539062\n",
      "val loss 3.3144588470458984 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6954495614035088}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8205128205128205}]\n",
      "______epoch 93 _____\n",
      "train imitation 1.7693803310394287 reward 2.4996278285980225\n",
      "val imitation 1.4587697982788086 reward 1.8522472381591797\n",
      "val loss 3.3110170364379883 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5552884615384616}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8217948717948718}]\n",
      "______epoch 94 _____\n",
      "train imitation 1.75021231174469 reward 2.4982059001922607\n",
      "val imitation 1.4533424377441406 reward 1.8530192375183105\n",
      "val loss 3.306361675262451 3.3081045150756836\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5552884615384616}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6970942982456141}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8221153846153846}]\n",
      "______epoch 95 _____\n",
      "train imitation 1.7490808963775635 reward 2.499190330505371\n",
      "val imitation 1.4477707147598267 reward 1.8524253368377686\n",
      "val loss 3.3001961708068848 3.306361675262451\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6965460526315789}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8221153846153846}]\n",
      "______epoch 96 _____\n",
      "train imitation 1.7298833131790161 reward 2.4990146160125732\n",
      "val imitation 1.4426947832107544 reward 1.8530546426773071\n",
      "val loss 3.2957494258880615 3.3001961708068848\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8224358974358974}]\n",
      "______epoch 97 _____\n",
      "train imitation 1.7578270435333252 reward 2.4972050189971924\n",
      "val imitation 1.4418267011642456 reward 1.8530786037445068\n",
      "val loss 3.294905185699463 3.2957494258880615\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6973684210526315}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8224358974358974}]\n",
      "______epoch 98 _____\n",
      "train imitation 1.7286055088043213 reward 2.4977974891662598\n",
      "val imitation 1.4417320489883423 reward 1.8534581661224365\n",
      "val loss 3.2951903343200684 3.294905185699463\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5552884615384616}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8237179487179487}]\n",
      "______epoch 99 _____\n",
      "train imitation 1.7316874265670776 reward 2.4960241317749023\n",
      "val imitation 1.443327784538269 reward 1.8522708415985107\n",
      "val loss 3.2955985069274902 3.294905185699463\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.696546052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8237179487179488}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 100 _____\n",
      "train imitation 1.747999906539917 reward 2.4975457191467285\n",
      "val imitation 1.4434361457824707 reward 1.851710319519043\n",
      "val loss 3.2951464653015137 3.294905185699463\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5533653846153845}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8246794871794871}]\n",
      "______epoch 101 _____\n",
      "train imitation 1.725341558456421 reward 2.497140884399414\n",
      "val imitation 1.4429669380187988 reward 1.8495854139328003\n",
      "val loss 3.2925524711608887 3.294905185699463\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5509615384615385}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8256410256410257}]\n",
      "______epoch 102 _____\n",
      "train imitation 1.71437406539917 reward 2.498710870742798\n",
      "val imitation 1.4423317909240723 reward 1.8496382236480713\n",
      "val loss 3.2919700145721436 3.2925524711608887\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5514423076923077}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6976425438596491}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.826602564102564}]\n",
      "______epoch 103 _____\n",
      "train imitation 1.7666566371917725 reward 2.497741937637329\n",
      "val imitation 1.4429216384887695 reward 1.849225640296936\n",
      "val loss 3.292147159576416 3.2919700145721436\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6979166666666666}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8259615384615385}]\n",
      "______epoch 104 _____\n",
      "train imitation 1.7132008075714111 reward 2.494915723800659\n",
      "val imitation 1.4451524019241333 reward 1.849225640296936\n",
      "val loss 3.2943780422210693 3.2919700145721436\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5524038461538462}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6981907894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8266025641025642}]\n",
      "______epoch 105 _____\n",
      "train imitation 1.705804705619812 reward 2.496596574783325\n",
      "val imitation 1.4444388151168823 reward 1.848890781402588\n",
      "val loss 3.2933297157287598 3.2919700145721436\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8282051282051281}]\n",
      "______epoch 106 _____\n",
      "train imitation 1.7185698747634888 reward 2.4959468841552734\n",
      "val imitation 1.4406987428665161 reward 1.8490450382232666\n",
      "val loss 3.2897439002990723 3.2919700145721436\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8285256410256411}]\n",
      "______epoch 107 _____\n",
      "train imitation 1.7121453285217285 reward 2.498220920562744\n",
      "val imitation 1.431910753250122 reward 1.848789930343628\n",
      "val loss 3.28070068359375 3.2897439002990723\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6992872807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8288461538461539}]\n",
      "______epoch 108 _____\n",
      "train imitation 1.713974118232727 reward 2.4949588775634766\n",
      "val imitation 1.4199833869934082 reward 1.8485599756240845\n",
      "val loss 3.268543243408203 3.28070068359375\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5552884615384616}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6995614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8288461538461538}]\n",
      "______epoch 109 _____\n",
      "train imitation 1.7253844738006592 reward 2.4953761100769043\n",
      "val imitation 1.412123203277588 reward 1.8486171960830688\n",
      "val loss 3.260740280151367 3.268543243408203\n",
      "[{'decision': 0, 'accuracy': 0.815068493150685, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8275641025641026}]\n",
      "______epoch 110 _____\n",
      "train imitation 1.7010997533798218 reward 2.494861364364624\n",
      "val imitation 1.4066542387008667 reward 1.8496230840682983\n",
      "val loss 3.256277322769165 3.260740280151367\n",
      "[{'decision': 0, 'accuracy': 0.821917808219178, 'auc': 0.5548076923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7003837719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8275641025641026}]\n",
      "______epoch 111 _____\n",
      "train imitation 1.7376799583435059 reward 2.4964630603790283\n",
      "val imitation 1.4032936096191406 reward 1.849740982055664\n",
      "val loss 3.2530345916748047 3.256277322769165\n",
      "[{'decision': 0, 'accuracy': 0.821917808219178, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7012061403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8278846153846154}]\n",
      "______epoch 112 _____\n",
      "train imitation 1.695749044418335 reward 2.495569944381714\n",
      "val imitation 1.4068394899368286 reward 1.849740982055664\n",
      "val loss 3.256580352783203 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.821917808219178, 'auc': 0.5538461538461538}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7017543859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8291666666666667}]\n",
      "______epoch 113 _____\n",
      "train imitation 1.6853681802749634 reward 2.4960527420043945\n",
      "val imitation 1.413325548171997 reward 1.8496837615966797\n",
      "val loss 3.2630093097686768 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.815068493150685, 'auc': 0.5557692307692308}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8307692307692308}]\n",
      "______epoch 114 _____\n",
      "train imitation 1.712033987045288 reward 2.494633913040161\n",
      "val imitation 1.4241951704025269 reward 1.8491849899291992\n",
      "val loss 3.2733802795410156 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5572115384615385}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8301282051282052}]\n",
      "______epoch 115 _____\n",
      "train imitation 1.6876437664031982 reward 2.498180866241455\n",
      "val imitation 1.4301198720932007 reward 1.8492422103881836\n",
      "val loss 3.279362201690674 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5576923076923077}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7009320175438596}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8307692307692308}]\n",
      "______epoch 116 _____\n",
      "train imitation 1.6967650651931763 reward 2.496830701828003\n",
      "val imitation 1.4326510429382324 reward 1.8501474857330322\n",
      "val loss 3.2827985286712646 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5581730769230769}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.7003837719298246}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8307692307692308}]\n",
      "______epoch 117 _____\n",
      "train imitation 1.6884558200836182 reward 2.493501901626587\n",
      "val imitation 1.4327795505523682 reward 1.851789951324463\n",
      "val loss 3.284569501876831 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5576923076923077}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.7014802631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8310897435897436}]\n",
      "______epoch 118 _____\n",
      "train imitation 1.706655502319336 reward 2.4985733032226562\n",
      "val imitation 1.434280514717102 reward 1.8519022464752197\n",
      "val loss 3.2861828804016113 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5591346153846154}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.7014802631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8317307692307692}]\n",
      "______epoch 119 _____\n",
      "train imitation 1.693180799484253 reward 2.496748208999634\n",
      "val imitation 1.4331166744232178 reward 1.8518155813217163\n",
      "val loss 3.2849321365356445 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5596153846153846}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.7001096491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8323717948717948}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 120 _____\n",
      "train imitation 1.701364278793335 reward 2.4978904724121094\n",
      "val imitation 1.4330124855041504 reward 1.8532582521438599\n",
      "val loss 3.2862706184387207 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5605769230769231}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6992872807017543}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8317307692307692}]\n",
      "______epoch 121 _____\n",
      "train imitation 1.680197834968567 reward 2.4978318214416504\n",
      "val imitation 1.4306070804595947 reward 1.853963851928711\n",
      "val loss 3.2845709323883057 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5600961538461539}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6984649122807017}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.832051282051282}]\n",
      "______epoch 122 _____\n",
      "train imitation 1.694934368133545 reward 2.4960415363311768\n",
      "val imitation 1.4234720468521118 reward 1.8540376424789429\n",
      "val loss 3.2775096893310547 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5586538461538462}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8314102564102565}]\n",
      "______epoch 123 _____\n",
      "train imitation 1.672856092453003 reward 2.4961395263671875\n",
      "val imitation 1.4168872833251953 reward 1.8538784980773926\n",
      "val loss 3.270765781402588 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5562499999999999}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6987390350877194}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8317307692307693}]\n",
      "______epoch 124 _____\n",
      "train imitation 1.6897504329681396 reward 2.4968297481536865\n",
      "val imitation 1.4121127128601074 reward 1.8538758754730225\n",
      "val loss 3.26598858833313 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5581730769230769}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6976425438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8317307692307692}]\n",
      "______epoch 125 _____\n",
      "train imitation 1.688931941986084 reward 2.499789237976074\n",
      "val imitation 1.4105339050292969 reward 1.853628396987915\n",
      "val loss 3.264162302017212 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5581730769230769}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6976425438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8317307692307692}]\n",
      "______epoch 126 _____\n",
      "train imitation 1.6990551948547363 reward 2.499346971511841\n",
      "val imitation 1.4151496887207031 reward 1.8538758754730225\n",
      "val loss 3.2690255641937256 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5567307692307693}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6981907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8317307692307692}]\n",
      "______epoch 127 _____\n",
      "train imitation 1.689753770828247 reward 2.499112606048584\n",
      "val imitation 1.424942970275879 reward 1.8553054332733154\n",
      "val loss 3.2802484035491943 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5552884615384616}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6984649122807017}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.832051282051282}]\n",
      "______epoch 128 _____\n",
      "train imitation 1.642472743988037 reward 2.4994096755981445\n",
      "val imitation 1.4358513355255127 reward 1.8550891876220703\n",
      "val loss 3.290940523147583 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5557692307692308}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6992872807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8323717948717948}]\n",
      "______epoch 129 _____\n",
      "train imitation 1.6634705066680908 reward 2.4973177909851074\n",
      "val imitation 1.4412938356399536 reward 1.854804515838623\n",
      "val loss 3.296098232269287 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5528846153846154}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8317307692307693}]\n",
      "______epoch 130 _____\n",
      "train imitation 1.657597303390503 reward 2.4987637996673584\n",
      "val imitation 1.4490026235580444 reward 1.853466272354126\n",
      "val loss 3.302468776702881 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7001096491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8310897435897436}]\n",
      "______epoch 131 _____\n",
      "train imitation 1.6799442768096924 reward 2.4984734058380127\n",
      "val imitation 1.44804847240448 reward 1.8544056415557861\n",
      "val loss 3.3024539947509766 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6995614035087718}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8307692307692308}]\n",
      "______epoch 132 _____\n",
      "train imitation 1.659733533859253 reward 2.4991841316223145\n",
      "val imitation 1.43987238407135 reward 1.8538930416107178\n",
      "val loss 3.2937655448913574 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5557692307692308}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8298076923076924}]\n",
      "______epoch 133 _____\n",
      "train imitation 1.664180040359497 reward 2.500225782394409\n",
      "val imitation 1.432204008102417 reward 1.854743242263794\n",
      "val loss 3.286947250366211 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5548076923076923}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8298076923076924}]\n",
      "______epoch 134 _____\n",
      "train imitation 1.6619813442230225 reward 2.4984495639801025\n",
      "val imitation 1.4244661331176758 reward 1.854067087173462\n",
      "val loss 3.2785332202911377 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6984649122807018}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8291666666666666}]\n",
      "______epoch 135 _____\n",
      "train imitation 1.6473774909973145 reward 2.4997854232788086\n",
      "val imitation 1.4256316423416138 reward 1.854080080986023\n",
      "val loss 3.2797117233276367 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5543269230769231}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8291666666666666}]\n",
      "______epoch 136 _____\n",
      "train imitation 1.6406886577606201 reward 2.497382164001465\n",
      "val imitation 1.4303832054138184 reward 1.8522043228149414\n",
      "val loss 3.2825875282287598 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5514423076923077}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6981907894736843}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8294871794871795}]\n",
      "______epoch 137 _____\n",
      "train imitation 1.659199833869934 reward 2.4981815814971924\n",
      "val imitation 1.439488410949707 reward 1.8500231504440308\n",
      "val loss 3.2895116806030273 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7328767123287672, 'auc': 0.5524038461538461}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6984649122807018}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8298076923076922}]\n",
      "______epoch 138 _____\n",
      "train imitation 1.6431941986083984 reward 2.4996705055236816\n",
      "val imitation 1.4515185356140137 reward 1.8488824367523193\n",
      "val loss 3.300400972366333 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.5538461538461539}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.699013157894737}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8291666666666667}]\n",
      "______epoch 139 _____\n",
      "train imitation 1.629936933517456 reward 2.497967481613159\n",
      "val imitation 1.4520283937454224 reward 1.8487581014633179\n",
      "val loss 3.3007864952087402 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.5533653846153846}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8307692307692308}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 140 _____\n",
      "train imitation 1.6135034561157227 reward 2.4983630180358887\n",
      "val imitation 1.4536811113357544 reward 1.8471031188964844\n",
      "val loss 3.300784111022949 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.5524038461538462}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.7012061403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8294871794871794}]\n",
      "______epoch 141 _____\n",
      "train imitation 1.6265554428100586 reward 2.4953114986419678\n",
      "val imitation 1.449310541152954 reward 1.846771478652954\n",
      "val loss 3.296082019805908 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5514423076923077}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.828525641025641}]\n",
      "______epoch 142 _____\n",
      "train imitation 1.661378264427185 reward 2.4976086616516113\n",
      "val imitation 1.4348303079605103 reward 1.8482502698898315\n",
      "val loss 3.283080577850342 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5485576923076924}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.700109649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8294871794871794}]\n",
      "______epoch 143 _____\n",
      "train imitation 1.6263291835784912 reward 2.4954674243927\n",
      "val imitation 1.42071533203125 reward 1.8484818935394287\n",
      "val loss 3.2691972255706787 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5495192307692308}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8278846153846153}]\n",
      "______epoch 144 _____\n",
      "train imitation 1.6387101411819458 reward 2.4965929985046387\n",
      "val imitation 1.413496732711792 reward 1.848874807357788\n",
      "val loss 3.26237154006958 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.826602564102564}]\n",
      "______epoch 145 _____\n",
      "train imitation 1.614425539970398 reward 2.499055862426758\n",
      "val imitation 1.415320873260498 reward 1.848862648010254\n",
      "val loss 3.264183521270752 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5485576923076924}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.826602564102564}]\n",
      "______epoch 146 _____\n",
      "train imitation 1.6304848194122314 reward 2.4978091716766357\n",
      "val imitation 1.425718069076538 reward 1.8497732877731323\n",
      "val loss 3.275491237640381 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.700109649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.826602564102564}]\n",
      "______epoch 147 _____\n",
      "train imitation 1.643656849861145 reward 2.497063159942627\n",
      "val imitation 1.4409220218658447 reward 1.8495652675628662\n",
      "val loss 3.290487289428711 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6995614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.828525641025641}]\n",
      "______epoch 148 _____\n",
      "train imitation 1.617064118385315 reward 2.4982962608337402\n",
      "val imitation 1.4562828540802002 reward 1.8486167192459106\n",
      "val loss 3.3048996925354004 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5466346153846154}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.700109649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8282051282051283}]\n",
      "______epoch 149 _____\n",
      "train imitation 1.597092866897583 reward 2.4974818229675293\n",
      "val imitation 1.4576635360717773 reward 1.848745584487915\n",
      "val loss 3.3064091205596924 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5451923076923078}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.700657894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8288461538461539}]\n",
      "______epoch 150 _____\n",
      "train imitation 1.6243921518325806 reward 2.4990744590759277\n",
      "val imitation 1.4595537185668945 reward 1.8492331504821777\n",
      "val loss 3.3087868690490723 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.7012061403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.828525641025641}]\n",
      "______epoch 151 _____\n",
      "train imitation 1.5936776399612427 reward 2.498561143875122\n",
      "val imitation 1.4575520753860474 reward 1.8487811088562012\n",
      "val loss 3.306333065032959 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5447115384615384}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.700657894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8288461538461538}]\n",
      "______epoch 152 _____\n",
      "train imitation 1.62055504322052 reward 2.49914288520813\n",
      "val imitation 1.456018328666687 reward 1.8488893508911133\n",
      "val loss 3.30490779876709 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7465753424657534, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6995614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8278846153846153}]\n",
      "______epoch 153 _____\n",
      "train imitation 1.5829620361328125 reward 2.495915174484253\n",
      "val imitation 1.4525456428527832 reward 1.848615288734436\n",
      "val loss 3.3011608123779297 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6984649122807018}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8282051282051281}]\n",
      "______epoch 154 _____\n",
      "train imitation 1.628904104232788 reward 2.4966673851013184\n",
      "val imitation 1.4479756355285645 reward 1.848615288734436\n",
      "val loss 3.296590805053711 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6981907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8272435897435897}]\n",
      "______epoch 155 _____\n",
      "train imitation 1.6162631511688232 reward 2.4998226165771484\n",
      "val imitation 1.448422908782959 reward 1.8488627672195435\n",
      "val loss 3.297285556793213 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6976425438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8269230769230769}]\n",
      "______epoch 156 _____\n",
      "train imitation 1.5887343883514404 reward 2.5000839233398438\n",
      "val imitation 1.4535810947418213 reward 1.8488627672195435\n",
      "val loss 3.3024439811706543 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6979166666666666}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.826923076923077}]\n",
      "______epoch 157 _____\n",
      "train imitation 1.6198811531066895 reward 2.499309778213501\n",
      "val imitation 1.465254783630371 reward 1.847548246383667\n",
      "val loss 3.312803030014038 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.826602564102564}]\n",
      "______epoch 158 _____\n",
      "train imitation 1.6022056341171265 reward 2.4977641105651855\n",
      "val imitation 1.4738061428070068 reward 1.8478891849517822\n",
      "val loss 3.321695327758789 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6992872807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8262820512820512}]\n",
      "______epoch 159 _____\n",
      "train imitation 1.5912632942199707 reward 2.4956421852111816\n",
      "val imitation 1.487074613571167 reward 1.8475089073181152\n",
      "val loss 3.3345835208892822 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7054794520547946, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.7006578947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.826602564102564}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 160 _____\n",
      "train imitation 1.6117401123046875 reward 2.4976818561553955\n",
      "val imitation 1.4917644262313843 reward 1.846806526184082\n",
      "val loss 3.338571071624756 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8262820512820512}]\n",
      "______epoch 161 _____\n",
      "train imitation 1.5723929405212402 reward 2.4961791038513184\n",
      "val imitation 1.484464406967163 reward 1.8462791442871094\n",
      "val loss 3.3307435512542725 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7054794520547946, 'auc': 0.5384615384615385}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.7006578947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8262820512820512}]\n",
      "______epoch 162 _____\n",
      "train imitation 1.5858948230743408 reward 2.496967315673828\n",
      "val imitation 1.4792784452438354 reward 1.8465592861175537\n",
      "val loss 3.3258376121520996 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7123287671232876, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.7012061403508772}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.826602564102564}]\n",
      "______epoch 163 _____\n",
      "train imitation 1.6093425750732422 reward 2.494459390640259\n",
      "val imitation 1.471270203590393 reward 1.8462791442871094\n",
      "val loss 3.317549228668213 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7191780821917808, 'auc': 0.5375}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.826602564102564}]\n",
      "______epoch 164 _____\n",
      "train imitation 1.5961979627609253 reward 2.495126962661743\n",
      "val imitation 1.4652057886123657 reward 1.8470728397369385\n",
      "val loss 3.3122787475585938 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.5379807692307693}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7017543859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8272435897435897}]\n",
      "______epoch 165 _____\n",
      "train imitation 1.5657775402069092 reward 2.49575138092041\n",
      "val imitation 1.4718300104141235 reward 1.8470728397369385\n",
      "val loss 3.3189029693603516 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7123287671232876, 'auc': 0.5360576923076924}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.7033991228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8275641025641025}]\n",
      "______epoch 166 _____\n",
      "train imitation 1.6060422658920288 reward 2.495140314102173\n",
      "val imitation 1.4807077646255493 reward 1.846293330192566\n",
      "val loss 3.3270010948181152 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.7054794520547946, 'auc': 0.5384615384615385}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7028508771929826}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8275641025641025}]\n",
      "______epoch 167 _____\n",
      "train imitation 1.590747356414795 reward 2.4975528717041016\n",
      "val imitation 1.4916348457336426 reward 1.8459128141403198\n",
      "val loss 3.337547779083252 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5350961538461538}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.7017543859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8269230769230769}]\n",
      "______epoch 168 _____\n",
      "train imitation 1.625018835067749 reward 2.4977054595947266\n",
      "val imitation 1.5008889436721802 reward 1.8452870845794678\n",
      "val loss 3.3461761474609375 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.7009320175438597}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8262820512820512}]\n",
      "______epoch 169 _____\n",
      "train imitation 1.5656769275665283 reward 2.4931423664093018\n",
      "val imitation 1.5027625560760498 reward 1.8462250232696533\n",
      "val loss 3.348987579345703 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6995614035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8269230769230769}]\n",
      "______epoch 170 _____\n",
      "train imitation 1.5854310989379883 reward 2.495678186416626\n",
      "val imitation 1.4975801706314087 reward 1.8462432622909546\n",
      "val loss 3.3438234329223633 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5365384615384616}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8259615384615384}]\n",
      "______epoch 171 _____\n",
      "train imitation 1.5469359159469604 reward 2.496107339859009\n",
      "val imitation 1.4988826513290405 reward 1.8465889692306519\n",
      "val loss 3.3454716205596924 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5375000000000001}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6981907894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8256410256410256}]\n",
      "______epoch 172 _____\n",
      "train imitation 1.569671869277954 reward 2.494853973388672\n",
      "val imitation 1.4960941076278687 reward 1.8469645977020264\n",
      "val loss 3.3430585861206055 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5379807692307692}, {'decision': 1, 'accuracy': 0.6643835616438356, 'auc': 0.6973684210526316}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.825}]\n",
      "______epoch 173 _____\n",
      "train imitation 1.5562318563461304 reward 2.496452808380127\n",
      "val imitation 1.5010544061660767 reward 1.846900224685669\n",
      "val loss 3.347954750061035 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5379807692307692}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6976425438596492}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8256410256410257}]\n",
      "______epoch 174 _____\n",
      "train imitation 1.5452587604522705 reward 2.496143341064453\n",
      "val imitation 1.5175930261611938 reward 1.846942663192749\n",
      "val loss 3.3645358085632324 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5375000000000001}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6962719298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8272435897435897}]\n",
      "______epoch 175 _____\n",
      "train imitation 1.5554172992706299 reward 2.497818946838379\n",
      "val imitation 1.526673674583435 reward 1.8467514514923096\n",
      "val loss 3.373425006866455 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5360576923076924}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.696546052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.826602564102564}]\n",
      "______epoch 176 _____\n",
      "train imitation 1.5577616691589355 reward 2.497312307357788\n",
      "val imitation 1.5200062990188599 reward 1.8466193675994873\n",
      "val loss 3.3666257858276367 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5370192307692309}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6968201754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8262820512820512}]\n",
      "______epoch 177 _____\n",
      "train imitation 1.5447537899017334 reward 2.4963107109069824\n",
      "val imitation 1.5101702213287354 reward 1.845702052116394\n",
      "val loss 3.35587215423584 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5370192307692309}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6970942982456141}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8243589743589743}]\n",
      "______epoch 178 _____\n",
      "train imitation 1.5826292037963867 reward 2.4961142539978027\n",
      "val imitation 1.5075628757476807 reward 1.8454196453094482\n",
      "val loss 3.352982521057129 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5355769230769232}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.6962719298245614}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8246794871794871}]\n",
      "______epoch 179 _____\n",
      "train imitation 1.553777813911438 reward 2.495150566101074\n",
      "val imitation 1.5270283222198486 reward 1.8473763465881348\n",
      "val loss 3.3744046688079834 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5355769230769231}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6954495614035088}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.825}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 180 _____\n",
      "train imitation 1.5430561304092407 reward 2.496851682662964\n",
      "val imitation 1.5471850633621216 reward 1.8474061489105225\n",
      "val loss 3.3945913314819336 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5346153846153846}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8237179487179488}]\n",
      "______epoch 181 _____\n",
      "train imitation 1.5376200675964355 reward 2.4966955184936523\n",
      "val imitation 1.5559942722320557 reward 1.8463497161865234\n",
      "val loss 3.402343988418579 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5331730769230769}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.694078947368421}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8233974358974359}]\n",
      "______epoch 182 _____\n",
      "train imitation 1.5171308517456055 reward 2.4969708919525146\n",
      "val imitation 1.559504747390747 reward 1.8463497161865234\n",
      "val loss 3.4058544635772705 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5317307692307692}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6943530701754386}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.823076923076923}]\n",
      "______epoch 183 _____\n",
      "train imitation 1.53292977809906 reward 2.496647596359253\n",
      "val imitation 1.5575952529907227 reward 1.846610188484192\n",
      "val loss 3.404205322265625 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5283653846153846}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.694078947368421}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8208333333333333}]\n",
      "______epoch 184 _____\n",
      "train imitation 1.5493825674057007 reward 2.497819662094116\n",
      "val imitation 1.5629150867462158 reward 1.846206545829773\n",
      "val loss 3.409121513366699 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5269230769230769}, {'decision': 1, 'accuracy': 0.6506849315068494, 'auc': 0.694078947368421}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8217948717948718}]\n",
      "______epoch 185 _____\n",
      "train imitation 1.5285398960113525 reward 2.494460105895996\n",
      "val imitation 1.5808855295181274 reward 1.8463350534439087\n",
      "val loss 3.427220582962036 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5269230769230769}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6929824561403508}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8208333333333333}]\n",
      "______epoch 186 _____\n",
      "train imitation 1.533691644668579 reward 2.494602680206299\n",
      "val imitation 1.6007492542266846 reward 1.8468726873397827\n",
      "val loss 3.4476218223571777 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.5278846153846154}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6902412280701754}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.819551282051282}]\n",
      "______epoch 187 _____\n",
      "train imitation 1.5039260387420654 reward 2.4972939491271973\n",
      "val imitation 1.6076794862747192 reward 1.8471415042877197\n",
      "val loss 3.4548211097717285 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5274038461538462}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6899671052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.819551282051282}]\n",
      "______epoch 188 _____\n",
      "train imitation 1.5149357318878174 reward 2.4961977005004883\n",
      "val imitation 1.6215258836746216 reward 1.8471415042877197\n",
      "val loss 3.468667507171631 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5278846153846154}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6896929824561404}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8189102564102564}]\n",
      "______epoch 189 _____\n",
      "train imitation 1.5386860370635986 reward 2.497830867767334\n",
      "val imitation 1.6185171604156494 reward 1.8471415042877197\n",
      "val loss 3.465658664703369 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5283653846153846}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6899671052631579}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8179487179487179}]\n",
      "______epoch 190 _____\n",
      "train imitation 1.513192057609558 reward 2.4974443912506104\n",
      "val imitation 1.6065623760223389 reward 1.8468925952911377\n",
      "val loss 3.4534549713134766 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5288461538461539}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6888706140350878}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8179487179487179}]\n",
      "______epoch 191 _____\n",
      "train imitation 1.542188048362732 reward 2.4978342056274414\n",
      "val imitation 1.5984591245651245 reward 1.8462083339691162\n",
      "val loss 3.444667339324951 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5298076923076923}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6894188596491229}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8182692307692307}]\n",
      "______epoch 192 _____\n",
      "train imitation 1.5420825481414795 reward 2.4982056617736816\n",
      "val imitation 1.6211546659469604 reward 1.8462364673614502\n",
      "val loss 3.467391014099121 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6896929824561403}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8173076923076923}]\n",
      "______epoch 193 _____\n",
      "train imitation 1.5241053104400635 reward 2.4973666667938232\n",
      "val imitation 1.6571422815322876 reward 1.8467084169387817\n",
      "val loss 3.5038506984710693 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5302884615384615}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6877741228070176}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.816025641025641}]\n",
      "______epoch 194 _____\n",
      "train imitation 1.524048089981079 reward 2.496058464050293\n",
      "val imitation 1.689414143562317 reward 1.8462356328964233\n",
      "val loss 3.5356497764587402 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6506849315068494, 'auc': 0.5346153846153847}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8157051282051282}]\n",
      "______epoch 195 _____\n",
      "train imitation 1.4752113819122314 reward 2.493945837020874\n",
      "val imitation 1.7032724618911743 reward 1.8466163873672485\n",
      "val loss 3.549888849258423 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6506849315068494, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6861293859649122}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8144230769230769}]\n",
      "______epoch 196 _____\n",
      "train imitation 1.4965852499008179 reward 2.4974756240844727\n",
      "val imitation 1.6617573499679565 reward 1.8468875885009766\n",
      "val loss 3.5086450576782227 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5355769230769231}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6861293859649122}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8144230769230769}]\n",
      "______epoch 197 _____\n",
      "train imitation 1.511814832687378 reward 2.4958384037017822\n",
      "val imitation 1.6161625385284424 reward 1.8475217819213867\n",
      "val loss 3.463684320449829 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5346153846153847}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6861293859649122}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8137820512820513}]\n",
      "______epoch 198 _____\n",
      "train imitation 1.5222476720809937 reward 2.496412515640259\n",
      "val imitation 1.6052860021591187 reward 1.8475217819213867\n",
      "val loss 3.452807903289795 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5355769230769232}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6855811403508771}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8131410256410256}]\n",
      "______epoch 199 _____\n",
      "train imitation 1.5085647106170654 reward 2.4985010623931885\n",
      "val imitation 1.649204969406128 reward 1.8482575416564941\n",
      "val loss 3.497462511062622 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6858552631578948}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8128205128205128}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 200 _____\n",
      "train imitation 1.5286964178085327 reward 2.495995283126831\n",
      "val imitation 1.691309928894043 reward 1.8476234674453735\n",
      "val loss 3.538933277130127 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6575342465753424, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6842105263157895}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8125}]\n",
      "______epoch 201 _____\n",
      "train imitation 1.493225336074829 reward 2.4958553314208984\n",
      "val imitation 1.7113475799560547 reward 1.847294807434082\n",
      "val loss 3.5586423873901367 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6506849315068494, 'auc': 0.5403846153846155}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6833881578947368}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8099358974358974}]\n",
      "______epoch 202 _____\n",
      "train imitation 1.4742844104766846 reward 2.4974613189697266\n",
      "val imitation 1.6928905248641968 reward 1.8477023839950562\n",
      "val loss 3.540592908859253 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.5423076923076924}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6820175438596491}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8076923076923077}]\n",
      "______epoch 203 _____\n",
      "train imitation 1.4782975912094116 reward 2.497860908508301\n",
      "val imitation 1.6787899732589722 reward 1.8482327461242676\n",
      "val loss 3.5270228385925293 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.5413461538461539}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6817434210526315}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8070512820512821}]\n",
      "______epoch 204 _____\n",
      "train imitation 1.4784209728240967 reward 2.4974207878112793\n",
      "val imitation 1.6736009120941162 reward 1.8477798700332642\n",
      "val loss 3.52138090133667 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.5403846153846155}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6798245614035088}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8048076923076923}]\n",
      "______epoch 205 _____\n",
      "train imitation 1.4680843353271484 reward 2.4986579418182373\n",
      "val imitation 1.688813328742981 reward 1.8473299741744995\n",
      "val loss 3.5361433029174805 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.5389423076923077}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6798245614035088}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8035256410256411}]\n",
      "______epoch 206 _____\n",
      "train imitation 1.4998605251312256 reward 2.498342514038086\n",
      "val imitation 1.6868839263916016 reward 1.8476632833480835\n",
      "val loss 3.5345473289489746 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.5389423076923077}, {'decision': 1, 'accuracy': 0.6164383561643836, 'auc': 0.6795504385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8032051282051282}]\n",
      "______epoch 207 _____\n",
      "train imitation 1.4766039848327637 reward 2.5007050037384033\n",
      "val imitation 1.6873935461044312 reward 1.8474918603897095\n",
      "val loss 3.5348854064941406 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5365384615384616}, {'decision': 1, 'accuracy': 0.6232876712328768, 'auc': 0.6792763157894737}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8012820512820512}]\n",
      "______epoch 208 _____\n",
      "train imitation 1.47305166721344 reward 2.496656656265259\n",
      "val imitation 1.6734468936920166 reward 1.847868800163269\n",
      "val loss 3.521315574645996 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5355769230769232}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6792763157894737}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8012820512820512}]\n",
      "______epoch 209 _____\n",
      "train imitation 1.455231785774231 reward 2.498781442642212\n",
      "val imitation 1.6831361055374146 reward 1.8469538688659668\n",
      "val loss 3.530089855194092 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5350961538461538}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.680921052631579}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8006410256410257}]\n",
      "______epoch 210 _____\n",
      "train imitation 1.4827909469604492 reward 2.498478412628174\n",
      "val imitation 1.7210795879364014 reward 1.8460071086883545\n",
      "val loss 3.567086696624756 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6506849315068494, 'auc': 0.5346153846153846}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.6814692982456141}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7977564102564103}]\n",
      "______epoch 211 _____\n",
      "train imitation 1.4780431985855103 reward 2.496978282928467\n",
      "val imitation 1.7795562744140625 reward 1.8452578783035278\n",
      "val loss 3.624814033508301 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.6301369863013698, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.636986301369863, 'auc': 0.6809210526315789}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7977564102564102}]\n",
      "______epoch 212 _____\n",
      "train imitation 1.4760899543762207 reward 2.4951798915863037\n",
      "val imitation 1.7664403915405273 reward 1.844622015953064\n",
      "val loss 3.611062526702881 3.2530345916748047\n",
      "[{'decision': 0, 'accuracy': 0.636986301369863, 'auc': 0.5341346153846154}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6790021929824561}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7977564102564102}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(3.2530, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.821917808219178, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.684931506849315, 'auc': 0.7012061403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8278846153846154}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def shuffle_col(v,col=None):\n",
    "    if col is None:\n",
    "        col = np.random.choice([i for i in range(v.shape[1])])\n",
    "    idx = torch.randperm(v.shape[0])\n",
    "    vv = torch.clone(v)\n",
    "    vv[:,col] = vv[idx,col]\n",
    "    return vv\n",
    "    \n",
    "def train_decision_model(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    lr=.0001,\n",
    "    epochs=10000,\n",
    "    patience=100,\n",
    "    weights=[3,1,1], #realtive weight of survival, feeding tube, and aspiration\n",
    "    imitation_weight=1,\n",
    "    shufflecol_chance = 0.1,\n",
    "    reward_weight=10,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    use_attention=False,\n",
    "    verbose=True,\n",
    "    threshold_decisions=True,\n",
    "    use_smote=True,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "\n",
    "    if use_smote:\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids)\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "\n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids])\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    def outcome_loss(ypred):\n",
    "        #convert survival to death\n",
    "        loss = torch.mul(torch.mean(-1*(ypred[:,0] - 1)),weights[0])\n",
    "        for i,weight in enumerate(weights[1:]):\n",
    "            newloss = torch.mean(ypred[:,i])*weight\n",
    "            loss = torch.add(loss,torch.mul(newloss,weight))\n",
    "        return loss\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    nllloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "\n",
    "    \n",
    "    #save the inputs from the whole dataset for future reference\n",
    "    full_data = []\n",
    "    for mstep in [0,1,2]:\n",
    "        full_data_step = [baseline, get_dlt(min(mstep,1)),\n",
    "                     get_dlt(mstep),get_pd(mstep),get_nd(mstep),get_cc(mstep),get_mod(mstep)]\n",
    "        full_data_step = torch.cat([formatdf(fd,train_ids+test_ids) for fd in full_data_step],axis=1)\n",
    "        full_data.append(full_data_step)\n",
    "    full_data = torch.stack(full_data)\n",
    "    model.save_memory(full_data)\n",
    "\n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            \n",
    "            \n",
    "        ytrain = df_to_torch(outcomedf.loc[ids])\n",
    "        #imitation losses and decision 1\n",
    "        xxtrained = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrained]\n",
    "        o1 = model(torch.cat(xxtrain,axis=1),position=0)\n",
    "            \n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1 = o1[:,0]\n",
    "        if threshold_decisions:\n",
    "            decision1 = threshold(decision1)\n",
    "#         imitation_loss1 = bce(threshold(decision1_imitation),ytrain[:,0])\n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        decision2_imitation = model(torch.cat(x1_imitation,axis=1),position=1)[:,4]\n",
    "        \n",
    "#         imitation_loss2 =  bce(threshold(decision2_imitation),ytrain[:,1])\n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "#         if model.keys is None:\n",
    "#             keyvals = torch.cat([formatdf(xxx,train_ids+test_ids) for xxx in x2_imitation],axis=1)\n",
    "#             model.set_keys(keyvals)\n",
    "            \n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        \n",
    "        decision3_imitation = model(torch.cat(x2_imitation,axis=1),position=2)[:,5]\n",
    "        \n",
    "#         imitation_loss3 = bce(threshold(decision3_imitation),ytrain[:,2])\n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        \n",
    "        #reward decisions\n",
    "        xx1 = makeinput(1,ids)\n",
    "        xx2 = makeinput(2,ids)\n",
    "        xx3 = makeinput(3,ids)\n",
    "\n",
    "        baseline_train_base = formatdf(baseline,ids)\n",
    "            \n",
    "        baseline_train = torch.clone(baseline_train_base)\n",
    "        if train and shufflecol_chance > 0.0001:\n",
    "            for col in range(baseline_train_base.shape[1]): \n",
    "                if np.random.random() < shufflecol_chance:\n",
    "                    baseline_train = shuffle_col(baseline_train,col)\n",
    "                    \n",
    "        \n",
    "        xi1 = torch.cat([xx1,decision1.view(-1,1)],axis=1)\n",
    "        [ypd1, ynd1, ymod, ydlt1] = tmodel1(xi1)\n",
    "        #this outputs log likelihoods (except for dlts) -> convert to probability\n",
    "        ypd1 = torch.exp(ypd1)\n",
    "        ynd1 = torch.exp(ynd1)\n",
    "        ymod = torch.exp(ymod)\n",
    "        x1 = [baseline_train,ydlt1,formatdf(get_dlt(0),ids),ypd1,ynd1,formatdf(get_cc(1),ids),ymod]\n",
    "        \n",
    "        decision2 = model(torch.cat(x1,axis=1),position=1)[:,1] \n",
    "        if threshold_decisions:\n",
    "            decision2 = threshold(decision2)\n",
    "            \n",
    "        xi2 = torch.cat([xx2,decision1.view(-1,1),decision2.view(-1,1)],axis=1)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = tmodel2(xi2)\n",
    "        ypd2 = torch.exp(ypd2)\n",
    "        ynd2 = torch.exp(ynd2)\n",
    "        ycc = torch.exp(ycc)\n",
    "        x2 = [baseline_train,ydlt1,ydlt2,ypd2,ynd2,ycc,ymod]\n",
    "            \n",
    "        decision3 = model(torch.cat(x2,axis=1),position=2)[:,2]\n",
    "        if threshold_decisions:\n",
    "            decision3 = threshold(decision3)\n",
    "            \n",
    "        \n",
    "        xi3 = torch.cat([xx3,decision1.view(-1,1),decision2.view(-1,1),decision3.view(-1,1)],axis=1)\n",
    "        outcomes = tmodel3(xi3)\n",
    "\n",
    "        reward_loss = outcome_loss(outcomes)\n",
    "        loss = torch.add(imitation_loss1,imitation_loss2)\n",
    "        loss = torch.add(loss,imitation_loss3)\n",
    "        loss = torch.mul(loss,imitation_weight/3)\n",
    "        loss = torch.add(loss,torch.mul(reward_loss,reward_weight))\n",
    "        losses = [imitation_loss1+imitation_loss2+imitation_loss3,reward_loss]\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            for i,decision in enumerate([decision1_imitation,decision2_imitation,decision3_imitation]):\n",
    "                dec = decision.cpu().detach().numpy()\n",
    "                dec0 = (dec > .5).astype(int)\n",
    "                out = ytrain[:,i].cpu().detach().numpy()\n",
    "                acc = accuracy_score(out,dec > .5)\n",
    "                auc = roc_auc_score(out,dec)\n",
    "                scores.append({'decision': i,'accuracy': acc,'auc': auc})\n",
    "            return losses, scores\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('train imitation',losses[0].item(),'reward',losses[1].item())\n",
    "            print('val imitation',val_losses[0].item(),'reward',val_losses[1].item())\n",
    "            print('val loss',vl.item(),best_val_loss.item())\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [600,300], \n",
    "    'attention_heads': [3,1], \n",
    "    'embed_size': 210, \n",
    "    'dropout': 0.9, \n",
    "    'input_dropout': 0.5, \n",
    "    'shufflecol_chance': 0.5,\n",
    "}\n",
    "decision_model, _, _ = train_decision_model(model1,model2,model3,lr=.0001,use_attention=True,**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c6f1a39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4204, 0.7079, 0.5565,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2065, 0.4552, 0.7320,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3848, 0.1127, 0.0104,  ..., 0.0000, 0.0000, 0.6749],\n",
       "        ...,\n",
       "        [1.4807, 0.1248, 0.6973,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [1.8474, 0.2117, 0.2452,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4463, 0.2753, 0.0000,  ..., 0.6557, 1.1129, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model.get_embedding(decision_model.memory[1][300:600],position=1,use_saved_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d25bc729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2186, 82])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model.memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062ec356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "done 0 tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "curr best 100000000000\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.5, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6639254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7371794871794872}]\n",
      "done 1 tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "done 2 tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.664423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7730769230769231}]\n",
      "done 3 tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6596153846153846}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7025767543859649}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7615384615384615}]\n",
      "done 4 tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5918269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897436}]\n",
      "done 5 tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461538}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6636513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7413461538461539}]\n",
      "done 6 tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8490, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.690515350877193}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7644230769230769}]\n",
      "done 7 tensor(2.8490, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7657, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6721153846153847}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6551535087719298}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7262820512820514}]\n",
      "done 8 tensor(2.7657, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7742, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6697115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "done 9 tensor(2.7742, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017545}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7666666666666666}]\n",
      "done 10 tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017545}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7666666666666666}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8505, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7403846153846154}]\n",
      "done 11 tensor(2.8505, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8421, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.621984649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7413461538461539}]\n",
      "done 12 tensor(2.8421, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8222, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7173076923076923}]\n",
      "done 13 tensor(2.8222, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8562, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6658653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333334}]\n",
      "done 14 tensor(2.8562, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8358, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.6711538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6631030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7442307692307693}]\n",
      "done 15 tensor(2.8358, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8148, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8767123287671232, 'auc': 0.6326923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6493969298245614}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "done 16 tensor(2.8148, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8188, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7458333333333333}]\n",
      "done 17 tensor(2.8188, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7478, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7685897435897435}]\n",
      "done 18 tensor(2.7478, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7967, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6918859649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7387820512820513}]\n",
      "done 19 tensor(2.7967, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7939, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6927083333333334}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7576923076923077}]\n",
      "done 20 tensor(2.7939, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.9093, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6201923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6403508771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6964743589743589}]\n",
      "done 21 tensor(2.9093, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8112, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6274038461538463}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7149122807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7701923076923077}]\n",
      "done 22 tensor(2.8112, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8290, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "done 23 tensor(2.8290, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7542, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6485576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6765350877192982}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7634615384615384}]\n",
      "done 24 tensor(2.7542, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8557, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5990384615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.665296052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7291666666666666}]\n",
      "done 25 tensor(2.8557, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7972, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "done 26 tensor(2.7972, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7995, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7069627192982456}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7663461538461539}]\n",
      "done 27 tensor(2.7995, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6370192307692308}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7053179824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7365384615384616}]\n",
      "done 28 tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7918, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.680921052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7323717948717948}]\n",
      "done 29 tensor(2.7918, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7197, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6500000000000001}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7450657894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179488}]\n",
      "done 30 tensor(2.7197, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7020285087719298}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7551282051282051}]\n",
      "done 31 tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8274, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7461538461538462}]\n",
      "done 32 tensor(2.8274, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7998, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6807692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.65625}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7503205128205128}]\n",
      "done 33 tensor(2.7998, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8270, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.6883223684210527}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7490384615384615}]\n",
      "done 34 tensor(2.8270, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8275, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6858552631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7266025641025642}]\n",
      "done 35 tensor(2.8275, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7048076923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6976425438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7676282051282052}]\n",
      "done 36 tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7048076923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6976425438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7676282051282052}]\n",
      "{'hidden_layers': [300], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.5, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8375, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.706140350877193}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7682692307692308}]\n",
      "done 37 tensor(2.8375, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7286, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6610576923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7456140350877194}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7724358974358975}]\n",
      "done 38 tensor(2.7286, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7758, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6721153846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6992872807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "done 39 tensor(2.7758, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8136, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.708173076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7576923076923077}]\n",
      "done 40 tensor(2.8136, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7640, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6716346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6447368421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7176282051282051}]\n",
      "done 41 tensor(2.7640, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8083, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6749999999999999}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.7214912280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.742948717948718}]\n",
      "done 42 tensor(2.8083, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8376, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6879807692307692}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6864035087719298}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7663461538461538}]\n",
      "done 43 tensor(2.8376, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7753, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6605769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6896929824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7695512820512821}]\n",
      "done 44 tensor(2.7753, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7879, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6745192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7154605263157895}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7301282051282052}]\n",
      "done 45 tensor(2.7879, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "done 46 tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "{'hidden_layers': [600], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7263, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692309}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7025767543859649}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7384615384615385}]\n",
      "done 47 tensor(2.7263, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7956, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6341346153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6735197368421053}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7419871794871795}]\n",
      "done 48 tensor(2.7956, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8560, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6812500000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6822916666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6852564102564103}]\n",
      "done 49 tensor(2.8560, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8169, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7094298245614035}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7442307692307693}]\n",
      "done 50 tensor(2.8169, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7564, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6669407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6746794871794872}]\n",
      "done 51 tensor(2.7564, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7691, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7153846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7519230769230769}]\n",
      "done 52 tensor(2.7691, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7305, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6908653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7201923076923077}]\n",
      "done 53 tensor(2.7305, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7444, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.670673076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7769230769230769}]\n",
      "done 54 tensor(2.7444, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8291, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6649038461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7631410256410257}]\n",
      "done 55 tensor(2.8291, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7556, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6471153846153845}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6647478070175439}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7413461538461539}]\n",
      "done 56 tensor(2.7556, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8389, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6908653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.659265350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7477564102564103}]\n",
      "done 57 tensor(2.8389, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8019, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7113486842105263}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.760576923076923}]\n",
      "done 58 tensor(2.8019, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8001, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6749999999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6705043859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "done 59 tensor(2.8001, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7223, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6711538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7083333333333333}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7391025641025641}]\n",
      "done 60 tensor(2.7223, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7080, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7466346153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6759868421052632}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7176282051282051}]\n",
      "done 61 tensor(2.7080, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7356, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6591346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6641995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7442307692307693}]\n",
      "done 62 tensor(2.7356, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8151, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.7024038461538461}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6979166666666667}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7666666666666666}]\n",
      "done 63 tensor(2.8151, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7464, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6677631578947368}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7403846153846154}]\n",
      "done 64 tensor(2.7464, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7897, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6729714912280702}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7580128205128205}]\n",
      "done 65 tensor(2.7897, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7963, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7069627192982456}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7685897435897435}]\n",
      "done 66 tensor(2.7963, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8113, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6615384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6729714912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205127}]\n",
      "done 67 tensor(2.8113, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7493, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6610576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7721153846153846}]\n",
      "done 68 tensor(2.7493, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8051, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7038461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7080592105263157}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7243589743589745}]\n",
      "done 69 tensor(2.8051, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7407, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6940789473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7259615384615384}]\n",
      "done 70 tensor(2.7407, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7586, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6086538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6650219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7307692307692308}]\n",
      "done 71 tensor(2.7586, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7063, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7397260273972602, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7589743589743589}]\n",
      "done 72 tensor(2.7063, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7378, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6586538461538463}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.778525641025641}]\n",
      "done 73 tensor(2.7378, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7615, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6956730769230769}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7439102564102564}]\n",
      "done 74 tensor(2.7615, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7420, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6240384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7509615384615385}]\n",
      "done 75 tensor(2.7420, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7639, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6331730769230769}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "done 76 tensor(2.7639, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8025, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6735576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6910635964912281}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7528846153846154}]\n",
      "done 77 tensor(2.8025, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8040, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6803728070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7336538461538462}]\n",
      "done 78 tensor(2.8040, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7637, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6427884615384616}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.6836622807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7541666666666667}]\n",
      "done 79 tensor(2.7637, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7725, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7211538461538463}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6992872807017545}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7246794871794873}]\n",
      "done 80 tensor(2.7725, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7330, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6949013157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "done 81 tensor(2.7330, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7552, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.68125}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7044956140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "done 82 tensor(2.7552, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8200, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7612179487179487}]\n",
      "done 83 tensor(2.8200, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "{'hidden_layers': [600], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionAttentionModel(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=210, out_features=600, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (final_layer): Linear(in_features=600, out_features=6, bias=True)\n",
       "  (resize_layer): Linear(in_features=97, out_features=210, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=210, out_features=210, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((210,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gridsearch_decision_model(m1,m2,m3):\n",
    "    model_arglist = [\n",
    "\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [50,50],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [2,2],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300,300],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600,600],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [0,120,210]:\n",
    "            #embed_size = 0 skips the firt layer that makes the sizes right\n",
    "            if embed_size == 0 and args['attention_heads'][0] != 1:\n",
    "                continue\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.5,.9]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.5]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    for shufflecol_chance in [.1,.5]:\n",
    "                        args['shufflecol_chance'] = shufflecol_chance\n",
    "                        model,m_metrics,m_loss = train_decision_model(m1,m2,m3,use_attention=True,verbose=False,**args)\n",
    "                        print('done',k,m_loss)\n",
    "                        print('curr best',best_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "\n",
    "from Models import *\n",
    "decision_model = gridsearch_decision_model(model1,model2,model3)\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e098f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_decision_model_statedecisions_input119_dims600,300_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(decision_model,'../data/models/final_decision_model_' + decision_model.identifier + '.pt')\n",
    "print('../data/models/final_decision_model_' + decision_model.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "91af46a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_transition1_model_state1_input50_dims1000_dropout0.5,0.9.pt\n",
      "../data/models/final_transition2_model_state2_input72_dims500,500_dropout0.5,0.9.pt\n",
      "../data/models/final_outcome_model_state1_input70_dims500,500_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model1,'../data/models/final_transition1_model_' + model1.identifier + '.pt')\n",
    "torch.save(model2,'../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "torch.save(model3,'../data/models/final_outcome_model_' + model3.identifier + '.pt')\n",
    "print('../data/models/final_transition1_model_' + model1.identifier + '.pt')\n",
    "print('../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "print('../data/models/final_outcome_model_' + model3.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "30998ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decision_model,'../resources/decision_model.pt')\n",
    "torch.save(model1,'../resources/transition1_model.pt')\n",
    "torch.save(model2,'../resources/transition2_model.pt')\n",
    "torch.save(model3,'../resources/outcome_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xatt = []\n",
    "for att,xxdf in zip(list(attributions),xdf):\n",
    "    new = pd.DataFrame(att.cpu().detach().numpy(),columns=xxdf.columns,index=xxdf.index)\n",
    "    xatt.append(new)\n",
    "attributions = pd.concat(xatt,axis=1)\n",
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ca3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(1,1,figsize=(100,100))\n",
    "sns.heatmap(data=attributions.T,ax=fig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakup_state_models(state_model):\n",
    "    #for state 1 and 2\n",
    "    models = {}\n",
    "    models['pd'] = lambda x: state_model(x)[0]\n",
    "    models['nd'] = lambda x: state_model(x)[1]\n",
    "    models['chemo'] = lambda x: state_model(x)[2]\n",
    "    for i,dlt in enumerate(Const.dlt1):\n",
    "        models[dlt] = lambda x: state_model(x)[3][:,i]\n",
    "    return models\n",
    "\n",
    "def breakup_outcome_models(omodel):\n",
    "    models = {}\n",
    "    for i,name in enumerate(Const.outcomes):\n",
    "        models[name] = lambda x: omodel(x)[:,i].reshape(-1,1)\n",
    "    return models\n",
    "\n",
    "def get_all_models(m1,m2,m3):\n",
    "    state1_models = breakup_state_models(m1)\n",
    "    state2_models = breakup_state_models(m2)\n",
    "    state3_models = breakup_outcome_models(m3)\n",
    "    all_models = {}\n",
    "    for i,sm in enumerate([state1_models,state2_models,state3_models]):\n",
    "        for ii,m in sm.items():\n",
    "            all_models[ii +  '_state' + str(i+1)] = m\n",
    "    return all_models\n",
    "\n",
    "all_models = get_all_models(model,model2,model3)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ytrue(name,df):\n",
    "    outcomes=None\n",
    "    value = None\n",
    "    if name == 'pd_state1':\n",
    "        outcomes = df[Const.primary_disease_states]\n",
    "    elif name == 'pd_state2':\n",
    "        outcomes = df[Const.primary_disease_states2]\n",
    "    elif name == 'nd_state1':\n",
    "        outcomes = df[Const.nodal_disease_states]\n",
    "    elif name == 'nd_state2':\n",
    "        outcomes = df[Const.nodal_disease_states2]\n",
    "    elif name == 'chemo_state1':\n",
    "        outcomes = df[Const.modifications]\n",
    "    elif name == 'chemo_state2':\n",
    "        outcomes = df[Const.ccs]   \n",
    "    if outcomes is not None:\n",
    "        value = outcomes.idxmax(axis=1)\n",
    "    if 'DLT' in name:\n",
    "        newname = name.replace('_state', ' ').replace('1','').strip()\n",
    "        value = df[newname]\n",
    "    if name.replace('_state3','') in Const.outcomes:\n",
    "        value = df[name.replace('_state3','')]\n",
    "    if value is None:\n",
    "        print(name,df.columns)\n",
    "    return value\n",
    "\n",
    "def check_impact_of_decisions(model_dict,data):\n",
    "    results = []\n",
    "    #todo: this is wrong fix it\n",
    "    ids = []\n",
    "    df = data.get_data()\n",
    "    outcomedict = {step: pd.concat(data.get_intermediate_outcomes(step=step),axis=1) for step in [1,2,3]}\n",
    "    for decision in Const.decisions:\n",
    "        for name, model in model_dict.items():\n",
    "            step = int(name[-1])\n",
    "            subset0 = dataset.get_input_state(step=step,fixed={decision: 0})\n",
    "            subset1 = dataset.get_input_state(step=step,fixed={decision: 1})\n",
    "            outcomes = outcomedict[step]\n",
    "            ids = subset0.index.values\n",
    "            x0 = df_to_torch(subset0)\n",
    "            x1 = df_to_torch(subset1)\n",
    "            y0 = model(x0).detach().cpu().numpy()\n",
    "            y1 = model(x1).detach().cpu().numpy()\n",
    "            original = data.get_input_state(step=step)\n",
    "            xx = df_to_torch(original)\n",
    "            yy = model(xx).detach().cpu().numpy()\n",
    "            ytrue = get_ytrue(name,outcomes)\n",
    "            if \"DLT\" in name:\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                change = y0 - y1\n",
    "                decision_change = (y0 != y1).astype(int)\n",
    "            elif y0.shape[1] == 1:\n",
    "                change = y1 - y0\n",
    "                decision_change = np.abs((y0 > .5).astype(int) - (y1 > .5).astype(int))\n",
    "            else:\n",
    "                index = np.unravel_index(np.argmax(yy, axis=1), yy.shape)\n",
    "                change = (y0[index] - y1[index]).reshape(-1,1)\n",
    "                decision_change =  (y0.argmax(axis=1).reshape(-1,1) != y1.argmax(axis=1).reshape(-1,1)).astype(int)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "            outcome = name.replace('_state','')\n",
    "            for ii,pid in enumerate(ids):\n",
    "                oo = ytrue.loc[pid]\n",
    "                onew = y0[ii][0]\n",
    "                original_decision = df.loc[pid,decision]\n",
    "                if original_decision > 0:\n",
    "                    onew = y0[ii][0]\n",
    "                oname = Const.name_dict.get(name)\n",
    "                if oname is not None:\n",
    "                    onew = oname[onew]\n",
    "                entry = {'id': pid, 'decision': decision,'outcome': outcome,'original_choice': original_decision, 'original_result': oo, 'alt_result': onew, 'change': change[ii][0], 'decision_change': decision_change[ii][0]}\n",
    "                results.append(entry)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "test = check_impact_of_decisions(all_models,dataset)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db23ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_data()['SD Primary 2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ce1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test[test.outcome == 'pd2'].original_result == 'SD Primary 2').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_impact_of_decisions(all_models,dataset).to_csv('../data/decision_impacts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321249c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
