{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050c878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c766fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Const.data_dir + '/models/'\n",
    "\n",
    "tuned_transition_models = [\n",
    "    'final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
    "    'final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
    "    'final_outcome_model_state1_input83_dims1000_dropout0,0.pt'\n",
    "]\n",
    "tuned_transition_models = [model_dir + f for f in tuned_transition_models]\n",
    "Const.tuned_transition_models = tuned_transition_models\n",
    "Const.tuned_decision_model = model_dir +  'final_decision_model_statedecisions_input132_dims100,100_dropout0.1,0.7.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c748333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "\n",
    "def get_tt_split(ids=None,use_default_split=True,use_bagging_split=False,resample_training=False):\n",
    "        if ids is None:\n",
    "            ids = get_dt_ids()\n",
    "        #pre-made, stratified by decision and outcome 72:28\n",
    "        if use_default_split:\n",
    "            train_ids = Const.stratified_train_ids[:]\n",
    "            test_ids = Const.stratified_test_ids[:]\n",
    "        elif use_bagging_split:\n",
    "            train_ids = np.random.choice(ids,len(ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        else:\n",
    "            test_ids = ids[0: int(len(ids)*(1-split))]\n",
    "            train_ids = [i for i in ids if i not in test_ids]\n",
    "\n",
    "        if resample_training:\n",
    "            train_ids = np.random.choice(train_ids,len(train_ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        return train_ids,test_ids\n",
    "    \n",
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "#     nloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = bce(dlt_pred[:,i].view(-1),dlt_true[:,i].view(-1))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "def outcome_loss(ytrue,ypred,weights=[1,1,1]):\n",
    "    loss = 0\n",
    "    nloss = torch.nn.BCELoss()\n",
    "    for i in range(len(weights)):\n",
    "        iloss = nloss(ypred[:,i],ytrue[i])*weights[i]\n",
    "        loss += iloss\n",
    "    return loss\n",
    "\n",
    "def mc_metrics(yt,yp,numpy=False,is_dlt=False):\n",
    "    if not numpy:\n",
    "        yt = yt .cpu().detach().numpy()\n",
    "        yp = yp.cpu().detach().numpy()\n",
    "    #dlt prediction (binary)\n",
    "    if is_dlt:\n",
    "        acc = accuracy_score(yt,yp>.5)\n",
    "        if yt.sum() > 1:\n",
    "            auc = roc_auc_score(yt,yp)\n",
    "        else:\n",
    "            auc=-1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': acc, 'mse': error, 'auc': auc}\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    elif yt.ndim > 1:\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        except:\n",
    "            roc_micro=-1\n",
    "        try:\n",
    "            roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        except:\n",
    "            roc_macro = -1\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    #outcomes (binary)\n",
    "    else:\n",
    "        if yp.ndim > 1:\n",
    "            yp = yp.argmax(axis=1)\n",
    "        try:\n",
    "            bacc = accuracy_score(yt,yp)\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc = roc_auc_score(yt,yp)\n",
    "        except:\n",
    "            roc = -1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred,numpy=False):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0],numpy=numpy)\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i].view(-1),is_dlt=True)\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'accuracy_mean': np.mean(dlt_acc),'auc': dlt_auc,'auc_mean': np.mean(dlt_auc)}}\n",
    "    \n",
    "def outcome_metrics(ytrue,ypred,numpy=False):\n",
    "    res = {}\n",
    "    for i, outcome in enumerate(Const.outcomes):\n",
    "        metrics = mc_metrics(ytrue[i],ypred[:,i])\n",
    "        res[outcome] = metrics\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95667ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd1': {'accuracy': 0.34712441314553993,\n",
       "  'roc_micro': 0.5057627557627558,\n",
       "  'roc_macro': 0.5069683908045977},\n",
       " 'nd1': {'accuracy': 0.38253241800152554,\n",
       "  'roc_micro': 0.5694120694120695,\n",
       "  'roc_macro': 0.5231884057971015},\n",
       " 'mod': {'accuracy': 0.16666666666666666,\n",
       "  'roc_micro': 0.5093167701863354,\n",
       "  'roc_macro': -1}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_state_rf(model_args={}):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "\n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    #most things are multiclass, dlts are several ordinal and outcomes are multiple binary\n",
    "    xtrain1 = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest1 = dataset.get_state('baseline',ids=test_ids)\n",
    "    \n",
    "    xtrain2 = dataset.get_input_state(step=2,ids=train_ids)\n",
    "    xtest2 = dataset.get_input_state(step=2,ids=test_ids)\n",
    "    \n",
    "    xtrain3 = dataset.get_input_state(step=3,ids=train_ids)\n",
    "    xtest3 = dataset.get_input_state(step=3,ids=test_ids)\n",
    "    \n",
    "    [pd1_train,nd1_train, mod_train,dlts1_train] = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    [pd2_train,nd2_train, cc_train,dlts2_train] = dataset.get_intermediate_outcomes(step=2,ids=train_ids)\n",
    "    [pd1_test,nd1_test, mod_test,dlts1_test] = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "    [pd2_test,nd2_test, cc_test,dlts2_test] = dataset.get_intermediate_outcomes(step=2,ids=test_ids)\n",
    "    outcomes_train = dataset.get_state('outcomes',ids=train_ids)\n",
    "    outcomes_test = dataset.get_state('outcomes',ids=test_ids)\n",
    "    \n",
    "\n",
    "    def train_multiclass_rf(xtrain,xtest,ytrain,ytest):\n",
    "        model = RandomForestClassifier(class_weight='balanced',**model_args).fit(xtrain,ytrain)\n",
    "        ypred = model.predict(xtest)\n",
    "        metrics = mc_metrics(ytest.values,ypred,numpy=True)\n",
    "        return model, metrics\n",
    "    \n",
    "    all_metrics = {}\n",
    "    pd1_model, all_metrics['pd1'] = train_multiclass_rf(xtrain1,xtest1,pd1_train,pd1_test)\n",
    "    nd1_model, all_metrics['nd1']  = train_multiclass_rf(xtrain1,xtest1,nd1_train,nd1_test)\n",
    "    mod_model, all_metrics['mod']  = train_multiclass_rf(xtrain1,xtest1,mod_train,mod_test)\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "train_state_rf({'max_depth': 5,'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a513da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B2A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A2B</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B5A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A5B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AJCC_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contra_spread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_fraction</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ips_spread</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ln_cluster_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dose</th>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                               3      5          6          7      \\\n",
       "1A                                 0.0    0.0        0.0        0.0   \n",
       "1A1B                               0.0    0.0        0.0        0.0   \n",
       "1A6                                0.0    0.0        0.0        0.0   \n",
       "1B                                 0.0    0.0        0.0        0.0   \n",
       "1B2A                               0.0    0.0        0.0        0.0   \n",
       "1B3                                0.0    0.0        0.0        0.0   \n",
       "2A                                 1.0    0.0        1.0        1.0   \n",
       "2A2B                               1.0    0.0        1.0        1.0   \n",
       "2A3                                1.0    0.0        1.0        1.0   \n",
       "2B                                 1.0    0.0        1.0        1.0   \n",
       "2B5A                               0.0    0.0        0.0        0.0   \n",
       "3                                  1.0    1.0        1.0        1.0   \n",
       "34                                 0.0    0.0        0.0        0.0   \n",
       "35A                                0.0    0.0        0.0        0.0   \n",
       "36                                 0.0    0.0        0.0        0.0   \n",
       "4                                  0.0    0.0        0.0        0.0   \n",
       "45B                                0.0    0.0        0.0        0.0   \n",
       "46                                 0.0    0.0        0.0        0.0   \n",
       "5A                                 0.0    0.0        0.0        0.0   \n",
       "5A5B                               0.0    0.0        0.0        0.0   \n",
       "5B                                 0.0    0.0        0.0        0.0   \n",
       "6                                  0.0    0.0        0.0        0.0   \n",
       "AJCC_1                               1      0          0          0   \n",
       "AJCC_2                               0      0          0          1   \n",
       "AJCC_3                               0      0          1          0   \n",
       "AJCC_4                               0      1          0          0   \n",
       "Aspiration rate Pre-therapy          0      0          1          0   \n",
       "DLT (Y/N)                            0      0          0          0   \n",
       "DLT_Grade                            0      0          0          0   \n",
       "N-category_0                         0      0          0          0   \n",
       "N-category_1                         1      0          0          0   \n",
       "N-category_2                         0      1          1          1   \n",
       "N-category_3                         0      0          0          0   \n",
       "Pathological Grade_0                 1      0          0          1   \n",
       "Pathological Grade_1                 0      0          0          0   \n",
       "Pathological Grade_2                 0      1          1          0   \n",
       "Pathological Grade_3                 0      0          0          0   \n",
       "Pathological Grade_4                 0      0          0          0   \n",
       "RPLN                               0.0    0.0        0.0        0.0   \n",
       "T-category_1                         0      0          0          1   \n",
       "T-category_2                         1      0          0          0   \n",
       "T-category_3                         0      0          0          0   \n",
       "T-category_4                         0      1          1          0   \n",
       "age                          55.969444  20.95  69.930556  72.319444   \n",
       "bilateral                        False  False       True      False   \n",
       "contra_spread                      0.0    0.0        0.0        0.0   \n",
       "dose_fraction                      2.2    1.8   2.121212   2.121212   \n",
       "gender                               1      1          0          1   \n",
       "hpv                                  1      0          1          1   \n",
       "ips_spread                         0.8    0.0        0.8        0.4   \n",
       "ln_cluster_1                         1      1          1          1   \n",
       "ln_cluster_2                         0      0          0          0   \n",
       "ln_cluster_3                         0      0          0          0   \n",
       "ln_cluster_4                         0      0          0          0   \n",
       "packs_per_year                     0.0   38.0       35.0        0.0   \n",
       "smoking_status                     0.0    1.0        1.0        1.0   \n",
       "subsite_BOT                          1      1          1          0   \n",
       "subsite_GPS                          0      0          0          0   \n",
       "subsite_NOS                          0      0          0          1   \n",
       "subsite_Soft palate                  0      0          0          0   \n",
       "subsite_Tonsil                       0      0          0          0   \n",
       "total_dose                        66.0   72.0       70.0       70.0   \n",
       "\n",
       "id                               8          9          10         11     \\\n",
       "1A                                 0.0        0.0        0.0        0.0   \n",
       "1A1B                               0.0        0.0        0.0        0.0   \n",
       "1A6                                0.0        0.0        0.0        0.0   \n",
       "1B                                 0.0        0.0        0.0        0.0   \n",
       "1B2A                               0.0        0.0        0.0        0.0   \n",
       "1B3                                0.0        0.0        0.0        0.0   \n",
       "2A                                 1.0        1.0        0.0        1.0   \n",
       "2A2B                               1.0        1.0        0.0        1.0   \n",
       "2A3                                0.0        0.0        0.0        0.0   \n",
       "2B                                 1.0        1.0        0.0        1.0   \n",
       "2B5A                               0.0        0.0        0.0        0.0   \n",
       "3                                  0.0        0.0        1.0        0.0   \n",
       "34                                 0.0        0.0        0.0        0.0   \n",
       "35A                                0.0        0.0        0.0        0.0   \n",
       "36                                 0.0        0.0        0.0        0.0   \n",
       "4                                  0.0        0.0        0.0        0.0   \n",
       "45B                                0.0        0.0        0.0        0.0   \n",
       "46                                 0.0        0.0        0.0        0.0   \n",
       "5A                                 0.0        0.0        0.0        0.0   \n",
       "5A5B                               0.0        0.0        0.0        0.0   \n",
       "5B                                 0.0        0.0        0.0        0.0   \n",
       "6                                  0.0        0.0        0.0        0.0   \n",
       "AJCC_1                               1          1          0          1   \n",
       "AJCC_2                               0          0          0          0   \n",
       "AJCC_3                               0          0          1          0   \n",
       "AJCC_4                               0          0          0          0   \n",
       "Aspiration rate Pre-therapy          0          0          0          0   \n",
       "DLT (Y/N)                            0          0          0          0   \n",
       "DLT_Grade                            0          0          0          0   \n",
       "N-category_0                         0          0          0          0   \n",
       "N-category_1                         1          1          1          1   \n",
       "N-category_2                         0          0          0          0   \n",
       "N-category_3                         0          0          0          0   \n",
       "Pathological Grade_0                 0          0          0          0   \n",
       "Pathological Grade_1                 0          0          0          0   \n",
       "Pathological Grade_2                 0          0          1          1   \n",
       "Pathological Grade_3                 1          1          0          0   \n",
       "Pathological Grade_4                 0          0          0          0   \n",
       "RPLN                               0.0        0.0        0.0        0.0   \n",
       "T-category_1                         1          1          0          0   \n",
       "T-category_2                         0          0          0          1   \n",
       "T-category_3                         0          0          1          0   \n",
       "T-category_4                         0          0          0          0   \n",
       "age                          59.730556  60.083333  67.708333  57.858333   \n",
       "bilateral                        False      False      False      False   \n",
       "contra_spread                      0.0        0.0        0.0        0.0   \n",
       "dose_fraction                      2.2        2.2       2.12   2.121212   \n",
       "gender                               1          1          1          1   \n",
       "hpv                                  1          1         -1          1   \n",
       "ips_spread                         0.4        0.4        0.0        0.4   \n",
       "ln_cluster_1                         1          1          1          1   \n",
       "ln_cluster_2                         0          0          0          0   \n",
       "ln_cluster_3                         0          0          0          0   \n",
       "ln_cluster_4                         0          0          0          0   \n",
       "packs_per_year                     0.0        0.0       40.0       44.0   \n",
       "smoking_status                     0.0        0.0        1.0        1.0   \n",
       "subsite_BOT                          0          1          1          0   \n",
       "subsite_GPS                          0          0          0          0   \n",
       "subsite_NOS                          0          0          0          1   \n",
       "subsite_Soft palate                  0          0          0          0   \n",
       "subsite_Tonsil                       1          0          0          0   \n",
       "total_dose                        66.0       66.0      69.96       70.0   \n",
       "\n",
       "id                               13        14     ...      10196      10197  \\\n",
       "1A                                 0.0       0.0  ...        0.0        0.0   \n",
       "1A1B                               0.0       0.0  ...        0.0        0.0   \n",
       "1A6                                0.0       0.0  ...        0.0        0.0   \n",
       "1B                                 0.0       0.0  ...        0.0        0.0   \n",
       "1B2A                               0.0       1.0  ...        0.0        0.0   \n",
       "1B3                                0.0       1.0  ...        0.0        0.0   \n",
       "2A                                 1.0       2.0  ...        0.0        1.0   \n",
       "2A2B                               1.0       2.0  ...        0.0        1.0   \n",
       "2A3                                1.0       2.0  ...        0.0        0.0   \n",
       "2B                                 1.0       2.0  ...        0.0        1.0   \n",
       "2B5A                               0.0       1.0  ...        0.0        0.0   \n",
       "3                                  1.0       2.0  ...        0.0        0.0   \n",
       "34                                 0.0       2.0  ...        0.0        0.0   \n",
       "35A                                0.0       1.0  ...        0.0        0.0   \n",
       "36                                 0.0       1.0  ...        0.0        0.0   \n",
       "4                                  0.0       2.0  ...        0.0        0.0   \n",
       "45B                                0.0       2.0  ...        0.0        0.0   \n",
       "46                                 0.0       1.0  ...        0.0        0.0   \n",
       "5A                                 0.0       0.0  ...        0.0        0.0   \n",
       "5A5B                               0.0       1.0  ...        0.0        0.0   \n",
       "5B                                 0.0       2.0  ...        0.0        0.0   \n",
       "6                                  0.0       0.0  ...        0.0        0.0   \n",
       "AJCC_1                               0         0  ...          0          0   \n",
       "AJCC_2                               0         1  ...          0          0   \n",
       "AJCC_3                               0         0  ...          0          1   \n",
       "AJCC_4                               1         0  ...          1          0   \n",
       "Aspiration rate Pre-therapy          0         0  ...          0          0   \n",
       "DLT (Y/N)                            0         0  ...          0          1   \n",
       "DLT_Grade                            0         0  ...          0          2   \n",
       "N-category_0                         0         0  ...          0          0   \n",
       "N-category_1                         0         0  ...          0          0   \n",
       "N-category_2                         1         1  ...          1          0   \n",
       "N-category_3                         0         0  ...          0          1   \n",
       "Pathological Grade_0                 0         0  ...          1          0   \n",
       "Pathological Grade_1                 0         0  ...          0          0   \n",
       "Pathological Grade_2                 1         0  ...          0          1   \n",
       "Pathological Grade_3                 0         1  ...          0          0   \n",
       "Pathological Grade_4                 0         0  ...          0          0   \n",
       "RPLN                               0.0       1.0  ...        0.0        0.0   \n",
       "T-category_1                         0         0  ...          0          0   \n",
       "T-category_2                         0         1  ...          1          0   \n",
       "T-category_3                         0         0  ...          0          1   \n",
       "T-category_4                         1         0  ...          0          0   \n",
       "age                          51.758333     56.25  ...  47.619444  50.163889   \n",
       "bilateral                         True     False  ...      False      False   \n",
       "contra_spread                      0.0       4.0  ...        0.0        0.0   \n",
       "dose_fraction                      2.0  2.121212  ...   2.121212        1.8   \n",
       "gender                               1         1  ...          0          1   \n",
       "hpv                                  0         1  ...          0          1   \n",
       "ips_spread                         0.8       1.6  ...        0.0        0.4   \n",
       "ln_cluster_1                         1         0  ...          1          1   \n",
       "ln_cluster_2                         0         0  ...          0          0   \n",
       "ln_cluster_3                         0         0  ...          0          0   \n",
       "ln_cluster_4                         0         1  ...          0          0   \n",
       "packs_per_year                     0.0      40.0  ...        5.0        0.0   \n",
       "smoking_status                     0.0       1.0  ...        0.5        0.0   \n",
       "subsite_BOT                          1         1  ...          0          1   \n",
       "subsite_GPS                          0         0  ...          0          0   \n",
       "subsite_NOS                          0         0  ...          0          0   \n",
       "subsite_Soft palate                  0         0  ...          0          0   \n",
       "subsite_Tonsil                       0         0  ...          1          0   \n",
       "total_dose                        70.0      70.0  ...       70.0       72.0   \n",
       "\n",
       "id                               10198     10199      10200      10201  \\\n",
       "1A                                 0.0       0.0        0.0        0.0   \n",
       "1A1B                               0.0       0.0        0.0        0.0   \n",
       "1A6                                0.0       0.0        0.0        0.0   \n",
       "1B                                 0.0       0.0        0.0        0.0   \n",
       "1B2A                               0.0       0.0        0.0        0.0   \n",
       "1B3                                0.0       0.0        0.0        0.0   \n",
       "2A                                 1.0       1.0        1.0        0.0   \n",
       "2A2B                               1.0       1.0        1.0        0.0   \n",
       "2A3                                0.0       0.0        0.0        0.0   \n",
       "2B                                 1.0       1.0        1.0        0.0   \n",
       "2B5A                               0.0       0.0        0.0        0.0   \n",
       "3                                  0.0       0.0        0.0        0.0   \n",
       "34                                 0.0       0.0        0.0        0.0   \n",
       "35A                                0.0       0.0        0.0        0.0   \n",
       "36                                 0.0       0.0        0.0        0.0   \n",
       "4                                  0.0       0.0        0.0        0.0   \n",
       "45B                                0.0       0.0        0.0        0.0   \n",
       "46                                 0.0       0.0        0.0        0.0   \n",
       "5A                                 0.0       0.0        0.0        0.0   \n",
       "5A5B                               0.0       0.0        0.0        0.0   \n",
       "5B                                 0.0       0.0        0.0        0.0   \n",
       "6                                  0.0       0.0        0.0        0.0   \n",
       "AJCC_1                               0         0          0          0   \n",
       "AJCC_2                               0         0          1          1   \n",
       "AJCC_3                               0         0          0          0   \n",
       "AJCC_4                               1         1          0          0   \n",
       "Aspiration rate Pre-therapy          0         0          0          0   \n",
       "DLT (Y/N)                            0         0          0          0   \n",
       "DLT_Grade                            0         0          0          0   \n",
       "N-category_0                         0         0          0          0   \n",
       "N-category_1                         0         0          1          1   \n",
       "N-category_2                         1         1          0          0   \n",
       "N-category_3                         0         0          0          0   \n",
       "Pathological Grade_0                 0         1          0          0   \n",
       "Pathological Grade_1                 1         0          0          0   \n",
       "Pathological Grade_2                 0         0          1          0   \n",
       "Pathological Grade_3                 0         0          0          1   \n",
       "Pathological Grade_4                 0         0          0          0   \n",
       "RPLN                               0.0       0.0        0.0        0.0   \n",
       "T-category_1                         1         0          0          0   \n",
       "T-category_2                         0         1          0          0   \n",
       "T-category_3                         0         0          1          1   \n",
       "T-category_4                         0         0          0          0   \n",
       "age                          70.888889    67.825  56.336111  49.566667   \n",
       "bilateral                        False     False      False      False   \n",
       "contra_spread                      0.0       0.0        0.0        0.0   \n",
       "dose_fraction                      2.2  2.121212       2.12   2.121212   \n",
       "gender                               0         1          1          1   \n",
       "hpv                                 -1         0          1          1   \n",
       "ips_spread                         0.4       0.4        0.4        0.0   \n",
       "ln_cluster_1                         1         1          1          1   \n",
       "ln_cluster_2                         0         0          0          0   \n",
       "ln_cluster_3                         0         0          0          0   \n",
       "ln_cluster_4                         0         0          0          0   \n",
       "packs_per_year                    50.0       0.0        0.0       30.0   \n",
       "smoking_status                     0.5       0.0        0.0        1.0   \n",
       "subsite_BOT                          0         1          0          1   \n",
       "subsite_GPS                          0         0          0          0   \n",
       "subsite_NOS                          0         0          1          0   \n",
       "subsite_Soft palate                  0         0          0          0   \n",
       "subsite_Tonsil                       1         0          0          0   \n",
       "total_dose                        66.0      70.0      69.96       70.0   \n",
       "\n",
       "id                               10202      10203  10204      10205  \n",
       "1A                                 0.0        0.0    0.0        0.0  \n",
       "1A1B                               0.0        0.0    0.0        0.0  \n",
       "1A6                                0.0        0.0    0.0        0.0  \n",
       "1B                                 0.0        0.0    0.0        0.0  \n",
       "1B2A                               0.0        0.0    0.0        0.0  \n",
       "1B3                                0.0        0.0    0.0        0.0  \n",
       "2A                                 1.0        1.0    1.0        1.0  \n",
       "2A2B                               1.0        1.0    1.0        1.0  \n",
       "2A3                                1.0        0.0    0.0        0.0  \n",
       "2B                                 1.0        1.0    1.0        1.0  \n",
       "2B5A                               0.0        0.0    0.0        0.0  \n",
       "3                                  1.0        0.0    0.0        0.0  \n",
       "34                                 0.0        0.0    0.0        0.0  \n",
       "35A                                0.0        0.0    0.0        0.0  \n",
       "36                                 0.0        0.0    0.0        0.0  \n",
       "4                                  0.0        0.0    0.0        0.0  \n",
       "45B                                0.0        0.0    0.0        0.0  \n",
       "46                                 0.0        0.0    0.0        0.0  \n",
       "5A                                 0.0        0.0    0.0        0.0  \n",
       "5A5B                               0.0        0.0    0.0        0.0  \n",
       "5B                                 0.0        0.0    0.0        0.0  \n",
       "6                                  0.0        0.0    0.0        0.0  \n",
       "AJCC_1                               0          1      0          0  \n",
       "AJCC_2                               0          0      0          0  \n",
       "AJCC_3                               0          0      0          1  \n",
       "AJCC_4                               1          0      1          0  \n",
       "Aspiration rate Pre-therapy          0          0      0          0  \n",
       "DLT (Y/N)                            0          0      0          0  \n",
       "DLT_Grade                            0          0      0          0  \n",
       "N-category_0                         0          0      0          0  \n",
       "N-category_1                         0          1      0          1  \n",
       "N-category_2                         1          0      0          0  \n",
       "N-category_3                         0          0      1          0  \n",
       "Pathological Grade_0                 0          1      0          0  \n",
       "Pathological Grade_1                 0          0      0          0  \n",
       "Pathological Grade_2                 0          0      0          1  \n",
       "Pathological Grade_3                 1          0      1          0  \n",
       "Pathological Grade_4                 0          0      0          0  \n",
       "RPLN                               0.0        0.0    0.0        0.0  \n",
       "T-category_1                         0          1      0          0  \n",
       "T-category_2                         0          0      0          0  \n",
       "T-category_3                         0          0      1          0  \n",
       "T-category_4                         1          0      0          1  \n",
       "age                          48.705556  77.116667  45.95  49.733333  \n",
       "bilateral                        False      False   True      False  \n",
       "contra_spread                      0.0   1.333333    0.0        0.0  \n",
       "dose_fraction                 1.714286   2.333333   2.12       2.12  \n",
       "gender                               1          1      1          1  \n",
       "hpv                                  0          1      0          1  \n",
       "ips_spread                         0.8        0.0    0.4        0.4  \n",
       "ln_cluster_1                         1          1      1          1  \n",
       "ln_cluster_2                         0          0      0          0  \n",
       "ln_cluster_3                         0          0      0          0  \n",
       "ln_cluster_4                         0          0      0          0  \n",
       "packs_per_year                    30.0        0.0    5.0        0.0  \n",
       "smoking_status                     1.0        0.0    0.5        0.0  \n",
       "subsite_BOT                          0          0      0          1  \n",
       "subsite_GPS                          0          0      0          0  \n",
       "subsite_NOS                          1          0      0          0  \n",
       "subsite_Soft palate                  0          0      0          0  \n",
       "subsite_Tonsil                       0          1      1          0  \n",
       "total_dose                        72.0       70.0  69.96      69.96  \n",
       "\n",
       "[62 rows x 536 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DTDataset().get_state('baseline').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c4445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_state(model=None,\n",
    "                model_args={},\n",
    "                state=1,\n",
    "                split=.7,\n",
    "                lr=.0001,\n",
    "                epochs=1000,\n",
    "                patience=10,\n",
    "                use_attention=True,\n",
    "                weights=[1,1,1,10],\n",
    "                save_path='../data/models/',\n",
    "                use_default_split=True,\n",
    "                use_bagging_split=False,\n",
    "                resample_training=False,#use bootstraping on training data after splitting\n",
    "                n_validation_trainsteps=2,\n",
    "                verbose=True,\n",
    "                file_suffix=''):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids)\n",
    "    \n",
    "\n",
    "    if state < 3:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = OutcomeAttentionSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "            else:\n",
    "                model = OutcomeSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "        lfunc = state_loss\n",
    "    else:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = EndpointAttentionSimulator(xtrain.shape[1],**model_args)\n",
    "            else:\n",
    "                model = EndpointSimulator(xtrain.shape[1],**model_args)\n",
    "        weights = weights[:3]\n",
    "        lfunc = outcome_loss\n",
    "        \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    save_file = save_path + 'model_' + model.identifier + '_split' + str(split) + '_resample' + str(resample_training) +  '_hash' + hashcode + file_suffix + '.tar'\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    model.fit_normalizer(xtrain)\n",
    "#     normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "#     unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    last_epoch = False\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(xtrain_sample)\n",
    "        loss = lfunc(ytrain,ypred,weights=weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        if state < 3:\n",
    "            val_metrics = state_metrics(ytest,yval)\n",
    "        else:\n",
    "            val_metrics = outcome_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if verbose:\n",
    "            print('val loss',val_loss.item())\n",
    "            print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    #train one step on validation data\n",
    "    for i in range(n_validation_trainsteps):\n",
    "        model.train()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        val_loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model.state_dict(),save_file)\n",
    "    \n",
    "    model.eval()\n",
    "    return model,  best_val_loss, best_loss_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9536fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def gridsearch_transition_models(state=1):\n",
    "#     model_arglist = [\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500,500],\n",
    "#             'attention_heads': [5,5,5]\n",
    "#         }\n",
    "#     ]\n",
    "    model_arglist = [\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [200,400,800]:\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.9,.95]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.25,.35,.5]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    model,m_loss,m_metrics = train_state(model_args=args,state=state,verbose=False)\n",
    "                    print('done',k,m_loss)\n",
    "                    k+=1\n",
    "                    if m_loss < best_loss:\n",
    "                        best_loss = m_loss\n",
    "                        best_metrics  = m_metrics\n",
    "                        best_model = model\n",
    "                        best_args = args\n",
    "                        print('_++++++++++New Best++++____')\n",
    "                        print(best_loss)\n",
    "                        print(best_metrics)\n",
    "                        print(best_args)\n",
    "                        print('___________')\n",
    "                        print('++++++++')\n",
    "                        print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "# model = gridsearch_transition_models(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cdf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = gridsearch_transition_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c33d908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = gridsearch_transition_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75b44897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
       " '../data/models/final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
       " '../data/models/final_outcome_model_state1_input83_dims1000_dropout0,0.pt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Const.tuned_transition_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models():\n",
    "    files = Const.tuned_transition_models\n",
    "    decision_file = Const.tuned_decision_model\n",
    "    [model1,model2,model3] = [torch.load(file) for file in files]\n",
    "    decision_model = torch.load(decision_file)\n",
    "    return decision_model, model1,model2,model3\n",
    "_, model1, model2, model3 =load_trained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8af5c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 0 _____\n",
      "train imitation 2.213536262512207 reward 1.535596489906311\n",
      "val imitation 2.0247085094451904 reward 1.5417895317077637\n",
      "val loss 3.566498041152954 1000000000.0\n",
      "[{'decision': 0, 'accuracy': 0.3835616438356164, 'auc': 0.3802884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.5778508771929824}, {'decision': 2, 'accuracy': 0.6301369863013698, 'auc': 0.36250000000000004}]\n",
      "______epoch 1 _____\n",
      "train imitation 2.175110101699829 reward 1.5305566787719727\n",
      "val imitation 1.9839191436767578 reward 1.5427231788635254\n",
      "val loss 3.526642322540283 3.566498041152954\n",
      "[{'decision': 0, 'accuracy': 0.5205479452054794, 'auc': 0.3889423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.5797697368421053}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.3698717948717949}]\n",
      "______epoch 2 _____\n",
      "train imitation 2.055936574935913 reward 1.5291204452514648\n",
      "val imitation 1.9450087547302246 reward 1.5427231788635254\n",
      "val loss 3.48773193359375 3.526642322540283\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.39134615384615384}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.5825109649122806}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.3753205128205128}]\n",
      "______epoch 3 _____\n",
      "train imitation 2.053478240966797 reward 1.5241466760635376\n",
      "val imitation 1.9078333377838135 reward 1.541996955871582\n",
      "val loss 3.4498302936553955 3.48773193359375\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.39519230769230773}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.5874451754385965}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.37852564102564107}]\n",
      "______epoch 4 _____\n",
      "train imitation 2.057065010070801 reward 1.5337660312652588\n",
      "val imitation 1.8723580837249756 reward 1.5417022705078125\n",
      "val loss 3.414060354232788 3.4498302936553955\n",
      "[{'decision': 0, 'accuracy': 0.8287671232876712, 'auc': 0.4}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.591282894736842}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.3871794871794872}]\n",
      "______epoch 5 _____\n",
      "train imitation 2.0577268600463867 reward 1.5357152223587036\n",
      "val imitation 1.838396430015564 reward 1.5407249927520752\n",
      "val loss 3.3791213035583496 3.414060354232788\n",
      "[{'decision': 0, 'accuracy': 0.8698630136986302, 'auc': 0.4033653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5929276315789473}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.392948717948718}]\n",
      "______epoch 6 _____\n",
      "train imitation 1.9609978199005127 reward 1.5320842266082764\n",
      "val imitation 1.8059831857681274 reward 1.5384492874145508\n",
      "val loss 3.3444323539733887 3.3791213035583496\n",
      "[{'decision': 0, 'accuracy': 0.8767123287671232, 'auc': 0.4057692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5932017543859649}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.39999999999999997}]\n",
      "______epoch 7 _____\n",
      "train imitation 1.91973876953125 reward 1.5285600423812866\n",
      "val imitation 1.7750163078308105 reward 1.5394909381866455\n",
      "val loss 3.314507246017456 3.3444323539733887\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.4105769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5942982456140351}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.40384615384615385}]\n",
      "______epoch 8 _____\n",
      "train imitation 1.8868186473846436 reward 1.5311472415924072\n",
      "val imitation 1.7453088760375977 reward 1.5394909381866455\n",
      "val loss 3.284799814224243 3.314507246017456\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4134615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5959429824561403}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.4096153846153846}]\n",
      "______epoch 9 _____\n",
      "train imitation 1.8474946022033691 reward 1.5281447172164917\n",
      "val imitation 1.717057228088379 reward 1.5402333736419678\n",
      "val loss 3.2572906017303467 3.284799814224243\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4206730769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5956688596491228}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.4147435897435897}]\n",
      "______epoch 10 _____\n",
      "train imitation 1.809446930885315 reward 1.538588523864746\n",
      "val imitation 1.690132975578308 reward 1.5406287908554077\n",
      "val loss 3.230761766433716 3.2572906017303467\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4245192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.597313596491228}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.42051282051282046}]\n",
      "______epoch 11 _____\n",
      "train imitation 1.857607126235962 reward 1.530673623085022\n",
      "val imitation 1.664489984512329 reward 1.5408709049224854\n",
      "val loss 3.2053608894348145 3.230761766433716\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4288461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6000548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.43012820512820515}]\n",
      "______epoch 12 _____\n",
      "train imitation 1.78031325340271 reward 1.533006191253662\n",
      "val imitation 1.6400631666183472 reward 1.5413035154342651\n",
      "val loss 3.1813666820526123 3.2053608894348145\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.43365384615384617}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6016995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.4375}]\n",
      "______epoch 13 _____\n",
      "train imitation 1.7955224514007568 reward 1.5227221250534058\n",
      "val imitation 1.6169646978378296 reward 1.5413035154342651\n",
      "val loss 3.1582682132720947 3.1813666820526123\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.43990384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.5997807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.44519230769230766}]\n",
      "______epoch 14 _____\n",
      "train imitation 1.7160199880599976 reward 1.5334259271621704\n",
      "val imitation 1.5948973894119263 reward 1.5412993431091309\n",
      "val loss 3.1361966133117676 3.1582682132720947\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.44423076923076926}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6025219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.45432692307692313}]\n",
      "______epoch 15 _____\n",
      "train imitation 1.706390619277954 reward 1.527278184890747\n",
      "val imitation 1.5740265846252441 reward 1.5412416458129883\n",
      "val loss 3.1152682304382324 3.1361966133117676\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4466346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6041666666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.4663461538461538}]\n",
      "______epoch 16 _____\n",
      "train imitation 1.680168628692627 reward 1.5260697603225708\n",
      "val imitation 1.5543503761291504 reward 1.5411546230316162\n",
      "val loss 3.0955049991607666 3.1152682304382324\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.45240384615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.606359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.475}]\n",
      "______epoch 17 _____\n",
      "train imitation 1.7272855043411255 reward 1.5284109115600586\n",
      "val imitation 1.5357670783996582 reward 1.542223572731018\n",
      "val loss 3.0779905319213867 3.0955049991607666\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.45769230769230773}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6104714912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.48365384615384616}]\n",
      "______epoch 18 _____\n",
      "train imitation 1.6659090518951416 reward 1.5322359800338745\n",
      "val imitation 1.5183427333831787 reward 1.5422849655151367\n",
      "val loss 3.0606276988983154 3.0779905319213867\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.46490384615384617}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6107456140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.4942307692307692}]\n",
      "______epoch 19 _____\n",
      "train imitation 1.648864507675171 reward 1.5347827672958374\n",
      "val imitation 1.5020318031311035 reward 1.5415393114089966\n",
      "val loss 3.0435709953308105 3.0606276988983154\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.46875}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6140350877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5067307692307692}]\n",
      "______epoch 20 _____\n",
      "train imitation 1.6242529153823853 reward 1.5225770473480225\n",
      "val imitation 1.4866983890533447 reward 1.5411807298660278\n",
      "val loss 3.027879238128662 3.0435709953308105\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.47019230769230774}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.615953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5137820512820512}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 21 _____\n",
      "train imitation 1.6462006568908691 reward 1.5312477350234985\n",
      "val imitation 1.472330927848816 reward 1.5400276184082031\n",
      "val loss 3.0123586654663086 3.027879238128662\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4745192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6178728070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5195512820512821}]\n",
      "______epoch 22 _____\n",
      "train imitation 1.5814028978347778 reward 1.5333291292190552\n",
      "val imitation 1.4588595628738403 reward 1.5400276184082031\n",
      "val loss 2.998887062072754 3.0123586654663086\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4798076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6165021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5256410256410257}]\n",
      "______epoch 23 _____\n",
      "train imitation 1.5970546007156372 reward 1.5326300859451294\n",
      "val imitation 1.4463844299316406 reward 1.5400745868682861\n",
      "val loss 2.9864590167999268 2.998887062072754\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.48894230769230773}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6175986842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5368589743589743}]\n",
      "______epoch 24 _____\n",
      "train imitation 1.569151759147644 reward 1.5336015224456787\n",
      "val imitation 1.4347697496414185 reward 1.5400745868682861\n",
      "val loss 2.974844455718994 2.9864590167999268\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.4947115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6181469298245613}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5455128205128206}]\n",
      "______epoch 25 _____\n",
      "train imitation 1.55001699924469 reward 1.5255934000015259\n",
      "val imitation 1.4240202903747559 reward 1.5400745868682861\n",
      "val loss 2.964094877243042 2.974844455718994\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6211622807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5541666666666667}]\n",
      "______epoch 26 _____\n",
      "train imitation 1.5797899961471558 reward 1.5311989784240723\n",
      "val imitation 1.4140597581863403 reward 1.5401815176010132\n",
      "val loss 2.9542412757873535 2.964094877243042\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6247258771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.567948717948718}]\n",
      "______epoch 27 _____\n",
      "train imitation 1.55037260055542 reward 1.5347304344177246\n",
      "val imitation 1.4048378467559814 reward 1.5405250787734985\n",
      "val loss 2.9453630447387695 2.9542412757873535\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5100961538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6307565789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5794871794871795}]\n",
      "______epoch 28 _____\n",
      "train imitation 1.545640230178833 reward 1.534906029701233\n",
      "val imitation 1.3963751792907715 reward 1.5397485494613647\n",
      "val loss 2.936123847961426 2.9453630447387695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5149038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6324013157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5868589743589743}]\n",
      "______epoch 29 _____\n",
      "train imitation 1.5588830709457397 reward 1.5292454957962036\n",
      "val imitation 1.3886308670043945 reward 1.5446490049362183\n",
      "val loss 2.9332799911499023 2.936123847961426\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5173076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6343201754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.5939102564102565}]\n",
      "______epoch 30 _____\n",
      "train imitation 1.4749021530151367 reward 1.533026933670044\n",
      "val imitation 1.381474256515503 reward 1.5440794229507446\n",
      "val loss 2.925553798675537 2.9332799911499023\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5173076923076922}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6381578947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6032051282051282}]\n",
      "______epoch 31 _____\n",
      "train imitation 1.4932677745819092 reward 1.529799461364746\n",
      "val imitation 1.3748302459716797 reward 1.5446102619171143\n",
      "val loss 2.919440507888794 2.925553798675537\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5163461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6428179824561403}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6112179487179488}]\n",
      "______epoch 32 _____\n",
      "train imitation 1.4830079078674316 reward 1.5293437242507935\n",
      "val imitation 1.368861436843872 reward 1.544430136680603\n",
      "val loss 2.9132914543151855 2.919440507888794\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5221153846153845}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6441885964912281}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6195512820512821}]\n",
      "______epoch 33 _____\n",
      "train imitation 1.4977788925170898 reward 1.5207639932632446\n",
      "val imitation 1.363511085510254 reward 1.5449508428573608\n",
      "val loss 2.9084620475769043 2.9132914543151855\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5235576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6472039473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6259615384615385}]\n",
      "______epoch 34 _____\n",
      "train imitation 1.4420812129974365 reward 1.5334185361862183\n",
      "val imitation 1.3585731983184814 reward 1.5449508428573608\n",
      "val loss 2.9035239219665527 2.9084620475769043\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5249999999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6499451754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6375000000000001}]\n",
      "______epoch 35 _____\n",
      "train imitation 1.4936225414276123 reward 1.533854603767395\n",
      "val imitation 1.354099988937378 reward 1.544962763786316\n",
      "val loss 2.8990626335144043 2.9035239219665527\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5254807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6526864035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6419871794871794}]\n",
      "______epoch 36 _____\n",
      "train imitation 1.4592621326446533 reward 1.5434650182724\n",
      "val imitation 1.349974513053894 reward 1.5475592613220215\n",
      "val loss 2.897533893585205 2.8990626335144043\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5274038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6565241228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6487179487179487}]\n",
      "______epoch 37 _____\n",
      "train imitation 1.4678254127502441 reward 1.5349225997924805\n",
      "val imitation 1.3463199138641357 reward 1.5477879047393799\n",
      "val loss 2.8941078186035156 2.897533893585205\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5278846153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6603618421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6532051282051282}]\n",
      "______epoch 38 _____\n",
      "train imitation 1.4606398344039917 reward 1.5359158515930176\n",
      "val imitation 1.342978596687317 reward 1.5483957529067993\n",
      "val loss 2.891374349594116 2.8941078186035156\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6633771929824562}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.658974358974359}]\n",
      "______epoch 39 _____\n",
      "train imitation 1.47395920753479 reward 1.5343613624572754\n",
      "val imitation 1.340010166168213 reward 1.5483957529067993\n",
      "val loss 2.8884057998657227 2.891374349594116\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6680372807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.666025641025641}]\n",
      "______epoch 40 _____\n",
      "train imitation 1.4275723695755005 reward 1.52737295627594\n",
      "val imitation 1.337362289428711 reward 1.5483957529067993\n",
      "val loss 2.8857579231262207 2.8884057998657227\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5403846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6688596491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6708333333333334}]\n",
      "______epoch 41 _____\n",
      "train imitation 1.4737277030944824 reward 1.5337992906570435\n",
      "val imitation 1.3350086212158203 reward 1.5484507083892822\n",
      "val loss 2.8834593296051025 2.8857579231262207\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.541826923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6705043859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6746794871794871}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 42 _____\n",
      "train imitation 1.477730631828308 reward 1.5387372970581055\n",
      "val imitation 1.3328640460968018 reward 1.5484507083892822\n",
      "val loss 2.881314754486084 2.8834593296051025\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6737938596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6823717948717949}]\n",
      "______epoch 43 _____\n",
      "train imitation 1.4722785949707031 reward 1.536476969718933\n",
      "val imitation 1.330936312675476 reward 1.5487303733825684\n",
      "val loss 2.879666805267334 2.881314754486084\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6751644736842106}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6865384615384615}]\n",
      "______epoch 44 _____\n",
      "train imitation 1.494117259979248 reward 1.536814570426941\n",
      "val imitation 1.3291969299316406 reward 1.5487303733825684\n",
      "val loss 2.877927303314209 2.879666805267334\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5442307692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6935897435897436}]\n",
      "______epoch 45 _____\n",
      "train imitation 1.4691883325576782 reward 1.53226900100708\n",
      "val imitation 1.3275806903839111 reward 1.5506136417388916\n",
      "val loss 2.8781943321228027 2.877927303314209\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.548076923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.680921052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6974358974358974}]\n",
      "______epoch 46 _____\n",
      "train imitation 1.4326059818267822 reward 1.5351938009262085\n",
      "val imitation 1.3261311054229736 reward 1.5506136417388916\n",
      "val loss 2.8767447471618652 2.877927303314209\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5495192307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6828399122807016}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7022435897435897}]\n",
      "______epoch 47 _____\n",
      "train imitation 1.4415113925933838 reward 1.536448359489441\n",
      "val imitation 1.324721097946167 reward 1.5510839223861694\n",
      "val loss 2.875804901123047 2.8767447471618652\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5495192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6858552631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.705448717948718}]\n",
      "______epoch 48 _____\n",
      "train imitation 1.4971351623535156 reward 1.5377306938171387\n",
      "val imitation 1.323373794555664 reward 1.5541210174560547\n",
      "val loss 2.8774948120117188 2.875804901123047\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5504807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6891447368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7080128205128204}]\n",
      "______epoch 49 _____\n",
      "train imitation 1.4820568561553955 reward 1.5342422723770142\n",
      "val imitation 1.322081208229065 reward 1.554070234298706\n",
      "val loss 2.8761515617370605 2.875804901123047\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5524038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6921600877192982}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7124999999999999}]\n",
      "______epoch 50 _____\n",
      "train imitation 1.4072999954223633 reward 1.5324327945709229\n",
      "val imitation 1.3208584785461426 reward 1.5548402070999146\n",
      "val loss 2.8756985664367676 2.875804901123047\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.554326923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6924342105263159}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.714102564102564}]\n",
      "______epoch 51 _____\n",
      "train imitation 1.4261986017227173 reward 1.525892734527588\n",
      "val imitation 1.319716215133667 reward 1.5548402070999146\n",
      "val loss 2.874556541442871 2.8756985664367676\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5557692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6940789473684212}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7173076923076923}]\n",
      "______epoch 52 _____\n",
      "train imitation 1.4236416816711426 reward 1.5305800437927246\n",
      "val imitation 1.3185975551605225 reward 1.5559018850326538\n",
      "val loss 2.8744993209838867 2.874556541442871\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5557692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.696546052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7173076923076922}]\n",
      "______epoch 53 _____\n",
      "train imitation 1.445530891418457 reward 1.5367445945739746\n",
      "val imitation 1.3175137042999268 reward 1.5562098026275635\n",
      "val loss 2.8737235069274902 2.8744993209838867\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5572115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6992872807017543}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7176282051282051}]\n",
      "______epoch 54 _____\n",
      "train imitation 1.4268858432769775 reward 1.5351957082748413\n",
      "val imitation 1.3164535760879517 reward 1.5582789182662964\n",
      "val loss 2.874732494354248 2.8737235069274902\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5591346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.700657894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7205128205128205}]\n",
      "______epoch 55 _____\n",
      "train imitation 1.4198710918426514 reward 1.5400134325027466\n",
      "val imitation 1.3153873682022095 reward 1.5588574409484863\n",
      "val loss 2.8742446899414062 2.8737235069274902\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5600961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7020285087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7211538461538461}]\n",
      "______epoch 56 _____\n",
      "train imitation 1.4467095136642456 reward 1.5357234477996826\n",
      "val imitation 1.3143240213394165 reward 1.5589606761932373\n",
      "val loss 2.8732848167419434 2.8737235069274902\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5591346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7023026315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7217948717948718}]\n",
      "______epoch 57 _____\n",
      "train imitation 1.4318581819534302 reward 1.5353610515594482\n",
      "val imitation 1.3132280111312866 reward 1.5591998100280762\n",
      "val loss 2.8724279403686523 2.8732848167419434\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5605769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7050438596491226}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7217948717948719}]\n",
      "______epoch 58 _____\n",
      "train imitation 1.391582727432251 reward 1.5422194004058838\n",
      "val imitation 1.31210196018219 reward 1.5591998100280762\n",
      "val loss 2.8713016510009766 2.8724279403686523\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5615384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7237179487179488}]\n",
      "______epoch 59 _____\n",
      "train imitation 1.445958137512207 reward 1.5418330430984497\n",
      "val imitation 1.3110042810440063 reward 1.559348702430725\n",
      "val loss 2.8703529834747314 2.8713016510009766\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7086074561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7243589743589745}]\n",
      "______epoch 60 _____\n",
      "train imitation 1.3952265977859497 reward 1.5363948345184326\n",
      "val imitation 1.309878945350647 reward 1.559348702430725\n",
      "val loss 2.869227647781372 2.8703529834747314\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5663461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7108004385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7259615384615385}]\n",
      "______epoch 61 _____\n",
      "train imitation 1.4373738765716553 reward 1.5323907136917114\n",
      "val imitation 1.3088098764419556 reward 1.559348702430725\n",
      "val loss 2.8681585788726807 2.869227647781372\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5692307692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7121710526315789}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7259615384615384}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 62 _____\n",
      "train imitation 1.4177806377410889 reward 1.5383515357971191\n",
      "val imitation 1.3077411651611328 reward 1.559348702430725\n",
      "val loss 2.8670897483825684 2.8681585788726807\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5701923076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7132675438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7282051282051283}]\n",
      "______epoch 63 _____\n",
      "train imitation 1.4150912761688232 reward 1.533603549003601\n",
      "val imitation 1.3066819906234741 reward 1.559348702430725\n",
      "val loss 2.866030693054199 2.8670897483825684\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5725961538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7288461538461539}]\n",
      "______epoch 64 _____\n",
      "train imitation 1.436271071434021 reward 1.5239148139953613\n",
      "val imitation 1.3056297302246094 reward 1.5598499774932861\n",
      "val loss 2.8654797077178955 2.866030693054199\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5735576923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7162828947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7282051282051282}]\n",
      "______epoch 65 _____\n",
      "train imitation 1.4584192037582397 reward 1.5319045782089233\n",
      "val imitation 1.3046045303344727 reward 1.5591437816619873\n",
      "val loss 2.86374831199646 2.8654797077178955\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5740384615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7165570175438597}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7288461538461538}]\n",
      "______epoch 66 _____\n",
      "train imitation 1.4343641996383667 reward 1.5338305234909058\n",
      "val imitation 1.3035861253738403 reward 1.5579475164413452\n",
      "val loss 2.8615336418151855 2.86374831199646\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5759615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7176535087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7298076923076924}]\n",
      "______epoch 67 _____\n",
      "train imitation 1.3878064155578613 reward 1.5402499437332153\n",
      "val imitation 1.30256986618042 reward 1.5579475164413452\n",
      "val loss 2.8605175018310547 2.8615336418151855\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5764423076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7190241228070177}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7307692307692307}]\n",
      "______epoch 68 _____\n",
      "train imitation 1.4156478643417358 reward 1.5344133377075195\n",
      "val imitation 1.3016014099121094 reward 1.5579475164413452\n",
      "val loss 2.859549045562744 2.8605175018310547\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5793269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.71875}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7320512820512821}]\n",
      "______epoch 69 _____\n",
      "train imitation 1.4075875282287598 reward 1.5273184776306152\n",
      "val imitation 1.3006268739700317 reward 1.5579475164413452\n",
      "val loss 2.858574390411377 2.859549045562744\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7326923076923076}]\n",
      "______epoch 70 _____\n",
      "train imitation 1.4439586400985718 reward 1.5412118434906006\n",
      "val imitation 1.299720048904419 reward 1.5579475164413452\n",
      "val loss 2.8576674461364746 2.858574390411377\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7217653508771931}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7320512820512821}]\n",
      "______epoch 71 _____\n",
      "train imitation 1.39541757106781 reward 1.5371451377868652\n",
      "val imitation 1.298820972442627 reward 1.5577077865600586\n",
      "val loss 2.8565287590026855 2.8576674461364746\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5841346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7225877192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7326923076923078}]\n",
      "______epoch 72 _____\n",
      "train imitation 1.3662291765213013 reward 1.5339999198913574\n",
      "val imitation 1.2979047298431396 reward 1.5587610006332397\n",
      "val loss 2.85666561126709 2.8565287590026855\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5860576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7336538461538461}]\n",
      "______epoch 73 _____\n",
      "train imitation 1.4031139612197876 reward 1.5321022272109985\n",
      "val imitation 1.2969744205474854 reward 1.5587610006332397\n",
      "val loss 2.8557353019714355 2.8565287590026855\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5874999999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7342948717948717}]\n",
      "______epoch 74 _____\n",
      "train imitation 1.3968013525009155 reward 1.5375127792358398\n",
      "val imitation 1.2960832118988037 reward 1.5587610006332397\n",
      "val loss 2.854844093322754 2.8557353019714355\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5855769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7272478070175438}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7355769230769231}]\n",
      "______epoch 75 _____\n",
      "train imitation 1.4159011840820312 reward 1.5323729515075684\n",
      "val imitation 1.2951900959014893 reward 1.5587610006332397\n",
      "val loss 2.8539509773254395 2.854844093322754\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5855769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035087}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7368589743589744}]\n",
      "______epoch 76 _____\n",
      "train imitation 1.4171504974365234 reward 1.5339298248291016\n",
      "val imitation 1.2942839860916138 reward 1.5587610006332397\n",
      "val loss 2.8530449867248535 2.8539509773254395\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5875}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725877192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7368589743589744}]\n",
      "______epoch 77 _____\n",
      "train imitation 1.3616652488708496 reward 1.5278041362762451\n",
      "val imitation 1.2933810949325562 reward 1.5587610006332397\n",
      "val loss 2.852142095565796 2.8530449867248535\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5879807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7272478070175438}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7375}]\n",
      "______epoch 78 _____\n",
      "train imitation 1.4245535135269165 reward 1.5343323945999146\n",
      "val imitation 1.2925145626068115 reward 1.5587610006332397\n",
      "val loss 2.8512754440307617 2.852142095565796\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5875}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7391025641025641}]\n",
      "______epoch 79 _____\n",
      "train imitation 1.38053297996521 reward 1.535082221031189\n",
      "val imitation 1.29167640209198 reward 1.5585359334945679\n",
      "val loss 2.850212335586548 2.8512754440307617\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5875}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7400641025641026}]\n",
      "______epoch 80 _____\n",
      "train imitation 1.4308562278747559 reward 1.5385658740997314\n",
      "val imitation 1.290894865989685 reward 1.5603561401367188\n",
      "val loss 2.8512511253356934 2.850212335586548\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5889423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7407051282051282}]\n",
      "______epoch 81 _____\n",
      "train imitation 1.3779937028884888 reward 1.5381667613983154\n",
      "val imitation 1.2901455163955688 reward 1.5603561401367188\n",
      "val loss 2.850501537322998 2.850212335586548\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5903846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7432692307692308}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 82 _____\n",
      "train imitation 1.3664249181747437 reward 1.5423691272735596\n",
      "val imitation 1.2894186973571777 reward 1.5603561401367188\n",
      "val loss 2.8497748374938965 2.850212335586548\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5903846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7442307692307693}]\n",
      "______epoch 83 _____\n",
      "train imitation 1.3608098030090332 reward 1.5380144119262695\n",
      "val imitation 1.2886989116668701 reward 1.5603406429290771\n",
      "val loss 2.8490395545959473 2.8497748374938965\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5908653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7439102564102564}]\n",
      "______epoch 84 _____\n",
      "train imitation 1.370718240737915 reward 1.5307117700576782\n",
      "val imitation 1.287951946258545 reward 1.5606660842895508\n",
      "val loss 2.8486180305480957 2.8490395545959473\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5913461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7448717948717949}]\n",
      "______epoch 85 _____\n",
      "train imitation 1.3624221086502075 reward 1.5402076244354248\n",
      "val imitation 1.2872025966644287 reward 1.5612890720367432\n",
      "val loss 2.848491668701172 2.8486180305480957\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5927884615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7455128205128205}]\n",
      "______epoch 86 _____\n",
      "train imitation 1.344295620918274 reward 1.5339744091033936\n",
      "val imitation 1.2864521741867065 reward 1.5612890720367432\n",
      "val loss 2.84774112701416 2.848491668701172\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5932692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7461538461538462}]\n",
      "______epoch 87 _____\n",
      "train imitation 1.4085502624511719 reward 1.5353469848632812\n",
      "val imitation 1.2857489585876465 reward 1.5613365173339844\n",
      "val loss 2.847085475921631 2.84774112701416\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5947115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7461538461538462}]\n",
      "______epoch 88 _____\n",
      "train imitation 1.3890831470489502 reward 1.5377637147903442\n",
      "val imitation 1.2850682735443115 reward 1.5613365173339844\n",
      "val loss 2.846404790878296 2.847085475921631\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5961538461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7467948717948718}]\n",
      "______epoch 89 _____\n",
      "train imitation 1.3515594005584717 reward 1.538399577140808\n",
      "val imitation 1.284394383430481 reward 1.5612142086029053\n",
      "val loss 2.845608711242676 2.846404790878296\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5971153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7483974358974359}]\n",
      "______epoch 90 _____\n",
      "train imitation 1.390376329421997 reward 1.5427095890045166\n",
      "val imitation 1.283665418624878 reward 1.561841607093811\n",
      "val loss 2.8455071449279785 2.845608711242676\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5971153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "______epoch 91 _____\n",
      "train imitation 1.3725183010101318 reward 1.5385291576385498\n",
      "val imitation 1.282938838005066 reward 1.5618865489959717\n",
      "val loss 2.844825267791748 2.8455071449279785\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5980769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "______epoch 92 _____\n",
      "train imitation 1.3720769882202148 reward 1.5397990942001343\n",
      "val imitation 1.2822129726409912 reward 1.5630791187286377\n",
      "val loss 2.845292091369629 2.844825267791748\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5995192307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7477564102564103}]\n",
      "______epoch 93 _____\n",
      "train imitation 1.3424253463745117 reward 1.5351794958114624\n",
      "val imitation 1.2814980745315552 reward 1.5630791187286377\n",
      "val loss 2.8445773124694824 2.844825267791748\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6009615384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7477564102564103}]\n",
      "______epoch 94 _____\n",
      "train imitation 1.340985894203186 reward 1.536350965499878\n",
      "val imitation 1.2807492017745972 reward 1.562637209892273\n",
      "val loss 2.84338641166687 2.8445773124694824\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6014423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7493589743589744}]\n",
      "______epoch 95 _____\n",
      "train imitation 1.3697222471237183 reward 1.5456377267837524\n",
      "val imitation 1.280006766319275 reward 1.5629477500915527\n",
      "val loss 2.842954635620117 2.84338641166687\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6024038461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7493589743589744}]\n",
      "______epoch 96 _____\n",
      "train imitation 1.3711802959442139 reward 1.538169264793396\n",
      "val imitation 1.2792564630508423 reward 1.5629477500915527\n",
      "val loss 2.8422040939331055 2.842954635620117\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6033653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7503205128205128}]\n",
      "______epoch 97 _____\n",
      "train imitation 1.3444633483886719 reward 1.5383610725402832\n",
      "val imitation 1.2785600423812866 reward 1.5631847381591797\n",
      "val loss 2.841744899749756 2.8422040939331055\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6038461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.75}]\n",
      "______epoch 98 _____\n",
      "train imitation 1.3585727214813232 reward 1.5357674360275269\n",
      "val imitation 1.2778441905975342 reward 1.5637861490249634\n",
      "val loss 2.841630458831787 2.841744899749756\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.604326923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7503205128205128}]\n",
      "______epoch 99 _____\n",
      "train imitation 1.377763032913208 reward 1.5423357486724854\n",
      "val imitation 1.2771327495574951 reward 1.5642507076263428\n",
      "val loss 2.841383457183838 2.841630458831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6057692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736843}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7516025641025641}]\n",
      "______epoch 100 _____\n",
      "train imitation 1.3614444732666016 reward 1.5407482385635376\n",
      "val imitation 1.2764766216278076 reward 1.5647577047348022\n",
      "val loss 2.8412342071533203 2.841383457183838\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6052884615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666665}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7519230769230769}]\n",
      "______epoch 101 _____\n",
      "train imitation 1.3582117557525635 reward 1.5411661863327026\n",
      "val imitation 1.2757899761199951 reward 1.564955234527588\n",
      "val loss 2.840745210647583 2.8412342071533203\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6072115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7512820512820513}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 102 _____\n",
      "train imitation 1.3170132637023926 reward 1.5426756143569946\n",
      "val imitation 1.2751433849334717 reward 1.564955234527588\n",
      "val loss 2.8400986194610596 2.840745210647583\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6096153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666665}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7516025641025641}]\n",
      "______epoch 103 _____\n",
      "train imitation 1.341646432876587 reward 1.5312227010726929\n",
      "val imitation 1.2745071649551392 reward 1.564955234527588\n",
      "val loss 2.8394622802734375 2.8400986194610596\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6100961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736843}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7509615384615385}]\n",
      "______epoch 104 _____\n",
      "train imitation 1.3743512630462646 reward 1.537083625793457\n",
      "val imitation 1.2738226652145386 reward 1.5654144287109375\n",
      "val loss 2.8392372131347656 2.8394622802734375\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6096153846153847}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7519230769230769}]\n",
      "______epoch 105 _____\n",
      "train imitation 1.3925590515136719 reward 1.5421130657196045\n",
      "val imitation 1.273160457611084 reward 1.5643517971038818\n",
      "val loss 2.837512254714966 2.8392372131347656\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6091346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7516025641025641}]\n",
      "______epoch 106 _____\n",
      "train imitation 1.3415961265563965 reward 1.5401748418807983\n",
      "val imitation 1.272510051727295 reward 1.5643517971038818\n",
      "val loss 2.8368618488311768 2.837512254714966\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6110576923076922}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7516025641025641}]\n",
      "______epoch 107 _____\n",
      "train imitation 1.3229671716690063 reward 1.5384504795074463\n",
      "val imitation 1.271925687789917 reward 1.5643517971038818\n",
      "val loss 2.836277484893799 2.8368618488311768\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6110576923076922}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7532051282051282}]\n",
      "______epoch 108 _____\n",
      "train imitation 1.3313872814178467 reward 1.53659188747406\n",
      "val imitation 1.271392583847046 reward 1.5643517971038818\n",
      "val loss 2.8357443809509277 2.836277484893799\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6125}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.753525641025641}]\n",
      "______epoch 109 _____\n",
      "train imitation 1.372319221496582 reward 1.5421345233917236\n",
      "val imitation 1.270936369895935 reward 1.5643517971038818\n",
      "val loss 2.8352880477905273 2.8357443809509277\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6125}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7532051282051282}]\n",
      "______epoch 110 _____\n",
      "train imitation 1.375002384185791 reward 1.5382490158081055\n",
      "val imitation 1.2704836130142212 reward 1.5643517971038818\n",
      "val loss 2.8348355293273926 2.8352880477905273\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6125}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7528846153846154}]\n",
      "______epoch 111 _____\n",
      "train imitation 1.3362836837768555 reward 1.5381605625152588\n",
      "val imitation 1.2699966430664062 reward 1.5643517971038818\n",
      "val loss 2.834348440170288 2.8348355293273926\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.614423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824562}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7528846153846154}]\n",
      "______epoch 112 _____\n",
      "train imitation 1.3312015533447266 reward 1.5378575325012207\n",
      "val imitation 1.2695434093475342 reward 1.5643517971038818\n",
      "val loss 2.833895206451416 2.834348440170288\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6134615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7532051282051282}]\n",
      "______epoch 113 _____\n",
      "train imitation 1.322725772857666 reward 1.5391775369644165\n",
      "val imitation 1.2691222429275513 reward 1.5643517971038818\n",
      "val loss 2.8334741592407227 2.833895206451416\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6134615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.753525641025641}]\n",
      "______epoch 114 _____\n",
      "train imitation 1.3575782775878906 reward 1.542641282081604\n",
      "val imitation 1.2687288522720337 reward 1.5643031597137451\n",
      "val loss 2.8330321311950684 2.8334741592407227\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6139423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 115 _____\n",
      "train imitation 1.3308758735656738 reward 1.540231466293335\n",
      "val imitation 1.268280029296875 reward 1.5643031597137451\n",
      "val loss 2.83258318901062 2.8330321311950684\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n",
      "______epoch 116 _____\n",
      "train imitation 1.320037603378296 reward 1.5396467447280884\n",
      "val imitation 1.2678608894348145 reward 1.5643031597137451\n",
      "val loss 2.8321640491485596 2.83258318901062\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6163461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7560897435897436}]\n",
      "______epoch 117 _____\n",
      "train imitation 1.301102876663208 reward 1.540881872177124\n",
      "val imitation 1.2674006223678589 reward 1.5634864568710327\n",
      "val loss 2.8308870792388916 2.8321640491485596\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6163461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7560897435897436}]\n",
      "______epoch 118 _____\n",
      "train imitation 1.321608543395996 reward 1.5349458456039429\n",
      "val imitation 1.266981601715088 reward 1.5635547637939453\n",
      "val loss 2.830536365509033 2.8308870792388916\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n",
      "______epoch 119 _____\n",
      "train imitation 1.3816194534301758 reward 1.5384114980697632\n",
      "val imitation 1.2664874792099 reward 1.5635745525360107\n",
      "val loss 2.830061912536621 2.830536365509033\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6168269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7554487179487179}]\n",
      "______epoch 120 _____\n",
      "train imitation 1.3294819593429565 reward 1.5413026809692383\n",
      "val imitation 1.2660212516784668 reward 1.5635745525360107\n",
      "val loss 2.8295958042144775 2.830061912536621\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6153846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 121 _____\n",
      "train imitation 1.3380563259124756 reward 1.543405294418335\n",
      "val imitation 1.2655248641967773 reward 1.5635745525360107\n",
      "val loss 2.829099416732788 2.8295958042144775\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6168269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 122 _____\n",
      "train imitation 1.3542122840881348 reward 1.5460255146026611\n",
      "val imitation 1.2649877071380615 reward 1.5635745525360107\n",
      "val loss 2.8285622596740723 2.829099416732788\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6163461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 123 _____\n",
      "train imitation 1.3334777355194092 reward 1.5432628393173218\n",
      "val imitation 1.2644308805465698 reward 1.5621693134307861\n",
      "val loss 2.8266000747680664 2.8285622596740723\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6168269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n",
      "______epoch 124 _____\n",
      "train imitation 1.3114463090896606 reward 1.5366657972335815\n",
      "val imitation 1.2638649940490723 reward 1.561967372894287\n",
      "val loss 2.8258323669433594 2.8266000747680664\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6168269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7554487179487179}]\n",
      "______epoch 125 _____\n",
      "train imitation 1.3343546390533447 reward 1.5292513370513916\n",
      "val imitation 1.2633171081542969 reward 1.5633150339126587\n",
      "val loss 2.826632022857666 2.8258323669433594\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6173076923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 126 _____\n",
      "train imitation 1.307750940322876 reward 1.5444246530532837\n",
      "val imitation 1.2627990245819092 reward 1.5627995729446411\n",
      "val loss 2.82559871673584 2.8258323669433594\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6182692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 127 _____\n",
      "train imitation 1.373061180114746 reward 1.5417125225067139\n",
      "val imitation 1.2622442245483398 reward 1.5627995729446411\n",
      "val loss 2.8250436782836914 2.82559871673584\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6197115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 128 _____\n",
      "train imitation 1.337414264678955 reward 1.5357615947723389\n",
      "val imitation 1.2617038488388062 reward 1.5627995729446411\n",
      "val loss 2.8245034217834473 2.8250436782836914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6201923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.753525641025641}]\n",
      "______epoch 129 _____\n",
      "train imitation 1.3102562427520752 reward 1.532801866531372\n",
      "val imitation 1.2611476182937622 reward 1.5627995729446411\n",
      "val loss 2.8239471912384033 2.8245034217834473\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6201923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7541666666666667}]\n",
      "______epoch 130 _____\n",
      "train imitation 1.3265585899353027 reward 1.5417962074279785\n",
      "val imitation 1.260610580444336 reward 1.5627995729446411\n",
      "val loss 2.8234100341796875 2.8239471912384033\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6211538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333333}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 131 _____\n",
      "train imitation 1.2897446155548096 reward 1.541215419769287\n",
      "val imitation 1.260037899017334 reward 1.5626846551895142\n",
      "val loss 2.8227224349975586 2.8234100341796875\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6216346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 132 _____\n",
      "train imitation 1.2748435735702515 reward 1.538041353225708\n",
      "val imitation 1.2594175338745117 reward 1.5626846551895142\n",
      "val loss 2.8221020698547363 2.8227224349975586\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6221153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 133 _____\n",
      "train imitation 1.350245714187622 reward 1.5494228601455688\n",
      "val imitation 1.2588350772857666 reward 1.5626846551895142\n",
      "val loss 2.8215198516845703 2.8221020698547363\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6225961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 134 _____\n",
      "train imitation 1.3234000205993652 reward 1.5416746139526367\n",
      "val imitation 1.2582184076309204 reward 1.5626846551895142\n",
      "val loss 2.8209030628204346 2.8215198516845703\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6225961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7554487179487179}]\n",
      "______epoch 135 _____\n",
      "train imitation 1.310636281967163 reward 1.541216492652893\n",
      "val imitation 1.2575688362121582 reward 1.5626846551895142\n",
      "val loss 2.820253372192383 2.8209030628204346\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n",
      "______epoch 136 _____\n",
      "train imitation 1.3183109760284424 reward 1.5348080396652222\n",
      "val imitation 1.2569334506988525 reward 1.5626846551895142\n",
      "val loss 2.8196182250976562 2.820253372192383\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7554487179487179}]\n",
      "______epoch 137 _____\n",
      "train imitation 1.2848458290100098 reward 1.5384869575500488\n",
      "val imitation 1.2563503980636597 reward 1.5627663135528564\n",
      "val loss 2.8191165924072266 2.8196182250976562\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6225961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7234100877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 138 _____\n",
      "train imitation 1.3055047988891602 reward 1.537122368812561\n",
      "val imitation 1.2558039426803589 reward 1.5627663135528564\n",
      "val loss 2.818570137023926 2.8191165924072266\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6221153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7231359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 139 _____\n",
      "train imitation 1.3166464567184448 reward 1.5329842567443848\n",
      "val imitation 1.25522780418396 reward 1.5627663135528564\n",
      "val loss 2.8179941177368164 2.818570137023926\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 140 _____\n",
      "train imitation 1.2941863536834717 reward 1.5338430404663086\n",
      "val imitation 1.2546899318695068 reward 1.5627663135528564\n",
      "val loss 2.8174562454223633 2.8179941177368164\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7234100877192982}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 141 _____\n",
      "train imitation 1.3168814182281494 reward 1.5415699481964111\n",
      "val imitation 1.254113793373108 reward 1.5627663135528564\n",
      "val loss 2.816880226135254 2.8174562454223633\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6235576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 142 _____\n",
      "train imitation 1.2941677570343018 reward 1.5422533750534058\n",
      "val imitation 1.2535983324050903 reward 1.5634280443191528\n",
      "val loss 2.817026376724243 2.816880226135254\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6240384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7541666666666667}]\n",
      "______epoch 143 _____\n",
      "train imitation 1.3416738510131836 reward 1.5395413637161255\n",
      "val imitation 1.253122091293335 reward 1.5634068250656128\n",
      "val loss 2.816528797149658 2.816880226135254\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6235576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.753525641025641}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 144 _____\n",
      "train imitation 1.3293651342391968 reward 1.5443511009216309\n",
      "val imitation 1.2526657581329346 reward 1.5619724988937378\n",
      "val loss 2.814638137817383 2.816528797149658\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6235576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7228618421052633}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7538461538461538}]\n",
      "______epoch 145 _____\n",
      "train imitation 1.2795491218566895 reward 1.544779658317566\n",
      "val imitation 1.2522480487823486 reward 1.5619724988937378\n",
      "val loss 2.814220428466797 2.814638137817383\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6225961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7228618421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7532051282051282}]\n",
      "______epoch 146 _____\n",
      "train imitation 1.2911376953125 reward 1.5413686037063599\n",
      "val imitation 1.2518527507781982 reward 1.5617529153823853\n",
      "val loss 2.813605785369873 2.814220428466797\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6225961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7234100877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7541666666666667}]\n",
      "______epoch 147 _____\n",
      "train imitation 1.3038325309753418 reward 1.5432000160217285\n",
      "val imitation 1.251483678817749 reward 1.5629459619522095\n",
      "val loss 2.814429759979248 2.813605785369873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7541666666666667}]\n",
      "______epoch 148 _____\n",
      "train imitation 1.2478392124176025 reward 1.5399014949798584\n",
      "val imitation 1.251124620437622 reward 1.5629459619522095\n",
      "val loss 2.814070701599121 2.813605785369873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6240384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 149 _____\n",
      "train imitation 1.274011492729187 reward 1.5310192108154297\n",
      "val imitation 1.2507847547531128 reward 1.5629459619522095\n",
      "val loss 2.8137307167053223 2.813605785369873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6245192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 150 _____\n",
      "train imitation 1.295567274093628 reward 1.546466588973999\n",
      "val imitation 1.2505077123641968 reward 1.5624866485595703\n",
      "val loss 2.8129944801330566 2.813605785369873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6259615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7551282051282051}]\n",
      "______epoch 151 _____\n",
      "train imitation 1.2875829935073853 reward 1.5453530550003052\n",
      "val imitation 1.2502355575561523 reward 1.5623595714569092\n",
      "val loss 2.8125951290130615 2.8129944801330566\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6259615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 152 _____\n",
      "train imitation 1.3028651475906372 reward 1.54274320602417\n",
      "val imitation 1.2500205039978027 reward 1.5623595714569092\n",
      "val loss 2.812380075454712 2.8125951290130615\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6259615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 153 _____\n",
      "train imitation 1.3088152408599854 reward 1.540757179260254\n",
      "val imitation 1.2497614622116089 reward 1.5625507831573486\n",
      "val loss 2.812312126159668 2.812380075454712\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6264423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7247807017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7557692307692307}]\n",
      "______epoch 154 _____\n",
      "train imitation 1.2611421346664429 reward 1.5442839860916138\n",
      "val imitation 1.2494304180145264 reward 1.5641753673553467\n",
      "val loss 2.813605785369873 2.812312126159668\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6274038461538461}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7560897435897436}]\n",
      "______epoch 155 _____\n",
      "train imitation 1.2352453470230103 reward 1.5418742895126343\n",
      "val imitation 1.2490358352661133 reward 1.5640472173690796\n",
      "val loss 2.8130831718444824 2.812312126159668\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6283653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7567307692307692}]\n",
      "______epoch 156 _____\n",
      "train imitation 1.2862683534622192 reward 1.5464935302734375\n",
      "val imitation 1.2486008405685425 reward 1.5633981227874756\n",
      "val loss 2.8119988441467285 2.812312126159668\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6288461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "______epoch 157 _____\n",
      "train imitation 1.2553564310073853 reward 1.5326833724975586\n",
      "val imitation 1.2481780052185059 reward 1.5633981227874756\n",
      "val loss 2.8115761280059814 2.8119988441467285\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6288461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.757051282051282}]\n",
      "______epoch 158 _____\n",
      "train imitation 1.245302677154541 reward 1.546526312828064\n",
      "val imitation 1.2477631568908691 reward 1.5646519660949707\n",
      "val loss 2.81241512298584 2.8115761280059814\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7586538461538462}]\n",
      "______epoch 159 _____\n",
      "train imitation 1.2938499450683594 reward 1.5319610834121704\n",
      "val imitation 1.2472915649414062 reward 1.5646519660949707\n",
      "val loss 2.811943531036377 2.8115761280059814\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333334}]\n",
      "______epoch 160 _____\n",
      "train imitation 1.2975661754608154 reward 1.5393009185791016\n",
      "val imitation 1.2468963861465454 reward 1.5633981227874756\n",
      "val loss 2.8102946281433105 2.8115761280059814\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7253289473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333334}]\n",
      "______epoch 161 _____\n",
      "train imitation 1.296773076057434 reward 1.5495662689208984\n",
      "val imitation 1.2464861869812012 reward 1.5633981227874756\n",
      "val loss 2.8098843097686768 2.8102946281433105\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6298076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7573717948717948}]\n",
      "______epoch 162 _____\n",
      "train imitation 1.2640068531036377 reward 1.541435956954956\n",
      "val imitation 1.246099591255188 reward 1.5614368915557861\n",
      "val loss 2.8075366020202637 2.8098843097686768\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6307692307692309}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7264254385964913}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n",
      "______epoch 163 _____\n",
      "train imitation 1.2824784517288208 reward 1.5436322689056396\n",
      "val imitation 1.2457609176635742 reward 1.5614368915557861\n",
      "val loss 2.8071978092193604 2.8075366020202637\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6312500000000001}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105262}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7583333333333333}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 164 _____\n",
      "train imitation 1.2818254232406616 reward 1.543867588043213\n",
      "val imitation 1.245447039604187 reward 1.5614368915557861\n",
      "val loss 2.8068838119506836 2.8071978092193604\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6326923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7250548245614036}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7576923076923077}]\n",
      "______epoch 165 _____\n",
      "train imitation 1.2351776361465454 reward 1.5429327487945557\n",
      "val imitation 1.2451493740081787 reward 1.5613198280334473\n",
      "val loss 2.806469202041626 2.8068838119506836\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.633173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7250548245614036}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7573717948717948}]\n",
      "______epoch 166 _____\n",
      "train imitation 1.2507483959197998 reward 1.5407251119613647\n",
      "val imitation 1.2448668479919434 reward 1.5613198280334473\n",
      "val loss 2.8061866760253906 2.806469202041626\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6322115384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7560897435897436}]\n",
      "______epoch 167 _____\n",
      "train imitation 1.2994658946990967 reward 1.5402523279190063\n",
      "val imitation 1.2445398569107056 reward 1.5615628957748413\n",
      "val loss 2.806102752685547 2.8061866760253906\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6322115384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7242324561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 168 _____\n",
      "train imitation 1.2472695112228394 reward 1.5402929782867432\n",
      "val imitation 1.2442004680633545 reward 1.5615628957748413\n",
      "val loss 2.8057632446289062 2.806102752685547\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.633173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7234100877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 169 _____\n",
      "train imitation 1.2699309587478638 reward 1.543931484222412\n",
      "val imitation 1.2438974380493164 reward 1.5605932474136353\n",
      "val loss 2.804490566253662 2.8057632446289062\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.633173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7223135964912281}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 170 _____\n",
      "train imitation 1.2535613775253296 reward 1.537020206451416\n",
      "val imitation 1.2436096668243408 reward 1.5603214502334595\n",
      "val loss 2.80393123626709 2.804490566253662\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6341346153846155}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7228618421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7544871794871795}]\n",
      "______epoch 171 _____\n",
      "train imitation 1.2698469161987305 reward 1.5410869121551514\n",
      "val imitation 1.2432496547698975 reward 1.5603214502334595\n",
      "val loss 2.8035712242126465 2.80393123626709\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6341346153846155}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7538461538461538}]\n",
      "______epoch 172 _____\n",
      "train imitation 1.2835443019866943 reward 1.5349843502044678\n",
      "val imitation 1.2428297996520996 reward 1.5603214502334595\n",
      "val loss 2.8031511306762695 2.8035712242126465\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6341346153846155}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.721765350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7538461538461538}]\n",
      "______epoch 173 _____\n",
      "train imitation 1.2288603782653809 reward 1.5373139381408691\n",
      "val imitation 1.2425031661987305 reward 1.5623209476470947\n",
      "val loss 2.804824113845825 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6336538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7538461538461538}]\n",
      "______epoch 174 _____\n",
      "train imitation 1.2548112869262695 reward 1.5366902351379395\n",
      "val imitation 1.242213487625122 reward 1.5637552738189697\n",
      "val loss 2.805968761444092 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6336538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "______epoch 175 _____\n",
      "train imitation 1.246396541595459 reward 1.5382412672042847\n",
      "val imitation 1.241916537284851 reward 1.5655720233917236\n",
      "val loss 2.807488441467285 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6350961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.721217105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7554487179487179}]\n",
      "______epoch 176 _____\n",
      "train imitation 1.2580914497375488 reward 1.5322926044464111\n",
      "val imitation 1.2415584325790405 reward 1.5674245357513428\n",
      "val loss 2.8089828491210938 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6350961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7214912280701755}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "______epoch 177 _____\n",
      "train imitation 1.2581562995910645 reward 1.5473151206970215\n",
      "val imitation 1.2412129640579224 reward 1.5674245357513428\n",
      "val loss 2.8086376190185547 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.635576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.757051282051282}]\n",
      "______epoch 178 _____\n",
      "train imitation 1.2711985111236572 reward 1.5489451885223389\n",
      "val imitation 1.2408640384674072 reward 1.5674245357513428\n",
      "val loss 2.80828857421875 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6360576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7220394736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7573717948717948}]\n",
      "______epoch 179 _____\n",
      "train imitation 1.2511849403381348 reward 1.5419048070907593\n",
      "val imitation 1.2404102087020874 reward 1.5674245357513428\n",
      "val loss 2.8078346252441406 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.635576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7228618421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7586538461538461}]\n",
      "______epoch 180 _____\n",
      "train imitation 1.2656794786453247 reward 1.5417131185531616\n",
      "val imitation 1.2398097515106201 reward 1.5674245357513428\n",
      "val loss 2.807234287261963 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6360576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7231359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7586538461538461}]\n",
      "______epoch 181 _____\n",
      "train imitation 1.2114217281341553 reward 1.5364989042282104\n",
      "val imitation 1.2393319606781006 reward 1.5674245357513428\n",
      "val loss 2.8067564964294434 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6360576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7231359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564103}]\n",
      "______epoch 182 _____\n",
      "train imitation 1.2642548084259033 reward 1.546226143836975\n",
      "val imitation 1.2389466762542725 reward 1.5679761171340942\n",
      "val loss 2.8069229125976562 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6370192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "______epoch 183 _____\n",
      "train imitation 1.2708790302276611 reward 1.535815715789795\n",
      "val imitation 1.238426923751831 reward 1.5679761171340942\n",
      "val loss 2.806403160095215 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6365384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403509}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179487}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 184 _____\n",
      "train imitation 1.231065034866333 reward 1.5418410301208496\n",
      "val imitation 1.2379446029663086 reward 1.5679761171340942\n",
      "val loss 2.8059206008911133 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6365384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7615384615384615}]\n",
      "______epoch 185 _____\n",
      "train imitation 1.2604572772979736 reward 1.55339777469635\n",
      "val imitation 1.2374578714370728 reward 1.5679761171340942\n",
      "val loss 2.805433988571167 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6365384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179487}]\n",
      "______epoch 186 _____\n",
      "train imitation 1.239485502243042 reward 1.5352487564086914\n",
      "val imitation 1.2369191646575928 reward 1.5667892694473267\n",
      "val loss 2.803708553314209 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6370192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7615384615384615}]\n",
      "______epoch 187 _____\n",
      "train imitation 1.214017629623413 reward 1.540527105331421\n",
      "val imitation 1.2365330457687378 reward 1.5667892694473267\n",
      "val loss 2.8033223152160645 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7612179487179487}]\n",
      "______epoch 188 _____\n",
      "train imitation 1.2819135189056396 reward 1.5390546321868896\n",
      "val imitation 1.2363241910934448 reward 1.5666024684906006\n",
      "val loss 2.802926540374756 2.8031511306762695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179487}]\n",
      "______epoch 189 _____\n",
      "train imitation 1.2073465585708618 reward 1.5426985025405884\n",
      "val imitation 1.236240267753601 reward 1.564894676208496\n",
      "val loss 2.8011350631713867 2.802926540374756\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179487}]\n",
      "______epoch 190 _____\n",
      "train imitation 1.2512000799179077 reward 1.5340741872787476\n",
      "val imitation 1.2362300157546997 reward 1.564894676208496\n",
      "val loss 2.8011245727539062 2.8011350631713867\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7231359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "______epoch 191 _____\n",
      "train imitation 1.3031213283538818 reward 1.5437220335006714\n",
      "val imitation 1.2361773252487183 reward 1.564894676208496\n",
      "val loss 2.801072120666504 2.8011245727539062\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7231359649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "______epoch 192 _____\n",
      "train imitation 1.2444748878479004 reward 1.547204852104187\n",
      "val imitation 1.2358757257461548 reward 1.5648207664489746\n",
      "val loss 2.80069637298584 2.801072120666504\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6375000000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7599358974358974}]\n",
      "______epoch 193 _____\n",
      "train imitation 1.259012222290039 reward 1.5451034307479858\n",
      "val imitation 1.2354918718338013 reward 1.5648207664489746\n",
      "val loss 2.8003125190734863 2.80069637298584\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403509}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "______epoch 194 _____\n",
      "train imitation 1.199156403541565 reward 1.5462720394134521\n",
      "val imitation 1.2350317239761353 reward 1.5648207664489746\n",
      "val loss 2.7998523712158203 2.8003125190734863\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6384615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7608974358974359}]\n",
      "______epoch 195 _____\n",
      "train imitation 1.2435626983642578 reward 1.5436500310897827\n",
      "val imitation 1.2344493865966797 reward 1.5648207664489746\n",
      "val loss 2.7992701530456543 2.7998523712158203\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.724780701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7615384615384615}]\n",
      "______epoch 196 _____\n",
      "train imitation 1.2458231449127197 reward 1.544177532196045\n",
      "val imitation 1.2339224815368652 reward 1.5648207664489746\n",
      "val loss 2.79874324798584 2.7992701530456543\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6399038461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7618589743589744}]\n",
      "______epoch 197 _____\n",
      "train imitation 1.241348147392273 reward 1.550797700881958\n",
      "val imitation 1.2334246635437012 reward 1.5648207664489746\n",
      "val loss 2.798245429992676 2.79874324798584\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7634615384615384}]\n",
      "______epoch 198 _____\n",
      "train imitation 1.268810749053955 reward 1.5426594018936157\n",
      "val imitation 1.2330601215362549 reward 1.5650955438613892\n",
      "val loss 2.7981557846069336 2.798245429992676\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.764423076923077}]\n",
      "______epoch 199 _____\n",
      "train imitation 1.218652606010437 reward 1.5390796661376953\n",
      "val imitation 1.2328064441680908 reward 1.5650955438613892\n",
      "val loss 2.7979021072387695 2.7981557846069336\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.639423076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7663461538461538}]\n",
      "______epoch 200 _____\n",
      "train imitation 1.2807354927062988 reward 1.53725004196167\n",
      "val imitation 1.2326631546020508 reward 1.5650955438613892\n",
      "val loss 2.7977585792541504 2.7979021072387695\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6403846153846153}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7666666666666666}]\n",
      "______epoch 201 _____\n",
      "train imitation 1.2647640705108643 reward 1.540949821472168\n",
      "val imitation 1.2324367761611938 reward 1.5648140907287598\n",
      "val loss 2.797250747680664 2.7977585792541504\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7666666666666666}]\n",
      "______epoch 202 _____\n",
      "train imitation 1.2606821060180664 reward 1.5466725826263428\n",
      "val imitation 1.2323329448699951 reward 1.5648140907287598\n",
      "val loss 2.797147035598755 2.797250747680664\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6423076923076922}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7679487179487179}]\n",
      "______epoch 203 _____\n",
      "train imitation 1.2323893308639526 reward 1.5454041957855225\n",
      "val imitation 1.232298493385315 reward 1.5650955438613892\n",
      "val loss 2.797394037246704 2.797147035598755\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6447115384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897436}]\n",
      "______epoch 204 _____\n",
      "train imitation 1.217583417892456 reward 1.5418620109558105\n",
      "val imitation 1.2322819232940674 reward 1.5650955438613892\n",
      "val loss 2.797377586364746 2.797147035598755\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897435}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 205 _____\n",
      "train imitation 1.2323276996612549 reward 1.534374713897705\n",
      "val imitation 1.2320419549942017 reward 1.5650955438613892\n",
      "val loss 2.797137498855591 2.797147035598755\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.645673076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897435}]\n",
      "______epoch 206 _____\n",
      "train imitation 1.235102653503418 reward 1.5456551313400269\n",
      "val imitation 1.2317914962768555 reward 1.5650955438613892\n",
      "val loss 2.796886920928955 2.797137498855591\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923076}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7275219298245613}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7689102564102563}]\n",
      "______epoch 207 _____\n",
      "train imitation 1.272595763206482 reward 1.5461760759353638\n",
      "val imitation 1.2314578294754028 reward 1.5650955438613892\n",
      "val loss 2.796553373336792 2.796886920928955\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923076}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7275219298245613}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897436}]\n",
      "______epoch 208 _____\n",
      "train imitation 1.2144538164138794 reward 1.5423692464828491\n",
      "val imitation 1.231218934059143 reward 1.5650955438613892\n",
      "val loss 2.7963144779205322 2.796553373336792\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6447115384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7689102564102565}]\n",
      "______epoch 209 _____\n",
      "train imitation 1.2339262962341309 reward 1.544800877571106\n",
      "val imitation 1.2311385869979858 reward 1.564965009689331\n",
      "val loss 2.7961034774780273 2.7963144779205322\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7682692307692307}]\n",
      "______epoch 210 _____\n",
      "train imitation 1.2360343933105469 reward 1.5392552614212036\n",
      "val imitation 1.2310765981674194 reward 1.564965009689331\n",
      "val loss 2.796041488647461 2.7961034774780273\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7679487179487179}]\n",
      "______epoch 211 _____\n",
      "train imitation 1.234041452407837 reward 1.5444762706756592\n",
      "val imitation 1.2312270402908325 reward 1.564965009689331\n",
      "val loss 2.796192169189453 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.64375}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7682692307692308}]\n",
      "______epoch 212 _____\n",
      "train imitation 1.229645013809204 reward 1.5402565002441406\n",
      "val imitation 1.231356143951416 reward 1.5646904706954956\n",
      "val loss 2.796046733856201 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6427884615384615}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7666666666666667}]\n",
      "______epoch 213 _____\n",
      "train imitation 1.1698760986328125 reward 1.5411473512649536\n",
      "val imitation 1.2314382791519165 reward 1.5646904706954956\n",
      "val loss 2.796128749847412 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6442307692307692}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7666666666666666}]\n",
      "______epoch 214 _____\n",
      "train imitation 1.2560880184173584 reward 1.5400103330612183\n",
      "val imitation 1.2314941883087158 reward 1.5646904706954956\n",
      "val loss 2.796184539794922 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6451923076923076}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.766025641025641}]\n",
      "______epoch 215 _____\n",
      "train imitation 1.2460095882415771 reward 1.5362910032272339\n",
      "val imitation 1.2313923835754395 reward 1.5646904706954956\n",
      "val loss 2.7960829734802246 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7663461538461538}]\n",
      "______epoch 216 _____\n",
      "train imitation 1.2526345252990723 reward 1.5473369359970093\n",
      "val imitation 1.2315051555633545 reward 1.5646904706954956\n",
      "val loss 2.7961955070495605 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6466346153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.766025641025641}]\n",
      "______epoch 217 _____\n",
      "train imitation 1.2056682109832764 reward 1.536238431930542\n",
      "val imitation 1.2314536571502686 reward 1.5644670724868774\n",
      "val loss 2.7959208488464355 2.796041488647461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6466346153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7647435897435897}]\n",
      "______epoch 218 _____\n",
      "train imitation 1.2297064065933228 reward 1.5431056022644043\n",
      "val imitation 1.2314082384109497 reward 1.5644670724868774\n",
      "val loss 2.795875310897827 2.7959208488464355\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7650641025641025}]\n",
      "______epoch 219 _____\n",
      "train imitation 1.2576740980148315 reward 1.542702078819275\n",
      "val imitation 1.2312723398208618 reward 1.5644670724868774\n",
      "val loss 2.7957394123077393 2.795875310897827\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6490384615384617}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7653846153846154}]\n",
      "______epoch 220 _____\n",
      "train imitation 1.2214549779891968 reward 1.5475914478302002\n",
      "val imitation 1.2310242652893066 reward 1.5652319192886353\n",
      "val loss 2.7962560653686523 2.7957394123077393\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6480769230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7653846153846154}]\n",
      "______epoch 221 _____\n",
      "train imitation 1.2308429479599 reward 1.5482711791992188\n",
      "val imitation 1.2306115627288818 reward 1.5654549598693848\n",
      "val loss 2.7960665225982666 2.7957394123077393\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7280701754385964}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7666666666666666}]\n",
      "______epoch 222 _____\n",
      "train imitation 1.1977393627166748 reward 1.5488669872283936\n",
      "val imitation 1.230231523513794 reward 1.5654549598693848\n",
      "val loss 2.7956864833831787 2.7957394123077393\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7673076923076924}]\n",
      "______epoch 223 _____\n",
      "train imitation 1.204864740371704 reward 1.5441254377365112\n",
      "val imitation 1.2300723791122437 reward 1.5666426420211792\n",
      "val loss 2.796715021133423 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6514423076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.728344298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7669871794871795}]\n",
      "______epoch 224 _____\n",
      "train imitation 1.205561876296997 reward 1.5499244928359985\n",
      "val imitation 1.230177402496338 reward 1.5666426420211792\n",
      "val loss 2.7968201637268066 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6514423076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7695512820512821}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 225 _____\n",
      "train imitation 1.2429537773132324 reward 1.5445237159729004\n",
      "val imitation 1.2305107116699219 reward 1.5677517652511597\n",
      "val loss 2.798262596130371 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846155}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7705128205128206}]\n",
      "______epoch 226 _____\n",
      "train imitation 1.2670388221740723 reward 1.5381250381469727\n",
      "val imitation 1.2308478355407715 reward 1.5680749416351318\n",
      "val loss 2.7989227771759033 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846155}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n",
      "______epoch 227 _____\n",
      "train imitation 1.1980640888214111 reward 1.5386240482330322\n",
      "val imitation 1.2312490940093994 reward 1.5677517652511597\n",
      "val loss 2.7990007400512695 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 228 _____\n",
      "train imitation 1.1836817264556885 reward 1.5432171821594238\n",
      "val imitation 1.231551170349121 reward 1.5677517652511597\n",
      "val loss 2.7993030548095703 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7708333333333334}]\n",
      "______epoch 229 _____\n",
      "train imitation 1.2271173000335693 reward 1.543798804283142\n",
      "val imitation 1.231485366821289 reward 1.5687822103500366\n",
      "val loss 2.8002676963806152 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.771474358974359}]\n",
      "______epoch 230 _____\n",
      "train imitation 1.250542163848877 reward 1.5458054542541504\n",
      "val imitation 1.2310749292373657 reward 1.5687822103500366\n",
      "val loss 2.7998571395874023 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6533653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7714743589743589}]\n",
      "______epoch 231 _____\n",
      "train imitation 1.2449511289596558 reward 1.5482783317565918\n",
      "val imitation 1.2305411100387573 reward 1.5687822103500366\n",
      "val loss 2.799323320388794 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6538461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7321820175438597}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7714743589743589}]\n",
      "______epoch 232 _____\n",
      "train imitation 1.2210626602172852 reward 1.5511000156402588\n",
      "val imitation 1.2299835681915283 reward 1.5686781406402588\n",
      "val loss 2.798661708831787 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6538461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7324561403508772}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.771474358974359}]\n",
      "______epoch 233 _____\n",
      "train imitation 1.2152339220046997 reward 1.540295958518982\n",
      "val imitation 1.2295851707458496 reward 1.5686781406402588\n",
      "val loss 2.7982633113861084 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6538461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948717}]\n",
      "______epoch 234 _____\n",
      "train imitation 1.209426999092102 reward 1.5458323955535889\n",
      "val imitation 1.2291606664657593 reward 1.5686781406402588\n",
      "val loss 2.7978386878967285 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948717}]\n",
      "______epoch 235 _____\n",
      "train imitation 1.2071077823638916 reward 1.5454466342926025\n",
      "val imitation 1.2289143800735474 reward 1.5686781406402588\n",
      "val loss 2.7975926399230957 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6538461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7724358974358974}]\n",
      "______epoch 236 _____\n",
      "train imitation 1.1974643468856812 reward 1.5450959205627441\n",
      "val imitation 1.2284382581710815 reward 1.569596290588379\n",
      "val loss 2.79803466796875 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7721153846153846}]\n",
      "______epoch 237 _____\n",
      "train imitation 1.1827812194824219 reward 1.543632984161377\n",
      "val imitation 1.2279670238494873 reward 1.569596290588379\n",
      "val loss 2.797563314437866 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7727564102564102}]\n",
      "______epoch 238 _____\n",
      "train imitation 1.1732219457626343 reward 1.548114538192749\n",
      "val imitation 1.2275707721710205 reward 1.570556402206421\n",
      "val loss 2.7981271743774414 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.773076923076923}]\n",
      "______epoch 239 _____\n",
      "train imitation 1.1713112592697144 reward 1.5421655178070068\n",
      "val imitation 1.2271811962127686 reward 1.570556402206421\n",
      "val loss 2.7977375984191895 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.653846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7727564102564102}]\n",
      "______epoch 240 _____\n",
      "train imitation 1.1944191455841064 reward 1.5491923093795776\n",
      "val imitation 1.226830244064331 reward 1.5678162574768066\n",
      "val loss 2.7946465015411377 2.7956864833831787\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6543269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7727564102564102}]\n",
      "______epoch 241 _____\n",
      "train imitation 1.2009608745574951 reward 1.5418500900268555\n",
      "val imitation 1.2265594005584717 reward 1.5678162574768066\n",
      "val loss 2.7943756580352783 2.7946465015411377\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6548076923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7730769230769231}]\n",
      "______epoch 242 _____\n",
      "train imitation 1.1705098152160645 reward 1.53373122215271\n",
      "val imitation 1.2263277769088745 reward 1.56794273853302\n",
      "val loss 2.7942705154418945 2.7943756580352783\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153845}]\n",
      "______epoch 243 _____\n",
      "train imitation 1.2325481176376343 reward 1.5439625978469849\n",
      "val imitation 1.2261641025543213 reward 1.5681068897247314\n",
      "val loss 2.7942709922790527 2.7942705154418945\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7724358974358975}]\n",
      "______epoch 244 _____\n",
      "train imitation 1.2042251825332642 reward 1.5494390726089478\n",
      "val imitation 1.226091980934143 reward 1.5678390264511108\n",
      "val loss 2.793931007385254 2.7942705154418945\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692309}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 245 _____\n",
      "train imitation 1.184584617614746 reward 1.5395187139511108\n",
      "val imitation 1.2258107662200928 reward 1.567713737487793\n",
      "val loss 2.7935245037078857 2.793931007385254\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692309}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153846}]\n",
      "______epoch 246 _____\n",
      "train imitation 1.1738641262054443 reward 1.5466978549957275\n",
      "val imitation 1.2253062725067139 reward 1.567713737487793\n",
      "val loss 2.793020009994507 2.7935245037078857\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7319078947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7733974358974359}]\n",
      "______epoch 247 _____\n",
      "train imitation 1.18866765499115 reward 1.5470819473266602\n",
      "val imitation 1.224778413772583 reward 1.567713737487793\n",
      "val loss 2.792492151260376 2.793020009994507\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6567307692307692}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 248 _____\n",
      "train imitation 1.2327831983566284 reward 1.546462059020996\n",
      "val imitation 1.224212408065796 reward 1.567713737487793\n",
      "val loss 2.791926145553589 2.792492151260376\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 249 _____\n",
      "train imitation 1.214963436126709 reward 1.5495169162750244\n",
      "val imitation 1.2235969305038452 reward 1.567981481552124\n",
      "val loss 2.7915782928466797 2.791926145553589\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 250 _____\n",
      "train imitation 1.1829627752304077 reward 1.5503132343292236\n",
      "val imitation 1.2230124473571777 reward 1.5683298110961914\n",
      "val loss 2.791342258453369 2.7915782928466797\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 251 _____\n",
      "train imitation 1.2244852781295776 reward 1.5446628332138062\n",
      "val imitation 1.2224570512771606 reward 1.568959355354309\n",
      "val loss 2.7914164066314697 2.791342258453369\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6572115384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n",
      "______epoch 252 _____\n",
      "train imitation 1.2232728004455566 reward 1.5443987846374512\n",
      "val imitation 1.2219551801681519 reward 1.568959355354309\n",
      "val loss 2.790914535522461 2.791342258453369\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.733826754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n",
      "______epoch 253 _____\n",
      "train imitation 1.197350263595581 reward 1.547690987586975\n",
      "val imitation 1.2215384244918823 reward 1.568959355354309\n",
      "val loss 2.7904977798461914 2.790914535522461\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6586538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.733826754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7759615384615385}]\n",
      "______epoch 254 _____\n",
      "train imitation 1.2005794048309326 reward 1.5463018417358398\n",
      "val imitation 1.2212142944335938 reward 1.570507287979126\n",
      "val loss 2.7917215824127197 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7769230769230769}]\n",
      "______epoch 255 _____\n",
      "train imitation 1.2090773582458496 reward 1.5536192655563354\n",
      "val imitation 1.2209134101867676 reward 1.570507287979126\n",
      "val loss 2.7914206981658936 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641026}]\n",
      "______epoch 256 _____\n",
      "train imitation 1.2374505996704102 reward 1.5419037342071533\n",
      "val imitation 1.2208986282348633 reward 1.570507287979126\n",
      "val loss 2.7914059162139893 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6620192307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7778846153846154}]\n",
      "______epoch 257 _____\n",
      "train imitation 1.1920585632324219 reward 1.5431090593338013\n",
      "val imitation 1.2211167812347412 reward 1.570507287979126\n",
      "val loss 2.791624069213867 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615384}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 258 _____\n",
      "train imitation 1.2535250186920166 reward 1.5432109832763672\n",
      "val imitation 1.221315860748291 reward 1.570507287979126\n",
      "val loss 2.791823148727417 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6649038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 259 _____\n",
      "train imitation 1.2166403532028198 reward 1.5462946891784668\n",
      "val imitation 1.2215501070022583 reward 1.5710384845733643\n",
      "val loss 2.792588710784912 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6649038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 260 _____\n",
      "train imitation 1.2170339822769165 reward 1.548020362854004\n",
      "val imitation 1.2218953371047974 reward 1.5710384845733643\n",
      "val loss 2.792933940887451 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6658653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 261 _____\n",
      "train imitation 1.210892915725708 reward 1.5467571020126343\n",
      "val imitation 1.2220673561096191 reward 1.5710384845733643\n",
      "val loss 2.7931058406829834 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6653846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 262 _____\n",
      "train imitation 1.2088706493377686 reward 1.5452200174331665\n",
      "val imitation 1.221832275390625 reward 1.5710384845733643\n",
      "val loss 2.7928707599639893 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6653846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 263 _____\n",
      "train imitation 1.1644799709320068 reward 1.5453369617462158\n",
      "val imitation 1.221561312675476 reward 1.5710384845733643\n",
      "val loss 2.792599678039551 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6653846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 264 _____\n",
      "train imitation 1.212828516960144 reward 1.5419862270355225\n",
      "val imitation 1.221069574356079 reward 1.5696074962615967\n",
      "val loss 2.790677070617676 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6658653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 265 _____\n",
      "train imitation 1.1970654726028442 reward 1.5394517183303833\n",
      "val imitation 1.220785140991211 reward 1.5696074962615967\n",
      "val loss 2.7903926372528076 2.7904977798461914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.666826923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7766025641025641}]\n",
      "______epoch 266 _____\n",
      "train imitation 1.213484287261963 reward 1.545840859413147\n",
      "val imitation 1.2207880020141602 reward 1.5696074962615967\n",
      "val loss 2.790395498275757 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.666826923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 267 _____\n",
      "train imitation 1.2253814935684204 reward 1.5498250722885132\n",
      "val imitation 1.2208244800567627 reward 1.569972038269043\n",
      "val loss 2.7907965183258057 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.666826923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n",
      "______epoch 268 _____\n",
      "train imitation 1.246215581893921 reward 1.544671893119812\n",
      "val imitation 1.2209993600845337 reward 1.569972038269043\n",
      "val loss 2.790971279144287 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6673076923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 269 _____\n",
      "train imitation 1.2209887504577637 reward 1.5418567657470703\n",
      "val imitation 1.2211453914642334 reward 1.5703911781311035\n",
      "val loss 2.791536569595337 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6663461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 270 _____\n",
      "train imitation 1.2191728353500366 reward 1.5449975728988647\n",
      "val imitation 1.2214138507843018 reward 1.5722787380218506\n",
      "val loss 2.7936925888061523 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6673076923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 271 _____\n",
      "train imitation 1.1682090759277344 reward 1.5489206314086914\n",
      "val imitation 1.2217354774475098 reward 1.5722787380218506\n",
      "val loss 2.7940142154693604 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6673076923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 272 _____\n",
      "train imitation 1.211299180984497 reward 1.544388771057129\n",
      "val imitation 1.2220056056976318 reward 1.5722787380218506\n",
      "val loss 2.7942843437194824 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 273 _____\n",
      "train imitation 1.1971498727798462 reward 1.5450693368911743\n",
      "val imitation 1.2222847938537598 reward 1.5723977088928223\n",
      "val loss 2.794682502746582 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.66875}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 274 _____\n",
      "train imitation 1.2152661085128784 reward 1.542984962463379\n",
      "val imitation 1.2225606441497803 reward 1.5723977088928223\n",
      "val loss 2.7949583530426025 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6697115384615384}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7362938596491228}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 275 _____\n",
      "train imitation 1.1913248300552368 reward 1.5470205545425415\n",
      "val imitation 1.2229962348937988 reward 1.5723977088928223\n",
      "val loss 2.795393943786621 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7373903508771931}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 276 _____\n",
      "train imitation 1.1912117004394531 reward 1.5459082126617432\n",
      "val imitation 1.2235872745513916 reward 1.5723977088928223\n",
      "val loss 2.795984983444214 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7379385964912281}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410257}]\n",
      "______epoch 277 _____\n",
      "train imitation 1.1740431785583496 reward 1.5434023141860962\n",
      "val imitation 1.2242999076843262 reward 1.5723977088928223\n",
      "val loss 2.7966976165771484 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7373903508771931}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7762820512820513}]\n",
      "______epoch 278 _____\n",
      "train imitation 1.2023203372955322 reward 1.5467685461044312\n",
      "val imitation 1.225045919418335 reward 1.5723977088928223\n",
      "val loss 2.7974436283111572 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.66875}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7762820512820513}]\n",
      "______epoch 279 _____\n",
      "train imitation 1.2165007591247559 reward 1.5449278354644775\n",
      "val imitation 1.2256035804748535 reward 1.5723977088928223\n",
      "val loss 2.798001289367676 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7379385964912282}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7759615384615384}]\n",
      "______epoch 280 _____\n",
      "train imitation 1.2193981409072876 reward 1.5456563234329224\n",
      "val imitation 1.2258753776550293 reward 1.5723364353179932\n",
      "val loss 2.7982118129730225 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6692307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7376644736842106}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7759615384615384}]\n",
      "______epoch 281 _____\n",
      "train imitation 1.1707136631011963 reward 1.5483448505401611\n",
      "val imitation 1.22621750831604 reward 1.5723364353179932\n",
      "val loss 2.798553943634033 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6692307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7371162280701755}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410257}]\n",
      "______epoch 282 _____\n",
      "train imitation 1.1839431524276733 reward 1.5496386289596558\n",
      "val imitation 1.2264424562454224 reward 1.5734243392944336\n",
      "val loss 2.7998666763305664 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.66875}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.736842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 283 _____\n",
      "train imitation 1.187679409980774 reward 1.549532175064087\n",
      "val imitation 1.2263743877410889 reward 1.5723364353179932\n",
      "val loss 2.798710823059082 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794872}]\n",
      "______epoch 284 _____\n",
      "train imitation 1.2119741439819336 reward 1.5346462726593018\n",
      "val imitation 1.2264360189437866 reward 1.5723364353179932\n",
      "val loss 2.7987723350524902 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 285 _____\n",
      "train imitation 1.1533056497573853 reward 1.5399456024169922\n",
      "val imitation 1.2265045642852783 reward 1.572661280632019\n",
      "val loss 2.799165725708008 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.66875}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 286 _____\n",
      "train imitation 1.2034943103790283 reward 1.5415668487548828\n",
      "val imitation 1.22629714012146 reward 1.5720871686935425\n",
      "val loss 2.798384189605713 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.66875}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.736842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 287 _____\n",
      "train imitation 1.1963703632354736 reward 1.5420432090759277\n",
      "val imitation 1.2257903814315796 reward 1.5715242624282837\n",
      "val loss 2.7973146438598633 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6692307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 288 _____\n",
      "train imitation 1.2164748907089233 reward 1.5491544008255005\n",
      "val imitation 1.225372076034546 reward 1.5715242624282837\n",
      "val loss 2.796896457672119 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6697115384615384}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7733974358974359}]\n",
      "______epoch 289 _____\n",
      "train imitation 1.2043367624282837 reward 1.5488295555114746\n",
      "val imitation 1.224969744682312 reward 1.5715242624282837\n",
      "val loss 2.7964940071105957 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6701923076923078}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7730769230769231}]\n",
      "______epoch 290 _____\n",
      "train imitation 1.181430459022522 reward 1.5418298244476318\n",
      "val imitation 1.2246569395065308 reward 1.5696369409561157\n",
      "val loss 2.7942938804626465 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6697115384615384}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564103}]\n",
      "______epoch 291 _____\n",
      "train imitation 1.1603529453277588 reward 1.5429210662841797\n",
      "val imitation 1.2243674993515015 reward 1.5691648721694946\n",
      "val loss 2.793532371520996 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6701923076923078}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7362938596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7737179487179487}]\n",
      "______epoch 292 _____\n",
      "train imitation 1.1883091926574707 reward 1.5487498044967651\n",
      "val imitation 1.2239744663238525 reward 1.568207025527954\n",
      "val loss 2.7921814918518066 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6706730769230769}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 293 _____\n",
      "train imitation 1.2162072658538818 reward 1.5441945791244507\n",
      "val imitation 1.2236324548721313 reward 1.567596673965454\n",
      "val loss 2.791229248046875 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6721153846153847}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 294 _____\n",
      "train imitation 1.1970751285552979 reward 1.5419121980667114\n",
      "val imitation 1.2233651876449585 reward 1.5671778917312622\n",
      "val loss 2.7905430793762207 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461538}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 295 _____\n",
      "train imitation 1.2169848680496216 reward 1.537257432937622\n",
      "val imitation 1.223070502281189 reward 1.5669118165969849\n",
      "val loss 2.789982318878174 2.7903926372528076\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6735576923076922}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n",
      "______epoch 296 _____\n",
      "train imitation 1.1962554454803467 reward 1.5411019325256348\n",
      "val imitation 1.2228879928588867 reward 1.566862940788269\n",
      "val loss 2.7897510528564453 2.789982318878174\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6754807692307692}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205128}]\n",
      "______epoch 297 _____\n",
      "train imitation 1.15787935256958 reward 1.5365209579467773\n",
      "val imitation 1.222760796546936 reward 1.5663546323776245\n",
      "val loss 2.7891154289245605 2.7897510528564453\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6759615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7756410256410255}]\n",
      "______epoch 298 _____\n",
      "train imitation 1.2078416347503662 reward 1.5447605848312378\n",
      "val imitation 1.2227437496185303 reward 1.5663546323776245\n",
      "val loss 2.7890982627868652 2.7891154289245605\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.676923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7759615384615384}]\n",
      "______epoch 299 _____\n",
      "train imitation 1.1557786464691162 reward 1.5417890548706055\n",
      "val imitation 1.2229669094085693 reward 1.5653254985809326\n",
      "val loss 2.788292407989502 2.7890982627868652\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6778846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7759615384615385}]\n",
      "______epoch 300 _____\n",
      "train imitation 1.1834032535552979 reward 1.5427732467651367\n",
      "val imitation 1.2234253883361816 reward 1.5655020475387573\n",
      "val loss 2.7889275550842285 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6778846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7766025641025641}]\n",
      "______epoch 301 _____\n",
      "train imitation 1.209377646446228 reward 1.540513038635254\n",
      "val imitation 1.223924160003662 reward 1.5655020475387573\n",
      "val loss 2.789426326751709 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6774038461538462}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7766025641025641}]\n",
      "______epoch 302 _____\n",
      "train imitation 1.1813987493515015 reward 1.5425854921340942\n",
      "val imitation 1.224111795425415 reward 1.5655020475387573\n",
      "val loss 2.789613723754883 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.676923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7769230769230769}]\n",
      "______epoch 303 _____\n",
      "train imitation 1.1923213005065918 reward 1.5544672012329102\n",
      "val imitation 1.2241231203079224 reward 1.5653820037841797\n",
      "val loss 2.7895050048828125 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6778846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435898}]\n",
      "______epoch 304 _____\n",
      "train imitation 1.1535334587097168 reward 1.5440245866775513\n",
      "val imitation 1.2240691184997559 reward 1.5653820037841797\n",
      "val loss 2.7894511222839355 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6774038461538462}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435898}]\n",
      "______epoch 305 _____\n",
      "train imitation 1.2139112949371338 reward 1.5445611476898193\n",
      "val imitation 1.2241419553756714 reward 1.5653820037841797\n",
      "val loss 2.7895240783691406 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6774038461538462}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435898}]\n",
      "______epoch 306 _____\n",
      "train imitation 1.1570724248886108 reward 1.5430450439453125\n",
      "val imitation 1.2243821620941162 reward 1.5653820037841797\n",
      "val loss 2.789764165878296 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6778846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641025}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 307 _____\n",
      "train imitation 1.2289069890975952 reward 1.5439480543136597\n",
      "val imitation 1.2239362001419067 reward 1.5653820037841797\n",
      "val loss 2.789318084716797 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6783653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435896}]\n",
      "______epoch 308 _____\n",
      "train imitation 1.15598464012146 reward 1.5434300899505615\n",
      "val imitation 1.2234879732131958 reward 1.5653340816497803\n",
      "val loss 2.7888221740722656 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6788461538461539}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7324561403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435896}]\n",
      "______epoch 309 _____\n",
      "train imitation 1.1636983156204224 reward 1.5453182458877563\n",
      "val imitation 1.223294973373413 reward 1.5653340816497803\n",
      "val loss 2.7886290550231934 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6802884615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641025}]\n",
      "______epoch 310 _____\n",
      "train imitation 1.1602263450622559 reward 1.5365372896194458\n",
      "val imitation 1.2233508825302124 reward 1.5653340816497803\n",
      "val loss 2.788684844970703 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6807692307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 311 _____\n",
      "train imitation 1.1971540451049805 reward 1.539859652519226\n",
      "val imitation 1.222854733467102 reward 1.5653340816497803\n",
      "val loss 2.788188934326172 2.788292407989502\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6802884615384616}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 312 _____\n",
      "train imitation 1.1690382957458496 reward 1.543131709098816\n",
      "val imitation 1.2222836017608643 reward 1.5653340816497803\n",
      "val loss 2.7876176834106445 2.788188934326172\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6802884615384616}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 313 _____\n",
      "train imitation 1.1795306205749512 reward 1.541386365890503\n",
      "val imitation 1.2213078737258911 reward 1.5654090642929077\n",
      "val loss 2.786716938018799 2.7876176834106445\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 314 _____\n",
      "train imitation 1.1674830913543701 reward 1.5382217168807983\n",
      "val imitation 1.2206939458847046 reward 1.564221739768982\n",
      "val loss 2.7849156856536865 2.786716938018799\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "______epoch 315 _____\n",
      "train imitation 1.2193577289581299 reward 1.5403820276260376\n",
      "val imitation 1.2199151515960693 reward 1.5621459484100342\n",
      "val loss 2.7820611000061035 2.7849156856536865\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 316 _____\n",
      "train imitation 1.2096645832061768 reward 1.5398683547973633\n",
      "val imitation 1.2192082405090332 reward 1.5621459484100342\n",
      "val loss 2.7813541889190674 2.7820611000061035\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 317 _____\n",
      "train imitation 1.2508769035339355 reward 1.536257266998291\n",
      "val imitation 1.2183772325515747 reward 1.5621689558029175\n",
      "val loss 2.780546188354492 2.7813541889190674\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641026}]\n",
      "______epoch 318 _____\n",
      "train imitation 1.1797566413879395 reward 1.5467721223831177\n",
      "val imitation 1.2176504135131836 reward 1.5616332292556763\n",
      "val loss 2.7792835235595703 2.780546188354492\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435898}]\n",
      "______epoch 319 _____\n",
      "train imitation 1.1620495319366455 reward 1.5442074537277222\n",
      "val imitation 1.2170014381408691 reward 1.5616332292556763\n",
      "val loss 2.778634548187256 2.7792835235595703\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7778846153846154}]\n",
      "______epoch 320 _____\n",
      "train imitation 1.187619924545288 reward 1.5395270586013794\n",
      "val imitation 1.2164206504821777 reward 1.5616332292556763\n",
      "val loss 2.7780537605285645 2.778634548187256\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.683173076923077}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641026}]\n",
      "______epoch 321 _____\n",
      "train imitation 1.2007697820663452 reward 1.546444296836853\n",
      "val imitation 1.2157566547393799 reward 1.5616332292556763\n",
      "val loss 2.7773900032043457 2.7780537605285645\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538463}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7775641025641026}]\n",
      "______epoch 322 _____\n",
      "train imitation 1.1822627782821655 reward 1.5483324527740479\n",
      "val imitation 1.2151424884796143 reward 1.5616332292556763\n",
      "val loss 2.77677583694458 2.7773900032043457\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.685096153846154}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7778846153846154}]\n",
      "______epoch 323 _____\n",
      "train imitation 1.2044342756271362 reward 1.5462919473648071\n",
      "val imitation 1.214442253112793 reward 1.5612797737121582\n",
      "val loss 2.775722026824951 2.77677583694458\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "______epoch 324 _____\n",
      "train imitation 1.1511425971984863 reward 1.5492780208587646\n",
      "val imitation 1.2138645648956299 reward 1.5612146854400635\n",
      "val loss 2.7750792503356934 2.775722026824951\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7801282051282051}]\n",
      "______epoch 325 _____\n",
      "train imitation 1.1853233575820923 reward 1.5390903949737549\n",
      "val imitation 1.2134053707122803 reward 1.5603688955307007\n",
      "val loss 2.7737741470336914 2.7750792503356934\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7327302631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7801282051282051}]\n",
      "______epoch 326 _____\n",
      "train imitation 1.1412568092346191 reward 1.537284255027771\n",
      "val imitation 1.2130979299545288 reward 1.5615036487579346\n",
      "val loss 2.774601459503174 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 327 _____\n",
      "train imitation 1.2178138494491577 reward 1.538156509399414\n",
      "val imitation 1.2129765748977661 reward 1.5615036487579346\n",
      "val loss 2.7744803428649902 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897436}]\n",
      "______epoch 328 _____\n",
      "train imitation 1.1122136116027832 reward 1.5447901487350464\n",
      "val imitation 1.213221549987793 reward 1.5616282224655151\n",
      "val loss 2.7748498916625977 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 329 _____\n",
      "train imitation 1.1591808795928955 reward 1.5469942092895508\n",
      "val imitation 1.2140004634857178 reward 1.5612144470214844\n",
      "val loss 2.775214910507202 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7362938596491229}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7823717948717949}]\n",
      "______epoch 330 _____\n",
      "train imitation 1.1477406024932861 reward 1.548797607421875\n",
      "val imitation 1.214813232421875 reward 1.5621916055679321\n",
      "val loss 2.7770047187805176 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7368421052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7833333333333333}]\n",
      "______epoch 331 _____\n",
      "train imitation 1.1695586442947388 reward 1.5427676439285278\n",
      "val imitation 1.21575927734375 reward 1.561044692993164\n",
      "val loss 2.776803970336914 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.683173076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7833333333333333}]\n",
      "______epoch 332 _____\n",
      "train imitation 1.2390027046203613 reward 1.5404185056686401\n",
      "val imitation 1.2162201404571533 reward 1.561044692993164\n",
      "val loss 2.7772648334503174 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.683173076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7836538461538461}]\n",
      "______epoch 333 _____\n",
      "train imitation 1.1651374101638794 reward 1.5422033071517944\n",
      "val imitation 1.2161551713943481 reward 1.561044692993164\n",
      "val loss 2.7771997451782227 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128205}]\n",
      "______epoch 334 _____\n",
      "train imitation 1.1480038166046143 reward 1.5450493097305298\n",
      "val imitation 1.2158417701721191 reward 1.561044692993164\n",
      "val loss 2.776886463165283 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7842948717948719}]\n",
      "______epoch 335 _____\n",
      "train imitation 1.1597614288330078 reward 1.5447689294815063\n",
      "val imitation 1.2152512073516846 reward 1.5594834089279175\n",
      "val loss 2.7747344970703125 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7842948717948719}]\n",
      "______epoch 336 _____\n",
      "train imitation 1.1626365184783936 reward 1.5520421266555786\n",
      "val imitation 1.2146611213684082 reward 1.5594834089279175\n",
      "val loss 2.7741446495056152 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.736842105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7839743589743591}]\n",
      "______epoch 337 _____\n",
      "train imitation 1.1521031856536865 reward 1.5441595315933228\n",
      "val imitation 1.2144111394882202 reward 1.5580766201019287\n",
      "val loss 2.7724876403808594 2.7737741470336914\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7376644736842106}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7839743589743591}]\n",
      "______epoch 338 _____\n",
      "train imitation 1.1947319507598877 reward 1.5409595966339111\n",
      "val imitation 1.21428382396698 reward 1.5580766201019287\n",
      "val loss 2.772360324859619 2.7724876403808594\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7373903508771931}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7833333333333333}]\n",
      "______epoch 339 _____\n",
      "train imitation 1.1883183717727661 reward 1.5446420907974243\n",
      "val imitation 1.214006781578064 reward 1.5580766201019287\n",
      "val loss 2.772083282470703 2.772360324859619\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7382127192982457}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128205}]\n",
      "______epoch 340 _____\n",
      "train imitation 1.1539822816848755 reward 1.5378224849700928\n",
      "val imitation 1.21427583694458 reward 1.5580766201019287\n",
      "val loss 2.772352457046509 2.772083282470703\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128205}]\n",
      "______epoch 341 _____\n",
      "train imitation 1.1904165744781494 reward 1.5437732934951782\n",
      "val imitation 1.2139394283294678 reward 1.5580766201019287\n",
      "val loss 2.7720160484313965 2.772083282470703\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128205}]\n",
      "______epoch 342 _____\n",
      "train imitation 1.1521759033203125 reward 1.5375391244888306\n",
      "val imitation 1.213543176651001 reward 1.5580766201019287\n",
      "val loss 2.7716197967529297 2.7720160484313965\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769232}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7830128205128205}]\n",
      "______epoch 343 _____\n",
      "train imitation 1.156820297241211 reward 1.5347918272018433\n",
      "val imitation 1.213261365890503 reward 1.5580284595489502\n",
      "val loss 2.771289825439453 2.7716197967529297\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7826923076923077}]\n",
      "______epoch 344 _____\n",
      "train imitation 1.1847349405288696 reward 1.5408273935317993\n",
      "val imitation 1.2130944728851318 reward 1.5580284595489502\n",
      "val loss 2.771122932434082 2.771289825439453\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769232}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7823717948717949}]\n",
      "______epoch 345 _____\n",
      "train imitation 1.1616350412368774 reward 1.5399186611175537\n",
      "val imitation 1.2127635478973389 reward 1.5580284595489502\n",
      "val loss 2.770792007446289 2.771122932434082\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769232}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.782051282051282}]\n",
      "______epoch 346 _____\n",
      "train imitation 1.2041267156600952 reward 1.545732855796814\n",
      "val imitation 1.2129104137420654 reward 1.5580284595489502\n",
      "val loss 2.7709388732910156 2.770792007446289\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7826923076923077}]\n",
      "______epoch 347 _____\n",
      "train imitation 1.160651445388794 reward 1.5454002618789673\n",
      "val imitation 1.212956190109253 reward 1.5580284595489502\n",
      "val loss 2.770984649658203 2.770792007446289\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6850961538461539}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7817307692307692}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 348 _____\n",
      "train imitation 1.2183024883270264 reward 1.5460684299468994\n",
      "val imitation 1.2131760120391846 reward 1.5575156211853027\n",
      "val loss 2.7706916332244873 2.770792007446289\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7814102564102564}]\n",
      "______epoch 349 _____\n",
      "train imitation 1.150640845298767 reward 1.5346527099609375\n",
      "val imitation 1.2133232355117798 reward 1.5590181350708008\n",
      "val loss 2.772341251373291 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7814102564102564}]\n",
      "______epoch 350 _____\n",
      "train imitation 1.1936639547348022 reward 1.5453333854675293\n",
      "val imitation 1.2133090496063232 reward 1.5592257976531982\n",
      "val loss 2.7725348472595215 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7817307692307692}]\n",
      "______epoch 351 _____\n",
      "train imitation 1.1788307428359985 reward 1.5435515642166138\n",
      "val imitation 1.2134112119674683 reward 1.5592257976531982\n",
      "val loss 2.772636890411377 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333333}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7820512820512822}]\n",
      "______epoch 352 _____\n",
      "train imitation 1.1421663761138916 reward 1.544195532798767\n",
      "val imitation 1.2138181924819946 reward 1.5592257976531982\n",
      "val loss 2.7730441093444824 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7820512820512822}]\n",
      "______epoch 353 _____\n",
      "train imitation 1.1842209100723267 reward 1.5392014980316162\n",
      "val imitation 1.2144757509231567 reward 1.5592257976531982\n",
      "val loss 2.7737016677856445 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7826923076923077}]\n",
      "______epoch 354 _____\n",
      "train imitation 1.1529889106750488 reward 1.5460612773895264\n",
      "val imitation 1.2151556015014648 reward 1.5601367950439453\n",
      "val loss 2.77529239654541 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7390350877192984}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.782051282051282}]\n",
      "______epoch 355 _____\n",
      "train imitation 1.1846357583999634 reward 1.5412935018539429\n",
      "val imitation 1.2160162925720215 reward 1.5601367950439453\n",
      "val loss 2.776153087615967 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384617}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7393092105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 356 _____\n",
      "train imitation 1.1572563648223877 reward 1.5427988767623901\n",
      "val imitation 1.216981291770935 reward 1.5633560419082642\n",
      "val loss 2.780337333679199 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 357 _____\n",
      "train imitation 1.1256165504455566 reward 1.5444996356964111\n",
      "val imitation 1.2178263664245605 reward 1.5633560419082642\n",
      "val loss 2.781182289123535 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076924}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 358 _____\n",
      "train imitation 1.192962884902954 reward 1.542909860610962\n",
      "val imitation 1.2187082767486572 reward 1.5633560419082642\n",
      "val loss 2.782064437866211 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7814102564102564}]\n",
      "______epoch 359 _____\n",
      "train imitation 1.1505017280578613 reward 1.5355119705200195\n",
      "val imitation 1.2193529605865479 reward 1.5633560419082642\n",
      "val loss 2.7827091217041016 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7810897435897436}]\n",
      "______epoch 360 _____\n",
      "train imitation 1.1607047319412231 reward 1.5463472604751587\n",
      "val imitation 1.2199034690856934 reward 1.5633560419082642\n",
      "val loss 2.783259391784668 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n",
      "______epoch 361 _____\n",
      "train imitation 1.1659404039382935 reward 1.5374188423156738\n",
      "val imitation 1.2200360298156738 reward 1.564549207687378\n",
      "val loss 2.7845852375030518 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n",
      "______epoch 362 _____\n",
      "train imitation 1.1646085977554321 reward 1.5473612546920776\n",
      "val imitation 1.2197520732879639 reward 1.564549207687378\n",
      "val loss 2.784301280975342 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7807692307692308}]\n",
      "______epoch 363 _____\n",
      "train imitation 1.139251470565796 reward 1.548437476158142\n",
      "val imitation 1.2195320129394531 reward 1.5644221305847168\n",
      "val loss 2.78395414352417 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7791666666666667}]\n",
      "______epoch 364 _____\n",
      "train imitation 1.1551116704940796 reward 1.5433292388916016\n",
      "val imitation 1.2192871570587158 reward 1.5644221305847168\n",
      "val loss 2.7837092876434326 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333333}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7791666666666667}]\n",
      "______epoch 365 _____\n",
      "train imitation 1.1553425788879395 reward 1.5467578172683716\n",
      "val imitation 1.2196820974349976 reward 1.5644221305847168\n",
      "val loss 2.784104347229004 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7794871794871795}]\n",
      "______epoch 366 _____\n",
      "train imitation 1.1434403657913208 reward 1.5493992567062378\n",
      "val imitation 1.2204173803329468 reward 1.5644221305847168\n",
      "val loss 2.784839630126953 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333333}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7788461538461539}]\n",
      "______epoch 367 _____\n",
      "train imitation 1.1638590097427368 reward 1.5509058237075806\n",
      "val imitation 1.2212541103363037 reward 1.5644221305847168\n",
      "val loss 2.7856762409210205 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7404057017543859}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7782051282051282}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 368 _____\n",
      "train imitation 1.1379607915878296 reward 1.5415208339691162\n",
      "val imitation 1.2219502925872803 reward 1.5644221305847168\n",
      "val loss 2.786372423171997 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7404057017543859}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7788461538461537}]\n",
      "______epoch 369 _____\n",
      "train imitation 1.148348093032837 reward 1.5427634716033936\n",
      "val imitation 1.2226805686950684 reward 1.5644797086715698\n",
      "val loss 2.7871603965759277 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7794871794871794}]\n",
      "______epoch 370 _____\n",
      "train imitation 1.1549850702285767 reward 1.5454974174499512\n",
      "val imitation 1.223056435585022 reward 1.5644797086715698\n",
      "val loss 2.787536144256592 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7409539473684211}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7788461538461537}]\n",
      "______epoch 371 _____\n",
      "train imitation 1.1822997331619263 reward 1.540755271911621\n",
      "val imitation 1.2225568294525146 reward 1.5644797086715698\n",
      "val loss 2.787036418914795 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7401315789473685}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7791666666666666}]\n",
      "______epoch 372 _____\n",
      "train imitation 1.1070339679718018 reward 1.5465939044952393\n",
      "val imitation 1.221954584121704 reward 1.5644797086715698\n",
      "val loss 2.7864341735839844 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7401315789473685}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7782051282051281}]\n",
      "______epoch 373 _____\n",
      "train imitation 1.1403967142105103 reward 1.5383164882659912\n",
      "val imitation 1.2211277484893799 reward 1.564549207687378\n",
      "val loss 2.785676956176758 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7785256410256409}]\n",
      "______epoch 374 _____\n",
      "train imitation 1.1913901567459106 reward 1.5350914001464844\n",
      "val imitation 1.2208242416381836 reward 1.564549207687378\n",
      "val loss 2.7853734493255615 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7406798245614036}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7785256410256409}]\n",
      "______epoch 375 _____\n",
      "train imitation 1.1407816410064697 reward 1.545214295387268\n",
      "val imitation 1.2207211256027222 reward 1.564549207687378\n",
      "val loss 2.7852702140808105 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7406798245614036}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7785256410256409}]\n",
      "______epoch 376 _____\n",
      "train imitation 1.1731675863265991 reward 1.5462696552276611\n",
      "val imitation 1.219987154006958 reward 1.5639047622680664\n",
      "val loss 2.7838919162750244 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614036}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7782051282051281}]\n",
      "______epoch 377 _____\n",
      "train imitation 1.1940983533859253 reward 1.5467594861984253\n",
      "val imitation 1.2190666198730469 reward 1.5627593994140625\n",
      "val loss 2.7818260192871094 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614036}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7769230769230768}]\n",
      "______epoch 378 _____\n",
      "train imitation 1.1626818180084229 reward 1.5475273132324219\n",
      "val imitation 1.2183815240859985 reward 1.5627593994140625\n",
      "val loss 2.7811408042907715 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7409539473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.776602564102564}]\n",
      "______epoch 379 _____\n",
      "train imitation 1.1486669778823853 reward 1.5449210405349731\n",
      "val imitation 1.2177937030792236 reward 1.5625529289245605\n",
      "val loss 2.780346632003784 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 380 _____\n",
      "train imitation 1.118877649307251 reward 1.5551141500473022\n",
      "val imitation 1.21726393699646 reward 1.5625529289245605\n",
      "val loss 2.7798168659210205 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6879807692307692}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7420504385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 381 _____\n",
      "train imitation 1.1511951684951782 reward 1.542856216430664\n",
      "val imitation 1.2168829441070557 reward 1.5620874166488647\n",
      "val loss 2.778970241546631 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.775}]\n",
      "______epoch 382 _____\n",
      "train imitation 1.186346411705017 reward 1.5476813316345215\n",
      "val imitation 1.2167634963989258 reward 1.5612969398498535\n",
      "val loss 2.7780604362487793 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 383 _____\n",
      "train imitation 1.1346338987350464 reward 1.5408180952072144\n",
      "val imitation 1.2166314125061035 reward 1.5612969398498535\n",
      "val loss 2.777928352355957 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6879807692307692}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589743}]\n",
      "______epoch 384 _____\n",
      "train imitation 1.1500165462493896 reward 1.5376118421554565\n",
      "val imitation 1.2169626951217651 reward 1.5612969398498535\n",
      "val loss 2.778259754180908 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7749999999999999}]\n",
      "______epoch 385 _____\n",
      "train imitation 1.1755539178848267 reward 1.546919584274292\n",
      "val imitation 1.2179235219955444 reward 1.5615187883377075\n",
      "val loss 2.779442310333252 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7762820512820512}]\n",
      "______epoch 386 _____\n",
      "train imitation 1.197291374206543 reward 1.5463262796401978\n",
      "val imitation 1.2188036441802979 reward 1.5617254972457886\n",
      "val loss 2.780529022216797 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7762820512820512}]\n",
      "______epoch 387 _____\n",
      "train imitation 1.1668713092803955 reward 1.5391640663146973\n",
      "val imitation 1.2197860479354858 reward 1.5617254972457886\n",
      "val loss 2.7815115451812744 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7420504385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.776602564102564}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 388 _____\n",
      "train imitation 1.156724214553833 reward 1.5474193096160889\n",
      "val imitation 1.2211552858352661 reward 1.5617254972457886\n",
      "val loss 2.7828807830810547 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7423245614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7772435897435896}]\n",
      "______epoch 389 _____\n",
      "train imitation 1.1393070220947266 reward 1.5455015897750854\n",
      "val imitation 1.2230719327926636 reward 1.5617254972457886\n",
      "val loss 2.784797430038452 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7420504385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 390 _____\n",
      "train imitation 1.126009464263916 reward 1.551119089126587\n",
      "val imitation 1.224608302116394 reward 1.5617254972457886\n",
      "val loss 2.7863337993621826 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7782051282051282}]\n",
      "______epoch 391 _____\n",
      "train imitation 1.157263159751892 reward 1.5497171878814697\n",
      "val imitation 1.226447582244873 reward 1.560729742050171\n",
      "val loss 2.787177324295044 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 392 _____\n",
      "train imitation 1.1724720001220703 reward 1.5510306358337402\n",
      "val imitation 1.2276248931884766 reward 1.560729742050171\n",
      "val loss 2.7883546352386475 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.778525641025641}]\n",
      "______epoch 393 _____\n",
      "train imitation 1.146345853805542 reward 1.5491610765457153\n",
      "val imitation 1.227571725845337 reward 1.5621929168701172\n",
      "val loss 2.789764642715454 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7778846153846154}]\n",
      "______epoch 394 _____\n",
      "train imitation 1.1593133211135864 reward 1.5442183017730713\n",
      "val imitation 1.2278354167938232 reward 1.5622408390045166\n",
      "val loss 2.79007625579834 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6850961538461539}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7769230769230769}]\n",
      "______epoch 395 _____\n",
      "train imitation 1.1884782314300537 reward 1.5450011491775513\n",
      "val imitation 1.2273646593093872 reward 1.5622408390045166\n",
      "val loss 2.7896056175231934 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6850961538461539}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7769230769230769}]\n",
      "______epoch 396 _____\n",
      "train imitation 1.1282997131347656 reward 1.543078899383545\n",
      "val imitation 1.2262476682662964 reward 1.5622408390045166\n",
      "val loss 2.7884883880615234 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333333}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7759615384615385}]\n",
      "______epoch 397 _____\n",
      "train imitation 1.1699590682983398 reward 1.542967677116394\n",
      "val imitation 1.2254157066345215 reward 1.5623998641967773\n",
      "val loss 2.787815570831299 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.775}]\n",
      "______epoch 398 _____\n",
      "train imitation 1.1757512092590332 reward 1.5479923486709595\n",
      "val imitation 1.2245900630950928 reward 1.5623517036437988\n",
      "val loss 2.7869417667388916 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.775}]\n",
      "______epoch 399 _____\n",
      "train imitation 1.1624159812927246 reward 1.5474451780319214\n",
      "val imitation 1.223689317703247 reward 1.5648648738861084\n",
      "val loss 2.7885541915893555 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6850961538461539}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589744}]\n",
      "______epoch 400 _____\n",
      "train imitation 1.132737636566162 reward 1.541355848312378\n",
      "val imitation 1.2234947681427002 reward 1.5648648738861084\n",
      "val loss 2.7883596420288086 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6850961538461539}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564103}]\n",
      "______epoch 401 _____\n",
      "train imitation 1.117943525314331 reward 1.5399503707885742\n",
      "val imitation 1.2236433029174805 reward 1.5648648738861084\n",
      "val loss 2.788508176803589 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153846}]\n",
      "______epoch 402 _____\n",
      "train imitation 1.160125732421875 reward 1.5506930351257324\n",
      "val imitation 1.2240405082702637 reward 1.567711353302002\n",
      "val loss 2.7917518615722656 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7382127192982456}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 403 _____\n",
      "train imitation 1.116049885749817 reward 1.539695143699646\n",
      "val imitation 1.2245562076568604 reward 1.567711353302002\n",
      "val loss 2.7922675609588623 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7384868421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 404 _____\n",
      "train imitation 1.105634331703186 reward 1.5423160791397095\n",
      "val imitation 1.2253538370132446 reward 1.568003535270691\n",
      "val loss 2.7933573722839355 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153847}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948717}]\n",
      "______epoch 405 _____\n",
      "train imitation 1.1325569152832031 reward 1.5529977083206177\n",
      "val imitation 1.2265186309814453 reward 1.568003535270691\n",
      "val loss 2.794522285461426 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.773076923076923}]\n",
      "______epoch 406 _____\n",
      "train imitation 1.1266801357269287 reward 1.5488228797912598\n",
      "val imitation 1.2279471158981323 reward 1.568003535270691\n",
      "val loss 2.7959506511688232 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153845}]\n",
      "______epoch 407 _____\n",
      "train imitation 1.138802170753479 reward 1.549616813659668\n",
      "val imitation 1.2299411296844482 reward 1.568003535270691\n",
      "val loss 2.7979445457458496 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7390350877192982}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948717}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 408 _____\n",
      "train imitation 1.1642241477966309 reward 1.5406465530395508\n",
      "val imitation 1.230198621749878 reward 1.568003535270691\n",
      "val loss 2.7982020378112793 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 409 _____\n",
      "train imitation 1.1457912921905518 reward 1.5463306903839111\n",
      "val imitation 1.229892611503601 reward 1.568003535270691\n",
      "val loss 2.797896146774292 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 410 _____\n",
      "train imitation 1.1276837587356567 reward 1.5446178913116455\n",
      "val imitation 1.2293195724487305 reward 1.568003535270691\n",
      "val loss 2.797323226928711 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7711538461538461}]\n",
      "______epoch 411 _____\n",
      "train imitation 1.1724659204483032 reward 1.547807216644287\n",
      "val imitation 1.2282750606536865 reward 1.567832350730896\n",
      "val loss 2.796107292175293 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6826923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7701923076923076}]\n",
      "______epoch 412 _____\n",
      "train imitation 1.1325430870056152 reward 1.5464085340499878\n",
      "val imitation 1.2275571823120117 reward 1.5683965682983398\n",
      "val loss 2.7959537506103516 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6826923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7701923076923076}]\n",
      "______epoch 413 _____\n",
      "train imitation 1.145826816558838 reward 1.5416442155838013\n",
      "val imitation 1.227041482925415 reward 1.5683965682983398\n",
      "val loss 2.795438051223755 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7698717948717948}]\n",
      "______epoch 414 _____\n",
      "train imitation 1.1118113994598389 reward 1.5432329177856445\n",
      "val imitation 1.2275818586349487 reward 1.5690431594848633\n",
      "val loss 2.7966251373291016 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7698717948717948}]\n",
      "______epoch 415 _____\n",
      "train imitation 1.1506143808364868 reward 1.547292947769165\n",
      "val imitation 1.2286741733551025 reward 1.5690431594848633\n",
      "val loss 2.797717332839966 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6831730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7698717948717948}]\n",
      "______epoch 416 _____\n",
      "train imitation 1.1934854984283447 reward 1.54341721534729\n",
      "val imitation 1.230256199836731 reward 1.5687652826309204\n",
      "val loss 2.7990214824676514 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6826923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7701923076923077}]\n",
      "______epoch 417 _____\n",
      "train imitation 1.1559382677078247 reward 1.542596459388733\n",
      "val imitation 1.2313668727874756 reward 1.5687652826309204\n",
      "val loss 2.8001322746276855 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7705128205128206}]\n",
      "______epoch 418 _____\n",
      "train imitation 1.091881275177002 reward 1.5459513664245605\n",
      "val imitation 1.233054757118225 reward 1.5687652826309204\n",
      "val loss 2.8018200397491455 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7714743589743589}]\n",
      "______epoch 419 _____\n",
      "train imitation 1.1447882652282715 reward 1.5464646816253662\n",
      "val imitation 1.2349045276641846 reward 1.5688676834106445\n",
      "val loss 2.803772211074829 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7733974358974359}]\n",
      "______epoch 420 _____\n",
      "train imitation 1.1428003311157227 reward 1.5443276166915894\n",
      "val imitation 1.2369180917739868 reward 1.5687607526779175\n",
      "val loss 2.8056788444519043 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6826923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7737179487179487}]\n",
      "______epoch 421 _____\n",
      "train imitation 1.1167010068893433 reward 1.5404247045516968\n",
      "val imitation 1.2379796504974365 reward 1.5686335563659668\n",
      "val loss 2.8066132068634033 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6822115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7746794871794871}]\n",
      "______epoch 422 _____\n",
      "train imitation 1.1691118478775024 reward 1.5477550029754639\n",
      "val imitation 1.237416386604309 reward 1.5686335563659668\n",
      "val loss 2.8060498237609863 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6826923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7733974358974359}]\n",
      "______epoch 423 _____\n",
      "train imitation 1.138305902481079 reward 1.5471621751785278\n",
      "val imitation 1.2376351356506348 reward 1.5689432621002197\n",
      "val loss 2.8065783977508545 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7730769230769231}]\n",
      "______epoch 424 _____\n",
      "train imitation 1.091703176498413 reward 1.5425753593444824\n",
      "val imitation 1.2368024587631226 reward 1.5690580606460571\n",
      "val loss 2.8058605194091797 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7730769230769231}]\n",
      "______epoch 425 _____\n",
      "train imitation 1.1493040323257446 reward 1.5472636222839355\n",
      "val imitation 1.2341293096542358 reward 1.5686335563659668\n",
      "val loss 2.802762985229492 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333333}]\n",
      "______epoch 426 _____\n",
      "train imitation 1.0906522274017334 reward 1.5472018718719482\n",
      "val imitation 1.2322475910186768 reward 1.568638563156128\n",
      "val loss 2.8008861541748047 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7404057017543859}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7711538461538462}]\n",
      "______epoch 427 _____\n",
      "train imitation 1.163013219833374 reward 1.539541244506836\n",
      "val imitation 1.2305980920791626 reward 1.568638563156128\n",
      "val loss 2.79923677444458 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7406798245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7698717948717948}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 428 _____\n",
      "train imitation 1.1038633584976196 reward 1.545990228652954\n",
      "val imitation 1.2287447452545166 reward 1.568638563156128\n",
      "val loss 2.7973833084106445 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6836538461538462}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333334}]\n",
      "______epoch 429 _____\n",
      "train imitation 1.1351114511489868 reward 1.5443835258483887\n",
      "val imitation 1.2272142171859741 reward 1.568638563156128\n",
      "val loss 2.7958526611328125 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n",
      "______epoch 430 _____\n",
      "train imitation 1.1273794174194336 reward 1.5475362539291382\n",
      "val imitation 1.2264297008514404 reward 1.568638563156128\n",
      "val loss 2.7950682640075684 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n",
      "______epoch 431 _____\n",
      "train imitation 1.1838390827178955 reward 1.5479904413223267\n",
      "val imitation 1.225326657295227 reward 1.568638563156128\n",
      "val loss 2.7939653396606445 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.771474358974359}]\n",
      "______epoch 432 _____\n",
      "train imitation 1.1713448762893677 reward 1.5425152778625488\n",
      "val imitation 1.2242082357406616 reward 1.5680739879608154\n",
      "val loss 2.7922821044921875 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7420504385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7711538461538462}]\n",
      "______epoch 433 _____\n",
      "train imitation 1.2083888053894043 reward 1.542178750038147\n",
      "val imitation 1.224117636680603 reward 1.5680739879608154\n",
      "val loss 2.792191505432129 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6884615384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7423245614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948718}]\n",
      "______epoch 434 _____\n",
      "train imitation 1.149570107460022 reward 1.5432415008544922\n",
      "val imitation 1.2239549160003662 reward 1.5680739879608154\n",
      "val loss 2.7920289039611816 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875000000000001}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564102}]\n",
      "______epoch 435 _____\n",
      "train imitation 1.172110676765442 reward 1.543196201324463\n",
      "val imitation 1.2241896390914917 reward 1.5680739879608154\n",
      "val loss 2.7922635078430176 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6884615384615386}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564102}]\n",
      "______epoch 436 _____\n",
      "train imitation 1.1577262878417969 reward 1.5366032123565674\n",
      "val imitation 1.2250679731369019 reward 1.5680739879608154\n",
      "val loss 2.7931418418884277 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6889423076923078}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.773076923076923}]\n",
      "______epoch 437 _____\n",
      "train imitation 1.137117862701416 reward 1.548887014389038\n",
      "val imitation 1.2264935970306396 reward 1.5680739879608154\n",
      "val loss 2.794567584991455 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6879807692307692}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384615}]\n",
      "______epoch 438 _____\n",
      "train imitation 1.156719446182251 reward 1.5450284481048584\n",
      "val imitation 1.2282353639602661 reward 1.568239688873291\n",
      "val loss 2.7964749336242676 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7749999999999999}]\n",
      "______epoch 439 _____\n",
      "train imitation 1.1659401655197144 reward 1.5410096645355225\n",
      "val imitation 1.2295676469802856 reward 1.5683706998825073\n",
      "val loss 2.797938346862793 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6865384615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7743589743589743}]\n",
      "______epoch 440 _____\n",
      "train imitation 1.160438060760498 reward 1.542445182800293\n",
      "val imitation 1.2310173511505127 reward 1.5684714317321777\n",
      "val loss 2.7994887828826904 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7412280701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7740384615384616}]\n",
      "______epoch 441 _____\n",
      "train imitation 1.1461728811264038 reward 1.5383754968643188\n",
      "val imitation 1.232679009437561 reward 1.5684714317321777\n",
      "val loss 2.801150321960449 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7730769230769231}]\n",
      "______epoch 442 _____\n",
      "train imitation 1.1667356491088867 reward 1.5454521179199219\n",
      "val imitation 1.233487844467163 reward 1.5689022541046143\n",
      "val loss 2.8023900985717773 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.740953947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7730769230769231}]\n",
      "______epoch 443 _____\n",
      "train imitation 1.1633111238479614 reward 1.548506736755371\n",
      "val imitation 1.2339341640472412 reward 1.5689022541046143\n",
      "val loss 2.8028364181518555 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6846153846153846}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7404057017543859}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7724358974358975}]\n",
      "______epoch 444 _____\n",
      "train imitation 1.1540286540985107 reward 1.5411248207092285\n",
      "val imitation 1.2330665588378906 reward 1.5689022541046143\n",
      "val loss 2.801968812942505 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7401315789473684}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7727564102564103}]\n",
      "______epoch 445 _____\n",
      "train imitation 1.1327073574066162 reward 1.549584150314331\n",
      "val imitation 1.2320687770843506 reward 1.5683397054672241\n",
      "val loss 2.800408363342285 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6870192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7721153846153846}]\n",
      "______epoch 446 _____\n",
      "train imitation 1.108420729637146 reward 1.5366209745407104\n",
      "val imitation 1.231306791305542 reward 1.5683397054672241\n",
      "val loss 2.7996463775634766 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6860576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7717948717948717}]\n",
      "______epoch 447 _____\n",
      "train imitation 1.1591688394546509 reward 1.5449802875518799\n",
      "val imitation 1.2312088012695312 reward 1.568291425704956\n",
      "val loss 2.7995002269744873 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6841346153846154}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7382127192982457}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333334}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 448 _____\n",
      "train imitation 1.1397809982299805 reward 1.544212818145752\n",
      "val imitation 1.230861783027649 reward 1.568291425704956\n",
      "val loss 2.7991533279418945 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7384868421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.769551282051282}]\n",
      "______epoch 449 _____\n",
      "train imitation 1.1461656093597412 reward 1.5468840599060059\n",
      "val imitation 1.2302359342575073 reward 1.5676478147506714\n",
      "val loss 2.7978837490081787 2.7706916332244873\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7376644736842106}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7698717948717948}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7707, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6855769230769231}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7814102564102564}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def shuffle_col(v,col=None):\n",
    "    if col is None:\n",
    "        col = np.random.choice([i for i in range(v.shape[1])])\n",
    "    idx = torch.randperm(v.shape[0])\n",
    "    vv = torch.clone(v)\n",
    "    vv[:,col] = vv[idx,col]\n",
    "    return vv\n",
    "    \n",
    "def train_decision_model(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    lr=.0001,\n",
    "    epochs=10000,\n",
    "    patience=100,\n",
    "    weights=[3,1,1], #realtive weight of survival, feeding tube, and aspiration\n",
    "    imitation_weight=1,\n",
    "    shufflecol_chance = 0.1,\n",
    "    reward_weight=10,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    use_attention=False,\n",
    "    verbose=True,\n",
    "    threshold_decisions=True,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "    \n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids])\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    def outcome_loss(ypred):\n",
    "        #convert survival to death\n",
    "        loss = torch.mul(torch.mean(-1*(ypred[:,0] - 1)),weights[0])\n",
    "        for i,weight in enumerate(weights[1:]):\n",
    "            newloss = torch.mean(ypred[:,i])*weight\n",
    "            loss = torch.add(loss,torch.mul(newloss,weight))\n",
    "        return loss\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    nllloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            \n",
    "            \n",
    "        ytrain = df_to_torch(outcomedf.loc[ids])\n",
    "        #imitation losses and decision 1\n",
    "        xxtrain = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrain]\n",
    "        o1 = model(torch.cat(xxtrain,axis=1),position=0)\n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1 = o1[:,0]\n",
    "        if threshold_decisions:\n",
    "            decision1 = threshold(decision1)\n",
    "#         imitation_loss1 = bce(threshold(decision1_imitation),ytrain[:,0])\n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        decision2_imitation = model(torch.cat(x1_imitation,axis=1),position=1)[:,4]\n",
    "        \n",
    "#         imitation_loss2 =  bce(threshold(decision2_imitation),ytrain[:,1])\n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        decision3_imitation = model(torch.cat(x2_imitation,axis=1),position=2)[:,5]\n",
    "        \n",
    "#         imitation_loss3 = bce(threshold(decision3_imitation),ytrain[:,2])\n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        \n",
    "        #reward decisions\n",
    "        xx1 = makeinput(1,ids)\n",
    "        xx2 = makeinput(2,ids)\n",
    "        xx3 = makeinput(3,ids)\n",
    "\n",
    "        baseline_train_base = formatdf(baseline,ids)\n",
    "            \n",
    "        baseline_train = torch.clone(baseline_train_base)\n",
    "        if train and shufflecol_chance > 0.0001:\n",
    "            for col in range(baseline_train_base.shape[1]): \n",
    "                if np.random.random() < shufflecol_chance:\n",
    "                    baseline_train = shuffle_col(baseline_train,col)\n",
    "                    \n",
    "        \n",
    "        xi1 = torch.cat([xx1,decision1.view(-1,1)],axis=1)\n",
    "        [ypd1, ynd1, ymod, ydlt1] = tmodel1(xi1)\n",
    "        #this outputs log likelihoods (except for dlts) -> convert to probability\n",
    "        ypd1 = torch.exp(ypd1)\n",
    "        ynd1 = torch.exp(ynd1)\n",
    "        ymod = torch.exp(ymod)\n",
    "        x1 = [baseline_train,ydlt1,formatdf(get_dlt(0),ids),ypd1,ynd1,formatdf(get_cc(1),ids),ymod]\n",
    "        \n",
    "        decision2 = model(torch.cat(x1,axis=1),position=1)[:,1] \n",
    "        if threshold_decisions:\n",
    "            decision2 = threshold(decision2)\n",
    "            \n",
    "        xi2 = torch.cat([xx2,decision1.view(-1,1),decision2.view(-1,1)],axis=1)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = tmodel2(xi2)\n",
    "        ypd2 = torch.exp(ypd2)\n",
    "        ynd2 = torch.exp(ynd2)\n",
    "        ycc = torch.exp(ycc)\n",
    "        x2 = [baseline_train,ydlt1,ydlt2,ypd2,ynd2,ycc,ymod]\n",
    "            \n",
    "        decision3 = model(torch.cat(x2,axis=1),position=2)[:,2]\n",
    "        if threshold_decisions:\n",
    "            decision3 = threshold(decision3)\n",
    "            \n",
    "        \n",
    "        xi3 = torch.cat([xx3,decision1.view(-1,1),decision2.view(-1,1),decision3.view(-1,1)],axis=1)\n",
    "        outcomes = tmodel3(xi3)\n",
    "\n",
    "        reward_loss = outcome_loss(outcomes)\n",
    "        loss = torch.add(imitation_loss1,imitation_loss2)\n",
    "        loss = torch.add(loss,imitation_loss3)\n",
    "        loss = torch.mul(loss,imitation_weight/3)\n",
    "        loss = torch.add(loss,torch.mul(reward_loss,reward_weight))\n",
    "        losses = [imitation_loss1+imitation_loss2+imitation_loss3,reward_loss]\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            for i,decision in enumerate([decision1_imitation,decision2_imitation,decision3_imitation]):\n",
    "                dec = decision.cpu().detach().numpy()\n",
    "                dec0 = (dec > .5).astype(int)\n",
    "                out = ytrain[:,i].cpu().detach().numpy()\n",
    "                acc = accuracy_score(out,dec > .5)\n",
    "                auc = roc_auc_score(out,dec)\n",
    "                scores.append({'decision': i,'accuracy': acc,'auc': auc})\n",
    "            return losses, scores\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('train imitation',losses[0].item(),'reward',losses[1].item())\n",
    "            print('val imitation',val_losses[0].item(),'reward',val_losses[1].item())\n",
    "            print('val loss',vl.item(),best_val_loss.item())\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [600], \n",
    "    'attention_heads': [3], \n",
    "    'embed_size': 210, \n",
    "    'dropout': 0.9, \n",
    "    'input_dropout': 0.5, \n",
    "    'shufflecol_chance': 0.1,\n",
    "}\n",
    "decision_model, _, _ = train_decision_model(model1,model2,model3,lr=.0001,use_attention=True,**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "done 0 tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "curr best 100000000000\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.5, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6639254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7371794871794872}]\n",
      "done 1 tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "done 2 tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.664423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7730769230769231}]\n",
      "done 3 tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6596153846153846}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7025767543859649}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7615384615384615}]\n",
      "done 4 tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5918269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897436}]\n",
      "done 5 tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461538}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6636513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7413461538461539}]\n",
      "done 6 tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    }
   ],
   "source": [
    "def gridsearch_decision_model(m1,m2,m3):\n",
    "#     model_arglist = [\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000],\n",
    "#             'attention_heads': [5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [1,1],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [100,100],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [1000,1000],\n",
    "#             'attention_heads': [5,5],\n",
    "#         },\n",
    "#         {\n",
    "#             'hidden_layers': [500,500,500],\n",
    "#             'attention_heads': [5,5,5]\n",
    "#         }\n",
    "#     ]\n",
    "    model_arglist = [\n",
    "\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [50,50],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [2,2],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300,300],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600,600],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [0,120,210]:\n",
    "            #embed_size = 0 skips the firt layer that makes the sizes right\n",
    "            if embed_size == 0 and args['attention_heads'][0] != 1:\n",
    "                continue\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.5,.9]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.5]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    for shufflecol_chance in [.1,.5]:\n",
    "                        args['shufflecol_chance'] = shufflecol_chance\n",
    "                        model,m_metrics,m_loss = train_decision_model(m1,m2,m3,use_attention=True,verbose=False,**args)\n",
    "                        print('done',k,m_loss)\n",
    "                        print('curr best',best_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "\n",
    "from Models import *\n",
    "decision_model = gridsearch_decision_model(model1,model2,model3)\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e098f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_decision_model_statedecisions_input132_dims600_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(decision_model,'../data/models/final_decision_model_' + decision_model.identifier + '.pt')\n",
    "print('../data/models/final_decision_model_' + decision_model.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'../data/models/final_transition1_model_' + model.identifier + '.pt')\n",
    "torch.save(model2,'../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "torch.save(model3,'../data/models/final_outcome_model_' + model3.identifier + '.pt')\n",
    "print('../data/models/final_transition1_model_' + model.identifier + '.pt')\n",
    "print('../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "print('../data/models/final_outcome_model_' + model3.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xatt = []\n",
    "for att,xxdf in zip(list(attributions),xdf):\n",
    "    new = pd.DataFrame(att.cpu().detach().numpy(),columns=xxdf.columns,index=xxdf.index)\n",
    "    xatt.append(new)\n",
    "attributions = pd.concat(xatt,axis=1)\n",
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ca3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(1,1,figsize=(100,100))\n",
    "sns.heatmap(data=attributions.T,ax=fig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakup_state_models(state_model):\n",
    "    #for state 1 and 2\n",
    "    models = {}\n",
    "    models['pd'] = lambda x: state_model(x)[0]\n",
    "    models['nd'] = lambda x: state_model(x)[1]\n",
    "    models['chemo'] = lambda x: state_model(x)[2]\n",
    "    for i,dlt in enumerate(Const.dlt1):\n",
    "        models[dlt] = lambda x: state_model(x)[3][:,i]\n",
    "    return models\n",
    "\n",
    "def breakup_outcome_models(omodel):\n",
    "    models = {}\n",
    "    for i,name in enumerate(Const.outcomes):\n",
    "        models[name] = lambda x: omodel(x)[:,i].reshape(-1,1)\n",
    "    return models\n",
    "\n",
    "def get_all_models(m1,m2,m3):\n",
    "    state1_models = breakup_state_models(m1)\n",
    "    state2_models = breakup_state_models(m2)\n",
    "    state3_models = breakup_outcome_models(m3)\n",
    "    all_models = {}\n",
    "    for i,sm in enumerate([state1_models,state2_models,state3_models]):\n",
    "        for ii,m in sm.items():\n",
    "            all_models[ii +  '_state' + str(i+1)] = m\n",
    "    return all_models\n",
    "\n",
    "all_models = get_all_models(model,model2,model3)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ytrue(name,df):\n",
    "    outcomes=None\n",
    "    value = None\n",
    "    if name == 'pd_state1':\n",
    "        outcomes = df[Const.primary_disease_states]\n",
    "    elif name == 'pd_state2':\n",
    "        outcomes = df[Const.primary_disease_states2]\n",
    "    elif name == 'nd_state1':\n",
    "        outcomes = df[Const.nodal_disease_states]\n",
    "    elif name == 'nd_state2':\n",
    "        outcomes = df[Const.nodal_disease_states2]\n",
    "    elif name == 'chemo_state1':\n",
    "        outcomes = df[Const.modifications]\n",
    "    elif name == 'chemo_state2':\n",
    "        outcomes = df[Const.ccs]   \n",
    "    if outcomes is not None:\n",
    "        value = outcomes.idxmax(axis=1)\n",
    "    if 'DLT' in name:\n",
    "        newname = name.replace('_state', ' ').replace('1','').strip()\n",
    "        value = df[newname]\n",
    "    if name.replace('_state3','') in Const.outcomes:\n",
    "        value = df[name.replace('_state3','')]\n",
    "    if value is None:\n",
    "        print(name,df.columns)\n",
    "    return value\n",
    "\n",
    "def check_impact_of_decisions(model_dict,data):\n",
    "    results = []\n",
    "    #todo: this is wrong fix it\n",
    "    ids = []\n",
    "    df = data.get_data()\n",
    "    outcomedict = {step: pd.concat(data.get_intermediate_outcomes(step=step),axis=1) for step in [1,2,3]}\n",
    "    for decision in Const.decisions:\n",
    "        for name, model in model_dict.items():\n",
    "            step = int(name[-1])\n",
    "            subset0 = dataset.get_input_state(step=step,fixed={decision: 0})\n",
    "            subset1 = dataset.get_input_state(step=step,fixed={decision: 1})\n",
    "            outcomes = outcomedict[step]\n",
    "            ids = subset0.index.values\n",
    "            x0 = df_to_torch(subset0)\n",
    "            x1 = df_to_torch(subset1)\n",
    "            y0 = model(x0).detach().cpu().numpy()\n",
    "            y1 = model(x1).detach().cpu().numpy()\n",
    "            original = data.get_input_state(step=step)\n",
    "            xx = df_to_torch(original)\n",
    "            yy = model(xx).detach().cpu().numpy()\n",
    "            ytrue = get_ytrue(name,outcomes)\n",
    "            if \"DLT\" in name:\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                change = y0 - y1\n",
    "                decision_change = (y0 != y1).astype(int)\n",
    "            elif y0.shape[1] == 1:\n",
    "                change = y1 - y0\n",
    "                decision_change = np.abs((y0 > .5).astype(int) - (y1 > .5).astype(int))\n",
    "            else:\n",
    "                index = np.unravel_index(np.argmax(yy, axis=1), yy.shape)\n",
    "                change = (y0[index] - y1[index]).reshape(-1,1)\n",
    "                decision_change =  (y0.argmax(axis=1).reshape(-1,1) != y1.argmax(axis=1).reshape(-1,1)).astype(int)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "            outcome = name.replace('_state','')\n",
    "            for ii,pid in enumerate(ids):\n",
    "                oo = ytrue.loc[pid]\n",
    "                onew = y0[ii][0]\n",
    "                original_decision = df.loc[pid,decision]\n",
    "                if original_decision > 0:\n",
    "                    onew = y0[ii][0]\n",
    "                oname = Const.name_dict.get(name)\n",
    "                if oname is not None:\n",
    "                    onew = oname[onew]\n",
    "                entry = {'id': pid, 'decision': decision,'outcome': outcome,'original_choice': original_decision, 'original_result': oo, 'alt_result': onew, 'change': change[ii][0], 'decision_change': decision_change[ii][0]}\n",
    "                results.append(entry)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "test = check_impact_of_decisions(all_models,dataset)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db23ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_data()['SD Primary 2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ce1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test[test.outcome == 'pd2'].original_result == 'SD Primary 2').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_impact_of_decisions(all_models,dataset).to_csv('../data/decision_impacts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321249c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
