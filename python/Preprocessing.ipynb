{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "050c878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7418d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score,accuracy_score\n",
    "from Constants import *\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4bcfe12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>1A1B</th>\n",
       "      <th>1A6</th>\n",
       "      <th>1B2A</th>\n",
       "      <th>1B3</th>\n",
       "      <th>2A2B</th>\n",
       "      <th>2A3</th>\n",
       "      <th>2B5A</th>\n",
       "      <th>34</th>\n",
       "      <th>...</th>\n",
       "      <th>1A</th>\n",
       "      <th>1B</th>\n",
       "      <th>2A</th>\n",
       "      <th>2B</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5A</th>\n",
       "      <th>5B</th>\n",
       "      <th>6</th>\n",
       "      <th>RPLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5089</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5087</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1033726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1033946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1035327</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1035635</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1036374</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1180 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  cluster  1A1B  1A6  1B2A  1B3  2A2B  2A3  2B5A   34  ...   1A  \\\n",
       "0           1        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1        5089        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "2        5088        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "3        5087        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "4        5085        1   0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0  ...  0.0   \n",
       "...       ...      ...   ...  ...   ...  ...   ...  ...   ...  ...  ...  ...   \n",
       "1175  1033726        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "1176  1033946        1   0.0  0.0   0.0  0.0   1.0  0.0   0.0  0.0  ...  0.0   \n",
       "1177  1035327        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1178  1035635        1   0.0  0.0   0.0  0.0   1.0  1.0   0.0  0.0  ...  0.0   \n",
       "1179  1036374        1   0.0  0.0   0.0  0.0   0.0  0.0   0.0  0.0  ...  0.0   \n",
       "\n",
       "       1B   2A   2B    3    4   5A   5B    6  RPLN  \n",
       "0     0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1     0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2     0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3     0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "4     0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "1175  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1176  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1177  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1178  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "1179  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[1180 rows x 27 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/digital_twin_ln_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "be070e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>L1A</th>\n",
       "      <th>L1B</th>\n",
       "      <th>L2A</th>\n",
       "      <th>L2B</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5A</th>\n",
       "      <th>L5B</th>\n",
       "      <th>L6</th>\n",
       "      <th>...</th>\n",
       "      <th>R1A</th>\n",
       "      <th>R1B</th>\n",
       "      <th>R2A</th>\n",
       "      <th>R2B</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5A</th>\n",
       "      <th>R5B</th>\n",
       "      <th>R6</th>\n",
       "      <th>RRPLN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>10202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>10203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>10204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>10205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  L1A  L1B  L2A  L2B   L3   L4  L5A  L5B   L6  ...  R1A  R1B  R2A  \\\n",
       "0        3  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1        5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "2        6  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "3        7  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "..     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "531  10201  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "532  10202  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "533  10203  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "534  10204  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
       "535  10205  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "     R2B   R3   R4  R5A  R5B   R6  RRPLN  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "1    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "2    1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "4    1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "..   ...  ...  ...  ...  ...  ...    ...  \n",
       "531  0.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "532  1.0  0.0  0.0  0.0  0.0  0.0    0.0  \n",
       "533  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "534  1.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "535  0.0  1.0  0.0  0.0  0.0  0.0    0.0  \n",
       "\n",
       "[536 rows x 21 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/digital_twin_ln_monograms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c427599a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpv</th>\n",
       "      <th>age</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>bilateral</th>\n",
       "      <th>cc_none</th>\n",
       "      <th>...</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>6_contra</th>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <th>RPLN_contra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55.969444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>45.950000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>49.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpv        age  packs_per_year  smoking_status  gender  \\\n",
       "id                                                              \n",
       "3        1  55.969444             0.0             0.0       1   \n",
       "5        0  20.950000            38.0             1.0       1   \n",
       "6        1  69.930556            35.0             1.0       0   \n",
       "7        1  72.319444             0.0             1.0       1   \n",
       "8        1  59.730556             0.0             0.0       1   \n",
       "...    ...        ...             ...             ...     ...   \n",
       "10201    1  49.566667            30.0             1.0       1   \n",
       "10202    0  48.705556            30.0             1.0       1   \n",
       "10203    1  77.116667             0.0             0.0       1   \n",
       "10204    0  45.950000             5.0             0.5       1   \n",
       "10205    1  49.733333             0.0             0.0       1   \n",
       "\n",
       "       Aspiration rate Pre-therapy  total_dose  dose_fraction  bilateral  \\\n",
       "id                                                                         \n",
       "3                                0       66.00       2.200000      False   \n",
       "5                                0       72.00       1.800000      False   \n",
       "6                                1       70.00       2.121212       True   \n",
       "7                                0       70.00       2.121212      False   \n",
       "8                                0       66.00       2.200000      False   \n",
       "...                            ...         ...            ...        ...   \n",
       "10201                            0       70.00       2.121212      False   \n",
       "10202                            0       72.00       1.714286      False   \n",
       "10203                            0       70.00       2.333333      False   \n",
       "10204                            0       69.96       2.120000       True   \n",
       "10205                            0       69.96       2.120000      False   \n",
       "\n",
       "       cc_none  ...  4_ipsi  4_contra  5A_ipsi  5A_contra  5B_ipsi  5B_contra  \\\n",
       "id              ...                                                             \n",
       "3            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "5            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "6            0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "7            1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "8            1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "...        ...  ...     ...       ...      ...        ...      ...        ...   \n",
       "10201        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10202        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10203        1  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10204        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "10205        0  ...     0.0       0.0      0.0        0.0      0.0        0.0   \n",
       "\n",
       "       6_ipsi  6_contra  RPLN_ipsi  RPLN_contra  \n",
       "id                                               \n",
       "3         0.0       0.0        0.0          0.0  \n",
       "5         0.0       0.0        0.0          0.0  \n",
       "6         0.0       0.0        0.0          0.0  \n",
       "7         0.0       0.0        0.0          0.0  \n",
       "8         0.0       0.0        0.0          0.0  \n",
       "...       ...       ...        ...          ...  \n",
       "10201     0.0       0.0        0.0          0.0  \n",
       "10202     0.0       0.0        0.0          0.0  \n",
       "10203     0.0       0.0        0.0          0.0  \n",
       "10204     0.0       0.0        0.0          0.0  \n",
       "10205     0.0       0.0        0.0          0.0  \n",
       "\n",
       "[536 rows x 98 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset(use_smote=False,smote_ids = Const.stratified_train_ids,ln_data_file = '../data/digital_twin_ln_monograms.csv')\n",
    "data.processed_df#.shape, len(data.processed_df.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5f57ff90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DLT (Y/N)</th>\n",
       "      <th>DLT_Dermatological</th>\n",
       "      <th>DLT_Neurological</th>\n",
       "      <th>DLT_Gastrointestinal</th>\n",
       "      <th>DLT_Hematological</th>\n",
       "      <th>DLT_Nephrological</th>\n",
       "      <th>DLT_Vascular</th>\n",
       "      <th>DLT_Infection (Pneumonia)</th>\n",
       "      <th>DLT_Grade</th>\n",
       "      <th>DLT_Other</th>\n",
       "      <th>DLT_Dermatological 2</th>\n",
       "      <th>DLT_Neurological 2</th>\n",
       "      <th>DLT_Gastrointestinal 2</th>\n",
       "      <th>DLT_Hematological 2</th>\n",
       "      <th>DLT_Nephrological 2</th>\n",
       "      <th>DLT_Vascular 2</th>\n",
       "      <th>DLT_Infection (Pneumonia) 2</th>\n",
       "      <th>DLT_Other 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DLT (Y/N)  DLT_Dermatological  DLT_Neurological  DLT_Gastrointestinal  \\\n",
       "id                                                                             \n",
       "200            1                 0.0               0.0                   0.0   \n",
       "213            1                 0.0               0.0                   0.0   \n",
       "10136          1                 0.0               0.0                   0.0   \n",
       "\n",
       "       DLT_Hematological  DLT_Nephrological  DLT_Vascular  \\\n",
       "id                                                          \n",
       "200                  1.0                1.0           0.0   \n",
       "213                  0.0                1.0           0.0   \n",
       "10136                0.0                1.0           0.0   \n",
       "\n",
       "       DLT_Infection (Pneumonia)  DLT_Grade  DLT_Other  DLT_Dermatological 2  \\\n",
       "id                                                                             \n",
       "200                          0.0          4        0.0                   0.0   \n",
       "213                          0.0          4        0.0                   0.0   \n",
       "10136                        1.0          3        0.0                   0.0   \n",
       "\n",
       "       DLT_Neurological 2  DLT_Gastrointestinal 2  DLT_Hematological 2  \\\n",
       "id                                                                       \n",
       "200                   0.0                     0.0                  0.0   \n",
       "213                   0.0                     0.0                  0.0   \n",
       "10136                 0.0                     0.0                  0.0   \n",
       "\n",
       "       DLT_Nephrological 2  DLT_Vascular 2  DLT_Infection (Pneumonia) 2  \\\n",
       "id                                                                        \n",
       "200                    0.0             0.0                          0.0   \n",
       "213                    0.0             0.0                          0.0   \n",
       "10136                  0.0             0.0                          0.0   \n",
       "\n",
       "       DLT_Other 2  \n",
       "id                  \n",
       "200            0.0  \n",
       "213            0.0  \n",
       "10136          0.0  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data.processed_df[data.processed_df['DLT_Nephrological'].apply(lambda x: x>0)]\n",
    "temp[[c for c in data.processed_df if 'DLT' in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c766fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Const.data_dir + '/models/'\n",
    "\n",
    "tuned_transition_models = [\n",
    "    'final_transition1_model_state1_input63_dims500,500_dropout0.25,0.5.pt',\n",
    "    'final_transition2_model_state2_input85_dims100_dropout0.25,0.pt',\n",
    "    'final_outcome_model_state1_input83_dims1000_dropout0,0.pt'\n",
    "]\n",
    "tuned_transition_models = [model_dir + f for f in tuned_transition_models]\n",
    "Const.tuned_transition_models = tuned_transition_models\n",
    "Const.tuned_decision_model = model_dir +  'final_decision_model_statedecisions_input132_dims100,100_dropout0.1,0.7.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3c748333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_ids():\n",
    "    df = load_digital_twin()\n",
    "    return df.id.values\n",
    "\n",
    "def get_tt_split(ids=None,use_default_split=True,use_bagging_split=False,resample_training=False):\n",
    "        if ids is None:\n",
    "            ids = get_dt_ids()\n",
    "        #pre-made, stratified by decision and outcome 72:28\n",
    "        if use_default_split:\n",
    "            train_ids = Const.stratified_train_ids[:]\n",
    "            test_ids = Const.stratified_test_ids[:]\n",
    "        elif use_bagging_split:\n",
    "            train_ids = np.random.choice(ids,len(ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        else:\n",
    "            test_ids = ids[0: int(len(ids)*(1-split))]\n",
    "            train_ids = [i for i in ids if i not in test_ids]\n",
    "\n",
    "        if resample_training:\n",
    "            train_ids = np.random.choice(train_ids,len(train_ids),replace=True)\n",
    "            test_ids = [i for i in ids if i not in train_ids]\n",
    "        return train_ids,test_ids\n",
    "    \n",
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5ef50362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(ytrue,ypred):\n",
    "    #nll loss with argmax added in\n",
    "    loss = torch.nn.NLLLoss()\n",
    "    return loss(ypred,ytrue.argmax(axis=1))\n",
    "\n",
    "def state_loss(ytrue,ypred,weights=[1,1,1,1]):\n",
    "    pd_loss = nllloss(ytrue[0],ypred[0])*weights[0]\n",
    "    nd_loss = nllloss(ytrue[1],ypred[1])*weights[1]\n",
    "    mod_loss = nllloss(ytrue[2],ypred[2])*weights[2]\n",
    "    loss = pd_loss + nd_loss + mod_loss\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "#     nloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    for i in range(ndlt):\n",
    "        dlt_loss = bce(dlt_pred[:,i].view(-1),dlt_true[:,i].view(-1))\n",
    "        loss += dlt_loss*weights[3]/ndlt\n",
    "    return loss\n",
    "\n",
    "def outcome_loss(ytrue,ypred,weights=[1,1,1]):\n",
    "    loss = 0\n",
    "    nloss = torch.nn.BCELoss()\n",
    "    for i in range(len(weights)):\n",
    "        iloss = nloss(ypred[:,i],ytrue[i])*weights[i]\n",
    "        loss += iloss\n",
    "    return loss\n",
    "\n",
    "def mc_metrics(yt,yp,numpy=False,is_dlt=False):\n",
    "    if not numpy:\n",
    "        yt = yt .cpu().detach().numpy()\n",
    "        yp = yp.cpu().detach().numpy()\n",
    "    #dlt prediction (binary)\n",
    "    if is_dlt:\n",
    "        acc = accuracy_score(yt,yp>.5)\n",
    "        if yt.sum() > 1:\n",
    "            auc = roc_auc_score(yt,yp)\n",
    "        else:\n",
    "            auc=-1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': acc, 'mse': error, 'auc': auc}\n",
    "    #this is a catch for when I se the dlt prediction format (encoded integer ordinal, predict as a categorical and take the argmax)\n",
    "    elif yt.ndim > 1:\n",
    "        try:\n",
    "            bacc = balanced_accuracy_score(yt.argmax(axis=1),yp.argmax(axis=1))\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc_micro = roc_auc_score(yt,yp,average='micro')\n",
    "        except:\n",
    "            roc_micro=-1\n",
    "        try:\n",
    "            roc_macro = roc_auc_score(yt,yp,average='macro')\n",
    "        except:\n",
    "            roc_macro = -1\n",
    "        return {'accuracy': bacc, 'roc_micro': roc_micro,'roc_macro': roc_macro}\n",
    "    #outcomes (binary)\n",
    "    else:\n",
    "        if yp.ndim > 1:\n",
    "            yp = yp.argmax(axis=1)\n",
    "        try:\n",
    "            bacc = accuracy_score(yt,yp)\n",
    "        except:\n",
    "            bacc = -1\n",
    "        try:\n",
    "            roc = roc_auc_score(yt,yp)\n",
    "        except:\n",
    "            roc = -1\n",
    "        error = np.mean((yt-yp)**2)\n",
    "        return {'accuracy': bacc, 'mse': error, 'auc': roc}\n",
    "\n",
    "def state_metrics(ytrue,ypred,numpy=False):\n",
    "    pd_metrics = mc_metrics(ytrue[0],ypred[0],numpy=numpy)\n",
    "    nd_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    mod_metrics = mc_metrics(ytrue[1],ypred[1],numpy=numpy)\n",
    "    \n",
    "    dlt_metrics = []\n",
    "    dlt_true = ytrue[3]\n",
    "    dlt_pred = ypred[3]\n",
    "    ndlt = dlt_true.shape[1]\n",
    "    nloss = torch.nn.NLLLoss()\n",
    "    for i in range(ndlt):\n",
    "        dm = mc_metrics(dlt_true[:,i],dlt_pred[:,i].view(-1),is_dlt=True)\n",
    "        dlt_metrics.append(dm)\n",
    "    dlt_acc =[d['accuracy'] for d in dlt_metrics]\n",
    "    dlt_error = [d['mse'] for d in dlt_metrics]\n",
    "    dlt_auc = [d['auc'] for d in dlt_metrics]\n",
    "    return {'pd': pd_metrics,'nd': nd_metrics,'mod': mod_metrics,'dlts': {'accuracy': dlt_acc,'accuracy_mean': np.mean(dlt_acc),'auc': dlt_auc,'auc_mean': np.mean(dlt_auc)}}\n",
    "    \n",
    "def outcome_metrics(ytrue,ypred,numpy=False):\n",
    "    res = {}\n",
    "    for i, outcome in enumerate(Const.outcomes):\n",
    "        metrics = mc_metrics(ytrue[i],ypred[:,i])\n",
    "        res[outcome] = metrics\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e95667ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hpv', 'age', 'packs_per_year', 'smoking_status', 'gender',\n",
      "       'Aspiration rate Pre-therapy', 'total_dose', 'dose_fraction', '1A1B',\n",
      "       '1A6',\n",
      "       ...\n",
      "       'SD Primary 2', 'CR Nodal 2', 'PR Nodal 2', 'SD Nodal 2',\n",
      "       'Decision 1 (Induction Chemo) Y/N', 'Decision 2 (CC / RT alone)',\n",
      "       'Decision 3 Neck Dissection (Y/N)', 'Overall Survival (4 Years)', 'FT',\n",
      "       'Aspiration rate Post-therapy'],\n",
      "      dtype='object', length=111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pd1': {'accuracy': 0.36326291079812206,\n",
       "  'roc_micro': 0.5126910126910126,\n",
       "  'roc_macro': 0.5150862068965517},\n",
       " 'nd1': {'accuracy': 0.38838037121789987,\n",
       "  'roc_micro': 0.5717430717430717,\n",
       "  'roc_macro': 0.5260869565217391},\n",
       " 'mod': {'accuracy': 0.16666666666666666,\n",
       "  'roc_micro': 0.515527950310559,\n",
       "  'roc_macro': -1}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_state_rf(model_args={}):\n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    dataset = DTDataset()\n",
    "\n",
    "    train_ids = ids[0:int(len(ids)*.7)]\n",
    "    test_ids = ids[int(len(ids)*.7):]\n",
    "    \n",
    "    #most things are multiclass, dlts are several ordinal and outcomes are multiple binary\n",
    "    xtrain1 = dataset.get_state('baseline',ids=train_ids)\n",
    "    xtest1 = dataset.get_state('baseline',ids=test_ids)\n",
    "    \n",
    "    xtrain2 = dataset.get_input_state(step=2,ids=train_ids)\n",
    "    xtest2 = dataset.get_input_state(step=2,ids=test_ids)\n",
    "    \n",
    "    xtrain3 = dataset.get_input_state(step=3,ids=train_ids)\n",
    "    xtest3 = dataset.get_input_state(step=3,ids=test_ids)\n",
    "    \n",
    "    [pd1_train,nd1_train, mod_train,dlts1_train] = dataset.get_intermediate_outcomes(ids=train_ids)\n",
    "    [pd2_train,nd2_train, cc_train,dlts2_train] = dataset.get_intermediate_outcomes(step=2,ids=train_ids)\n",
    "    [pd1_test,nd1_test, mod_test,dlts1_test] = dataset.get_intermediate_outcomes(ids=test_ids)\n",
    "    [pd2_test,nd2_test, cc_test,dlts2_test] = dataset.get_intermediate_outcomes(step=2,ids=test_ids)\n",
    "    outcomes_train = dataset.get_state('outcomes',ids=train_ids)\n",
    "    outcomes_test = dataset.get_state('outcomes',ids=test_ids)\n",
    "    \n",
    "\n",
    "    def train_multiclass_rf(xtrain,xtest,ytrain,ytest):\n",
    "        model = RandomForestClassifier(class_weight='balanced',**model_args).fit(xtrain,ytrain)\n",
    "        ypred = model.predict(xtest)\n",
    "        metrics = mc_metrics(ytest.values,ypred,numpy=True)\n",
    "        return model, metrics\n",
    "    \n",
    "    all_metrics = {}\n",
    "    pd1_model, all_metrics['pd1'] = train_multiclass_rf(xtrain1,xtest1,pd1_train,pd1_test)\n",
    "    nd1_model, all_metrics['nd1']  = train_multiclass_rf(xtrain1,xtest1,nd1_train,nd1_test)\n",
    "    mod_model, all_metrics['mod']  = train_multiclass_rf(xtrain1,xtest1,mod_train,mod_test)\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "train_state_rf({'max_depth': 5,'n_estimators': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a513da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>10196</th>\n",
       "      <th>10197</th>\n",
       "      <th>10198</th>\n",
       "      <th>10199</th>\n",
       "      <th>10200</th>\n",
       "      <th>10201</th>\n",
       "      <th>10202</th>\n",
       "      <th>10203</th>\n",
       "      <th>10204</th>\n",
       "      <th>10205</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_contra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5A_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5B_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT (Y/N)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLT_Grade</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pathological Grade_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_contra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-category_4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>55.969444</td>\n",
       "      <td>20.95</td>\n",
       "      <td>69.930556</td>\n",
       "      <td>72.319444</td>\n",
       "      <td>59.730556</td>\n",
       "      <td>60.083333</td>\n",
       "      <td>67.708333</td>\n",
       "      <td>57.858333</td>\n",
       "      <td>51.758333</td>\n",
       "      <td>56.25</td>\n",
       "      <td>...</td>\n",
       "      <td>47.619444</td>\n",
       "      <td>50.163889</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>67.825</td>\n",
       "      <td>56.336111</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>48.705556</td>\n",
       "      <td>77.116667</td>\n",
       "      <td>45.95</td>\n",
       "      <td>49.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilateral</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose_fraction</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hpv</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>packs_per_year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_BOT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_GPS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_NOS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dose</th>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows × 536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "id                               3      5          6          7      \\\n",
       "1A_contra                          0.0    0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0    0.0        0.0        0.0   \n",
       "1B_contra                          0.0    0.0        0.0        1.0   \n",
       "1B_ipsi                            0.0    0.0        0.0        0.0   \n",
       "2A_contra                          1.0    0.0        1.0        0.0   \n",
       "2A_ipsi                            0.0    1.0        1.0        0.0   \n",
       "2B_contra                          1.0    0.0        1.0        0.0   \n",
       "2B_ipsi                            0.0    1.0        1.0        0.0   \n",
       "3_contra                           0.0    0.0        1.0        0.0   \n",
       "3_ipsi                             0.0    0.0        1.0        0.0   \n",
       "4_contra                           0.0    0.0        0.0        0.0   \n",
       "4_ipsi                             0.0    0.0        0.0        0.0   \n",
       "5A_contra                          0.0    0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0    0.0        0.0        0.0   \n",
       "5B_contra                          0.0    0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0    0.0        0.0        0.0   \n",
       "6_contra                           0.0    0.0        0.0        0.0   \n",
       "6_ipsi                             0.0    0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0      0          1          0   \n",
       "DLT (Y/N)                            0      0          0          0   \n",
       "DLT_Grade                            0      0          0          0   \n",
       "N-category_0                         0      0          0          0   \n",
       "N-category_1                         1      0          0          0   \n",
       "N-category_2                         0      1          1          1   \n",
       "N-category_3                         0      0          0          0   \n",
       "Pathological Grade_0                 1      0          0          1   \n",
       "Pathological Grade_1                 0      0          0          0   \n",
       "Pathological Grade_2                 0      1          1          0   \n",
       "Pathological Grade_3                 0      0          0          0   \n",
       "Pathological Grade_4                 0      0          0          0   \n",
       "RPLN_contra                        0.0    0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0    0.0        0.0        0.0   \n",
       "T-category_1                         0      0          0          1   \n",
       "T-category_2                         1      0          0          0   \n",
       "T-category_3                         0      0          0          0   \n",
       "T-category_4                         0      1          1          0   \n",
       "age                          55.969444  20.95  69.930556  72.319444   \n",
       "bilateral                        False  False       True      False   \n",
       "dose_fraction                      2.2    1.8   2.121212   2.121212   \n",
       "gender                               1      1          0          1   \n",
       "hpv                                  1      0          1          1   \n",
       "packs_per_year                     0.0   38.0       35.0        0.0   \n",
       "smoking_status                     0.0    1.0        1.0        1.0   \n",
       "subsite_BOT                          1      1          1          0   \n",
       "subsite_GPS                          0      0          0          0   \n",
       "subsite_NOS                          0      0          0          1   \n",
       "subsite_Soft palate                  0      0          0          0   \n",
       "subsite_Tonsil                       0      0          0          0   \n",
       "total_dose                        66.0   72.0       70.0       70.0   \n",
       "\n",
       "id                               8          9          10         11     \\\n",
       "1A_contra                          0.0        0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0        0.0        0.0        0.0   \n",
       "1B_contra                          0.0        0.0        0.0        0.0   \n",
       "1B_ipsi                            0.0        0.0        0.0        0.0   \n",
       "2A_contra                          0.0        0.0        0.0        0.0   \n",
       "2A_ipsi                            1.0        1.0        1.0        1.0   \n",
       "2B_contra                          0.0        0.0        0.0        0.0   \n",
       "2B_ipsi                            1.0        1.0        1.0        1.0   \n",
       "3_contra                           0.0        0.0        0.0        0.0   \n",
       "3_ipsi                             0.0        0.0        0.0        1.0   \n",
       "4_contra                           0.0        0.0        0.0        0.0   \n",
       "4_ipsi                             0.0        0.0        0.0        0.0   \n",
       "5A_contra                          0.0        0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0        0.0        0.0        0.0   \n",
       "5B_contra                          0.0        0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0        0.0        0.0        0.0   \n",
       "6_contra                           0.0        0.0        0.0        0.0   \n",
       "6_ipsi                             0.0        0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0          0          0          0   \n",
       "DLT (Y/N)                            0          0          0          0   \n",
       "DLT_Grade                            0          0          0          0   \n",
       "N-category_0                         0          0          0          0   \n",
       "N-category_1                         1          1          1          1   \n",
       "N-category_2                         0          0          0          0   \n",
       "N-category_3                         0          0          0          0   \n",
       "Pathological Grade_0                 0          0          0          0   \n",
       "Pathological Grade_1                 0          0          0          0   \n",
       "Pathological Grade_2                 0          0          1          1   \n",
       "Pathological Grade_3                 1          1          0          0   \n",
       "Pathological Grade_4                 0          0          0          0   \n",
       "RPLN_contra                        0.0        0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0        0.0        0.0        0.0   \n",
       "T-category_1                         1          1          0          0   \n",
       "T-category_2                         0          0          0          1   \n",
       "T-category_3                         0          0          1          0   \n",
       "T-category_4                         0          0          0          0   \n",
       "age                          59.730556  60.083333  67.708333  57.858333   \n",
       "bilateral                        False      False      False      False   \n",
       "dose_fraction                      2.2        2.2       2.12   2.121212   \n",
       "gender                               1          1          1          1   \n",
       "hpv                                  1          1         -1          1   \n",
       "packs_per_year                     0.0        0.0       40.0       44.0   \n",
       "smoking_status                     0.0        0.0        1.0        1.0   \n",
       "subsite_BOT                          0          1          1          0   \n",
       "subsite_GPS                          0          0          0          0   \n",
       "subsite_NOS                          0          0          0          1   \n",
       "subsite_Soft palate                  0          0          0          0   \n",
       "subsite_Tonsil                       1          0          0          0   \n",
       "total_dose                        66.0       66.0      69.96       70.0   \n",
       "\n",
       "id                               13        14     ...      10196      10197  \\\n",
       "1A_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "1A_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "1B_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "1B_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "2A_contra                          1.0       0.0  ...        0.0        0.0   \n",
       "2A_ipsi                            1.0       1.0  ...        0.0        1.0   \n",
       "2B_contra                          1.0       0.0  ...        0.0        0.0   \n",
       "2B_ipsi                            1.0       1.0  ...        0.0        1.0   \n",
       "3_contra                           0.0       1.0  ...        0.0        0.0   \n",
       "3_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "4_contra                           0.0       0.0  ...        0.0        0.0   \n",
       "4_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "5A_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "5A_ipsi                            0.0       0.0  ...        1.0        0.0   \n",
       "5B_contra                          0.0       0.0  ...        0.0        0.0   \n",
       "5B_ipsi                            0.0       0.0  ...        0.0        0.0   \n",
       "6_contra                           0.0       0.0  ...        0.0        0.0   \n",
       "6_ipsi                             0.0       0.0  ...        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0         0  ...          0          0   \n",
       "DLT (Y/N)                            0         0  ...          0          1   \n",
       "DLT_Grade                            0         0  ...          0          2   \n",
       "N-category_0                         0         0  ...          0          0   \n",
       "N-category_1                         0         0  ...          0          0   \n",
       "N-category_2                         1         1  ...          1          0   \n",
       "N-category_3                         0         0  ...          0          1   \n",
       "Pathological Grade_0                 0         0  ...          1          0   \n",
       "Pathological Grade_1                 0         0  ...          0          0   \n",
       "Pathological Grade_2                 1         0  ...          0          1   \n",
       "Pathological Grade_3                 0         1  ...          0          0   \n",
       "Pathological Grade_4                 0         0  ...          0          0   \n",
       "RPLN_contra                        0.0       0.0  ...        0.0        0.0   \n",
       "RPLN_ipsi                          0.0       0.0  ...        1.0        0.0   \n",
       "T-category_1                         0         0  ...          0          0   \n",
       "T-category_2                         0         1  ...          1          0   \n",
       "T-category_3                         0         0  ...          0          1   \n",
       "T-category_4                         1         0  ...          0          0   \n",
       "age                          51.758333     56.25  ...  47.619444  50.163889   \n",
       "bilateral                         True     False  ...      False      False   \n",
       "dose_fraction                      2.0  2.121212  ...   2.121212        1.8   \n",
       "gender                               1         1  ...          0          1   \n",
       "hpv                                  0         1  ...          0          1   \n",
       "packs_per_year                     0.0      40.0  ...        5.0        0.0   \n",
       "smoking_status                     0.0       1.0  ...        0.5        0.0   \n",
       "subsite_BOT                          1         1  ...          0          1   \n",
       "subsite_GPS                          0         0  ...          0          0   \n",
       "subsite_NOS                          0         0  ...          0          0   \n",
       "subsite_Soft palate                  0         0  ...          0          0   \n",
       "subsite_Tonsil                       0         0  ...          1          0   \n",
       "total_dose                        70.0      70.0  ...       70.0       72.0   \n",
       "\n",
       "id                               10198     10199      10200      10201  \\\n",
       "1A_contra                          0.0       0.0        0.0        0.0   \n",
       "1A_ipsi                            0.0       0.0        0.0        0.0   \n",
       "1B_contra                          0.0       0.0        0.0        0.0   \n",
       "1B_ipsi                            0.0       0.0        0.0        0.0   \n",
       "2A_contra                          0.0       1.0        0.0        0.0   \n",
       "2A_ipsi                            1.0       0.0        0.0        1.0   \n",
       "2B_contra                          0.0       1.0        0.0        0.0   \n",
       "2B_ipsi                            1.0       0.0        0.0        1.0   \n",
       "3_contra                           0.0       1.0        0.0        0.0   \n",
       "3_ipsi                             0.0       0.0        1.0        0.0   \n",
       "4_contra                           0.0       0.0        0.0        0.0   \n",
       "4_ipsi                             0.0       0.0        0.0        0.0   \n",
       "5A_contra                          0.0       0.0        0.0        0.0   \n",
       "5A_ipsi                            0.0       0.0        0.0        0.0   \n",
       "5B_contra                          0.0       0.0        0.0        0.0   \n",
       "5B_ipsi                            0.0       0.0        0.0        0.0   \n",
       "6_contra                           0.0       0.0        0.0        0.0   \n",
       "6_ipsi                             0.0       0.0        0.0        0.0   \n",
       "Aspiration rate Pre-therapy          0         0          0          0   \n",
       "DLT (Y/N)                            0         0          0          0   \n",
       "DLT_Grade                            0         0          0          0   \n",
       "N-category_0                         0         0          0          0   \n",
       "N-category_1                         0         0          1          1   \n",
       "N-category_2                         1         1          0          0   \n",
       "N-category_3                         0         0          0          0   \n",
       "Pathological Grade_0                 0         1          0          0   \n",
       "Pathological Grade_1                 1         0          0          0   \n",
       "Pathological Grade_2                 0         0          1          0   \n",
       "Pathological Grade_3                 0         0          0          1   \n",
       "Pathological Grade_4                 0         0          0          0   \n",
       "RPLN_contra                        0.0       0.0        0.0        0.0   \n",
       "RPLN_ipsi                          0.0       0.0        0.0        0.0   \n",
       "T-category_1                         1         0          0          0   \n",
       "T-category_2                         0         1          0          0   \n",
       "T-category_3                         0         0          1          1   \n",
       "T-category_4                         0         0          0          0   \n",
       "age                          70.888889    67.825  56.336111  49.566667   \n",
       "bilateral                        False     False      False      False   \n",
       "dose_fraction                      2.2  2.121212       2.12   2.121212   \n",
       "gender                               0         1          1          1   \n",
       "hpv                                 -1         0          1          1   \n",
       "packs_per_year                    50.0       0.0        0.0       30.0   \n",
       "smoking_status                     0.5       0.0        0.0        1.0   \n",
       "subsite_BOT                          0         1          0          1   \n",
       "subsite_GPS                          0         0          0          0   \n",
       "subsite_NOS                          0         0          1          0   \n",
       "subsite_Soft palate                  0         0          0          0   \n",
       "subsite_Tonsil                       1         0          0          0   \n",
       "total_dose                        66.0      70.0      69.96       70.0   \n",
       "\n",
       "id                               10202      10203  10204      10205  \n",
       "1A_contra                          0.0        0.0    0.0        0.0  \n",
       "1A_ipsi                            0.0        0.0    0.0        0.0  \n",
       "1B_contra                          0.0        0.0    0.0        0.0  \n",
       "1B_ipsi                            0.0        0.0    0.0        0.0  \n",
       "2A_contra                          0.0        0.0    0.0        0.0  \n",
       "2A_ipsi                            1.0        1.0    1.0        0.0  \n",
       "2B_contra                          0.0        0.0    0.0        0.0  \n",
       "2B_ipsi                            1.0        1.0    1.0        0.0  \n",
       "3_contra                           0.0        0.0    0.0        0.0  \n",
       "3_ipsi                             0.0        1.0    1.0        1.0  \n",
       "4_contra                           0.0        0.0    0.0        0.0  \n",
       "4_ipsi                             0.0        0.0    0.0        0.0  \n",
       "5A_contra                          0.0        0.0    0.0        0.0  \n",
       "5A_ipsi                            0.0        0.0    0.0        0.0  \n",
       "5B_contra                          0.0        0.0    0.0        0.0  \n",
       "5B_ipsi                            0.0        0.0    0.0        0.0  \n",
       "6_contra                           0.0        0.0    0.0        0.0  \n",
       "6_ipsi                             0.0        0.0    0.0        0.0  \n",
       "Aspiration rate Pre-therapy          0          0      0          0  \n",
       "DLT (Y/N)                            0          0      0          0  \n",
       "DLT_Grade                            0          0      0          0  \n",
       "N-category_0                         0          0      0          0  \n",
       "N-category_1                         0          1      0          1  \n",
       "N-category_2                         1          0      0          0  \n",
       "N-category_3                         0          0      1          0  \n",
       "Pathological Grade_0                 0          1      0          0  \n",
       "Pathological Grade_1                 0          0      0          0  \n",
       "Pathological Grade_2                 0          0      0          1  \n",
       "Pathological Grade_3                 1          0      1          0  \n",
       "Pathological Grade_4                 0          0      0          0  \n",
       "RPLN_contra                        0.0        0.0    0.0        0.0  \n",
       "RPLN_ipsi                          0.0        0.0    0.0        0.0  \n",
       "T-category_1                         0          1      0          0  \n",
       "T-category_2                         0          0      0          0  \n",
       "T-category_3                         0          0      1          0  \n",
       "T-category_4                         1          0      0          1  \n",
       "age                          48.705556  77.116667  45.95  49.733333  \n",
       "bilateral                        False      False   True      False  \n",
       "dose_fraction                 1.714286   2.333333   2.12       2.12  \n",
       "gender                               1          1      1          1  \n",
       "hpv                                  0          1      0          1  \n",
       "packs_per_year                    30.0        0.0    5.0        0.0  \n",
       "smoking_status                     1.0        0.0    0.5        0.0  \n",
       "subsite_BOT                          0          0      0          1  \n",
       "subsite_GPS                          0          0      0          0  \n",
       "subsite_NOS                          1          0      0          0  \n",
       "subsite_Soft palate                  0          0      0          0  \n",
       "subsite_Tonsil                       0          1      1          0  \n",
       "total_dose                        72.0       70.0  69.96      69.96  \n",
       "\n",
       "[49 rows x 536 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " DTDataset().get_state('baseline').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "91c4445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "epoch 0 train loss 12.584715843200684\n",
      "val loss 10.469034194946289\n",
      "______________\n",
      "epoch 1 train loss 12.27181625366211\n",
      "val loss 10.260318756103516\n",
      "______________\n",
      "epoch 2 train loss 12.172605514526367\n",
      "val loss 10.057838439941406\n",
      "______________\n",
      "epoch 3 train loss 11.924123764038086\n",
      "val loss 9.861397743225098\n",
      "______________\n",
      "epoch 4 train loss 11.583189010620117\n",
      "val loss 9.670869827270508\n",
      "______________\n",
      "epoch 5 train loss 11.3615140914917\n",
      "val loss 9.486045837402344\n",
      "______________\n",
      "epoch 6 train loss 11.173789024353027\n",
      "val loss 9.306960105895996\n",
      "______________\n",
      "epoch 7 train loss 10.843757629394531\n",
      "val loss 9.13375473022461\n",
      "______________\n",
      "epoch 8 train loss 10.620189666748047\n",
      "val loss 8.966254234313965\n",
      "______________\n",
      "epoch 9 train loss 10.544535636901855\n",
      "val loss 8.804043769836426\n",
      "______________\n",
      "epoch 10 train loss 10.400749206542969\n",
      "val loss 8.647340774536133\n",
      "______________\n",
      "epoch 11 train loss 10.13203239440918\n",
      "val loss 8.496108055114746\n",
      "______________\n",
      "epoch 12 train loss 9.810145378112793\n",
      "val loss 8.350218772888184\n",
      "______________\n",
      "epoch 13 train loss 9.736988067626953\n",
      "val loss 8.209567070007324\n",
      "______________\n",
      "epoch 14 train loss 9.436933517456055\n",
      "val loss 8.074161529541016\n",
      "______________\n",
      "epoch 15 train loss 9.321846961975098\n",
      "val loss 7.943721771240234\n",
      "______________\n",
      "epoch 16 train loss 9.176478385925293\n",
      "val loss 7.818108081817627\n",
      "______________\n",
      "epoch 17 train loss 9.052103996276855\n",
      "val loss 7.697082042694092\n",
      "______________\n",
      "epoch 18 train loss 8.863633155822754\n",
      "val loss 7.580601692199707\n",
      "______________\n",
      "epoch 19 train loss 8.668476104736328\n",
      "val loss 7.468371391296387\n",
      "______________\n",
      "epoch 20 train loss 8.601198196411133\n",
      "val loss 7.360256195068359\n",
      "______________\n",
      "epoch 21 train loss 8.295671463012695\n",
      "val loss 7.256147861480713\n",
      "______________\n",
      "epoch 22 train loss 8.231879234313965\n",
      "val loss 7.155982971191406\n",
      "______________\n",
      "epoch 23 train loss 8.017110824584961\n",
      "val loss 7.059642791748047\n",
      "______________\n",
      "epoch 24 train loss 7.956551551818848\n",
      "val loss 6.966963291168213\n",
      "______________\n",
      "epoch 25 train loss 7.818236827850342\n",
      "val loss 6.87772798538208\n",
      "______________\n",
      "epoch 26 train loss 7.687744617462158\n",
      "val loss 6.7918548583984375\n",
      "______________\n",
      "epoch 27 train loss 7.556063652038574\n",
      "val loss 6.70931339263916\n",
      "______________\n",
      "epoch 28 train loss 7.378205299377441\n",
      "val loss 6.629790306091309\n",
      "______________\n",
      "epoch 29 train loss 7.239410400390625\n",
      "val loss 6.55319881439209\n",
      "______________\n",
      "epoch 30 train loss 7.217813491821289\n",
      "val loss 6.479290008544922\n",
      "______________\n",
      "epoch 31 train loss 7.114105701446533\n",
      "val loss 6.4080729484558105\n",
      "______________\n",
      "epoch 32 train loss 6.963917255401611\n",
      "val loss 6.339511394500732\n",
      "______________\n",
      "epoch 33 train loss 6.861073970794678\n",
      "val loss 6.273359775543213\n",
      "______________\n",
      "epoch 34 train loss 6.711249828338623\n",
      "val loss 6.209609508514404\n",
      "______________\n",
      "epoch 35 train loss 6.680523872375488\n",
      "val loss 6.148094177246094\n",
      "______________\n",
      "epoch 36 train loss 6.5761871337890625\n",
      "val loss 6.0887346267700195\n",
      "______________\n",
      "epoch 37 train loss 6.463581562042236\n",
      "val loss 6.031405448913574\n",
      "______________\n",
      "epoch 38 train loss 6.3984856605529785\n",
      "val loss 5.975999355316162\n",
      "______________\n",
      "epoch 39 train loss 6.3027567863464355\n",
      "val loss 5.922508239746094\n",
      "______________\n",
      "epoch 40 train loss 6.144794940948486\n",
      "val loss 5.870728492736816\n",
      "______________\n",
      "epoch 41 train loss 6.163642883300781\n",
      "val loss 5.820615291595459\n",
      "______________\n",
      "epoch 42 train loss 6.053435802459717\n",
      "val loss 5.772096633911133\n",
      "______________\n",
      "epoch 43 train loss 5.969487190246582\n",
      "val loss 5.725095272064209\n",
      "______________\n",
      "epoch 44 train loss 5.859048843383789\n",
      "val loss 5.679428577423096\n",
      "______________\n",
      "epoch 45 train loss 5.75316047668457\n",
      "val loss 5.635179042816162\n",
      "______________\n",
      "epoch 46 train loss 5.708063125610352\n",
      "val loss 5.592263698577881\n",
      "______________\n",
      "epoch 47 train loss 5.614434719085693\n",
      "val loss 5.550637722015381\n",
      "______________\n",
      "epoch 48 train loss 5.631956577301025\n",
      "val loss 5.510187149047852\n",
      "______________\n",
      "epoch 49 train loss 5.519903182983398\n",
      "val loss 5.470751762390137\n",
      "______________\n",
      "epoch 50 train loss 5.472914695739746\n",
      "val loss 5.432497024536133\n",
      "______________\n",
      "epoch 51 train loss 5.3749566078186035\n",
      "val loss 5.395246982574463\n",
      "______________\n",
      "epoch 52 train loss 5.415824890136719\n",
      "val loss 5.358913421630859\n",
      "______________\n",
      "epoch 53 train loss 5.367862224578857\n",
      "val loss 5.323481559753418\n",
      "______________\n",
      "epoch 54 train loss 5.258735656738281\n",
      "val loss 5.288957595825195\n",
      "______________\n",
      "epoch 55 train loss 5.179498672485352\n",
      "val loss 5.255265235900879\n",
      "______________\n",
      "epoch 56 train loss 5.154857158660889\n",
      "val loss 5.222324371337891\n",
      "______________\n",
      "epoch 57 train loss 5.078902721405029\n",
      "val loss 5.190080642700195\n",
      "______________\n",
      "epoch 58 train loss 5.010520935058594\n",
      "val loss 5.158649921417236\n",
      "______________\n",
      "epoch 59 train loss 4.918704032897949\n",
      "val loss 5.128030776977539\n",
      "______________\n",
      "epoch 60 train loss 4.934598922729492\n",
      "val loss 5.098302841186523\n",
      "______________\n",
      "epoch 61 train loss 4.839386940002441\n",
      "val loss 5.069253444671631\n",
      "______________\n",
      "epoch 62 train loss 4.871876239776611\n",
      "val loss 5.040748119354248\n",
      "______________\n",
      "epoch 63 train loss 4.720797061920166\n",
      "val loss 5.012922286987305\n",
      "______________\n",
      "epoch 64 train loss 4.652711868286133\n",
      "val loss 4.985772132873535\n",
      "______________\n",
      "epoch 65 train loss 4.6065287590026855\n",
      "val loss 4.959307670593262\n",
      "______________\n",
      "epoch 66 train loss 4.691559791564941\n",
      "val loss 4.9333038330078125\n",
      "______________\n",
      "epoch 67 train loss 4.646878242492676\n",
      "val loss 4.907790660858154\n",
      "______________\n",
      "epoch 68 train loss 4.585435390472412\n",
      "val loss 4.882723331451416\n",
      "______________\n",
      "epoch 69 train loss 4.489042282104492\n",
      "val loss 4.8581061363220215\n",
      "______________\n",
      "epoch 70 train loss 4.458982944488525\n",
      "val loss 4.83420991897583\n",
      "______________\n",
      "epoch 71 train loss 4.4199604988098145\n",
      "val loss 4.810771942138672\n",
      "______________\n",
      "epoch 72 train loss 4.429242134094238\n",
      "val loss 4.78758430480957\n",
      "______________\n",
      "epoch 73 train loss 4.394016265869141\n",
      "val loss 4.76474142074585\n",
      "______________\n",
      "epoch 74 train loss 4.381341934204102\n",
      "val loss 4.742143630981445\n",
      "______________\n",
      "epoch 75 train loss 4.330459117889404\n",
      "val loss 4.720036029815674\n",
      "______________\n",
      "epoch 76 train loss 4.300756931304932\n",
      "val loss 4.698307037353516\n",
      "______________\n",
      "epoch 77 train loss 4.29311466217041\n",
      "val loss 4.676905632019043\n",
      "______________\n",
      "epoch 78 train loss 4.199702262878418\n",
      "val loss 4.65588903427124\n",
      "______________\n",
      "epoch 79 train loss 4.1196794509887695\n",
      "val loss 4.63527250289917\n",
      "______________\n",
      "epoch 80 train loss 4.16632080078125\n",
      "val loss 4.614908218383789\n",
      "______________\n",
      "epoch 81 train loss 4.159268856048584\n",
      "val loss 4.594977855682373\n",
      "______________\n",
      "epoch 82 train loss 4.10751485824585\n",
      "val loss 4.5752363204956055\n",
      "______________\n",
      "epoch 83 train loss 4.077518939971924\n",
      "val loss 4.555757999420166\n",
      "______________\n",
      "epoch 84 train loss 4.071890354156494\n",
      "val loss 4.536620616912842\n",
      "______________\n",
      "epoch 85 train loss 3.9498839378356934\n",
      "val loss 4.517792701721191\n",
      "______________\n",
      "epoch 86 train loss 3.961138963699341\n",
      "val loss 4.499173641204834\n",
      "______________\n",
      "epoch 87 train loss 3.9822261333465576\n",
      "val loss 4.48079776763916\n",
      "______________\n",
      "epoch 88 train loss 4.004734039306641\n",
      "val loss 4.46268367767334\n",
      "______________\n",
      "epoch 89 train loss 3.98293137550354\n",
      "val loss 4.444748401641846\n",
      "______________\n",
      "epoch 90 train loss 3.8600683212280273\n",
      "val loss 4.4269914627075195\n",
      "______________\n",
      "epoch 91 train loss 3.8827879428863525\n",
      "val loss 4.409395217895508\n",
      "______________\n",
      "epoch 92 train loss 3.8324971199035645\n",
      "val loss 4.392026901245117\n",
      "______________\n",
      "epoch 93 train loss 3.8512167930603027\n",
      "val loss 4.374868392944336\n",
      "______________\n",
      "epoch 94 train loss 3.7722601890563965\n",
      "val loss 4.357789516448975\n",
      "______________\n",
      "epoch 95 train loss 3.78861403465271\n",
      "val loss 4.3408989906311035\n",
      "______________\n",
      "epoch 96 train loss 3.7960429191589355\n",
      "val loss 4.324217796325684\n",
      "______________\n",
      "epoch 97 train loss 3.7614850997924805\n",
      "val loss 4.307904243469238\n",
      "______________\n",
      "epoch 98 train loss 3.6526896953582764\n",
      "val loss 4.291874885559082\n",
      "______________\n",
      "epoch 99 train loss 3.7261009216308594\n",
      "val loss 4.276151180267334\n",
      "______________\n",
      "epoch 100 train loss 3.7630162239074707\n",
      "val loss 4.260638236999512\n",
      "______________\n",
      "epoch 101 train loss 3.6575496196746826\n",
      "val loss 4.245355129241943\n",
      "______________\n",
      "epoch 102 train loss 3.6887381076812744\n",
      "val loss 4.230307579040527\n",
      "______________\n",
      "epoch 103 train loss 3.604600667953491\n",
      "val loss 4.215427398681641\n",
      "______________\n",
      "epoch 104 train loss 3.6420342922210693\n",
      "val loss 4.200753211975098\n",
      "______________\n",
      "epoch 105 train loss 3.5724985599517822\n",
      "val loss 4.186470985412598\n",
      "______________\n",
      "epoch 106 train loss 3.587618827819824\n",
      "val loss 4.1722869873046875\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107 train loss 3.637948989868164\n",
      "val loss 4.158107757568359\n",
      "______________\n",
      "epoch 108 train loss 3.4630680084228516\n",
      "val loss 4.1442413330078125\n",
      "______________\n",
      "epoch 109 train loss 3.557813882827759\n",
      "val loss 4.130547046661377\n",
      "______________\n",
      "epoch 110 train loss 3.580655336380005\n",
      "val loss 4.116995811462402\n",
      "______________\n",
      "epoch 111 train loss 3.4690659046173096\n",
      "val loss 4.10364294052124\n",
      "______________\n",
      "epoch 112 train loss 3.410067319869995\n",
      "val loss 4.090603828430176\n",
      "______________\n",
      "epoch 113 train loss 3.45928692817688\n",
      "val loss 4.077873706817627\n",
      "______________\n",
      "epoch 114 train loss 3.374988555908203\n",
      "val loss 4.065329551696777\n",
      "______________\n",
      "epoch 115 train loss 3.426192045211792\n",
      "val loss 4.05294942855835\n",
      "______________\n",
      "epoch 116 train loss 3.4066555500030518\n",
      "val loss 4.0407304763793945\n",
      "______________\n",
      "epoch 117 train loss 3.3791098594665527\n",
      "val loss 4.028628349304199\n",
      "______________\n",
      "epoch 118 train loss 3.4128146171569824\n",
      "val loss 4.016730308532715\n",
      "______________\n",
      "epoch 119 train loss 3.404822826385498\n",
      "val loss 4.005054473876953\n",
      "______________\n",
      "epoch 120 train loss 3.363905668258667\n",
      "val loss 3.9934985637664795\n",
      "______________\n",
      "epoch 121 train loss 3.378016233444214\n",
      "val loss 3.9819986820220947\n",
      "______________\n",
      "epoch 122 train loss 3.383537530899048\n",
      "val loss 3.9704678058624268\n",
      "______________\n",
      "epoch 123 train loss 3.3759307861328125\n",
      "val loss 3.959012269973755\n",
      "______________\n",
      "epoch 124 train loss 3.3273401260375977\n",
      "val loss 3.947722911834717\n",
      "______________\n",
      "epoch 125 train loss 3.255462169647217\n",
      "val loss 3.9364774227142334\n",
      "______________\n",
      "epoch 126 train loss 3.213883638381958\n",
      "val loss 3.925382614135742\n",
      "______________\n",
      "epoch 127 train loss 3.2551403045654297\n",
      "val loss 3.914370059967041\n",
      "______________\n",
      "epoch 128 train loss 3.2470145225524902\n",
      "val loss 3.903562068939209\n",
      "______________\n",
      "epoch 129 train loss 3.2485854625701904\n",
      "val loss 3.8928720951080322\n",
      "______________\n",
      "epoch 130 train loss 3.1790103912353516\n",
      "val loss 3.882351875305176\n",
      "______________\n",
      "epoch 131 train loss 3.1414296627044678\n",
      "val loss 3.8720953464508057\n",
      "______________\n",
      "epoch 132 train loss 3.198695421218872\n",
      "val loss 3.8618462085723877\n",
      "______________\n",
      "epoch 133 train loss 3.246704578399658\n",
      "val loss 3.8516154289245605\n",
      "______________\n",
      "epoch 134 train loss 3.17185378074646\n",
      "val loss 3.8415439128875732\n",
      "______________\n",
      "epoch 135 train loss 3.211066722869873\n",
      "val loss 3.831531524658203\n",
      "______________\n",
      "epoch 136 train loss 3.149167776107788\n",
      "val loss 3.8216192722320557\n",
      "______________\n",
      "epoch 137 train loss 3.150674819946289\n",
      "val loss 3.8118162155151367\n",
      "______________\n",
      "epoch 138 train loss 3.1786787509918213\n",
      "val loss 3.8020102977752686\n",
      "______________\n",
      "epoch 139 train loss 3.1086764335632324\n",
      "val loss 3.792344570159912\n",
      "______________\n",
      "epoch 140 train loss 3.144925594329834\n",
      "val loss 3.782829523086548\n",
      "______________\n",
      "epoch 141 train loss 3.0846123695373535\n",
      "val loss 3.773463487625122\n",
      "______________\n",
      "epoch 142 train loss 3.065035343170166\n",
      "val loss 3.7641375064849854\n",
      "______________\n",
      "epoch 143 train loss 3.058250904083252\n",
      "val loss 3.755044460296631\n",
      "______________\n",
      "epoch 144 train loss 3.1085591316223145\n",
      "val loss 3.7459511756896973\n",
      "______________\n",
      "epoch 145 train loss 3.068241834640503\n",
      "val loss 3.737001895904541\n",
      "______________\n",
      "epoch 146 train loss 3.009265422821045\n",
      "val loss 3.7282981872558594\n",
      "______________\n",
      "epoch 147 train loss 3.062436819076538\n",
      "val loss 3.719588041305542\n",
      "______________\n",
      "epoch 148 train loss 2.980897903442383\n",
      "val loss 3.711007595062256\n",
      "______________\n",
      "epoch 149 train loss 2.9731225967407227\n",
      "val loss 3.702557325363159\n",
      "______________\n",
      "epoch 150 train loss 2.949920654296875\n",
      "val loss 3.6940524578094482\n",
      "______________\n",
      "epoch 151 train loss 3.0371830463409424\n",
      "val loss 3.6854400634765625\n",
      "______________\n",
      "epoch 152 train loss 2.9600515365600586\n",
      "val loss 3.6769096851348877\n",
      "______________\n",
      "epoch 153 train loss 2.9712541103363037\n",
      "val loss 3.668529748916626\n",
      "______________\n",
      "epoch 154 train loss 2.9905924797058105\n",
      "val loss 3.6601428985595703\n",
      "______________\n",
      "epoch 155 train loss 2.897045850753784\n",
      "val loss 3.6519126892089844\n",
      "______________\n",
      "epoch 156 train loss 2.874504566192627\n",
      "val loss 3.643799304962158\n",
      "______________\n",
      "epoch 157 train loss 2.9320971965789795\n",
      "val loss 3.6357955932617188\n",
      "______________\n",
      "epoch 158 train loss 2.903102397918701\n",
      "val loss 3.627906322479248\n",
      "______________\n",
      "epoch 159 train loss 2.9515037536621094\n",
      "val loss 3.61995267868042\n",
      "______________\n",
      "epoch 160 train loss 2.955688238143921\n",
      "val loss 3.612058401107788\n",
      "______________\n",
      "epoch 161 train loss 2.88490629196167\n",
      "val loss 3.6042556762695312\n",
      "______________\n",
      "epoch 162 train loss 2.8744895458221436\n",
      "val loss 3.5964605808258057\n",
      "______________\n",
      "epoch 163 train loss 2.951002597808838\n",
      "val loss 3.5886943340301514\n",
      "______________\n",
      "epoch 164 train loss 2.9465298652648926\n",
      "val loss 3.5808265209198\n",
      "______________\n",
      "epoch 165 train loss 2.9297525882720947\n",
      "val loss 3.5729832649230957\n",
      "______________\n",
      "epoch 166 train loss 2.836432933807373\n",
      "val loss 3.5652689933776855\n",
      "______________\n",
      "epoch 167 train loss 2.8567581176757812\n",
      "val loss 3.5575919151306152\n",
      "______________\n",
      "epoch 168 train loss 2.8494932651519775\n",
      "val loss 3.5500571727752686\n",
      "______________\n",
      "epoch 169 train loss 2.801694631576538\n",
      "val loss 3.5426199436187744\n",
      "______________\n",
      "epoch 170 train loss 2.837629556655884\n",
      "val loss 3.535290479660034\n",
      "______________\n",
      "epoch 171 train loss 2.825005054473877\n",
      "val loss 3.5280332565307617\n",
      "______________\n",
      "epoch 172 train loss 2.7997782230377197\n",
      "val loss 3.5208561420440674\n",
      "______________\n",
      "epoch 173 train loss 2.8354692459106445\n",
      "val loss 3.513749361038208\n",
      "______________\n",
      "epoch 174 train loss 2.79475736618042\n",
      "val loss 3.506671190261841\n",
      "______________\n",
      "epoch 175 train loss 2.809814453125\n",
      "val loss 3.4997761249542236\n",
      "______________\n",
      "epoch 176 train loss 2.836311101913452\n",
      "val loss 3.4928596019744873\n",
      "______________\n",
      "epoch 177 train loss 2.847517251968384\n",
      "val loss 3.4859566688537598\n",
      "______________\n",
      "epoch 178 train loss 2.75823974609375\n",
      "val loss 3.479125738143921\n",
      "______________\n",
      "epoch 179 train loss 2.822023391723633\n",
      "val loss 3.4723446369171143\n",
      "______________\n",
      "epoch 180 train loss 2.792525053024292\n",
      "val loss 3.465794324874878\n",
      "______________\n",
      "epoch 181 train loss 2.71505069732666\n",
      "val loss 3.459282875061035\n",
      "______________\n",
      "epoch 182 train loss 2.76784610748291\n",
      "val loss 3.4528231620788574\n",
      "______________\n",
      "epoch 183 train loss 2.751706123352051\n",
      "val loss 3.446441888809204\n",
      "______________\n",
      "epoch 184 train loss 2.7241134643554688\n",
      "val loss 3.4400792121887207\n",
      "______________\n",
      "epoch 185 train loss 2.7289273738861084\n",
      "val loss 3.433713912963867\n",
      "______________\n",
      "epoch 186 train loss 2.8009393215179443\n",
      "val loss 3.4272992610931396\n",
      "______________\n",
      "epoch 187 train loss 2.766116142272949\n",
      "val loss 3.4208340644836426\n",
      "______________\n",
      "epoch 188 train loss 2.704115390777588\n",
      "val loss 3.4145960807800293\n",
      "______________\n",
      "epoch 189 train loss 2.7435920238494873\n",
      "val loss 3.4082658290863037\n",
      "______________\n",
      "epoch 190 train loss 2.7680506706237793\n",
      "val loss 3.4018614292144775\n",
      "______________\n",
      "epoch 191 train loss 2.7185842990875244\n",
      "val loss 3.3954169750213623\n",
      "______________\n",
      "epoch 192 train loss 2.6907436847686768\n",
      "val loss 3.388996124267578\n",
      "______________\n",
      "epoch 193 train loss 2.676642656326294\n",
      "val loss 3.3826568126678467\n",
      "______________\n",
      "epoch 194 train loss 2.66025447845459\n",
      "val loss 3.3763973712921143\n",
      "______________\n",
      "epoch 195 train loss 2.6182708740234375\n",
      "val loss 3.3702118396759033\n",
      "______________\n",
      "epoch 196 train loss 2.7013943195343018\n",
      "val loss 3.364136219024658\n",
      "______________\n",
      "epoch 197 train loss 2.7086033821105957\n",
      "val loss 3.3580684661865234\n",
      "______________\n",
      "epoch 198 train loss 2.62483549118042\n",
      "val loss 3.3520636558532715\n",
      "______________\n",
      "epoch 199 train loss 2.6472666263580322\n",
      "val loss 3.3461108207702637\n",
      "______________\n",
      "epoch 200 train loss 2.6810145378112793\n",
      "val loss 3.340071201324463\n",
      "______________\n",
      "epoch 201 train loss 2.6773793697357178\n",
      "val loss 3.3341012001037598\n",
      "______________\n",
      "epoch 202 train loss 2.649783134460449\n",
      "val loss 3.328249454498291\n",
      "______________\n",
      "epoch 203 train loss 2.6673707962036133\n",
      "val loss 3.322481632232666\n",
      "______________\n",
      "epoch 204 train loss 2.632958173751831\n",
      "val loss 3.316800832748413\n",
      "______________\n",
      "epoch 205 train loss 2.687331438064575\n",
      "val loss 3.3110435009002686\n",
      "______________\n",
      "epoch 206 train loss 2.6330695152282715\n",
      "val loss 3.3053901195526123\n",
      "______________\n",
      "epoch 207 train loss 2.6527915000915527\n",
      "val loss 3.2996573448181152\n",
      "______________\n",
      "epoch 208 train loss 2.5656445026397705\n",
      "val loss 3.293976306915283\n",
      "______________\n",
      "epoch 209 train loss 2.650158405303955\n",
      "val loss 3.2882955074310303\n",
      "______________\n",
      "epoch 210 train loss 2.576390266418457\n",
      "val loss 3.28265380859375\n",
      "______________\n",
      "epoch 211 train loss 2.586573839187622\n",
      "val loss 3.277017593383789\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 212 train loss 2.6064164638519287\n",
      "val loss 3.2714107036590576\n",
      "______________\n",
      "epoch 213 train loss 2.62460994720459\n",
      "val loss 3.265824794769287\n",
      "______________\n",
      "epoch 214 train loss 2.569301128387451\n",
      "val loss 3.2602081298828125\n",
      "______________\n",
      "epoch 215 train loss 2.6350433826446533\n",
      "val loss 3.2544400691986084\n",
      "______________\n",
      "epoch 216 train loss 2.5891263484954834\n",
      "val loss 3.248676300048828\n",
      "______________\n",
      "epoch 217 train loss 2.568282127380371\n",
      "val loss 3.242978096008301\n",
      "______________\n",
      "epoch 218 train loss 2.5573487281799316\n",
      "val loss 3.2374496459960938\n",
      "______________\n",
      "epoch 219 train loss 2.5776150226593018\n",
      "val loss 3.2319722175598145\n",
      "______________\n",
      "epoch 220 train loss 2.4912197589874268\n",
      "val loss 3.2265193462371826\n",
      "______________\n",
      "epoch 221 train loss 2.6213626861572266\n",
      "val loss 3.2210707664489746\n",
      "______________\n",
      "epoch 222 train loss 2.544618606567383\n",
      "val loss 3.2155752182006836\n",
      "______________\n",
      "epoch 223 train loss 2.531808853149414\n",
      "val loss 3.2101669311523438\n",
      "______________\n",
      "epoch 224 train loss 2.6165640354156494\n",
      "val loss 3.2048327922821045\n",
      "______________\n",
      "epoch 225 train loss 2.6088554859161377\n",
      "val loss 3.199324369430542\n",
      "______________\n",
      "epoch 226 train loss 2.490543842315674\n",
      "val loss 3.1937882900238037\n",
      "______________\n",
      "epoch 227 train loss 2.5017879009246826\n",
      "val loss 3.1883442401885986\n",
      "______________\n",
      "epoch 228 train loss 2.553161859512329\n",
      "val loss 3.182971954345703\n",
      "______________\n",
      "epoch 229 train loss 2.59381103515625\n",
      "val loss 3.177593231201172\n",
      "______________\n",
      "epoch 230 train loss 2.471156358718872\n",
      "val loss 3.172391176223755\n",
      "______________\n",
      "epoch 231 train loss 2.4781925678253174\n",
      "val loss 3.167325258255005\n",
      "______________\n",
      "epoch 232 train loss 2.4442965984344482\n",
      "val loss 3.162348985671997\n",
      "______________\n",
      "epoch 233 train loss 2.4538447856903076\n",
      "val loss 3.157414674758911\n",
      "______________\n",
      "epoch 234 train loss 2.5048866271972656\n",
      "val loss 3.152416229248047\n",
      "______________\n",
      "epoch 235 train loss 2.489778995513916\n",
      "val loss 3.147430896759033\n",
      "______________\n",
      "epoch 236 train loss 2.486659526824951\n",
      "val loss 3.1424968242645264\n",
      "______________\n",
      "epoch 237 train loss 2.5019283294677734\n",
      "val loss 3.137576103210449\n",
      "______________\n",
      "epoch 238 train loss 2.511406660079956\n",
      "val loss 3.1327645778656006\n",
      "______________\n",
      "epoch 239 train loss 2.4507079124450684\n",
      "val loss 3.1280436515808105\n",
      "______________\n",
      "epoch 240 train loss 2.458317518234253\n",
      "val loss 3.123354434967041\n",
      "______________\n",
      "epoch 241 train loss 2.504642963409424\n",
      "val loss 3.118769645690918\n",
      "______________\n",
      "epoch 242 train loss 2.5324339866638184\n",
      "val loss 3.1140387058258057\n",
      "______________\n",
      "epoch 243 train loss 2.5012710094451904\n",
      "val loss 3.1093153953552246\n",
      "______________\n",
      "epoch 244 train loss 2.4987754821777344\n",
      "val loss 3.1045591831207275\n",
      "______________\n",
      "epoch 245 train loss 2.5323009490966797\n",
      "val loss 3.0998637676239014\n",
      "______________\n",
      "epoch 246 train loss 2.4114322662353516\n",
      "val loss 3.0953428745269775\n",
      "______________\n",
      "epoch 247 train loss 2.428952932357788\n",
      "val loss 3.0908939838409424\n",
      "______________\n",
      "epoch 248 train loss 2.436206817626953\n",
      "val loss 3.0865187644958496\n",
      "______________\n",
      "epoch 249 train loss 2.480198621749878\n",
      "val loss 3.082170009613037\n",
      "______________\n",
      "epoch 250 train loss 2.42771315574646\n",
      "val loss 3.0777690410614014\n",
      "______________\n",
      "epoch 251 train loss 2.334104061126709\n",
      "val loss 3.07346510887146\n",
      "______________\n",
      "epoch 252 train loss 2.463083028793335\n",
      "val loss 3.069211006164551\n",
      "______________\n",
      "epoch 253 train loss 2.399110794067383\n",
      "val loss 3.064816951751709\n",
      "______________\n",
      "epoch 254 train loss 2.3613922595977783\n",
      "val loss 3.060511827468872\n",
      "______________\n",
      "epoch 255 train loss 2.3956801891326904\n",
      "val loss 3.0562896728515625\n",
      "______________\n",
      "epoch 256 train loss 2.40492844581604\n",
      "val loss 3.0519731044769287\n",
      "______________\n",
      "epoch 257 train loss 2.443342685699463\n",
      "val loss 3.0477538108825684\n",
      "______________\n",
      "epoch 258 train loss 2.4217803478240967\n",
      "val loss 3.0434489250183105\n",
      "______________\n",
      "epoch 259 train loss 2.4565677642822266\n",
      "val loss 3.0391781330108643\n",
      "______________\n",
      "epoch 260 train loss 2.3301427364349365\n",
      "val loss 3.0349950790405273\n",
      "______________\n",
      "epoch 261 train loss 2.427419662475586\n",
      "val loss 3.030792236328125\n",
      "______________\n",
      "epoch 262 train loss 2.3926377296447754\n",
      "val loss 3.026685953140259\n",
      "______________\n",
      "epoch 263 train loss 2.3182191848754883\n",
      "val loss 3.0226359367370605\n",
      "______________\n",
      "epoch 264 train loss 2.4266340732574463\n",
      "val loss 3.018580913543701\n",
      "______________\n",
      "epoch 265 train loss 2.373103141784668\n",
      "val loss 3.0146918296813965\n",
      "______________\n",
      "epoch 266 train loss 2.3677165508270264\n",
      "val loss 3.0107204914093018\n",
      "______________\n",
      "epoch 267 train loss 2.3190600872039795\n",
      "val loss 3.006777286529541\n",
      "______________\n",
      "epoch 268 train loss 2.3710360527038574\n",
      "val loss 3.002894878387451\n",
      "______________\n",
      "epoch 269 train loss 2.3698740005493164\n",
      "val loss 2.9989614486694336\n",
      "______________\n",
      "epoch 270 train loss 2.367398738861084\n",
      "val loss 2.995044708251953\n",
      "______________\n",
      "epoch 271 train loss 2.4069998264312744\n",
      "val loss 2.9911179542541504\n",
      "______________\n",
      "epoch 272 train loss 2.3427579402923584\n",
      "val loss 2.9873201847076416\n",
      "______________\n",
      "epoch 273 train loss 2.3470919132232666\n",
      "val loss 2.9835574626922607\n",
      "______________\n",
      "epoch 274 train loss 2.3451685905456543\n",
      "val loss 2.979874610900879\n",
      "______________\n",
      "epoch 275 train loss 2.344618082046509\n",
      "val loss 2.976092576980591\n",
      "______________\n",
      "epoch 276 train loss 2.3213937282562256\n",
      "val loss 2.9724161624908447\n",
      "______________\n",
      "epoch 277 train loss 2.3347160816192627\n",
      "val loss 2.9688186645507812\n",
      "______________\n",
      "epoch 278 train loss 2.399118423461914\n",
      "val loss 2.9651427268981934\n",
      "______________\n",
      "epoch 279 train loss 2.3571181297302246\n",
      "val loss 2.961419105529785\n",
      "______________\n",
      "epoch 280 train loss 2.3995730876922607\n",
      "val loss 2.9576292037963867\n",
      "______________\n",
      "epoch 281 train loss 2.316643476486206\n",
      "val loss 2.9538984298706055\n",
      "______________\n",
      "epoch 282 train loss 2.411072254180908\n",
      "val loss 2.950035810470581\n",
      "______________\n",
      "epoch 283 train loss 2.3684303760528564\n",
      "val loss 2.946150779724121\n",
      "______________\n",
      "epoch 284 train loss 2.3316848278045654\n",
      "val loss 2.9421894550323486\n",
      "______________\n",
      "epoch 285 train loss 2.246642589569092\n",
      "val loss 2.938467025756836\n",
      "______________\n",
      "epoch 286 train loss 2.2797670364379883\n",
      "val loss 2.9347214698791504\n",
      "______________\n",
      "epoch 287 train loss 2.3019731044769287\n",
      "val loss 2.930990219116211\n",
      "______________\n",
      "epoch 288 train loss 2.342974901199341\n",
      "val loss 2.9273483753204346\n",
      "______________\n",
      "epoch 289 train loss 2.3038880825042725\n",
      "val loss 2.9238381385803223\n",
      "______________\n",
      "epoch 290 train loss 2.3560664653778076\n",
      "val loss 2.920236825942993\n",
      "______________\n",
      "epoch 291 train loss 2.2670247554779053\n",
      "val loss 2.916748523712158\n",
      "______________\n",
      "epoch 292 train loss 2.282078504562378\n",
      "val loss 2.913358449935913\n",
      "______________\n",
      "epoch 293 train loss 2.303010940551758\n",
      "val loss 2.9099881649017334\n",
      "______________\n",
      "epoch 294 train loss 2.2895724773406982\n",
      "val loss 2.906633138656616\n",
      "______________\n",
      "epoch 295 train loss 2.2681307792663574\n",
      "val loss 2.9033143520355225\n",
      "______________\n",
      "epoch 296 train loss 2.3091015815734863\n",
      "val loss 2.900015115737915\n",
      "______________\n",
      "epoch 297 train loss 2.317561388015747\n",
      "val loss 2.896664619445801\n",
      "______________\n",
      "epoch 298 train loss 2.288174867630005\n",
      "val loss 2.893312931060791\n",
      "______________\n",
      "epoch 299 train loss 2.2517433166503906\n",
      "val loss 2.889911651611328\n",
      "______________\n",
      "epoch 300 train loss 2.261551856994629\n",
      "val loss 2.886523485183716\n",
      "______________\n",
      "epoch 301 train loss 2.355788230895996\n",
      "val loss 2.8830859661102295\n",
      "______________\n",
      "epoch 302 train loss 2.289746046066284\n",
      "val loss 2.879629373550415\n",
      "______________\n",
      "epoch 303 train loss 2.2608673572540283\n",
      "val loss 2.876253604888916\n",
      "______________\n",
      "epoch 304 train loss 2.2914395332336426\n",
      "val loss 2.8729238510131836\n",
      "______________\n",
      "epoch 305 train loss 2.270407199859619\n",
      "val loss 2.869544267654419\n",
      "______________\n",
      "epoch 306 train loss 2.2067649364471436\n",
      "val loss 2.866319179534912\n",
      "______________\n",
      "epoch 307 train loss 2.1971750259399414\n",
      "val loss 2.863175630569458\n",
      "______________\n",
      "epoch 308 train loss 2.308579206466675\n",
      "val loss 2.860093116760254\n",
      "______________\n",
      "epoch 309 train loss 2.2613685131073\n",
      "val loss 2.856995105743408\n",
      "______________\n",
      "epoch 310 train loss 2.2681422233581543\n",
      "val loss 2.8538012504577637\n",
      "______________\n",
      "epoch 311 train loss 2.219207286834717\n",
      "val loss 2.850649356842041\n",
      "______________\n",
      "epoch 312 train loss 2.2098939418792725\n",
      "val loss 2.8474509716033936\n",
      "______________\n",
      "epoch 313 train loss 2.185943365097046\n",
      "val loss 2.8443081378936768\n",
      "______________\n",
      "epoch 314 train loss 2.229604721069336\n",
      "val loss 2.841148614883423\n",
      "______________\n",
      "epoch 315 train loss 2.283129930496216\n",
      "val loss 2.8379733562469482\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 316 train loss 2.1980443000793457\n",
      "val loss 2.8349807262420654\n",
      "______________\n",
      "epoch 317 train loss 2.2516279220581055\n",
      "val loss 2.8319449424743652\n",
      "______________\n",
      "epoch 318 train loss 2.2116870880126953\n",
      "val loss 2.8288817405700684\n",
      "______________\n",
      "epoch 319 train loss 2.2016820907592773\n",
      "val loss 2.8259103298187256\n",
      "______________\n",
      "epoch 320 train loss 2.2543516159057617\n",
      "val loss 2.8229711055755615\n",
      "______________\n",
      "epoch 321 train loss 2.2158987522125244\n",
      "val loss 2.820063591003418\n",
      "______________\n",
      "epoch 322 train loss 2.3049445152282715\n",
      "val loss 2.81710147857666\n",
      "______________\n",
      "epoch 323 train loss 2.2857961654663086\n",
      "val loss 2.814126491546631\n",
      "______________\n",
      "epoch 324 train loss 2.2143938541412354\n",
      "val loss 2.811228036880493\n",
      "______________\n",
      "epoch 325 train loss 2.2146270275115967\n",
      "val loss 2.808393955230713\n",
      "______________\n",
      "epoch 326 train loss 2.2381787300109863\n",
      "val loss 2.8056719303131104\n",
      "______________\n",
      "epoch 327 train loss 2.2027840614318848\n",
      "val loss 2.803011655807495\n",
      "______________\n",
      "epoch 328 train loss 2.1623477935791016\n",
      "val loss 2.8003244400024414\n",
      "______________\n",
      "epoch 329 train loss 2.298367977142334\n",
      "val loss 2.79758882522583\n",
      "______________\n",
      "epoch 330 train loss 2.1786038875579834\n",
      "val loss 2.794886827468872\n",
      "______________\n",
      "epoch 331 train loss 2.2792046070098877\n",
      "val loss 2.7921488285064697\n",
      "______________\n",
      "epoch 332 train loss 2.161896228790283\n",
      "val loss 2.789491653442383\n",
      "______________\n",
      "epoch 333 train loss 2.1661064624786377\n",
      "val loss 2.7868809700012207\n",
      "______________\n",
      "epoch 334 train loss 2.1918578147888184\n",
      "val loss 2.784236192703247\n",
      "______________\n",
      "epoch 335 train loss 2.220872402191162\n",
      "val loss 2.7816340923309326\n",
      "______________\n",
      "epoch 336 train loss 2.2311482429504395\n",
      "val loss 2.7790427207946777\n",
      "______________\n",
      "epoch 337 train loss 2.2306318283081055\n",
      "val loss 2.7764179706573486\n",
      "______________\n",
      "epoch 338 train loss 2.230621576309204\n",
      "val loss 2.7737529277801514\n",
      "______________\n",
      "epoch 339 train loss 2.222595453262329\n",
      "val loss 2.770986795425415\n",
      "______________\n",
      "epoch 340 train loss 2.159130573272705\n",
      "val loss 2.7681503295898438\n",
      "______________\n",
      "epoch 341 train loss 2.211683750152588\n",
      "val loss 2.7653658390045166\n",
      "______________\n",
      "epoch 342 train loss 2.1898601055145264\n",
      "val loss 2.7625644207000732\n",
      "______________\n",
      "epoch 343 train loss 2.2412502765655518\n",
      "val loss 2.759744644165039\n",
      "______________\n",
      "epoch 344 train loss 2.127349853515625\n",
      "val loss 2.757028818130493\n",
      "______________\n",
      "epoch 345 train loss 2.183716297149658\n",
      "val loss 2.7543351650238037\n",
      "______________\n",
      "epoch 346 train loss 2.0848348140716553\n",
      "val loss 2.75174617767334\n",
      "______________\n",
      "epoch 347 train loss 2.197378635406494\n",
      "val loss 2.749154806137085\n",
      "______________\n",
      "epoch 348 train loss 2.173715591430664\n",
      "val loss 2.746532440185547\n",
      "______________\n",
      "epoch 349 train loss 2.197721004486084\n",
      "val loss 2.743927240371704\n",
      "______________\n",
      "epoch 350 train loss 2.1517584323883057\n",
      "val loss 2.741426944732666\n",
      "______________\n",
      "epoch 351 train loss 2.215933084487915\n",
      "val loss 2.7388036251068115\n",
      "______________\n",
      "epoch 352 train loss 2.278834342956543\n",
      "val loss 2.736215829849243\n",
      "______________\n",
      "epoch 353 train loss 2.1838881969451904\n",
      "val loss 2.7335948944091797\n",
      "______________\n",
      "epoch 354 train loss 2.1416919231414795\n",
      "val loss 2.7310469150543213\n",
      "______________\n",
      "epoch 355 train loss 2.14882755279541\n",
      "val loss 2.728436231613159\n",
      "______________\n",
      "epoch 356 train loss 2.0915026664733887\n",
      "val loss 2.7258293628692627\n",
      "______________\n",
      "epoch 357 train loss 2.108603000640869\n",
      "val loss 2.723289728164673\n",
      "______________\n",
      "epoch 358 train loss 2.12804913520813\n",
      "val loss 2.720764636993408\n",
      "______________\n",
      "epoch 359 train loss 2.055466890335083\n",
      "val loss 2.7183592319488525\n",
      "______________\n",
      "epoch 360 train loss 2.1775717735290527\n",
      "val loss 2.715970993041992\n",
      "______________\n",
      "epoch 361 train loss 2.1237571239471436\n",
      "val loss 2.7134592533111572\n",
      "______________\n",
      "epoch 362 train loss 2.161796808242798\n",
      "val loss 2.7109568119049072\n",
      "______________\n",
      "epoch 363 train loss 2.1643946170806885\n",
      "val loss 2.708418846130371\n",
      "______________\n",
      "epoch 364 train loss 2.117788791656494\n",
      "val loss 2.7059764862060547\n",
      "______________\n",
      "epoch 365 train loss 2.123563051223755\n",
      "val loss 2.7035858631134033\n",
      "______________\n",
      "epoch 366 train loss 2.09889817237854\n",
      "val loss 2.7011282444000244\n",
      "______________\n",
      "epoch 367 train loss 2.1244401931762695\n",
      "val loss 2.698795795440674\n",
      "______________\n",
      "epoch 368 train loss 2.1311426162719727\n",
      "val loss 2.6964664459228516\n",
      "______________\n",
      "epoch 369 train loss 2.151576519012451\n",
      "val loss 2.6942267417907715\n",
      "______________\n",
      "epoch 370 train loss 2.1002814769744873\n",
      "val loss 2.6920697689056396\n",
      "______________\n",
      "epoch 371 train loss 2.155909776687622\n",
      "val loss 2.689892530441284\n",
      "______________\n",
      "epoch 372 train loss 2.124058961868286\n",
      "val loss 2.6877620220184326\n",
      "______________\n",
      "epoch 373 train loss 2.1320204734802246\n",
      "val loss 2.6855783462524414\n",
      "______________\n",
      "epoch 374 train loss 2.1016170978546143\n",
      "val loss 2.6833481788635254\n",
      "______________\n",
      "epoch 375 train loss 2.1604835987091064\n",
      "val loss 2.6811270713806152\n",
      "______________\n",
      "epoch 376 train loss 2.1010448932647705\n",
      "val loss 2.678969621658325\n",
      "______________\n",
      "epoch 377 train loss 2.1504111289978027\n",
      "val loss 2.6767258644104004\n",
      "______________\n",
      "epoch 378 train loss 2.0725176334381104\n",
      "val loss 2.674534797668457\n",
      "______________\n",
      "epoch 379 train loss 2.0845484733581543\n",
      "val loss 2.6723170280456543\n",
      "______________\n",
      "epoch 380 train loss 2.1212503910064697\n",
      "val loss 2.67004656791687\n",
      "______________\n",
      "epoch 381 train loss 2.093109607696533\n",
      "val loss 2.66780948638916\n",
      "______________\n",
      "epoch 382 train loss 2.165066719055176\n",
      "val loss 2.6656579971313477\n",
      "______________\n",
      "epoch 383 train loss 2.1529223918914795\n",
      "val loss 2.663362741470337\n",
      "______________\n",
      "epoch 384 train loss 2.0516083240509033\n",
      "val loss 2.661090135574341\n",
      "______________\n",
      "epoch 385 train loss 2.121133804321289\n",
      "val loss 2.6587698459625244\n",
      "______________\n",
      "epoch 386 train loss 2.027968645095825\n",
      "val loss 2.6564767360687256\n",
      "______________\n",
      "epoch 387 train loss 2.1236021518707275\n",
      "val loss 2.6541624069213867\n",
      "______________\n",
      "epoch 388 train loss 2.1022825241088867\n",
      "val loss 2.651841163635254\n",
      "______________\n",
      "epoch 389 train loss 1.9763987064361572\n",
      "val loss 2.6497292518615723\n",
      "______________\n",
      "epoch 390 train loss 2.0573267936706543\n",
      "val loss 2.6476550102233887\n",
      "______________\n",
      "epoch 391 train loss 2.175828218460083\n",
      "val loss 2.645596504211426\n",
      "______________\n",
      "epoch 392 train loss 2.0334436893463135\n",
      "val loss 2.643557071685791\n",
      "______________\n",
      "epoch 393 train loss 2.0670554637908936\n",
      "val loss 2.641514539718628\n",
      "______________\n",
      "epoch 394 train loss 2.148484706878662\n",
      "val loss 2.6394052505493164\n",
      "______________\n",
      "epoch 395 train loss 2.0691661834716797\n",
      "val loss 2.637397527694702\n",
      "______________\n",
      "epoch 396 train loss 2.1020665168762207\n",
      "val loss 2.6354117393493652\n",
      "______________\n",
      "epoch 397 train loss 2.0889415740966797\n",
      "val loss 2.6334540843963623\n",
      "______________\n",
      "epoch 398 train loss 2.0773239135742188\n",
      "val loss 2.6315414905548096\n",
      "______________\n",
      "epoch 399 train loss 2.032985210418701\n",
      "val loss 2.6296308040618896\n",
      "______________\n",
      "epoch 400 train loss 2.0454559326171875\n",
      "val loss 2.627849578857422\n",
      "______________\n",
      "epoch 401 train loss 2.1200947761535645\n",
      "val loss 2.626142978668213\n",
      "______________\n",
      "epoch 402 train loss 2.089712381362915\n",
      "val loss 2.6244046688079834\n",
      "______________\n",
      "epoch 403 train loss 2.1216964721679688\n",
      "val loss 2.6226470470428467\n",
      "______________\n",
      "epoch 404 train loss 2.069859266281128\n",
      "val loss 2.6209378242492676\n",
      "______________\n",
      "epoch 405 train loss 2.060943126678467\n",
      "val loss 2.6194136142730713\n",
      "______________\n",
      "epoch 406 train loss 2.0704681873321533\n",
      "val loss 2.617794990539551\n",
      "______________\n",
      "epoch 407 train loss 2.102132558822632\n",
      "val loss 2.6160740852355957\n",
      "______________\n",
      "epoch 408 train loss 2.0741069316864014\n",
      "val loss 2.6143312454223633\n",
      "______________\n",
      "epoch 409 train loss 2.108792781829834\n",
      "val loss 2.6125268936157227\n",
      "______________\n",
      "epoch 410 train loss 2.0300753116607666\n",
      "val loss 2.6106865406036377\n",
      "______________\n",
      "epoch 411 train loss 2.0166759490966797\n",
      "val loss 2.6088523864746094\n",
      "______________\n",
      "epoch 412 train loss 2.104684829711914\n",
      "val loss 2.60699462890625\n",
      "______________\n",
      "epoch 413 train loss 2.091336727142334\n",
      "val loss 2.6051065921783447\n",
      "______________\n",
      "epoch 414 train loss 2.0310463905334473\n",
      "val loss 2.6032094955444336\n",
      "______________\n",
      "epoch 415 train loss 2.046567440032959\n",
      "val loss 2.601241111755371\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 416 train loss 2.038479804992676\n",
      "val loss 2.5992519855499268\n",
      "______________\n",
      "epoch 417 train loss 2.0148868560791016\n",
      "val loss 2.5974209308624268\n",
      "______________\n",
      "epoch 418 train loss 2.0489487648010254\n",
      "val loss 2.5956647396087646\n",
      "______________\n",
      "epoch 419 train loss 1.9956870079040527\n",
      "val loss 2.59391450881958\n",
      "______________\n",
      "epoch 420 train loss 2.0681252479553223\n",
      "val loss 2.592113494873047\n",
      "______________\n",
      "epoch 421 train loss 2.051940441131592\n",
      "val loss 2.5902748107910156\n",
      "______________\n",
      "epoch 422 train loss 1.992535948753357\n",
      "val loss 2.588487148284912\n",
      "______________\n",
      "epoch 423 train loss 2.0468642711639404\n",
      "val loss 2.586674928665161\n",
      "______________\n",
      "epoch 424 train loss 2.101731061935425\n",
      "val loss 2.584754467010498\n",
      "______________\n",
      "epoch 425 train loss 2.04748797416687\n",
      "val loss 2.58278489112854\n",
      "______________\n",
      "epoch 426 train loss 2.0997016429901123\n",
      "val loss 2.5809128284454346\n",
      "______________\n",
      "epoch 427 train loss 2.0924575328826904\n",
      "val loss 2.5790791511535645\n",
      "______________\n",
      "epoch 428 train loss 2.0075571537017822\n",
      "val loss 2.5772557258605957\n",
      "______________\n",
      "epoch 429 train loss 2.0487406253814697\n",
      "val loss 2.575490713119507\n",
      "______________\n",
      "epoch 430 train loss 2.02738618850708\n",
      "val loss 2.5737221240997314\n",
      "______________\n",
      "epoch 431 train loss 1.983040690422058\n",
      "val loss 2.5720558166503906\n",
      "______________\n",
      "epoch 432 train loss 2.0340986251831055\n",
      "val loss 2.5703001022338867\n",
      "______________\n",
      "epoch 433 train loss 2.0370218753814697\n",
      "val loss 2.5685360431671143\n",
      "______________\n",
      "epoch 434 train loss 2.0310657024383545\n",
      "val loss 2.5668742656707764\n",
      "______________\n",
      "epoch 435 train loss 2.004701614379883\n",
      "val loss 2.565209150314331\n",
      "______________\n",
      "epoch 436 train loss 1.9672962427139282\n",
      "val loss 2.563634157180786\n",
      "______________\n",
      "epoch 437 train loss 2.092085838317871\n",
      "val loss 2.562063217163086\n",
      "______________\n",
      "epoch 438 train loss 1.9677886962890625\n",
      "val loss 2.5605413913726807\n",
      "______________\n",
      "epoch 439 train loss 2.0679471492767334\n",
      "val loss 2.5589895248413086\n",
      "______________\n",
      "epoch 440 train loss 1.991065263748169\n",
      "val loss 2.557500123977661\n",
      "______________\n",
      "epoch 441 train loss 2.0306780338287354\n",
      "val loss 2.55595064163208\n",
      "______________\n",
      "epoch 442 train loss 2.0647504329681396\n",
      "val loss 2.554392099380493\n",
      "______________\n",
      "epoch 443 train loss 2.0925211906433105\n",
      "val loss 2.552811622619629\n",
      "______________\n",
      "epoch 444 train loss 1.995330810546875\n",
      "val loss 2.5513343811035156\n",
      "______________\n",
      "epoch 445 train loss 2.009133815765381\n",
      "val loss 2.549848794937134\n",
      "______________\n",
      "epoch 446 train loss 1.9981284141540527\n",
      "val loss 2.548400640487671\n",
      "______________\n",
      "epoch 447 train loss 2.028163194656372\n",
      "val loss 2.547001600265503\n",
      "______________\n",
      "epoch 448 train loss 1.9888863563537598\n",
      "val loss 2.5456430912017822\n",
      "______________\n",
      "epoch 449 train loss 1.9993914365768433\n",
      "val loss 2.5442371368408203\n",
      "______________\n",
      "epoch 450 train loss 2.062281847000122\n",
      "val loss 2.5426828861236572\n",
      "______________\n",
      "epoch 451 train loss 1.9682825803756714\n",
      "val loss 2.5412380695343018\n",
      "______________\n",
      "epoch 452 train loss 1.9868361949920654\n",
      "val loss 2.5398786067962646\n",
      "______________\n",
      "epoch 453 train loss 2.0446557998657227\n",
      "val loss 2.5384480953216553\n",
      "______________\n",
      "epoch 454 train loss 2.0256552696228027\n",
      "val loss 2.537048578262329\n",
      "______________\n",
      "epoch 455 train loss 1.9618903398513794\n",
      "val loss 2.5356554985046387\n",
      "______________\n",
      "epoch 456 train loss 2.003265857696533\n",
      "val loss 2.534233808517456\n",
      "______________\n",
      "epoch 457 train loss 1.9660409688949585\n",
      "val loss 2.532806396484375\n",
      "______________\n",
      "epoch 458 train loss 1.9782381057739258\n",
      "val loss 2.5313315391540527\n",
      "______________\n",
      "epoch 459 train loss 1.9646852016448975\n",
      "val loss 2.5298500061035156\n",
      "______________\n",
      "epoch 460 train loss 1.9893803596496582\n",
      "val loss 2.5283124446868896\n",
      "______________\n",
      "epoch 461 train loss 1.991408348083496\n",
      "val loss 2.526780605316162\n",
      "______________\n",
      "epoch 462 train loss 2.0171122550964355\n",
      "val loss 2.5251259803771973\n",
      "______________\n",
      "epoch 463 train loss 1.997290015220642\n",
      "val loss 2.5234570503234863\n",
      "______________\n",
      "epoch 464 train loss 2.021394968032837\n",
      "val loss 2.5217208862304688\n",
      "______________\n",
      "epoch 465 train loss 1.9753103256225586\n",
      "val loss 2.5199615955352783\n",
      "______________\n",
      "epoch 466 train loss 1.9835987091064453\n",
      "val loss 2.518239736557007\n",
      "______________\n",
      "epoch 467 train loss 1.9869149923324585\n",
      "val loss 2.5165035724639893\n",
      "______________\n",
      "epoch 468 train loss 2.019446611404419\n",
      "val loss 2.514803171157837\n",
      "______________\n",
      "epoch 469 train loss 1.951844573020935\n",
      "val loss 2.513190984725952\n",
      "______________\n",
      "epoch 470 train loss 1.9855877161026\n",
      "val loss 2.5116899013519287\n",
      "______________\n",
      "epoch 471 train loss 1.9728530645370483\n",
      "val loss 2.5101654529571533\n",
      "______________\n",
      "epoch 472 train loss 1.9732205867767334\n",
      "val loss 2.5087366104125977\n",
      "______________\n",
      "epoch 473 train loss 2.012794017791748\n",
      "val loss 2.5072803497314453\n",
      "______________\n",
      "epoch 474 train loss 1.981575608253479\n",
      "val loss 2.5059056282043457\n",
      "______________\n",
      "epoch 475 train loss 1.9536142349243164\n",
      "val loss 2.5044829845428467\n",
      "______________\n",
      "epoch 476 train loss 1.942334771156311\n",
      "val loss 2.5030713081359863\n",
      "______________\n",
      "epoch 477 train loss 1.9394253492355347\n",
      "val loss 2.501659631729126\n",
      "______________\n",
      "epoch 478 train loss 1.9701766967773438\n",
      "val loss 2.5002498626708984\n",
      "______________\n",
      "epoch 479 train loss 1.998489499092102\n",
      "val loss 2.4988884925842285\n",
      "______________\n",
      "epoch 480 train loss 1.9633941650390625\n",
      "val loss 2.49751615524292\n",
      "______________\n",
      "epoch 481 train loss 2.0093929767608643\n",
      "val loss 2.496151924133301\n",
      "______________\n",
      "epoch 482 train loss 1.9979621171951294\n",
      "val loss 2.4948039054870605\n",
      "______________\n",
      "epoch 483 train loss 1.9408336877822876\n",
      "val loss 2.493436336517334\n",
      "______________\n",
      "epoch 484 train loss 1.9055125713348389\n",
      "val loss 2.4922144412994385\n",
      "______________\n",
      "epoch 485 train loss 1.9729948043823242\n",
      "val loss 2.4909920692443848\n",
      "______________\n",
      "epoch 486 train loss 1.9954601526260376\n",
      "val loss 2.48974609375\n",
      "______________\n",
      "epoch 487 train loss 1.9603325128555298\n",
      "val loss 2.4884755611419678\n",
      "______________\n",
      "epoch 488 train loss 1.9289515018463135\n",
      "val loss 2.4871394634246826\n",
      "______________\n",
      "epoch 489 train loss 1.954237937927246\n",
      "val loss 2.4857611656188965\n",
      "______________\n",
      "epoch 490 train loss 1.918044090270996\n",
      "val loss 2.484393835067749\n",
      "______________\n",
      "epoch 491 train loss 1.9444094896316528\n",
      "val loss 2.4830174446105957\n",
      "______________\n",
      "epoch 492 train loss 1.9319469928741455\n",
      "val loss 2.481632709503174\n",
      "______________\n",
      "epoch 493 train loss 1.9827717542648315\n",
      "val loss 2.4802281856536865\n",
      "______________\n",
      "epoch 494 train loss 2.0144565105438232\n",
      "val loss 2.4789605140686035\n",
      "______________\n",
      "epoch 495 train loss 1.9591987133026123\n",
      "val loss 2.4776833057403564\n",
      "______________\n",
      "epoch 496 train loss 1.9821419715881348\n",
      "val loss 2.4763636589050293\n",
      "______________\n",
      "epoch 497 train loss 1.947376012802124\n",
      "val loss 2.4750733375549316\n",
      "______________\n",
      "epoch 498 train loss 1.9620338678359985\n",
      "val loss 2.4737753868103027\n",
      "______________\n",
      "epoch 499 train loss 1.905239462852478\n",
      "val loss 2.4725348949432373\n",
      "______________\n",
      "epoch 500 train loss 1.9277456998825073\n",
      "val loss 2.4713661670684814\n",
      "______________\n",
      "epoch 501 train loss 1.9003323316574097\n",
      "val loss 2.470317840576172\n",
      "______________\n",
      "epoch 502 train loss 1.8754737377166748\n",
      "val loss 2.469310998916626\n",
      "______________\n",
      "epoch 503 train loss 1.9954973459243774\n",
      "val loss 2.468306541442871\n",
      "______________\n",
      "epoch 504 train loss 1.9649176597595215\n",
      "val loss 2.4671719074249268\n",
      "______________\n",
      "epoch 505 train loss 2.013381004333496\n",
      "val loss 2.4660348892211914\n",
      "______________\n",
      "epoch 506 train loss 1.9336700439453125\n",
      "val loss 2.464815139770508\n",
      "______________\n",
      "epoch 507 train loss 1.8749713897705078\n",
      "val loss 2.4635612964630127\n",
      "______________\n",
      "epoch 508 train loss 1.908504843711853\n",
      "val loss 2.4623489379882812\n",
      "______________\n",
      "epoch 509 train loss 1.9699803590774536\n",
      "val loss 2.461169719696045\n",
      "______________\n",
      "epoch 510 train loss 1.9599649906158447\n",
      "val loss 2.459994316101074\n",
      "______________\n",
      "epoch 511 train loss 1.9494438171386719\n",
      "val loss 2.458784341812134\n",
      "______________\n",
      "epoch 512 train loss 1.951817274093628\n",
      "val loss 2.4574930667877197\n",
      "______________\n",
      "epoch 513 train loss 1.9913358688354492\n",
      "val loss 2.456115245819092\n",
      "______________\n",
      "epoch 514 train loss 1.946968913078308\n",
      "val loss 2.4547314643859863\n",
      "______________\n",
      "epoch 515 train loss 1.939049243927002\n",
      "val loss 2.4533469676971436\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 516 train loss 1.8962562084197998\n",
      "val loss 2.4520905017852783\n",
      "______________\n",
      "epoch 517 train loss 1.9293277263641357\n",
      "val loss 2.450821876525879\n",
      "______________\n",
      "epoch 518 train loss 1.9839297533035278\n",
      "val loss 2.4496102333068848\n",
      "______________\n",
      "epoch 519 train loss 1.9015847444534302\n",
      "val loss 2.448415994644165\n",
      "______________\n",
      "epoch 520 train loss 1.9059488773345947\n",
      "val loss 2.447178602218628\n",
      "______________\n",
      "epoch 521 train loss 1.8910077810287476\n",
      "val loss 2.445984125137329\n",
      "______________\n",
      "epoch 522 train loss 1.946161150932312\n",
      "val loss 2.4447813034057617\n",
      "______________\n",
      "epoch 523 train loss 1.8800580501556396\n",
      "val loss 2.443615436553955\n",
      "______________\n",
      "epoch 524 train loss 1.9005367755889893\n",
      "val loss 2.442521333694458\n",
      "______________\n",
      "epoch 525 train loss 1.9038960933685303\n",
      "val loss 2.4414055347442627\n",
      "______________\n",
      "epoch 526 train loss 1.9455182552337646\n",
      "val loss 2.440321445465088\n",
      "______________\n",
      "epoch 527 train loss 1.9061335325241089\n",
      "val loss 2.4392588138580322\n",
      "______________\n",
      "epoch 528 train loss 1.9329663515090942\n",
      "val loss 2.438067674636841\n",
      "______________\n",
      "epoch 529 train loss 1.894426703453064\n",
      "val loss 2.4369351863861084\n",
      "______________\n",
      "epoch 530 train loss 1.9685155153274536\n",
      "val loss 2.4358017444610596\n",
      "______________\n",
      "epoch 531 train loss 1.8754265308380127\n",
      "val loss 2.434741973876953\n",
      "______________\n",
      "epoch 532 train loss 1.8906329870224\n",
      "val loss 2.4337093830108643\n",
      "______________\n",
      "epoch 533 train loss 1.9145512580871582\n",
      "val loss 2.4326131343841553\n",
      "______________\n",
      "epoch 534 train loss 1.8664966821670532\n",
      "val loss 2.4315226078033447\n",
      "______________\n",
      "epoch 535 train loss 1.9256139993667603\n",
      "val loss 2.43044114112854\n",
      "______________\n",
      "epoch 536 train loss 1.8770835399627686\n",
      "val loss 2.429304838180542\n",
      "______________\n",
      "epoch 537 train loss 1.882543683052063\n",
      "val loss 2.428196430206299\n",
      "______________\n",
      "epoch 538 train loss 1.928327202796936\n",
      "val loss 2.426938056945801\n",
      "______________\n",
      "epoch 539 train loss 1.9254636764526367\n",
      "val loss 2.425623655319214\n",
      "______________\n",
      "epoch 540 train loss 1.8529444932937622\n",
      "val loss 2.424403667449951\n",
      "______________\n",
      "epoch 541 train loss 1.8782535791397095\n",
      "val loss 2.4231514930725098\n",
      "______________\n",
      "epoch 542 train loss 1.8987717628479004\n",
      "val loss 2.421844244003296\n",
      "______________\n",
      "epoch 543 train loss 1.9436630010604858\n",
      "val loss 2.4206340312957764\n",
      "______________\n",
      "epoch 544 train loss 1.9336936473846436\n",
      "val loss 2.419435501098633\n",
      "______________\n",
      "epoch 545 train loss 1.9106203317642212\n",
      "val loss 2.418229579925537\n",
      "______________\n",
      "epoch 546 train loss 1.851037859916687\n",
      "val loss 2.4171061515808105\n",
      "______________\n",
      "epoch 547 train loss 1.967435598373413\n",
      "val loss 2.415998697280884\n",
      "______________\n",
      "epoch 548 train loss 1.9218453168869019\n",
      "val loss 2.414857864379883\n",
      "______________\n",
      "epoch 549 train loss 1.8756036758422852\n",
      "val loss 2.41378116607666\n",
      "______________\n",
      "epoch 550 train loss 1.8247385025024414\n",
      "val loss 2.4127748012542725\n",
      "______________\n",
      "epoch 551 train loss 1.8720000982284546\n",
      "val loss 2.41184663772583\n",
      "______________\n",
      "epoch 552 train loss 1.8835439682006836\n",
      "val loss 2.4109301567077637\n",
      "______________\n",
      "epoch 553 train loss 1.8482136726379395\n",
      "val loss 2.410072088241577\n",
      "______________\n",
      "epoch 554 train loss 1.9004348516464233\n",
      "val loss 2.4091806411743164\n",
      "______________\n",
      "epoch 555 train loss 1.9623342752456665\n",
      "val loss 2.4082324504852295\n",
      "______________\n",
      "epoch 556 train loss 1.87371826171875\n",
      "val loss 2.4072823524475098\n",
      "______________\n",
      "epoch 557 train loss 1.859858751296997\n",
      "val loss 2.406392812728882\n",
      "______________\n",
      "epoch 558 train loss 1.880649209022522\n",
      "val loss 2.405501365661621\n",
      "______________\n",
      "epoch 559 train loss 1.932358741760254\n",
      "val loss 2.404536247253418\n",
      "______________\n",
      "epoch 560 train loss 1.9163792133331299\n",
      "val loss 2.403578758239746\n",
      "______________\n",
      "epoch 561 train loss 1.8717831373214722\n",
      "val loss 2.4025938510894775\n",
      "______________\n",
      "epoch 562 train loss 1.929565191268921\n",
      "val loss 2.401505708694458\n",
      "______________\n",
      "epoch 563 train loss 1.8602397441864014\n",
      "val loss 2.4004218578338623\n",
      "______________\n",
      "epoch 564 train loss 1.9103434085845947\n",
      "val loss 2.399367570877075\n",
      "______________\n",
      "epoch 565 train loss 1.883377194404602\n",
      "val loss 2.398331642150879\n",
      "______________\n",
      "epoch 566 train loss 1.8929086923599243\n",
      "val loss 2.397374391555786\n",
      "______________\n",
      "epoch 567 train loss 1.9163295030593872\n",
      "val loss 2.396389961242676\n",
      "______________\n",
      "epoch 568 train loss 1.9314452409744263\n",
      "val loss 2.39544939994812\n",
      "______________\n",
      "epoch 569 train loss 1.9300280809402466\n",
      "val loss 2.394503355026245\n",
      "______________\n",
      "epoch 570 train loss 1.8719886541366577\n",
      "val loss 2.393587350845337\n",
      "______________\n",
      "epoch 571 train loss 1.9110844135284424\n",
      "val loss 2.392646312713623\n",
      "______________\n",
      "epoch 572 train loss 1.8724472522735596\n",
      "val loss 2.3917174339294434\n",
      "______________\n",
      "epoch 573 train loss 1.9076982736587524\n",
      "val loss 2.39086651802063\n",
      "______________\n",
      "epoch 574 train loss 1.932386040687561\n",
      "val loss 2.3899483680725098\n",
      "______________\n",
      "epoch 575 train loss 1.880265712738037\n",
      "val loss 2.389082193374634\n",
      "______________\n",
      "epoch 576 train loss 1.8377630710601807\n",
      "val loss 2.3882014751434326\n",
      "______________\n",
      "epoch 577 train loss 1.9056884050369263\n",
      "val loss 2.3873395919799805\n",
      "______________\n",
      "epoch 578 train loss 1.8182121515274048\n",
      "val loss 2.386552572250366\n",
      "______________\n",
      "epoch 579 train loss 1.9517358541488647\n",
      "val loss 2.3857269287109375\n",
      "______________\n",
      "epoch 580 train loss 1.878762125968933\n",
      "val loss 2.384922981262207\n",
      "______________\n",
      "epoch 581 train loss 1.915220856666565\n",
      "val loss 2.384061813354492\n",
      "______________\n",
      "epoch 582 train loss 1.9099433422088623\n",
      "val loss 2.3831675052642822\n",
      "______________\n",
      "epoch 583 train loss 1.8311705589294434\n",
      "val loss 2.3823189735412598\n",
      "______________\n",
      "epoch 584 train loss 1.880169153213501\n",
      "val loss 2.3815391063690186\n",
      "______________\n",
      "epoch 585 train loss 1.8527750968933105\n",
      "val loss 2.3807804584503174\n",
      "______________\n",
      "epoch 586 train loss 1.904741883277893\n",
      "val loss 2.3801040649414062\n",
      "______________\n",
      "epoch 587 train loss 1.8580026626586914\n",
      "val loss 2.379471778869629\n",
      "______________\n",
      "epoch 588 train loss 1.8654124736785889\n",
      "val loss 2.378856658935547\n",
      "______________\n",
      "epoch 589 train loss 1.8340784311294556\n",
      "val loss 2.378256320953369\n",
      "______________\n",
      "epoch 590 train loss 1.8429763317108154\n",
      "val loss 2.377584218978882\n",
      "______________\n",
      "epoch 591 train loss 1.8401035070419312\n",
      "val loss 2.3770065307617188\n",
      "______________\n",
      "epoch 592 train loss 1.8176456689834595\n",
      "val loss 2.3764569759368896\n",
      "______________\n",
      "epoch 593 train loss 1.800220012664795\n",
      "val loss 2.375946521759033\n",
      "______________\n",
      "epoch 594 train loss 1.9046775102615356\n",
      "val loss 2.375321865081787\n",
      "______________\n",
      "epoch 595 train loss 1.882282018661499\n",
      "val loss 2.374589681625366\n",
      "______________\n",
      "epoch 596 train loss 1.9029793739318848\n",
      "val loss 2.3738481998443604\n",
      "______________\n",
      "epoch 597 train loss 1.8455568552017212\n",
      "val loss 2.3730881214141846\n",
      "______________\n",
      "epoch 598 train loss 1.89687180519104\n",
      "val loss 2.372271776199341\n",
      "______________\n",
      "epoch 599 train loss 1.8267310857772827\n",
      "val loss 2.371459484100342\n",
      "______________\n",
      "epoch 600 train loss 1.9161787033081055\n",
      "val loss 2.3706226348876953\n",
      "______________\n",
      "epoch 601 train loss 1.8860801458358765\n",
      "val loss 2.369746685028076\n",
      "______________\n",
      "epoch 602 train loss 1.852040410041809\n",
      "val loss 2.3688740730285645\n",
      "______________\n",
      "epoch 603 train loss 1.8583228588104248\n",
      "val loss 2.368022918701172\n",
      "______________\n",
      "epoch 604 train loss 1.8509665727615356\n",
      "val loss 2.367180824279785\n",
      "______________\n",
      "epoch 605 train loss 1.869828701019287\n",
      "val loss 2.36635160446167\n",
      "______________\n",
      "epoch 606 train loss 1.8305877447128296\n",
      "val loss 2.365584373474121\n",
      "______________\n",
      "epoch 607 train loss 1.8429878950119019\n",
      "val loss 2.3647639751434326\n",
      "______________\n",
      "epoch 608 train loss 1.916961908340454\n",
      "val loss 2.363936185836792\n",
      "______________\n",
      "epoch 609 train loss 1.9061789512634277\n",
      "val loss 2.363065242767334\n",
      "______________\n",
      "epoch 610 train loss 1.8591810464859009\n",
      "val loss 2.362269401550293\n",
      "______________\n",
      "epoch 611 train loss 1.7818808555603027\n",
      "val loss 2.3615312576293945\n",
      "______________\n",
      "epoch 612 train loss 1.8597408533096313\n",
      "val loss 2.3606953620910645\n",
      "______________\n",
      "epoch 613 train loss 1.8204808235168457\n",
      "val loss 2.3598766326904297\n",
      "______________\n",
      "epoch 614 train loss 1.8536157608032227\n",
      "val loss 2.358999490737915\n",
      "______________\n",
      "epoch 615 train loss 1.849578857421875\n",
      "val loss 2.358156681060791\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 616 train loss 1.8102638721466064\n",
      "val loss 2.357335329055786\n",
      "______________\n",
      "epoch 617 train loss 1.8821309804916382\n",
      "val loss 2.356456756591797\n",
      "______________\n",
      "epoch 618 train loss 1.8421550989151\n",
      "val loss 2.35561203956604\n",
      "______________\n",
      "epoch 619 train loss 1.8658998012542725\n",
      "val loss 2.3548107147216797\n",
      "______________\n",
      "epoch 620 train loss 1.8027706146240234\n",
      "val loss 2.3541066646575928\n",
      "______________\n",
      "epoch 621 train loss 1.8508849143981934\n",
      "val loss 2.3533689975738525\n",
      "______________\n",
      "epoch 622 train loss 1.8420522212982178\n",
      "val loss 2.35263991355896\n",
      "______________\n",
      "epoch 623 train loss 1.8534283638000488\n",
      "val loss 2.3519647121429443\n",
      "______________\n",
      "epoch 624 train loss 1.8595632314682007\n",
      "val loss 2.351236581802368\n",
      "______________\n",
      "epoch 625 train loss 1.8404078483581543\n",
      "val loss 2.350466012954712\n",
      "______________\n",
      "epoch 626 train loss 1.7805637121200562\n",
      "val loss 2.3496806621551514\n",
      "______________\n",
      "epoch 627 train loss 1.8499927520751953\n",
      "val loss 2.3488807678222656\n",
      "______________\n",
      "epoch 628 train loss 1.8358089923858643\n",
      "val loss 2.348050594329834\n",
      "______________\n",
      "epoch 629 train loss 1.8423856496810913\n",
      "val loss 2.3472204208374023\n",
      "______________\n",
      "epoch 630 train loss 1.8893646001815796\n",
      "val loss 2.346339225769043\n",
      "______________\n",
      "epoch 631 train loss 1.8271129131317139\n",
      "val loss 2.3454506397247314\n",
      "______________\n",
      "epoch 632 train loss 1.8481993675231934\n",
      "val loss 2.34454607963562\n",
      "______________\n",
      "epoch 633 train loss 1.824817180633545\n",
      "val loss 2.343766212463379\n",
      "______________\n",
      "epoch 634 train loss 1.8671224117279053\n",
      "val loss 2.3430142402648926\n",
      "______________\n",
      "epoch 635 train loss 1.827726125717163\n",
      "val loss 2.342200517654419\n",
      "______________\n",
      "epoch 636 train loss 1.8076279163360596\n",
      "val loss 2.3414418697357178\n",
      "______________\n",
      "epoch 637 train loss 1.8329105377197266\n",
      "val loss 2.3407351970672607\n",
      "______________\n",
      "epoch 638 train loss 1.880640983581543\n",
      "val loss 2.339951992034912\n",
      "______________\n",
      "epoch 639 train loss 1.8096104860305786\n",
      "val loss 2.3391830921173096\n",
      "______________\n",
      "epoch 640 train loss 1.8124195337295532\n",
      "val loss 2.338388442993164\n",
      "______________\n",
      "epoch 641 train loss 1.8533027172088623\n",
      "val loss 2.3376054763793945\n",
      "______________\n",
      "epoch 642 train loss 1.8105298280715942\n",
      "val loss 2.3368189334869385\n",
      "______________\n",
      "epoch 643 train loss 1.8225573301315308\n",
      "val loss 2.3361012935638428\n",
      "______________\n",
      "epoch 644 train loss 1.8331832885742188\n",
      "val loss 2.335447072982788\n",
      "______________\n",
      "epoch 645 train loss 1.7967276573181152\n",
      "val loss 2.3347952365875244\n",
      "______________\n",
      "epoch 646 train loss 1.8829288482666016\n",
      "val loss 2.3341872692108154\n",
      "______________\n",
      "epoch 647 train loss 1.7519193887710571\n",
      "val loss 2.333533525466919\n",
      "______________\n",
      "epoch 648 train loss 1.8114221096038818\n",
      "val loss 2.332834482192993\n",
      "______________\n",
      "epoch 649 train loss 1.8625000715255737\n",
      "val loss 2.332155227661133\n",
      "______________\n",
      "epoch 650 train loss 1.8986996412277222\n",
      "val loss 2.33140230178833\n",
      "______________\n",
      "epoch 651 train loss 1.8809212446212769\n",
      "val loss 2.330634593963623\n",
      "______________\n",
      "epoch 652 train loss 1.7754123210906982\n",
      "val loss 2.3299288749694824\n",
      "______________\n",
      "epoch 653 train loss 1.8133913278579712\n",
      "val loss 2.3292253017425537\n",
      "______________\n",
      "epoch 654 train loss 1.7963768243789673\n",
      "val loss 2.3285388946533203\n",
      "______________\n",
      "epoch 655 train loss 1.8146820068359375\n",
      "val loss 2.3278605937957764\n",
      "______________\n",
      "epoch 656 train loss 1.8321605920791626\n",
      "val loss 2.327199935913086\n",
      "______________\n",
      "epoch 657 train loss 1.86319100856781\n",
      "val loss 2.3265774250030518\n",
      "______________\n",
      "epoch 658 train loss 1.807267427444458\n",
      "val loss 2.325930595397949\n",
      "______________\n",
      "epoch 659 train loss 1.8690037727355957\n",
      "val loss 2.3252973556518555\n",
      "______________\n",
      "epoch 660 train loss 1.8519062995910645\n",
      "val loss 2.3246514797210693\n",
      "______________\n",
      "epoch 661 train loss 1.813010573387146\n",
      "val loss 2.3240511417388916\n",
      "______________\n",
      "epoch 662 train loss 1.7763794660568237\n",
      "val loss 2.3234918117523193\n",
      "______________\n",
      "epoch 663 train loss 1.8439457416534424\n",
      "val loss 2.3229448795318604\n",
      "______________\n",
      "epoch 664 train loss 1.7779545783996582\n",
      "val loss 2.322396755218506\n",
      "______________\n",
      "epoch 665 train loss 1.7531172037124634\n",
      "val loss 2.321887493133545\n",
      "______________\n",
      "epoch 666 train loss 1.7769285440444946\n",
      "val loss 2.3214528560638428\n",
      "______________\n",
      "epoch 667 train loss 1.8217074871063232\n",
      "val loss 2.3210015296936035\n",
      "______________\n",
      "epoch 668 train loss 1.8370147943496704\n",
      "val loss 2.3205161094665527\n",
      "______________\n",
      "epoch 669 train loss 1.8135998249053955\n",
      "val loss 2.3201165199279785\n",
      "______________\n",
      "epoch 670 train loss 1.8090529441833496\n",
      "val loss 2.31972336769104\n",
      "______________\n",
      "epoch 671 train loss 1.787939190864563\n",
      "val loss 2.3193976879119873\n",
      "______________\n",
      "epoch 672 train loss 1.7653982639312744\n",
      "val loss 2.3191134929656982\n",
      "______________\n",
      "epoch 673 train loss 1.8025938272476196\n",
      "val loss 2.3187711238861084\n",
      "______________\n",
      "epoch 674 train loss 1.7866833209991455\n",
      "val loss 2.3183701038360596\n",
      "______________\n",
      "epoch 675 train loss 1.7643388509750366\n",
      "val loss 2.3179361820220947\n",
      "______________\n",
      "epoch 676 train loss 1.7888751029968262\n",
      "val loss 2.317530870437622\n",
      "______________\n",
      "epoch 677 train loss 1.7878572940826416\n",
      "val loss 2.3171026706695557\n",
      "______________\n",
      "epoch 678 train loss 1.8090258836746216\n",
      "val loss 2.31669545173645\n",
      "______________\n",
      "epoch 679 train loss 1.8536509275436401\n",
      "val loss 2.316195011138916\n",
      "______________\n",
      "epoch 680 train loss 1.828074336051941\n",
      "val loss 2.315601110458374\n",
      "______________\n",
      "epoch 681 train loss 1.8842308521270752\n",
      "val loss 2.3149731159210205\n",
      "______________\n",
      "epoch 682 train loss 1.7845141887664795\n",
      "val loss 2.3143842220306396\n",
      "______________\n",
      "epoch 683 train loss 1.7810250520706177\n",
      "val loss 2.313774347305298\n",
      "______________\n",
      "epoch 684 train loss 1.829964280128479\n",
      "val loss 2.313241720199585\n",
      "______________\n",
      "epoch 685 train loss 1.7722679376602173\n",
      "val loss 2.312683582305908\n",
      "______________\n",
      "epoch 686 train loss 1.8442909717559814\n",
      "val loss 2.312101364135742\n",
      "______________\n",
      "epoch 687 train loss 1.7920653820037842\n",
      "val loss 2.3115766048431396\n",
      "______________\n",
      "epoch 688 train loss 1.797411561012268\n",
      "val loss 2.311100959777832\n",
      "______________\n",
      "epoch 689 train loss 1.7498116493225098\n",
      "val loss 2.310610055923462\n",
      "______________\n",
      "epoch 690 train loss 1.8169045448303223\n",
      "val loss 2.31007719039917\n",
      "______________\n",
      "epoch 691 train loss 1.7469687461853027\n",
      "val loss 2.3096072673797607\n",
      "______________\n",
      "epoch 692 train loss 1.7883758544921875\n",
      "val loss 2.3091213703155518\n",
      "______________\n",
      "epoch 693 train loss 1.8219914436340332\n",
      "val loss 2.3086037635803223\n",
      "______________\n",
      "epoch 694 train loss 1.8121111392974854\n",
      "val loss 2.3080315589904785\n",
      "______________\n",
      "epoch 695 train loss 1.789299488067627\n",
      "val loss 2.3073911666870117\n",
      "______________\n",
      "epoch 696 train loss 1.8034716844558716\n",
      "val loss 2.306751012802124\n",
      "______________\n",
      "epoch 697 train loss 1.7678335905075073\n",
      "val loss 2.3061373233795166\n",
      "______________\n",
      "epoch 698 train loss 1.7430496215820312\n",
      "val loss 2.3055648803710938\n",
      "______________\n",
      "epoch 699 train loss 1.7997498512268066\n",
      "val loss 2.3050200939178467\n",
      "______________\n",
      "epoch 700 train loss 1.7920037508010864\n",
      "val loss 2.3044753074645996\n",
      "______________\n",
      "epoch 701 train loss 1.7982268333435059\n",
      "val loss 2.303917169570923\n",
      "______________\n",
      "epoch 702 train loss 1.794752836227417\n",
      "val loss 2.3033339977264404\n",
      "______________\n",
      "epoch 703 train loss 1.744797706604004\n",
      "val loss 2.3028204441070557\n",
      "______________\n",
      "epoch 704 train loss 1.7694319486618042\n",
      "val loss 2.3022959232330322\n",
      "______________\n",
      "epoch 705 train loss 1.8479321002960205\n",
      "val loss 2.3017375469207764\n",
      "______________\n",
      "epoch 706 train loss 1.8080811500549316\n",
      "val loss 2.301246166229248\n",
      "______________\n",
      "epoch 707 train loss 1.8180444240570068\n",
      "val loss 2.300692081451416\n",
      "______________\n",
      "epoch 708 train loss 1.7434496879577637\n",
      "val loss 2.3000917434692383\n",
      "______________\n",
      "epoch 709 train loss 1.7672865390777588\n",
      "val loss 2.2994375228881836\n",
      "______________\n",
      "epoch 710 train loss 1.8449525833129883\n",
      "val loss 2.2987966537475586\n",
      "______________\n",
      "epoch 711 train loss 1.846897840499878\n",
      "val loss 2.2981889247894287\n",
      "______________\n",
      "epoch 712 train loss 1.803304672241211\n",
      "val loss 2.2976748943328857\n",
      "______________\n",
      "epoch 713 train loss 1.7830454111099243\n",
      "val loss 2.2971079349517822\n",
      "______________\n",
      "epoch 714 train loss 1.7409565448760986\n",
      "val loss 2.296581983566284\n",
      "______________\n",
      "epoch 715 train loss 1.7413771152496338\n",
      "val loss 2.2960891723632812\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 716 train loss 1.8093935251235962\n",
      "val loss 2.2956342697143555\n",
      "______________\n",
      "epoch 717 train loss 1.8172975778579712\n",
      "val loss 2.295180320739746\n",
      "______________\n",
      "epoch 718 train loss 1.8008874654769897\n",
      "val loss 2.2947776317596436\n",
      "______________\n",
      "epoch 719 train loss 1.7355549335479736\n",
      "val loss 2.294374465942383\n",
      "______________\n",
      "epoch 720 train loss 1.7758588790893555\n",
      "val loss 2.2939488887786865\n",
      "______________\n",
      "epoch 721 train loss 1.721895456314087\n",
      "val loss 2.2934911251068115\n",
      "______________\n",
      "epoch 722 train loss 1.8234310150146484\n",
      "val loss 2.2930240631103516\n",
      "______________\n",
      "epoch 723 train loss 1.8571240901947021\n",
      "val loss 2.29253888130188\n",
      "______________\n",
      "epoch 724 train loss 1.7865300178527832\n",
      "val loss 2.292057991027832\n",
      "______________\n",
      "epoch 725 train loss 1.8160970211029053\n",
      "val loss 2.2916665077209473\n",
      "______________\n",
      "epoch 726 train loss 1.7262141704559326\n",
      "val loss 2.291252851486206\n",
      "______________\n",
      "epoch 727 train loss 1.755845308303833\n",
      "val loss 2.2908432483673096\n",
      "______________\n",
      "epoch 728 train loss 1.7790377140045166\n",
      "val loss 2.290450096130371\n",
      "______________\n",
      "epoch 729 train loss 1.7514255046844482\n",
      "val loss 2.290010452270508\n",
      "______________\n",
      "epoch 730 train loss 1.732859492301941\n",
      "val loss 2.289621353149414\n",
      "______________\n",
      "epoch 731 train loss 1.810605764389038\n",
      "val loss 2.2893285751342773\n",
      "______________\n",
      "epoch 732 train loss 1.7705819606781006\n",
      "val loss 2.2889914512634277\n",
      "______________\n",
      "epoch 733 train loss 1.809153437614441\n",
      "val loss 2.2885935306549072\n",
      "______________\n",
      "epoch 734 train loss 1.7906450033187866\n",
      "val loss 2.2882204055786133\n",
      "______________\n",
      "epoch 735 train loss 1.8023563623428345\n",
      "val loss 2.2878034114837646\n",
      "______________\n",
      "epoch 736 train loss 1.7532587051391602\n",
      "val loss 2.2873167991638184\n",
      "______________\n",
      "epoch 737 train loss 1.7897382974624634\n",
      "val loss 2.2868120670318604\n",
      "______________\n",
      "epoch 738 train loss 1.8025404214859009\n",
      "val loss 2.2863290309906006\n",
      "______________\n",
      "epoch 739 train loss 1.7815967798233032\n",
      "val loss 2.2858529090881348\n",
      "______________\n",
      "epoch 740 train loss 1.7435638904571533\n",
      "val loss 2.2854089736938477\n",
      "______________\n",
      "epoch 741 train loss 1.7462774515151978\n",
      "val loss 2.2848660945892334\n",
      "______________\n",
      "epoch 742 train loss 1.7954989671707153\n",
      "val loss 2.284303903579712\n",
      "______________\n",
      "epoch 743 train loss 1.7732045650482178\n",
      "val loss 2.2837655544281006\n",
      "______________\n",
      "epoch 744 train loss 1.747834324836731\n",
      "val loss 2.2832608222961426\n",
      "______________\n",
      "epoch 745 train loss 1.7421005964279175\n",
      "val loss 2.282719612121582\n",
      "______________\n",
      "epoch 746 train loss 1.7663371562957764\n",
      "val loss 2.282116651535034\n",
      "______________\n",
      "epoch 747 train loss 1.7446937561035156\n",
      "val loss 2.281564235687256\n",
      "______________\n",
      "epoch 748 train loss 1.7502570152282715\n",
      "val loss 2.281034231185913\n",
      "______________\n",
      "epoch 749 train loss 1.8036019802093506\n",
      "val loss 2.2804579734802246\n",
      "______________\n",
      "epoch 750 train loss 1.7458795309066772\n",
      "val loss 2.2798571586608887\n",
      "______________\n",
      "epoch 751 train loss 1.816368818283081\n",
      "val loss 2.2792391777038574\n",
      "______________\n",
      "epoch 752 train loss 1.825049877166748\n",
      "val loss 2.278615951538086\n",
      "______________\n",
      "epoch 753 train loss 1.7765787839889526\n",
      "val loss 2.278012275695801\n",
      "______________\n",
      "epoch 754 train loss 1.7911971807479858\n",
      "val loss 2.2774288654327393\n",
      "______________\n",
      "epoch 755 train loss 1.7762500047683716\n",
      "val loss 2.2769100666046143\n",
      "______________\n",
      "epoch 756 train loss 1.7451237440109253\n",
      "val loss 2.276465654373169\n",
      "______________\n",
      "epoch 757 train loss 1.783819556236267\n",
      "val loss 2.2760119438171387\n",
      "______________\n",
      "epoch 758 train loss 1.80012047290802\n",
      "val loss 2.2755286693573\n",
      "______________\n",
      "epoch 759 train loss 1.7470706701278687\n",
      "val loss 2.2749900817871094\n",
      "______________\n",
      "epoch 760 train loss 1.782351016998291\n",
      "val loss 2.274522066116333\n",
      "______________\n",
      "epoch 761 train loss 1.778483271598816\n",
      "val loss 2.274087905883789\n",
      "______________\n",
      "epoch 762 train loss 1.73783540725708\n",
      "val loss 2.2736568450927734\n",
      "______________\n",
      "epoch 763 train loss 1.7724220752716064\n",
      "val loss 2.273256301879883\n",
      "______________\n",
      "epoch 764 train loss 1.7309505939483643\n",
      "val loss 2.272860527038574\n",
      "______________\n",
      "epoch 765 train loss 1.7149443626403809\n",
      "val loss 2.2724721431732178\n",
      "______________\n",
      "epoch 766 train loss 1.7531471252441406\n",
      "val loss 2.2721011638641357\n",
      "______________\n",
      "epoch 767 train loss 1.777657389640808\n",
      "val loss 2.271686315536499\n",
      "______________\n",
      "epoch 768 train loss 1.7284067869186401\n",
      "val loss 2.271265745162964\n",
      "______________\n",
      "epoch 769 train loss 1.7939945459365845\n",
      "val loss 2.270808219909668\n",
      "______________\n",
      "epoch 770 train loss 1.7682020664215088\n",
      "val loss 2.270352840423584\n",
      "______________\n",
      "epoch 771 train loss 1.689391851425171\n",
      "val loss 2.269913911819458\n",
      "______________\n",
      "epoch 772 train loss 1.8198578357696533\n",
      "val loss 2.2695181369781494\n",
      "______________\n",
      "epoch 773 train loss 1.7537357807159424\n",
      "val loss 2.269090414047241\n",
      "______________\n",
      "epoch 774 train loss 1.7049791812896729\n",
      "val loss 2.2686471939086914\n",
      "______________\n",
      "epoch 775 train loss 1.7485127449035645\n",
      "val loss 2.268209934234619\n",
      "______________\n",
      "epoch 776 train loss 1.777827501296997\n",
      "val loss 2.2678282260894775\n",
      "______________\n",
      "epoch 777 train loss 1.6973851919174194\n",
      "val loss 2.267467737197876\n",
      "______________\n",
      "epoch 778 train loss 1.7446032762527466\n",
      "val loss 2.2671172618865967\n",
      "______________\n",
      "epoch 779 train loss 1.7094073295593262\n",
      "val loss 2.266761064529419\n",
      "______________\n",
      "epoch 780 train loss 1.7884941101074219\n",
      "val loss 2.2663064002990723\n",
      "______________\n",
      "epoch 781 train loss 1.7536731958389282\n",
      "val loss 2.2658579349517822\n",
      "______________\n",
      "epoch 782 train loss 1.6872649192810059\n",
      "val loss 2.265411615371704\n",
      "______________\n",
      "epoch 783 train loss 1.7783265113830566\n",
      "val loss 2.2649354934692383\n",
      "______________\n",
      "epoch 784 train loss 1.7194058895111084\n",
      "val loss 2.264456272125244\n",
      "______________\n",
      "epoch 785 train loss 1.8103147745132446\n",
      "val loss 2.264009952545166\n",
      "______________\n",
      "epoch 786 train loss 1.6946464776992798\n",
      "val loss 2.2635762691497803\n",
      "______________\n",
      "epoch 787 train loss 1.7192323207855225\n",
      "val loss 2.263254165649414\n",
      "______________\n",
      "epoch 788 train loss 1.7501928806304932\n",
      "val loss 2.2629473209381104\n",
      "______________\n",
      "epoch 789 train loss 1.7690322399139404\n",
      "val loss 2.2625837326049805\n",
      "______________\n",
      "epoch 790 train loss 1.709822416305542\n",
      "val loss 2.2622392177581787\n",
      "______________\n",
      "epoch 791 train loss 1.715591549873352\n",
      "val loss 2.2619433403015137\n",
      "______________\n",
      "epoch 792 train loss 1.7590631246566772\n",
      "val loss 2.261629104614258\n",
      "______________\n",
      "epoch 793 train loss 1.752540946006775\n",
      "val loss 2.261275053024292\n",
      "______________\n",
      "epoch 794 train loss 1.7954440116882324\n",
      "val loss 2.2607810497283936\n",
      "______________\n",
      "epoch 795 train loss 1.7813270092010498\n",
      "val loss 2.260350465774536\n",
      "______________\n",
      "epoch 796 train loss 1.7147724628448486\n",
      "val loss 2.2598509788513184\n",
      "______________\n",
      "epoch 797 train loss 1.7830893993377686\n",
      "val loss 2.2593576908111572\n",
      "______________\n",
      "epoch 798 train loss 1.6755987405776978\n",
      "val loss 2.258880376815796\n",
      "______________\n",
      "epoch 799 train loss 1.799741268157959\n",
      "val loss 2.258331537246704\n",
      "______________\n",
      "epoch 800 train loss 1.758428692817688\n",
      "val loss 2.2578632831573486\n",
      "______________\n",
      "epoch 801 train loss 1.7320719957351685\n",
      "val loss 2.2573702335357666\n",
      "______________\n",
      "epoch 802 train loss 1.7516300678253174\n",
      "val loss 2.256943941116333\n",
      "______________\n",
      "epoch 803 train loss 1.742937684059143\n",
      "val loss 2.256547451019287\n",
      "______________\n",
      "epoch 804 train loss 1.7155083417892456\n",
      "val loss 2.256181478500366\n",
      "______________\n",
      "epoch 805 train loss 1.6794853210449219\n",
      "val loss 2.255826711654663\n",
      "______________\n",
      "epoch 806 train loss 1.7233490943908691\n",
      "val loss 2.255519151687622\n",
      "______________\n",
      "epoch 807 train loss 1.6814439296722412\n",
      "val loss 2.255295515060425\n",
      "______________\n",
      "epoch 808 train loss 1.7634108066558838\n",
      "val loss 2.2551541328430176\n",
      "______________\n",
      "epoch 809 train loss 1.7172987461090088\n",
      "val loss 2.2550089359283447\n",
      "______________\n",
      "epoch 810 train loss 1.7609565258026123\n",
      "val loss 2.254835605621338\n",
      "______________\n",
      "epoch 811 train loss 1.7898035049438477\n",
      "val loss 2.254633903503418\n",
      "______________\n",
      "epoch 812 train loss 1.7582484483718872\n",
      "val loss 2.254411220550537\n",
      "______________\n",
      "epoch 813 train loss 1.6946607828140259\n",
      "val loss 2.254197120666504\n",
      "______________\n",
      "epoch 814 train loss 1.7564913034439087\n",
      "val loss 2.2539355754852295\n",
      "______________\n",
      "epoch 815 train loss 1.7198963165283203\n",
      "val loss 2.2535507678985596\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 816 train loss 1.7169924974441528\n",
      "val loss 2.2531566619873047\n",
      "______________\n",
      "epoch 817 train loss 1.7225542068481445\n",
      "val loss 2.2527925968170166\n",
      "______________\n",
      "epoch 818 train loss 1.7004363536834717\n",
      "val loss 2.2524161338806152\n",
      "______________\n",
      "epoch 819 train loss 1.6965844631195068\n",
      "val loss 2.2520627975463867\n",
      "______________\n",
      "epoch 820 train loss 1.6837445497512817\n",
      "val loss 2.2517824172973633\n",
      "______________\n",
      "epoch 821 train loss 1.728363275527954\n",
      "val loss 2.2514970302581787\n",
      "______________\n",
      "epoch 822 train loss 1.770051121711731\n",
      "val loss 2.2511847019195557\n",
      "______________\n",
      "epoch 823 train loss 1.7271164655685425\n",
      "val loss 2.2508561611175537\n",
      "______________\n",
      "epoch 824 train loss 1.7721513509750366\n",
      "val loss 2.250488042831421\n",
      "______________\n",
      "epoch 825 train loss 1.7059080600738525\n",
      "val loss 2.2500851154327393\n",
      "______________\n",
      "epoch 826 train loss 1.709416389465332\n",
      "val loss 2.2496907711029053\n",
      "______________\n",
      "epoch 827 train loss 1.7152849435806274\n",
      "val loss 2.249293088912964\n",
      "______________\n",
      "epoch 828 train loss 1.693503499031067\n",
      "val loss 2.2489547729492188\n",
      "______________\n",
      "epoch 829 train loss 1.7019774913787842\n",
      "val loss 2.2486188411712646\n",
      "______________\n",
      "epoch 830 train loss 1.6781963109970093\n",
      "val loss 2.2483229637145996\n",
      "______________\n",
      "epoch 831 train loss 1.7403205633163452\n",
      "val loss 2.2480790615081787\n",
      "______________\n",
      "epoch 832 train loss 1.702807903289795\n",
      "val loss 2.247904062271118\n",
      "______________\n",
      "epoch 833 train loss 1.6972237825393677\n",
      "val loss 2.247771978378296\n",
      "______________\n",
      "epoch 834 train loss 1.695759654045105\n",
      "val loss 2.2475712299346924\n",
      "______________\n",
      "epoch 835 train loss 1.7277041673660278\n",
      "val loss 2.2473702430725098\n",
      "______________\n",
      "epoch 836 train loss 1.741696834564209\n",
      "val loss 2.2472541332244873\n",
      "______________\n",
      "epoch 837 train loss 1.7531875371932983\n",
      "val loss 2.2471373081207275\n",
      "______________\n",
      "epoch 838 train loss 1.6943838596343994\n",
      "val loss 2.247051477432251\n",
      "______________\n",
      "epoch 839 train loss 1.714266061782837\n",
      "val loss 2.2469286918640137\n",
      "______________\n",
      "epoch 840 train loss 1.6700592041015625\n",
      "val loss 2.2467434406280518\n",
      "______________\n",
      "epoch 841 train loss 1.754909634590149\n",
      "val loss 2.2464873790740967\n",
      "______________\n",
      "epoch 842 train loss 1.6957000494003296\n",
      "val loss 2.2461912631988525\n",
      "______________\n",
      "epoch 843 train loss 1.7439988851547241\n",
      "val loss 2.2457973957061768\n",
      "______________\n",
      "epoch 844 train loss 1.7627471685409546\n",
      "val loss 2.24540376663208\n",
      "______________\n",
      "epoch 845 train loss 1.7249101400375366\n",
      "val loss 2.2449724674224854\n",
      "______________\n",
      "epoch 846 train loss 1.7325783967971802\n",
      "val loss 2.2445719242095947\n",
      "______________\n",
      "epoch 847 train loss 1.6995793581008911\n",
      "val loss 2.2441813945770264\n",
      "______________\n",
      "epoch 848 train loss 1.7623385190963745\n",
      "val loss 2.2437260150909424\n",
      "______________\n",
      "epoch 849 train loss 1.7239134311676025\n",
      "val loss 2.2432286739349365\n",
      "______________\n",
      "epoch 850 train loss 1.6734281778335571\n",
      "val loss 2.2427525520324707\n",
      "______________\n",
      "epoch 851 train loss 1.7081992626190186\n",
      "val loss 2.2422542572021484\n",
      "______________\n",
      "epoch 852 train loss 1.697875738143921\n",
      "val loss 2.241772174835205\n",
      "______________\n",
      "epoch 853 train loss 1.6814807653427124\n",
      "val loss 2.241323947906494\n",
      "______________\n",
      "epoch 854 train loss 1.7102041244506836\n",
      "val loss 2.240853786468506\n",
      "______________\n",
      "epoch 855 train loss 1.7298130989074707\n",
      "val loss 2.2403769493103027\n",
      "______________\n",
      "epoch 856 train loss 1.677741527557373\n",
      "val loss 2.239854574203491\n",
      "______________\n",
      "epoch 857 train loss 1.6655327081680298\n",
      "val loss 2.2392642498016357\n",
      "______________\n",
      "epoch 858 train loss 1.685006856918335\n",
      "val loss 2.2387232780456543\n",
      "______________\n",
      "epoch 859 train loss 1.6393805742263794\n",
      "val loss 2.238156318664551\n",
      "______________\n",
      "epoch 860 train loss 1.7145555019378662\n",
      "val loss 2.237656593322754\n",
      "______________\n",
      "epoch 861 train loss 1.7325538396835327\n",
      "val loss 2.2372355461120605\n",
      "______________\n",
      "epoch 862 train loss 1.6881917715072632\n",
      "val loss 2.2368714809417725\n",
      "______________\n",
      "epoch 863 train loss 1.7121648788452148\n",
      "val loss 2.236480236053467\n",
      "______________\n",
      "epoch 864 train loss 1.762455701828003\n",
      "val loss 2.236085891723633\n",
      "______________\n",
      "epoch 865 train loss 1.7243238687515259\n",
      "val loss 2.2355973720550537\n",
      "______________\n",
      "epoch 866 train loss 1.7105295658111572\n",
      "val loss 2.2351701259613037\n",
      "______________\n",
      "epoch 867 train loss 1.7776868343353271\n",
      "val loss 2.2347910404205322\n",
      "______________\n",
      "epoch 868 train loss 1.6771764755249023\n",
      "val loss 2.2343995571136475\n",
      "______________\n",
      "epoch 869 train loss 1.6664981842041016\n",
      "val loss 2.234063148498535\n",
      "______________\n",
      "epoch 870 train loss 1.6731106042861938\n",
      "val loss 2.233790636062622\n",
      "______________\n",
      "epoch 871 train loss 1.7018095254898071\n",
      "val loss 2.2335381507873535\n",
      "______________\n",
      "epoch 872 train loss 1.6904301643371582\n",
      "val loss 2.2333405017852783\n",
      "______________\n",
      "epoch 873 train loss 1.7074694633483887\n",
      "val loss 2.233184814453125\n",
      "______________\n",
      "epoch 874 train loss 1.6687042713165283\n",
      "val loss 2.233078956604004\n",
      "______________\n",
      "epoch 875 train loss 1.7037773132324219\n",
      "val loss 2.233025074005127\n",
      "______________\n",
      "epoch 876 train loss 1.7152503728866577\n",
      "val loss 2.2329540252685547\n",
      "______________\n",
      "epoch 877 train loss 1.64848792552948\n",
      "val loss 2.2328622341156006\n",
      "______________\n",
      "epoch 878 train loss 1.7209811210632324\n",
      "val loss 2.2327160835266113\n",
      "______________\n",
      "epoch 879 train loss 1.702852725982666\n",
      "val loss 2.232663154602051\n",
      "______________\n",
      "epoch 880 train loss 1.6917970180511475\n",
      "val loss 2.2325689792633057\n",
      "______________\n",
      "epoch 881 train loss 1.6963568925857544\n",
      "val loss 2.2324728965759277\n",
      "______________\n",
      "epoch 882 train loss 1.724174976348877\n",
      "val loss 2.2323200702667236\n",
      "______________\n",
      "epoch 883 train loss 1.6665538549423218\n",
      "val loss 2.232086658477783\n",
      "______________\n",
      "epoch 884 train loss 1.7269572019577026\n",
      "val loss 2.2318639755249023\n",
      "______________\n",
      "epoch 885 train loss 1.7111248970031738\n",
      "val loss 2.231631278991699\n",
      "______________\n",
      "epoch 886 train loss 1.6898608207702637\n",
      "val loss 2.2314200401306152\n",
      "______________\n",
      "epoch 887 train loss 1.6622109413146973\n",
      "val loss 2.231250047683716\n",
      "______________\n",
      "epoch 888 train loss 1.7218263149261475\n",
      "val loss 2.2310502529144287\n",
      "______________\n",
      "epoch 889 train loss 1.6673250198364258\n",
      "val loss 2.230879306793213\n",
      "______________\n",
      "epoch 890 train loss 1.6809865236282349\n",
      "val loss 2.230695962905884\n",
      "______________\n",
      "epoch 891 train loss 1.704558253288269\n",
      "val loss 2.230497360229492\n",
      "______________\n",
      "epoch 892 train loss 1.727036476135254\n",
      "val loss 2.230351686477661\n",
      "______________\n",
      "epoch 893 train loss 1.6999942064285278\n",
      "val loss 2.23014235496521\n",
      "______________\n",
      "epoch 894 train loss 1.6765317916870117\n",
      "val loss 2.2300124168395996\n",
      "______________\n",
      "epoch 895 train loss 1.6580699682235718\n",
      "val loss 2.229846715927124\n",
      "______________\n",
      "epoch 896 train loss 1.7190258502960205\n",
      "val loss 2.2297260761260986\n",
      "______________\n",
      "epoch 897 train loss 1.686192512512207\n",
      "val loss 2.22957706451416\n",
      "______________\n",
      "epoch 898 train loss 1.686646580696106\n",
      "val loss 2.229428768157959\n",
      "______________\n",
      "epoch 899 train loss 1.6937724351882935\n",
      "val loss 2.2292540073394775\n",
      "______________\n",
      "epoch 900 train loss 1.699484944343567\n",
      "val loss 2.229067802429199\n",
      "______________\n",
      "epoch 901 train loss 1.660582423210144\n",
      "val loss 2.228855848312378\n",
      "______________\n",
      "epoch 902 train loss 1.6781781911849976\n",
      "val loss 2.228724241256714\n",
      "______________\n",
      "epoch 903 train loss 1.6575322151184082\n",
      "val loss 2.2286062240600586\n",
      "______________\n",
      "epoch 904 train loss 1.6899040937423706\n",
      "val loss 2.228506326675415\n",
      "______________\n",
      "epoch 905 train loss 1.6524304151535034\n",
      "val loss 2.228408098220825\n",
      "______________\n",
      "epoch 906 train loss 1.666384220123291\n",
      "val loss 2.2282185554504395\n",
      "______________\n",
      "epoch 907 train loss 1.7371833324432373\n",
      "val loss 2.2280361652374268\n",
      "______________\n",
      "epoch 908 train loss 1.7357680797576904\n",
      "val loss 2.2278852462768555\n",
      "______________\n",
      "epoch 909 train loss 1.6954561471939087\n",
      "val loss 2.2276804447174072\n",
      "______________\n",
      "epoch 910 train loss 1.6655821800231934\n",
      "val loss 2.227492570877075\n",
      "______________\n",
      "epoch 911 train loss 1.6911695003509521\n",
      "val loss 2.2272024154663086\n",
      "______________\n",
      "epoch 912 train loss 1.6836507320404053\n",
      "val loss 2.2269341945648193\n",
      "______________\n",
      "epoch 913 train loss 1.6767361164093018\n",
      "val loss 2.2266318798065186\n",
      "______________\n",
      "epoch 914 train loss 1.6923065185546875\n",
      "val loss 2.2263715267181396\n",
      "______________\n",
      "epoch 915 train loss 1.6458113193511963\n",
      "val loss 2.226102590560913\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 916 train loss 1.6226109266281128\n",
      "val loss 2.225822925567627\n",
      "______________\n",
      "epoch 917 train loss 1.6238603591918945\n",
      "val loss 2.225560188293457\n",
      "______________\n",
      "epoch 918 train loss 1.6393274068832397\n",
      "val loss 2.22529935836792\n",
      "______________\n",
      "epoch 919 train loss 1.6936843395233154\n",
      "val loss 2.224980115890503\n",
      "______________\n",
      "epoch 920 train loss 1.7075833082199097\n",
      "val loss 2.224660634994507\n",
      "______________\n",
      "epoch 921 train loss 1.665897250175476\n",
      "val loss 2.2242674827575684\n",
      "______________\n",
      "epoch 922 train loss 1.6821403503417969\n",
      "val loss 2.223872661590576\n",
      "______________\n",
      "epoch 923 train loss 1.6746023893356323\n",
      "val loss 2.2234535217285156\n",
      "______________\n",
      "epoch 924 train loss 1.7006337642669678\n",
      "val loss 2.2230160236358643\n",
      "______________\n",
      "epoch 925 train loss 1.7257481813430786\n",
      "val loss 2.222581148147583\n",
      "______________\n",
      "epoch 926 train loss 1.6753166913986206\n",
      "val loss 2.2221100330352783\n",
      "______________\n",
      "epoch 927 train loss 1.71686851978302\n",
      "val loss 2.221709728240967\n",
      "______________\n",
      "epoch 928 train loss 1.66597318649292\n",
      "val loss 2.221404552459717\n",
      "______________\n",
      "epoch 929 train loss 1.6715000867843628\n",
      "val loss 2.2211904525756836\n",
      "______________\n",
      "epoch 930 train loss 1.7289385795593262\n",
      "val loss 2.22088623046875\n",
      "______________\n",
      "epoch 931 train loss 1.7066582441329956\n",
      "val loss 2.2205145359039307\n",
      "______________\n",
      "epoch 932 train loss 1.7212334871292114\n",
      "val loss 2.2201499938964844\n",
      "______________\n",
      "epoch 933 train loss 1.6517744064331055\n",
      "val loss 2.219827651977539\n",
      "______________\n",
      "epoch 934 train loss 1.670579195022583\n",
      "val loss 2.2195260524749756\n",
      "______________\n",
      "epoch 935 train loss 1.7393943071365356\n",
      "val loss 2.2192044258117676\n",
      "______________\n",
      "epoch 936 train loss 1.6761761903762817\n",
      "val loss 2.218949556350708\n",
      "______________\n",
      "epoch 937 train loss 1.7258427143096924\n",
      "val loss 2.218743085861206\n",
      "______________\n",
      "epoch 938 train loss 1.6719754934310913\n",
      "val loss 2.2185254096984863\n",
      "______________\n",
      "epoch 939 train loss 1.6715867519378662\n",
      "val loss 2.2183337211608887\n",
      "______________\n",
      "epoch 940 train loss 1.6627082824707031\n",
      "val loss 2.218158483505249\n",
      "______________\n",
      "epoch 941 train loss 1.692692518234253\n",
      "val loss 2.217952013015747\n",
      "______________\n",
      "epoch 942 train loss 1.6776020526885986\n",
      "val loss 2.217747688293457\n",
      "______________\n",
      "epoch 943 train loss 1.7015879154205322\n",
      "val loss 2.2174625396728516\n",
      "______________\n",
      "epoch 944 train loss 1.6956936120986938\n",
      "val loss 2.2171630859375\n",
      "______________\n",
      "epoch 945 train loss 1.731022834777832\n",
      "val loss 2.216893434524536\n",
      "______________\n",
      "epoch 946 train loss 1.7027298212051392\n",
      "val loss 2.216644763946533\n",
      "______________\n",
      "epoch 947 train loss 1.6789650917053223\n",
      "val loss 2.2163479328155518\n",
      "______________\n",
      "epoch 948 train loss 1.6102561950683594\n",
      "val loss 2.2161550521850586\n",
      "______________\n",
      "epoch 949 train loss 1.6666945219039917\n",
      "val loss 2.2159664630889893\n",
      "______________\n",
      "epoch 950 train loss 1.701545238494873\n",
      "val loss 2.215794086456299\n",
      "______________\n",
      "epoch 951 train loss 1.6704127788543701\n",
      "val loss 2.215672492980957\n",
      "______________\n",
      "epoch 952 train loss 1.6870510578155518\n",
      "val loss 2.215507745742798\n",
      "______________\n",
      "epoch 953 train loss 1.6625005006790161\n",
      "val loss 2.215345859527588\n",
      "______________\n",
      "epoch 954 train loss 1.6268432140350342\n",
      "val loss 2.2151949405670166\n",
      "______________\n",
      "epoch 955 train loss 1.724509835243225\n",
      "val loss 2.21498966217041\n",
      "______________\n",
      "epoch 956 train loss 1.690853476524353\n",
      "val loss 2.214728593826294\n",
      "______________\n",
      "epoch 957 train loss 1.6388270854949951\n",
      "val loss 2.2145562171936035\n",
      "______________\n",
      "epoch 958 train loss 1.6095025539398193\n",
      "val loss 2.2143521308898926\n",
      "______________\n",
      "epoch 959 train loss 1.7008082866668701\n",
      "val loss 2.2140707969665527\n",
      "______________\n",
      "epoch 960 train loss 1.7018221616744995\n",
      "val loss 2.2137937545776367\n",
      "______________\n",
      "epoch 961 train loss 1.7355161905288696\n",
      "val loss 2.213477611541748\n",
      "______________\n",
      "epoch 962 train loss 1.659175157546997\n",
      "val loss 2.213186502456665\n",
      "______________\n",
      "epoch 963 train loss 1.678689956665039\n",
      "val loss 2.212886095046997\n",
      "______________\n",
      "epoch 964 train loss 1.6429544687271118\n",
      "val loss 2.212550163269043\n",
      "______________\n",
      "epoch 965 train loss 1.7096776962280273\n",
      "val loss 2.2122108936309814\n",
      "______________\n",
      "epoch 966 train loss 1.6811028718948364\n",
      "val loss 2.211855411529541\n",
      "______________\n",
      "epoch 967 train loss 1.6884350776672363\n",
      "val loss 2.211526393890381\n",
      "______________\n",
      "epoch 968 train loss 1.6261624097824097\n",
      "val loss 2.2112042903900146\n",
      "______________\n",
      "epoch 969 train loss 1.7049223184585571\n",
      "val loss 2.2108778953552246\n",
      "______________\n",
      "epoch 970 train loss 1.679018497467041\n",
      "val loss 2.210684061050415\n",
      "______________\n",
      "epoch 971 train loss 1.7105880975723267\n",
      "val loss 2.2105419635772705\n",
      "______________\n",
      "epoch 972 train loss 1.6358437538146973\n",
      "val loss 2.210407257080078\n",
      "______________\n",
      "epoch 973 train loss 1.6779158115386963\n",
      "val loss 2.210268974304199\n",
      "______________\n",
      "epoch 974 train loss 1.672329068183899\n",
      "val loss 2.2101101875305176\n",
      "______________\n",
      "epoch 975 train loss 1.670022964477539\n",
      "val loss 2.2099664211273193\n",
      "______________\n",
      "epoch 976 train loss 1.661791443824768\n",
      "val loss 2.2098186016082764\n",
      "______________\n",
      "epoch 977 train loss 1.6654738187789917\n",
      "val loss 2.2096574306488037\n",
      "______________\n",
      "epoch 978 train loss 1.6898307800292969\n",
      "val loss 2.209498643875122\n",
      "______________\n",
      "epoch 979 train loss 1.665810227394104\n",
      "val loss 2.2093636989593506\n",
      "______________\n",
      "epoch 980 train loss 1.6281331777572632\n",
      "val loss 2.2092983722686768\n",
      "______________\n",
      "epoch 981 train loss 1.647474765777588\n",
      "val loss 2.2092456817626953\n",
      "______________\n",
      "epoch 982 train loss 1.6683051586151123\n",
      "val loss 2.209167718887329\n",
      "______________\n",
      "epoch 983 train loss 1.6826539039611816\n",
      "val loss 2.209120512008667\n",
      "______________\n",
      "epoch 984 train loss 1.6382248401641846\n",
      "val loss 2.2090582847595215\n",
      "______________\n",
      "epoch 985 train loss 1.7100257873535156\n",
      "val loss 2.209009885787964\n",
      "______________\n",
      "epoch 986 train loss 1.7039813995361328\n",
      "val loss 2.2089459896087646\n",
      "______________\n",
      "epoch 987 train loss 1.6864464282989502\n",
      "val loss 2.2087900638580322\n",
      "______________\n",
      "epoch 988 train loss 1.6556155681610107\n",
      "val loss 2.2085864543914795\n",
      "______________\n",
      "epoch 989 train loss 1.6642488241195679\n",
      "val loss 2.2084012031555176\n",
      "______________\n",
      "epoch 990 train loss 1.6143227815628052\n",
      "val loss 2.2082371711730957\n",
      "______________\n",
      "epoch 991 train loss 1.6224968433380127\n",
      "val loss 2.2080888748168945\n",
      "______________\n",
      "epoch 992 train loss 1.687296986579895\n",
      "val loss 2.20784330368042\n",
      "______________\n",
      "epoch 993 train loss 1.7037007808685303\n",
      "val loss 2.207615613937378\n",
      "______________\n",
      "epoch 994 train loss 1.6441702842712402\n",
      "val loss 2.207362413406372\n",
      "______________\n",
      "epoch 995 train loss 1.7334297895431519\n",
      "val loss 2.2070934772491455\n",
      "______________\n",
      "epoch 996 train loss 1.6693795919418335\n",
      "val loss 2.2068021297454834\n",
      "______________\n",
      "epoch 997 train loss 1.6686441898345947\n",
      "val loss 2.206434488296509\n",
      "______________\n",
      "epoch 998 train loss 1.6126872301101685\n",
      "val loss 2.2060866355895996\n",
      "______________\n",
      "epoch 999 train loss 1.6323806047439575\n",
      "val loss 2.2058005332946777\n",
      "______________\n",
      "best loss 2.2058005332946777 {'pd': {'accuracy': 0.4580999066293184, 'roc_micro': 0.6750534061239022, 'roc_macro': 0.5734789928781829}, 'nd': {'accuracy': 0.4914348577714914, 'roc_micro': 0.6919382504288165, 'roc_macro': 0.670605964084225}, 'mod': {'accuracy': 0.4914348577714914, 'roc_micro': 0.6919382504288165, 'roc_macro': 0.670605964084225}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9207459207459208, 0.9407407407407408, 0.927860696517413, -1, 0.9163120567375886, -1, 0.7726190476190476, -1], 'auc_mean': 0.18478480779508888}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=50, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_state(model=None,\n",
    "                model_args={},\n",
    "                state=1,\n",
    "                split=.7,\n",
    "                lr=.0001,\n",
    "                epochs=1000,\n",
    "                patience=10,\n",
    "                use_attention=True,\n",
    "                weights=[1,1,1,10],\n",
    "                save_path='../data/models/',\n",
    "                use_default_split=True,\n",
    "                use_bagging_split=False,\n",
    "                resample_training=False,#use bootstraping on training data after splitting\n",
    "                n_validation_trainsteps=2,\n",
    "                verbose=True,\n",
    "                use_smote=True,\n",
    "                file_suffix=''):\n",
    "    \n",
    "    ids = get_dt_ids()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "    \n",
    "    if use_smote:\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids)\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "\n",
    "    xtrain = dataset.get_input_state(step=state,ids=train_ids)\n",
    "    xtest = dataset.get_input_state(step=state,ids=test_ids)\n",
    "    ytrain = dataset.get_intermediate_outcomes(step=state,ids=train_ids)\n",
    "    ytest = dataset.get_intermediate_outcomes(step=state,ids=test_ids)\n",
    "    \n",
    "\n",
    "    if not use_attention:\n",
    "        model_args = {k:v for k,v in model_args.items() if 'attention' not in k and 'embed_size' not in k}\n",
    "    if state < 3:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = OutcomeAttentionSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "            else:\n",
    "                model = OutcomeSimulator(xtrain.shape[1],state=state,**model_args)\n",
    "        lfunc = state_loss\n",
    "    else:\n",
    "        if model is None:\n",
    "            if use_attention:\n",
    "                model = EndpointAttentionSimulator(xtrain.shape[1],**model_args)\n",
    "            else:\n",
    "                model = EndpointSimulator(xtrain.shape[1],**model_args)\n",
    "        weights = weights[:3]\n",
    "        lfunc = outcome_loss\n",
    "        \n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    save_file = save_path + 'model_' + model.identifier + '_split' + str(split) + '_resample' + str(resample_training) +  '_hash' + hashcode + file_suffix + '.tar'\n",
    "    xtrain = df_to_torch(xtrain)\n",
    "    xtest = df_to_torch(xtest)\n",
    "    ytrain = [df_to_torch(t) for t in ytrain]\n",
    "    ytest= [df_to_torch(t) for t in ytest]\n",
    "    \n",
    "    model.fit_normalizer(xtrain)\n",
    "#     normalize = lambda x: (x - xtrain.mean(axis=0)+.01)/(xtrain.std(axis=0)+.01)\n",
    "#     unnormalize = lambda x: (x * (xtrain.std(axis=0) +.01)) + xtrain.mean(axis=0) - .01\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    best_val_loss = 1000000000000000000000000000\n",
    "    best_loss_metrics = {}\n",
    "    last_epoch = False\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        xtrain_sample = xtrain#[torch.randint(len(xtrain),(len(xtrain),) )]\n",
    "        ypred = model(xtrain_sample)\n",
    "        loss = lfunc(ytrain,ypred,weights=weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print('epoch',epoch,'train loss',loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        if state < 3:\n",
    "            val_metrics = state_metrics(ytest,yval)\n",
    "        else:\n",
    "            val_metrics = outcome_metrics(ytest,yval)\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_loss_metrics = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if verbose:\n",
    "            print('val loss',val_loss.item())\n",
    "            print('______________')\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('best loss',best_val_loss,best_loss_metrics)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    \n",
    "    #train one step on validation data\n",
    "    for i in range(n_validation_trainsteps):\n",
    "        model.train()\n",
    "        yval = model(xtest)\n",
    "        val_loss = lfunc(ytest,yval,weights=weights)\n",
    "        val_loss.backward()\n",
    "        optimizer.step()\n",
    "        torch.save(model.state_dict(),save_file)\n",
    "    \n",
    "    model.eval()\n",
    "    return model,  best_val_loss, best_loss_metrics\n",
    "\n",
    "t1_args = {'hidden_layers': [1000], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model1,_,_ = train_state(model_args=t1_args,use_attention=False)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1a06334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "epoch 0 train loss 10.965421676635742\n",
      "val loss 10.463837623596191\n",
      "______________\n",
      "epoch 1 train loss 10.817804336547852\n",
      "val loss 10.26890754699707\n",
      "______________\n",
      "epoch 2 train loss 10.649312019348145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 10.082319259643555\n",
      "______________\n",
      "epoch 3 train loss 10.486175537109375\n",
      "val loss 9.902894020080566\n",
      "______________\n",
      "epoch 4 train loss 10.31086540222168\n",
      "val loss 9.730097770690918\n",
      "______________\n",
      "epoch 5 train loss 10.197577476501465\n",
      "val loss 9.562862396240234\n",
      "______________\n",
      "epoch 6 train loss 10.046643257141113\n",
      "val loss 9.400331497192383\n",
      "______________\n",
      "epoch 7 train loss 9.90276050567627\n",
      "val loss 9.241881370544434\n",
      "______________\n",
      "epoch 8 train loss 9.725255966186523\n",
      "val loss 9.087478637695312\n",
      "______________\n",
      "epoch 9 train loss 9.60567569732666\n",
      "val loss 8.936623573303223\n",
      "______________\n",
      "epoch 10 train loss 9.475502014160156\n",
      "val loss 8.789018630981445\n",
      "______________\n",
      "epoch 11 train loss 9.335063934326172\n",
      "val loss 8.64405632019043\n",
      "______________\n",
      "epoch 12 train loss 9.241536140441895\n",
      "val loss 8.501664161682129\n",
      "______________\n",
      "epoch 13 train loss 9.122686386108398\n",
      "val loss 8.361593246459961\n",
      "______________\n",
      "epoch 14 train loss 8.989729881286621\n",
      "val loss 8.223686218261719\n",
      "______________\n",
      "epoch 15 train loss 8.833279609680176\n",
      "val loss 8.08752155303955\n",
      "______________\n",
      "epoch 16 train loss 8.736252784729004\n",
      "val loss 7.95314359664917\n",
      "______________\n",
      "epoch 17 train loss 8.630229949951172\n",
      "val loss 7.8205437660217285\n",
      "______________\n",
      "epoch 18 train loss 8.519593238830566\n",
      "val loss 7.68951416015625\n",
      "______________\n",
      "epoch 19 train loss 8.362424850463867\n",
      "val loss 7.560188293457031\n",
      "______________\n",
      "epoch 20 train loss 8.245488166809082\n",
      "val loss 7.432969570159912\n",
      "______________\n",
      "epoch 21 train loss 8.155077934265137\n",
      "val loss 7.307594299316406\n",
      "______________\n",
      "epoch 22 train loss 8.079130172729492\n",
      "val loss 7.184209823608398\n",
      "______________\n",
      "epoch 23 train loss 7.930695533752441\n",
      "val loss 7.062931537628174\n",
      "______________\n",
      "epoch 24 train loss 7.813150882720947\n",
      "val loss 6.9438958168029785\n",
      "______________\n",
      "epoch 25 train loss 7.703968048095703\n",
      "val loss 6.827212810516357\n",
      "______________\n",
      "epoch 26 train loss 7.594753742218018\n",
      "val loss 6.713249683380127\n",
      "______________\n",
      "epoch 27 train loss 7.494009971618652\n",
      "val loss 6.601822376251221\n",
      "______________\n",
      "epoch 28 train loss 7.387094020843506\n",
      "val loss 6.4929399490356445\n",
      "______________\n",
      "epoch 29 train loss 7.325048923492432\n",
      "val loss 6.386984825134277\n",
      "______________\n",
      "epoch 30 train loss 7.177332401275635\n",
      "val loss 6.283863067626953\n",
      "______________\n",
      "epoch 31 train loss 7.100008487701416\n",
      "val loss 6.183743476867676\n",
      "______________\n",
      "epoch 32 train loss 6.976893901824951\n",
      "val loss 6.086618900299072\n",
      "______________\n",
      "epoch 33 train loss 6.895291805267334\n",
      "val loss 5.992751121520996\n",
      "______________\n",
      "epoch 34 train loss 6.782562255859375\n",
      "val loss 5.901864528656006\n",
      "______________\n",
      "epoch 35 train loss 6.693855285644531\n",
      "val loss 5.814295768737793\n",
      "______________\n",
      "epoch 36 train loss 6.581757068634033\n",
      "val loss 5.730026721954346\n",
      "______________\n",
      "epoch 37 train loss 6.528017044067383\n",
      "val loss 5.649165630340576\n",
      "______________\n",
      "epoch 38 train loss 6.453231334686279\n",
      "val loss 5.571547985076904\n",
      "______________\n",
      "epoch 39 train loss 6.3497772216796875\n",
      "val loss 5.4973063468933105\n",
      "______________\n",
      "epoch 40 train loss 6.2615532875061035\n",
      "val loss 5.425876617431641\n",
      "______________\n",
      "epoch 41 train loss 6.151388645172119\n",
      "val loss 5.357789993286133\n",
      "______________\n",
      "epoch 42 train loss 6.163521766662598\n",
      "val loss 5.292708873748779\n",
      "______________\n",
      "epoch 43 train loss 6.043025493621826\n",
      "val loss 5.230574131011963\n",
      "______________\n",
      "epoch 44 train loss 5.9489641189575195\n",
      "val loss 5.17125129699707\n",
      "______________\n",
      "epoch 45 train loss 5.925412178039551\n",
      "val loss 5.114981174468994\n",
      "______________\n",
      "epoch 46 train loss 5.839018821716309\n",
      "val loss 5.0615644454956055\n",
      "______________\n",
      "epoch 47 train loss 5.804680347442627\n",
      "val loss 5.011012077331543\n",
      "______________\n",
      "epoch 48 train loss 5.777312278747559\n",
      "val loss 4.962822437286377\n",
      "______________\n",
      "epoch 49 train loss 5.634466648101807\n",
      "val loss 4.916702747344971\n",
      "______________\n",
      "epoch 50 train loss 5.531836032867432\n",
      "val loss 4.872887134552002\n",
      "______________\n",
      "epoch 51 train loss 5.568260669708252\n",
      "val loss 4.831451416015625\n",
      "______________\n",
      "epoch 52 train loss 5.501204013824463\n",
      "val loss 4.791973114013672\n",
      "______________\n",
      "epoch 53 train loss 5.428725242614746\n",
      "val loss 4.754225730895996\n",
      "______________\n",
      "epoch 54 train loss 5.398975849151611\n",
      "val loss 4.7179460525512695\n",
      "______________\n",
      "epoch 55 train loss 5.323367118835449\n",
      "val loss 4.6834940910339355\n",
      "______________\n",
      "epoch 56 train loss 5.317088603973389\n",
      "val loss 4.650484561920166\n",
      "______________\n",
      "epoch 57 train loss 5.222097396850586\n",
      "val loss 4.619260311126709\n",
      "______________\n",
      "epoch 58 train loss 5.221783638000488\n",
      "val loss 4.5896897315979\n",
      "______________\n",
      "epoch 59 train loss 5.222081661224365\n",
      "val loss 4.561801910400391\n",
      "______________\n",
      "epoch 60 train loss 5.164464473724365\n",
      "val loss 4.5351786613464355\n",
      "______________\n",
      "epoch 61 train loss 5.1371307373046875\n",
      "val loss 4.5103983879089355\n",
      "______________\n",
      "epoch 62 train loss 5.158568382263184\n",
      "val loss 4.486791133880615\n",
      "______________\n",
      "epoch 63 train loss 5.10761022567749\n",
      "val loss 4.464468002319336\n",
      "______________\n",
      "epoch 64 train loss 5.032383441925049\n",
      "val loss 4.443566799163818\n",
      "______________\n",
      "epoch 65 train loss 5.004845142364502\n",
      "val loss 4.423521995544434\n",
      "______________\n",
      "epoch 66 train loss 5.030259132385254\n",
      "val loss 4.4047322273254395\n",
      "______________\n",
      "epoch 67 train loss 4.959425449371338\n",
      "val loss 4.3871026039123535\n",
      "______________\n",
      "epoch 68 train loss 4.968306541442871\n",
      "val loss 4.369698524475098\n",
      "______________\n",
      "epoch 69 train loss 4.937963485717773\n",
      "val loss 4.352705955505371\n",
      "______________\n",
      "epoch 70 train loss 4.848093509674072\n",
      "val loss 4.33622932434082\n",
      "______________\n",
      "epoch 71 train loss 4.864164352416992\n",
      "val loss 4.3202805519104\n",
      "______________\n",
      "epoch 72 train loss 4.841043949127197\n",
      "val loss 4.3054118156433105\n",
      "______________\n",
      "epoch 73 train loss 4.780562400817871\n",
      "val loss 4.290799140930176\n",
      "______________\n",
      "epoch 74 train loss 4.772852420806885\n",
      "val loss 4.276308536529541\n",
      "______________\n",
      "epoch 75 train loss 4.773219108581543\n",
      "val loss 4.261962890625\n",
      "______________\n",
      "epoch 76 train loss 4.699153900146484\n",
      "val loss 4.247854709625244\n",
      "______________\n",
      "epoch 77 train loss 4.677385330200195\n",
      "val loss 4.233804225921631\n",
      "______________\n",
      "epoch 78 train loss 4.663141250610352\n",
      "val loss 4.220457553863525\n",
      "______________\n",
      "epoch 79 train loss 4.697909355163574\n",
      "val loss 4.20784330368042\n",
      "______________\n",
      "epoch 80 train loss 4.637852668762207\n",
      "val loss 4.195696830749512\n",
      "______________\n",
      "epoch 81 train loss 4.6123881340026855\n",
      "val loss 4.184345245361328\n",
      "______________\n",
      "epoch 82 train loss 4.62205171585083\n",
      "val loss 4.17327880859375\n",
      "______________\n",
      "epoch 83 train loss 4.6029839515686035\n",
      "val loss 4.1621599197387695\n",
      "______________\n",
      "epoch 84 train loss 4.552417755126953\n",
      "val loss 4.151773929595947\n",
      "______________\n",
      "epoch 85 train loss 4.6208648681640625\n",
      "val loss 4.141704559326172\n",
      "______________\n",
      "epoch 86 train loss 4.591903209686279\n",
      "val loss 4.132147312164307\n",
      "______________\n",
      "epoch 87 train loss 4.572612285614014\n",
      "val loss 4.122756004333496\n",
      "______________\n",
      "epoch 88 train loss 4.562451362609863\n",
      "val loss 4.113779544830322\n",
      "______________\n",
      "epoch 89 train loss 4.501945972442627\n",
      "val loss 4.105100154876709\n",
      "______________\n",
      "epoch 90 train loss 4.510311126708984\n",
      "val loss 4.096854209899902\n",
      "______________\n",
      "epoch 91 train loss 4.494381904602051\n",
      "val loss 4.089414119720459\n",
      "______________\n",
      "epoch 92 train loss 4.47380256652832\n",
      "val loss 4.082231521606445\n",
      "______________\n",
      "epoch 93 train loss 4.449863910675049\n",
      "val loss 4.075595855712891\n",
      "______________\n",
      "epoch 94 train loss 4.447549819946289\n",
      "val loss 4.069459438323975\n",
      "______________\n",
      "epoch 95 train loss 4.526614665985107\n",
      "val loss 4.0630717277526855\n",
      "______________\n",
      "epoch 96 train loss 4.476217269897461\n",
      "val loss 4.056999206542969\n",
      "______________\n",
      "epoch 97 train loss 4.462944507598877\n",
      "val loss 4.051400184631348\n",
      "______________\n",
      "epoch 98 train loss 4.373985767364502\n",
      "val loss 4.04628849029541\n",
      "______________\n",
      "epoch 99 train loss 4.4237751960754395\n",
      "val loss 4.041464328765869\n",
      "______________\n",
      "epoch 100 train loss 4.383050918579102\n",
      "val loss 4.0370588302612305\n",
      "______________\n",
      "epoch 101 train loss 4.349400043487549\n",
      "val loss 4.033064842224121\n",
      "______________\n",
      "epoch 102 train loss 4.385441780090332\n",
      "val loss 4.028869152069092\n",
      "______________\n",
      "epoch 103 train loss 4.352591037750244\n",
      "val loss 4.025091171264648\n",
      "______________\n",
      "epoch 104 train loss 4.35624361038208\n",
      "val loss 4.021276473999023\n",
      "______________\n",
      "epoch 105 train loss 4.3633341789245605\n",
      "val loss 4.017696857452393\n",
      "______________\n",
      "epoch 106 train loss 4.310502052307129\n",
      "val loss 4.013762950897217\n",
      "______________\n",
      "epoch 107 train loss 4.257735252380371\n",
      "val loss 4.009814262390137\n",
      "______________\n",
      "epoch 108 train loss 4.300571918487549\n",
      "val loss 4.005891799926758\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109 train loss 4.28939962387085\n",
      "val loss 4.002512454986572\n",
      "______________\n",
      "epoch 110 train loss 4.288366317749023\n",
      "val loss 3.9989430904388428\n",
      "______________\n",
      "epoch 111 train loss 4.281261444091797\n",
      "val loss 3.9953134059906006\n",
      "______________\n",
      "epoch 112 train loss 4.279115676879883\n",
      "val loss 3.9915127754211426\n",
      "______________\n",
      "epoch 113 train loss 4.329204559326172\n",
      "val loss 3.9878389835357666\n",
      "______________\n",
      "epoch 114 train loss 4.254798412322998\n",
      "val loss 3.9845175743103027\n",
      "______________\n",
      "epoch 115 train loss 4.236929416656494\n",
      "val loss 3.9813358783721924\n",
      "______________\n",
      "epoch 116 train loss 4.227950096130371\n",
      "val loss 3.978368043899536\n",
      "______________\n",
      "epoch 117 train loss 4.2185235023498535\n",
      "val loss 3.9753341674804688\n",
      "______________\n",
      "epoch 118 train loss 4.216078758239746\n",
      "val loss 3.9721522331237793\n",
      "______________\n",
      "epoch 119 train loss 4.224706172943115\n",
      "val loss 3.968489646911621\n",
      "______________\n",
      "epoch 120 train loss 4.240245819091797\n",
      "val loss 3.9644663333892822\n",
      "______________\n",
      "epoch 121 train loss 4.148427486419678\n",
      "val loss 3.9607598781585693\n",
      "______________\n",
      "epoch 122 train loss 4.16875696182251\n",
      "val loss 3.9569902420043945\n",
      "______________\n",
      "epoch 123 train loss 4.192890167236328\n",
      "val loss 3.9531121253967285\n",
      "______________\n",
      "epoch 124 train loss 4.177322864532471\n",
      "val loss 3.949068784713745\n",
      "______________\n",
      "epoch 125 train loss 4.122757911682129\n",
      "val loss 3.944551706314087\n",
      "______________\n",
      "epoch 126 train loss 4.180201530456543\n",
      "val loss 3.940129041671753\n",
      "______________\n",
      "epoch 127 train loss 4.138989448547363\n",
      "val loss 3.9363179206848145\n",
      "______________\n",
      "epoch 128 train loss 4.112597942352295\n",
      "val loss 3.932860851287842\n",
      "______________\n",
      "epoch 129 train loss 4.165017604827881\n",
      "val loss 3.9296138286590576\n",
      "______________\n",
      "epoch 130 train loss 4.170982360839844\n",
      "val loss 3.926034688949585\n",
      "______________\n",
      "epoch 131 train loss 4.101169109344482\n",
      "val loss 3.9228391647338867\n",
      "______________\n",
      "epoch 132 train loss 4.081424236297607\n",
      "val loss 3.9197282791137695\n",
      "______________\n",
      "epoch 133 train loss 4.070879936218262\n",
      "val loss 3.9164226055145264\n",
      "______________\n",
      "epoch 134 train loss 4.092280387878418\n",
      "val loss 3.9133334159851074\n",
      "______________\n",
      "epoch 135 train loss 4.0617265701293945\n",
      "val loss 3.9102134704589844\n",
      "______________\n",
      "epoch 136 train loss 4.066761493682861\n",
      "val loss 3.907285690307617\n",
      "______________\n",
      "epoch 137 train loss 4.0940117835998535\n",
      "val loss 3.904386281967163\n",
      "______________\n",
      "epoch 138 train loss 4.042354106903076\n",
      "val loss 3.901357889175415\n",
      "______________\n",
      "epoch 139 train loss 4.043378829956055\n",
      "val loss 3.898333787918091\n",
      "______________\n",
      "epoch 140 train loss 4.062685012817383\n",
      "val loss 3.894975185394287\n",
      "______________\n",
      "epoch 141 train loss 4.052220821380615\n",
      "val loss 3.891566276550293\n",
      "______________\n",
      "epoch 142 train loss 4.030916213989258\n",
      "val loss 3.887833595275879\n",
      "______________\n",
      "epoch 143 train loss 4.008704662322998\n",
      "val loss 3.8843495845794678\n",
      "______________\n",
      "epoch 144 train loss 3.9803013801574707\n",
      "val loss 3.880737781524658\n",
      "______________\n",
      "epoch 145 train loss 4.000068187713623\n",
      "val loss 3.8776276111602783\n",
      "______________\n",
      "epoch 146 train loss 3.963855743408203\n",
      "val loss 3.874645233154297\n",
      "______________\n",
      "epoch 147 train loss 3.9758057594299316\n",
      "val loss 3.8718771934509277\n",
      "______________\n",
      "epoch 148 train loss 3.98772931098938\n",
      "val loss 3.8691961765289307\n",
      "______________\n",
      "epoch 149 train loss 3.98604679107666\n",
      "val loss 3.8667078018188477\n",
      "______________\n",
      "epoch 150 train loss 3.966933250427246\n",
      "val loss 3.864116668701172\n",
      "______________\n",
      "epoch 151 train loss 3.9502768516540527\n",
      "val loss 3.861550807952881\n",
      "______________\n",
      "epoch 152 train loss 3.9589362144470215\n",
      "val loss 3.8592190742492676\n",
      "______________\n",
      "epoch 153 train loss 3.9747474193573\n",
      "val loss 3.8572304248809814\n",
      "______________\n",
      "epoch 154 train loss 3.9194867610931396\n",
      "val loss 3.855638027191162\n",
      "______________\n",
      "epoch 155 train loss 3.9346580505371094\n",
      "val loss 3.8541102409362793\n",
      "______________\n",
      "epoch 156 train loss 3.905012369155884\n",
      "val loss 3.8521647453308105\n",
      "______________\n",
      "epoch 157 train loss 3.8940374851226807\n",
      "val loss 3.8502721786499023\n",
      "______________\n",
      "epoch 158 train loss 3.9144790172576904\n",
      "val loss 3.8481664657592773\n",
      "______________\n",
      "epoch 159 train loss 3.870835304260254\n",
      "val loss 3.846071481704712\n",
      "______________\n",
      "epoch 160 train loss 3.908602476119995\n",
      "val loss 3.8435211181640625\n",
      "______________\n",
      "epoch 161 train loss 3.9007046222686768\n",
      "val loss 3.8408420085906982\n",
      "______________\n",
      "epoch 162 train loss 3.8745968341827393\n",
      "val loss 3.8378496170043945\n",
      "______________\n",
      "epoch 163 train loss 3.884542465209961\n",
      "val loss 3.834822654724121\n",
      "______________\n",
      "epoch 164 train loss 3.8889894485473633\n",
      "val loss 3.8318400382995605\n",
      "______________\n",
      "epoch 165 train loss 3.8602449893951416\n",
      "val loss 3.8286101818084717\n",
      "______________\n",
      "epoch 166 train loss 3.857760190963745\n",
      "val loss 3.8257558345794678\n",
      "______________\n",
      "epoch 167 train loss 3.837394952774048\n",
      "val loss 3.822978973388672\n",
      "______________\n",
      "epoch 168 train loss 3.8543689250946045\n",
      "val loss 3.820096731185913\n",
      "______________\n",
      "epoch 169 train loss 3.8495867252349854\n",
      "val loss 3.817399024963379\n",
      "______________\n",
      "epoch 170 train loss 3.836974859237671\n",
      "val loss 3.8147168159484863\n",
      "______________\n",
      "epoch 171 train loss 3.846309185028076\n",
      "val loss 3.8121895790100098\n",
      "______________\n",
      "epoch 172 train loss 3.829965591430664\n",
      "val loss 3.809929132461548\n",
      "______________\n",
      "epoch 173 train loss 3.8295772075653076\n",
      "val loss 3.807748317718506\n",
      "______________\n",
      "epoch 174 train loss 3.8181183338165283\n",
      "val loss 3.8055450916290283\n",
      "______________\n",
      "epoch 175 train loss 3.8407692909240723\n",
      "val loss 3.8035809993743896\n",
      "______________\n",
      "epoch 176 train loss 3.846954584121704\n",
      "val loss 3.8018016815185547\n",
      "______________\n",
      "epoch 177 train loss 3.83957576751709\n",
      "val loss 3.799767017364502\n",
      "______________\n",
      "epoch 178 train loss 3.8440232276916504\n",
      "val loss 3.797717332839966\n",
      "______________\n",
      "epoch 179 train loss 3.82753586769104\n",
      "val loss 3.7954254150390625\n",
      "______________\n",
      "epoch 180 train loss 3.859428882598877\n",
      "val loss 3.7931368350982666\n",
      "______________\n",
      "epoch 181 train loss 3.800837516784668\n",
      "val loss 3.7908859252929688\n",
      "______________\n",
      "epoch 182 train loss 3.819758892059326\n",
      "val loss 3.788797616958618\n",
      "______________\n",
      "epoch 183 train loss 3.804171562194824\n",
      "val loss 3.7866859436035156\n",
      "______________\n",
      "epoch 184 train loss 3.82999849319458\n",
      "val loss 3.784557819366455\n",
      "______________\n",
      "epoch 185 train loss 3.767929792404175\n",
      "val loss 3.782696008682251\n",
      "______________\n",
      "epoch 186 train loss 3.781858205795288\n",
      "val loss 3.7806711196899414\n",
      "______________\n",
      "epoch 187 train loss 3.7654125690460205\n",
      "val loss 3.7787928581237793\n",
      "______________\n",
      "epoch 188 train loss 3.759086847305298\n",
      "val loss 3.7767813205718994\n",
      "______________\n",
      "epoch 189 train loss 3.77862548828125\n",
      "val loss 3.77486252784729\n",
      "______________\n",
      "epoch 190 train loss 3.7951457500457764\n",
      "val loss 3.773206949234009\n",
      "______________\n",
      "epoch 191 train loss 3.7755446434020996\n",
      "val loss 3.7715768814086914\n",
      "______________\n",
      "epoch 192 train loss 3.7489254474639893\n",
      "val loss 3.770035743713379\n",
      "______________\n",
      "epoch 193 train loss 3.6817073822021484\n",
      "val loss 3.768817186355591\n",
      "______________\n",
      "epoch 194 train loss 3.7578132152557373\n",
      "val loss 3.7672276496887207\n",
      "______________\n",
      "epoch 195 train loss 3.7807650566101074\n",
      "val loss 3.7656452655792236\n",
      "______________\n",
      "epoch 196 train loss 3.7259719371795654\n",
      "val loss 3.7640480995178223\n",
      "______________\n",
      "epoch 197 train loss 3.7718560695648193\n",
      "val loss 3.762455463409424\n",
      "______________\n",
      "epoch 198 train loss 3.7253732681274414\n",
      "val loss 3.7610270977020264\n",
      "______________\n",
      "epoch 199 train loss 3.7314276695251465\n",
      "val loss 3.759495973587036\n",
      "______________\n",
      "epoch 200 train loss 3.7465949058532715\n",
      "val loss 3.758071184158325\n",
      "______________\n",
      "epoch 201 train loss 3.710242986679077\n",
      "val loss 3.7568299770355225\n",
      "______________\n",
      "epoch 202 train loss 3.7123169898986816\n",
      "val loss 3.755521774291992\n",
      "______________\n",
      "epoch 203 train loss 3.741558074951172\n",
      "val loss 3.7540953159332275\n",
      "______________\n",
      "epoch 204 train loss 3.7551515102386475\n",
      "val loss 3.7524964809417725\n",
      "______________\n",
      "epoch 205 train loss 3.7199513912200928\n",
      "val loss 3.7510931491851807\n",
      "______________\n",
      "epoch 206 train loss 3.714076280593872\n",
      "val loss 3.74932599067688\n",
      "______________\n",
      "epoch 207 train loss 3.6971781253814697\n",
      "val loss 3.747497081756592\n",
      "______________\n",
      "epoch 208 train loss 3.7144737243652344\n",
      "val loss 3.745270013809204\n",
      "______________\n",
      "epoch 209 train loss 3.723867654800415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.742677688598633\n",
      "______________\n",
      "epoch 210 train loss 3.674138069152832\n",
      "val loss 3.7399439811706543\n",
      "______________\n",
      "epoch 211 train loss 3.676138401031494\n",
      "val loss 3.7375588417053223\n",
      "______________\n",
      "epoch 212 train loss 3.6826281547546387\n",
      "val loss 3.7350358963012695\n",
      "______________\n",
      "epoch 213 train loss 3.6802828311920166\n",
      "val loss 3.7324655055999756\n",
      "______________\n",
      "epoch 214 train loss 3.685964584350586\n",
      "val loss 3.729979991912842\n",
      "______________\n",
      "epoch 215 train loss 3.6834497451782227\n",
      "val loss 3.727660655975342\n",
      "______________\n",
      "epoch 216 train loss 3.647573709487915\n",
      "val loss 3.7254745960235596\n",
      "______________\n",
      "epoch 217 train loss 3.670948028564453\n",
      "val loss 3.723177671432495\n",
      "______________\n",
      "epoch 218 train loss 3.6340973377227783\n",
      "val loss 3.7210564613342285\n",
      "______________\n",
      "epoch 219 train loss 3.6380815505981445\n",
      "val loss 3.7191154956817627\n",
      "______________\n",
      "epoch 220 train loss 3.690976619720459\n",
      "val loss 3.7173686027526855\n",
      "______________\n",
      "epoch 221 train loss 3.6562817096710205\n",
      "val loss 3.7158141136169434\n",
      "______________\n",
      "epoch 222 train loss 3.6547040939331055\n",
      "val loss 3.7143285274505615\n",
      "______________\n",
      "epoch 223 train loss 3.6617581844329834\n",
      "val loss 3.7128007411956787\n",
      "______________\n",
      "epoch 224 train loss 3.6648623943328857\n",
      "val loss 3.7113757133483887\n",
      "______________\n",
      "epoch 225 train loss 3.614910840988159\n",
      "val loss 3.70959734916687\n",
      "______________\n",
      "epoch 226 train loss 3.615963935852051\n",
      "val loss 3.7080156803131104\n",
      "______________\n",
      "epoch 227 train loss 3.628389835357666\n",
      "val loss 3.706482172012329\n",
      "______________\n",
      "epoch 228 train loss 3.6204371452331543\n",
      "val loss 3.7050063610076904\n",
      "______________\n",
      "epoch 229 train loss 3.6437675952911377\n",
      "val loss 3.703505277633667\n",
      "______________\n",
      "epoch 230 train loss 3.6465907096862793\n",
      "val loss 3.7021901607513428\n",
      "______________\n",
      "epoch 231 train loss 3.6176624298095703\n",
      "val loss 3.7011756896972656\n",
      "______________\n",
      "epoch 232 train loss 3.623896837234497\n",
      "val loss 3.700166702270508\n",
      "______________\n",
      "epoch 233 train loss 3.6008496284484863\n",
      "val loss 3.6991331577301025\n",
      "______________\n",
      "epoch 234 train loss 3.589289903640747\n",
      "val loss 3.6981945037841797\n",
      "______________\n",
      "epoch 235 train loss 3.606133222579956\n",
      "val loss 3.6970412731170654\n",
      "______________\n",
      "epoch 236 train loss 3.6015872955322266\n",
      "val loss 3.6956541538238525\n",
      "______________\n",
      "epoch 237 train loss 3.600337028503418\n",
      "val loss 3.6943047046661377\n",
      "______________\n",
      "epoch 238 train loss 3.6199228763580322\n",
      "val loss 3.6930630207061768\n",
      "______________\n",
      "epoch 239 train loss 3.6132614612579346\n",
      "val loss 3.6918962001800537\n",
      "______________\n",
      "epoch 240 train loss 3.6033570766448975\n",
      "val loss 3.690702199935913\n",
      "______________\n",
      "epoch 241 train loss 3.6147470474243164\n",
      "val loss 3.6892640590667725\n",
      "______________\n",
      "epoch 242 train loss 3.5933775901794434\n",
      "val loss 3.68782639503479\n",
      "______________\n",
      "epoch 243 train loss 3.574864387512207\n",
      "val loss 3.68625545501709\n",
      "______________\n",
      "epoch 244 train loss 3.6023130416870117\n",
      "val loss 3.684770107269287\n",
      "______________\n",
      "epoch 245 train loss 3.579824924468994\n",
      "val loss 3.683056592941284\n",
      "______________\n",
      "epoch 246 train loss 3.576185703277588\n",
      "val loss 3.6814382076263428\n",
      "______________\n",
      "epoch 247 train loss 3.5479726791381836\n",
      "val loss 3.680074453353882\n",
      "______________\n",
      "epoch 248 train loss 3.5695009231567383\n",
      "val loss 3.679044723510742\n",
      "______________\n",
      "epoch 249 train loss 3.5763814449310303\n",
      "val loss 3.6779074668884277\n",
      "______________\n",
      "epoch 250 train loss 3.5483787059783936\n",
      "val loss 3.6768136024475098\n",
      "______________\n",
      "epoch 251 train loss 3.552560329437256\n",
      "val loss 3.675633430480957\n",
      "______________\n",
      "epoch 252 train loss 3.5634801387786865\n",
      "val loss 3.6743693351745605\n",
      "______________\n",
      "epoch 253 train loss 3.5651206970214844\n",
      "val loss 3.6731879711151123\n",
      "______________\n",
      "epoch 254 train loss 3.5748703479766846\n",
      "val loss 3.671685218811035\n",
      "______________\n",
      "epoch 255 train loss 3.54781174659729\n",
      "val loss 3.6702916622161865\n",
      "______________\n",
      "epoch 256 train loss 3.5650863647460938\n",
      "val loss 3.6690990924835205\n",
      "______________\n",
      "epoch 257 train loss 3.5348963737487793\n",
      "val loss 3.6678152084350586\n",
      "______________\n",
      "epoch 258 train loss 3.5177791118621826\n",
      "val loss 3.666337490081787\n",
      "______________\n",
      "epoch 259 train loss 3.5643551349639893\n",
      "val loss 3.6650121212005615\n",
      "______________\n",
      "epoch 260 train loss 3.5425186157226562\n",
      "val loss 3.6635549068450928\n",
      "______________\n",
      "epoch 261 train loss 3.5786049365997314\n",
      "val loss 3.6620771884918213\n",
      "______________\n",
      "epoch 262 train loss 3.5067596435546875\n",
      "val loss 3.660928964614868\n",
      "______________\n",
      "epoch 263 train loss 3.5451085567474365\n",
      "val loss 3.6598305702209473\n",
      "______________\n",
      "epoch 264 train loss 3.573413610458374\n",
      "val loss 3.658780574798584\n",
      "______________\n",
      "epoch 265 train loss 3.5336685180664062\n",
      "val loss 3.6578636169433594\n",
      "______________\n",
      "epoch 266 train loss 3.5343658924102783\n",
      "val loss 3.6569385528564453\n",
      "______________\n",
      "epoch 267 train loss 3.5329699516296387\n",
      "val loss 3.6560401916503906\n",
      "______________\n",
      "epoch 268 train loss 3.4928979873657227\n",
      "val loss 3.655033826828003\n",
      "______________\n",
      "epoch 269 train loss 3.5086987018585205\n",
      "val loss 3.6541850566864014\n",
      "______________\n",
      "epoch 270 train loss 3.517740488052368\n",
      "val loss 3.6535253524780273\n",
      "______________\n",
      "epoch 271 train loss 3.5086309909820557\n",
      "val loss 3.6524903774261475\n",
      "______________\n",
      "epoch 272 train loss 3.5144264698028564\n",
      "val loss 3.6512815952301025\n",
      "______________\n",
      "epoch 273 train loss 3.52016282081604\n",
      "val loss 3.649928569793701\n",
      "______________\n",
      "epoch 274 train loss 3.5498080253601074\n",
      "val loss 3.6484382152557373\n",
      "______________\n",
      "epoch 275 train loss 3.5226433277130127\n",
      "val loss 3.646913528442383\n",
      "______________\n",
      "epoch 276 train loss 3.5242385864257812\n",
      "val loss 3.6454288959503174\n",
      "______________\n",
      "epoch 277 train loss 3.51214599609375\n",
      "val loss 3.6439075469970703\n",
      "______________\n",
      "epoch 278 train loss 3.4894402027130127\n",
      "val loss 3.642265558242798\n",
      "______________\n",
      "epoch 279 train loss 3.5253348350524902\n",
      "val loss 3.640533924102783\n",
      "______________\n",
      "epoch 280 train loss 3.5086047649383545\n",
      "val loss 3.6390459537506104\n",
      "______________\n",
      "epoch 281 train loss 3.502690553665161\n",
      "val loss 3.6375625133514404\n",
      "______________\n",
      "epoch 282 train loss 3.5079236030578613\n",
      "val loss 3.636070728302002\n",
      "______________\n",
      "epoch 283 train loss 3.4829792976379395\n",
      "val loss 3.6345391273498535\n",
      "______________\n",
      "epoch 284 train loss 3.487882137298584\n",
      "val loss 3.6331465244293213\n",
      "______________\n",
      "epoch 285 train loss 3.5064239501953125\n",
      "val loss 3.6320641040802\n",
      "______________\n",
      "epoch 286 train loss 3.467926263809204\n",
      "val loss 3.63080096244812\n",
      "______________\n",
      "epoch 287 train loss 3.4991538524627686\n",
      "val loss 3.629445791244507\n",
      "______________\n",
      "epoch 288 train loss 3.4879066944122314\n",
      "val loss 3.6281144618988037\n",
      "______________\n",
      "epoch 289 train loss 3.4793331623077393\n",
      "val loss 3.6268608570098877\n",
      "______________\n",
      "epoch 290 train loss 3.5044291019439697\n",
      "val loss 3.6256775856018066\n",
      "______________\n",
      "epoch 291 train loss 3.4931304454803467\n",
      "val loss 3.624687433242798\n",
      "______________\n",
      "epoch 292 train loss 3.4815378189086914\n",
      "val loss 3.6238346099853516\n",
      "______________\n",
      "epoch 293 train loss 3.41018009185791\n",
      "val loss 3.6229827404022217\n",
      "______________\n",
      "epoch 294 train loss 3.4732236862182617\n",
      "val loss 3.6222729682922363\n",
      "______________\n",
      "epoch 295 train loss 3.4427270889282227\n",
      "val loss 3.6215662956237793\n",
      "______________\n",
      "epoch 296 train loss 3.4103779792785645\n",
      "val loss 3.6207058429718018\n",
      "______________\n",
      "epoch 297 train loss 3.4615683555603027\n",
      "val loss 3.6198203563690186\n",
      "______________\n",
      "epoch 298 train loss 3.481510639190674\n",
      "val loss 3.618882417678833\n",
      "______________\n",
      "epoch 299 train loss 3.4421253204345703\n",
      "val loss 3.617928981781006\n",
      "______________\n",
      "epoch 300 train loss 3.4702792167663574\n",
      "val loss 3.6170036792755127\n",
      "______________\n",
      "epoch 301 train loss 3.45267915725708\n",
      "val loss 3.616215705871582\n",
      "______________\n",
      "epoch 302 train loss 3.426509380340576\n",
      "val loss 3.615462064743042\n",
      "______________\n",
      "epoch 303 train loss 3.464660167694092\n",
      "val loss 3.614854097366333\n",
      "______________\n",
      "epoch 304 train loss 3.4398672580718994\n",
      "val loss 3.61403489112854\n",
      "______________\n",
      "epoch 305 train loss 3.431581735610962\n",
      "val loss 3.613062620162964\n",
      "______________\n",
      "epoch 306 train loss 3.409123420715332\n",
      "val loss 3.611981153488159\n",
      "______________\n",
      "epoch 307 train loss 3.4373600482940674\n",
      "val loss 3.610870599746704\n",
      "______________\n",
      "epoch 308 train loss 3.430617332458496\n",
      "val loss 3.609710454940796\n",
      "______________\n",
      "epoch 309 train loss 3.441225528717041\n",
      "val loss 3.608649253845215\n",
      "______________\n",
      "epoch 310 train loss 3.425682544708252\n",
      "val loss 3.6073246002197266\n",
      "______________\n",
      "epoch 311 train loss 3.451704263687134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.606131076812744\n",
      "______________\n",
      "epoch 312 train loss 3.4167873859405518\n",
      "val loss 3.604841470718384\n",
      "______________\n",
      "epoch 313 train loss 3.4165425300598145\n",
      "val loss 3.603576421737671\n",
      "______________\n",
      "epoch 314 train loss 3.410043954849243\n",
      "val loss 3.6020164489746094\n",
      "______________\n",
      "epoch 315 train loss 3.3925907611846924\n",
      "val loss 3.6006524562835693\n",
      "______________\n",
      "epoch 316 train loss 3.4345102310180664\n",
      "val loss 3.5992469787597656\n",
      "______________\n",
      "epoch 317 train loss 3.427387237548828\n",
      "val loss 3.5977535247802734\n",
      "______________\n",
      "epoch 318 train loss 3.411287784576416\n",
      "val loss 3.5964274406433105\n",
      "______________\n",
      "epoch 319 train loss 3.4333302974700928\n",
      "val loss 3.5948424339294434\n",
      "______________\n",
      "epoch 320 train loss 3.4245665073394775\n",
      "val loss 3.593414545059204\n",
      "______________\n",
      "epoch 321 train loss 3.446314573287964\n",
      "val loss 3.5918984413146973\n",
      "______________\n",
      "epoch 322 train loss 3.3924412727355957\n",
      "val loss 3.5906054973602295\n",
      "______________\n",
      "epoch 323 train loss 3.395936965942383\n",
      "val loss 3.589486598968506\n",
      "______________\n",
      "epoch 324 train loss 3.395570993423462\n",
      "val loss 3.5887415409088135\n",
      "______________\n",
      "epoch 325 train loss 3.389258623123169\n",
      "val loss 3.5882506370544434\n",
      "______________\n",
      "epoch 326 train loss 3.446378231048584\n",
      "val loss 3.587808132171631\n",
      "______________\n",
      "epoch 327 train loss 3.4225974082946777\n",
      "val loss 3.587434768676758\n",
      "______________\n",
      "epoch 328 train loss 3.3914947509765625\n",
      "val loss 3.586965560913086\n",
      "______________\n",
      "epoch 329 train loss 3.4231467247009277\n",
      "val loss 3.586641311645508\n",
      "______________\n",
      "epoch 330 train loss 3.392693042755127\n",
      "val loss 3.5862295627593994\n",
      "______________\n",
      "epoch 331 train loss 3.390913963317871\n",
      "val loss 3.5857443809509277\n",
      "______________\n",
      "epoch 332 train loss 3.419177532196045\n",
      "val loss 3.585346221923828\n",
      "______________\n",
      "epoch 333 train loss 3.397035837173462\n",
      "val loss 3.5849289894104004\n",
      "______________\n",
      "epoch 334 train loss 3.384037494659424\n",
      "val loss 3.584500312805176\n",
      "______________\n",
      "epoch 335 train loss 3.3701820373535156\n",
      "val loss 3.584216356277466\n",
      "______________\n",
      "epoch 336 train loss 3.3518195152282715\n",
      "val loss 3.5839884281158447\n",
      "______________\n",
      "epoch 337 train loss 3.4076642990112305\n",
      "val loss 3.5832738876342773\n",
      "______________\n",
      "epoch 338 train loss 3.3387341499328613\n",
      "val loss 3.5823795795440674\n",
      "______________\n",
      "epoch 339 train loss 3.3982417583465576\n",
      "val loss 3.5813682079315186\n",
      "______________\n",
      "epoch 340 train loss 3.350809097290039\n",
      "val loss 3.5802602767944336\n",
      "______________\n",
      "epoch 341 train loss 3.3619141578674316\n",
      "val loss 3.579282760620117\n",
      "______________\n",
      "epoch 342 train loss 3.405102252960205\n",
      "val loss 3.577958106994629\n",
      "______________\n",
      "epoch 343 train loss 3.3428478240966797\n",
      "val loss 3.5767130851745605\n",
      "______________\n",
      "epoch 344 train loss 3.36232328414917\n",
      "val loss 3.575373649597168\n",
      "______________\n",
      "epoch 345 train loss 3.3705220222473145\n",
      "val loss 3.574225902557373\n",
      "______________\n",
      "epoch 346 train loss 3.3833179473876953\n",
      "val loss 3.57336688041687\n",
      "______________\n",
      "epoch 347 train loss 3.391545295715332\n",
      "val loss 3.5725796222686768\n",
      "______________\n",
      "epoch 348 train loss 3.3915047645568848\n",
      "val loss 3.5718584060668945\n",
      "______________\n",
      "epoch 349 train loss 3.380413293838501\n",
      "val loss 3.571254014968872\n",
      "______________\n",
      "epoch 350 train loss 3.3574485778808594\n",
      "val loss 3.570547342300415\n",
      "______________\n",
      "epoch 351 train loss 3.3597817420959473\n",
      "val loss 3.569936513900757\n",
      "______________\n",
      "epoch 352 train loss 3.3119709491729736\n",
      "val loss 3.5693154335021973\n",
      "______________\n",
      "epoch 353 train loss 3.3598055839538574\n",
      "val loss 3.568655490875244\n",
      "______________\n",
      "epoch 354 train loss 3.3176541328430176\n",
      "val loss 3.567924737930298\n",
      "______________\n",
      "epoch 355 train loss 3.356823205947876\n",
      "val loss 3.5671226978302\n",
      "______________\n",
      "epoch 356 train loss 3.325256824493408\n",
      "val loss 3.56654953956604\n",
      "______________\n",
      "epoch 357 train loss 3.380594253540039\n",
      "val loss 3.5658657550811768\n",
      "______________\n",
      "epoch 358 train loss 3.365234136581421\n",
      "val loss 3.5652272701263428\n",
      "______________\n",
      "epoch 359 train loss 3.309826612472534\n",
      "val loss 3.5643811225891113\n",
      "______________\n",
      "epoch 360 train loss 3.3643181324005127\n",
      "val loss 3.563413143157959\n",
      "______________\n",
      "epoch 361 train loss 3.348282814025879\n",
      "val loss 3.562650680541992\n",
      "______________\n",
      "epoch 362 train loss 3.3429293632507324\n",
      "val loss 3.561979293823242\n",
      "______________\n",
      "epoch 363 train loss 3.3415260314941406\n",
      "val loss 3.5614442825317383\n",
      "______________\n",
      "epoch 364 train loss 3.344477891921997\n",
      "val loss 3.5609138011932373\n",
      "______________\n",
      "epoch 365 train loss 3.3710920810699463\n",
      "val loss 3.560255765914917\n",
      "______________\n",
      "epoch 366 train loss 3.3854973316192627\n",
      "val loss 3.5594937801361084\n",
      "______________\n",
      "epoch 367 train loss 3.316836357116699\n",
      "val loss 3.558561086654663\n",
      "______________\n",
      "epoch 368 train loss 3.3366541862487793\n",
      "val loss 3.5575754642486572\n",
      "______________\n",
      "epoch 369 train loss 3.2808022499084473\n",
      "val loss 3.5567047595977783\n",
      "______________\n",
      "epoch 370 train loss 3.2978711128234863\n",
      "val loss 3.5555925369262695\n",
      "______________\n",
      "epoch 371 train loss 3.32863187789917\n",
      "val loss 3.554372787475586\n",
      "______________\n",
      "epoch 372 train loss 3.308464765548706\n",
      "val loss 3.5531809329986572\n",
      "______________\n",
      "epoch 373 train loss 3.3259735107421875\n",
      "val loss 3.5521249771118164\n",
      "______________\n",
      "epoch 374 train loss 3.352773427963257\n",
      "val loss 3.551203727722168\n",
      "______________\n",
      "epoch 375 train loss 3.3132028579711914\n",
      "val loss 3.55043363571167\n",
      "______________\n",
      "epoch 376 train loss 3.3118865489959717\n",
      "val loss 3.5496466159820557\n",
      "______________\n",
      "epoch 377 train loss 3.3218369483947754\n",
      "val loss 3.5488619804382324\n",
      "______________\n",
      "epoch 378 train loss 3.3205432891845703\n",
      "val loss 3.5482075214385986\n",
      "______________\n",
      "epoch 379 train loss 3.3250198364257812\n",
      "val loss 3.5476861000061035\n",
      "______________\n",
      "epoch 380 train loss 3.3027493953704834\n",
      "val loss 3.5475761890411377\n",
      "______________\n",
      "epoch 381 train loss 3.3303561210632324\n",
      "val loss 3.5474770069122314\n",
      "______________\n",
      "epoch 382 train loss 3.3677332401275635\n",
      "val loss 3.5473344326019287\n",
      "______________\n",
      "epoch 383 train loss 3.321723222732544\n",
      "val loss 3.5470688343048096\n",
      "______________\n",
      "epoch 384 train loss 3.262829303741455\n",
      "val loss 3.54673171043396\n",
      "______________\n",
      "epoch 385 train loss 3.310087203979492\n",
      "val loss 3.5462050437927246\n",
      "______________\n",
      "epoch 386 train loss 3.2782182693481445\n",
      "val loss 3.545604944229126\n",
      "______________\n",
      "epoch 387 train loss 3.315957546234131\n",
      "val loss 3.54520845413208\n",
      "______________\n",
      "epoch 388 train loss 3.308232069015503\n",
      "val loss 3.5449893474578857\n",
      "______________\n",
      "epoch 389 train loss 3.3117308616638184\n",
      "val loss 3.5445353984832764\n",
      "______________\n",
      "epoch 390 train loss 3.2757010459899902\n",
      "val loss 3.5440521240234375\n",
      "______________\n",
      "epoch 391 train loss 3.2890584468841553\n",
      "val loss 3.5435075759887695\n",
      "______________\n",
      "epoch 392 train loss 3.2729010581970215\n",
      "val loss 3.5428693294525146\n",
      "______________\n",
      "epoch 393 train loss 3.322833776473999\n",
      "val loss 3.5421671867370605\n",
      "______________\n",
      "epoch 394 train loss 3.2893195152282715\n",
      "val loss 3.541311740875244\n",
      "______________\n",
      "epoch 395 train loss 3.3031373023986816\n",
      "val loss 3.5406079292297363\n",
      "______________\n",
      "epoch 396 train loss 3.3214094638824463\n",
      "val loss 3.539822578430176\n",
      "______________\n",
      "epoch 397 train loss 3.335118532180786\n",
      "val loss 3.5389249324798584\n",
      "______________\n",
      "epoch 398 train loss 3.309471845626831\n",
      "val loss 3.5381481647491455\n",
      "______________\n",
      "epoch 399 train loss 3.2820584774017334\n",
      "val loss 3.5372767448425293\n",
      "______________\n",
      "epoch 400 train loss 3.321634531021118\n",
      "val loss 3.5363495349884033\n",
      "______________\n",
      "epoch 401 train loss 3.3086659908294678\n",
      "val loss 3.535306215286255\n",
      "______________\n",
      "epoch 402 train loss 3.3021976947784424\n",
      "val loss 3.5342559814453125\n",
      "______________\n",
      "epoch 403 train loss 3.2736191749572754\n",
      "val loss 3.5330991744995117\n",
      "______________\n",
      "epoch 404 train loss 3.3192596435546875\n",
      "val loss 3.5320281982421875\n",
      "______________\n",
      "epoch 405 train loss 3.272721767425537\n",
      "val loss 3.531041145324707\n",
      "______________\n",
      "epoch 406 train loss 3.2691712379455566\n",
      "val loss 3.5299973487854004\n",
      "______________\n",
      "epoch 407 train loss 3.3047330379486084\n",
      "val loss 3.5292587280273438\n",
      "______________\n",
      "epoch 408 train loss 3.2554702758789062\n",
      "val loss 3.5285263061523438\n",
      "______________\n",
      "epoch 409 train loss 3.299731731414795\n",
      "val loss 3.5279381275177\n",
      "______________\n",
      "epoch 410 train loss 3.250176191329956\n",
      "val loss 3.5272974967956543\n",
      "______________\n",
      "epoch 411 train loss 3.29398512840271\n",
      "val loss 3.5266106128692627\n",
      "______________\n",
      "epoch 412 train loss 3.2600505352020264\n",
      "val loss 3.5258007049560547\n",
      "______________\n",
      "epoch 413 train loss 3.272918224334717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 3.524904727935791\n",
      "______________\n",
      "epoch 414 train loss 3.2590880393981934\n",
      "val loss 3.5238914489746094\n",
      "______________\n",
      "epoch 415 train loss 3.2677688598632812\n",
      "val loss 3.5225753784179688\n",
      "______________\n",
      "epoch 416 train loss 3.2480385303497314\n",
      "val loss 3.5213963985443115\n",
      "______________\n",
      "epoch 417 train loss 3.25256609916687\n",
      "val loss 3.520350694656372\n",
      "______________\n",
      "epoch 418 train loss 3.30407977104187\n",
      "val loss 3.5194461345672607\n",
      "______________\n",
      "epoch 419 train loss 3.2569167613983154\n",
      "val loss 3.5187203884124756\n",
      "______________\n",
      "epoch 420 train loss 3.264942169189453\n",
      "val loss 3.518305778503418\n",
      "______________\n",
      "epoch 421 train loss 3.277289390563965\n",
      "val loss 3.5178754329681396\n",
      "______________\n",
      "epoch 422 train loss 3.2801218032836914\n",
      "val loss 3.517397880554199\n",
      "______________\n",
      "epoch 423 train loss 3.263296127319336\n",
      "val loss 3.5169155597686768\n",
      "______________\n",
      "epoch 424 train loss 3.261009931564331\n",
      "val loss 3.5167860984802246\n",
      "______________\n",
      "epoch 425 train loss 3.24609375\n",
      "val loss 3.516845226287842\n",
      "______________\n",
      "epoch 426 train loss 3.298741340637207\n",
      "val loss 3.5169410705566406\n",
      "______________\n",
      "epoch 427 train loss 3.2520334720611572\n",
      "val loss 3.5170369148254395\n",
      "______________\n",
      "epoch 428 train loss 3.270256280899048\n",
      "val loss 3.5169742107391357\n",
      "______________\n",
      "epoch 429 train loss 3.252652168273926\n",
      "val loss 3.5168864727020264\n",
      "______________\n",
      "epoch 430 train loss 3.2787811756134033\n",
      "val loss 3.5167317390441895\n",
      "______________\n",
      "epoch 431 train loss 3.2478580474853516\n",
      "val loss 3.5163984298706055\n",
      "______________\n",
      "epoch 432 train loss 3.2346227169036865\n",
      "val loss 3.516036033630371\n",
      "______________\n",
      "epoch 433 train loss 3.301107883453369\n",
      "val loss 3.5156567096710205\n",
      "______________\n",
      "epoch 434 train loss 3.203352928161621\n",
      "val loss 3.5155177116394043\n",
      "______________\n",
      "epoch 435 train loss 3.258209228515625\n",
      "val loss 3.5151610374450684\n",
      "______________\n",
      "epoch 436 train loss 3.256734609603882\n",
      "val loss 3.5147054195404053\n",
      "______________\n",
      "epoch 437 train loss 3.2668161392211914\n",
      "val loss 3.5141820907592773\n",
      "______________\n",
      "epoch 438 train loss 3.2366695404052734\n",
      "val loss 3.513606309890747\n",
      "______________\n",
      "epoch 439 train loss 3.2554869651794434\n",
      "val loss 3.5130600929260254\n",
      "______________\n",
      "epoch 440 train loss 3.250339984893799\n",
      "val loss 3.512249231338501\n",
      "______________\n",
      "epoch 441 train loss 3.24522066116333\n",
      "val loss 3.5116753578186035\n",
      "______________\n",
      "epoch 442 train loss 3.2247157096862793\n",
      "val loss 3.5112967491149902\n",
      "______________\n",
      "epoch 443 train loss 3.2162671089172363\n",
      "val loss 3.510741949081421\n",
      "______________\n",
      "epoch 444 train loss 3.232036828994751\n",
      "val loss 3.5099551677703857\n",
      "______________\n",
      "epoch 445 train loss 3.258857011795044\n",
      "val loss 3.509185552597046\n",
      "______________\n",
      "epoch 446 train loss 3.2131526470184326\n",
      "val loss 3.50830340385437\n",
      "______________\n",
      "epoch 447 train loss 3.217604637145996\n",
      "val loss 3.5073740482330322\n",
      "______________\n",
      "epoch 448 train loss 3.2353408336639404\n",
      "val loss 3.506446599960327\n",
      "______________\n",
      "epoch 449 train loss 3.226977825164795\n",
      "val loss 3.5055346488952637\n",
      "______________\n",
      "epoch 450 train loss 3.2623770236968994\n",
      "val loss 3.5045969486236572\n",
      "______________\n",
      "epoch 451 train loss 3.2309064865112305\n",
      "val loss 3.5036590099334717\n",
      "______________\n",
      "epoch 452 train loss 3.241811990737915\n",
      "val loss 3.502899169921875\n",
      "______________\n",
      "epoch 453 train loss 3.2056236267089844\n",
      "val loss 3.5022730827331543\n",
      "______________\n",
      "epoch 454 train loss 3.21132230758667\n",
      "val loss 3.501584053039551\n",
      "______________\n",
      "epoch 455 train loss 3.2191545963287354\n",
      "val loss 3.500784158706665\n",
      "______________\n",
      "epoch 456 train loss 3.217633008956909\n",
      "val loss 3.4998841285705566\n",
      "______________\n",
      "epoch 457 train loss 3.2344954013824463\n",
      "val loss 3.499166965484619\n",
      "______________\n",
      "epoch 458 train loss 3.2305665016174316\n",
      "val loss 3.4983625411987305\n",
      "______________\n",
      "epoch 459 train loss 3.2256276607513428\n",
      "val loss 3.497605085372925\n",
      "______________\n",
      "epoch 460 train loss 3.2158617973327637\n",
      "val loss 3.4968385696411133\n",
      "______________\n",
      "epoch 461 train loss 3.1942689418792725\n",
      "val loss 3.4961915016174316\n",
      "______________\n",
      "epoch 462 train loss 3.195103168487549\n",
      "val loss 3.4955055713653564\n",
      "______________\n",
      "epoch 463 train loss 3.220958948135376\n",
      "val loss 3.49477219581604\n",
      "______________\n",
      "epoch 464 train loss 3.258838176727295\n",
      "val loss 3.4941141605377197\n",
      "______________\n",
      "epoch 465 train loss 3.207960844039917\n",
      "val loss 3.4934475421905518\n",
      "______________\n",
      "epoch 466 train loss 3.1828646659851074\n",
      "val loss 3.492671489715576\n",
      "______________\n",
      "epoch 467 train loss 3.2148585319519043\n",
      "val loss 3.492079257965088\n",
      "______________\n",
      "epoch 468 train loss 3.1880829334259033\n",
      "val loss 3.491321563720703\n",
      "______________\n",
      "epoch 469 train loss 3.2187252044677734\n",
      "val loss 3.4905083179473877\n",
      "______________\n",
      "epoch 470 train loss 3.232023239135742\n",
      "val loss 3.489779233932495\n",
      "______________\n",
      "epoch 471 train loss 3.229475259780884\n",
      "val loss 3.4892475605010986\n",
      "______________\n",
      "epoch 472 train loss 3.2407102584838867\n",
      "val loss 3.4888956546783447\n",
      "______________\n",
      "epoch 473 train loss 3.2288246154785156\n",
      "val loss 3.488403081893921\n",
      "______________\n",
      "epoch 474 train loss 3.232834577560425\n",
      "val loss 3.488027811050415\n",
      "______________\n",
      "epoch 475 train loss 3.2108352184295654\n",
      "val loss 3.48777174949646\n",
      "______________\n",
      "epoch 476 train loss 3.2410192489624023\n",
      "val loss 3.487553358078003\n",
      "______________\n",
      "epoch 477 train loss 3.2017593383789062\n",
      "val loss 3.4874472618103027\n",
      "______________\n",
      "epoch 478 train loss 3.225264310836792\n",
      "val loss 3.487335205078125\n",
      "______________\n",
      "epoch 479 train loss 3.2151448726654053\n",
      "val loss 3.487104654312134\n",
      "______________\n",
      "epoch 480 train loss 3.1920037269592285\n",
      "val loss 3.486926794052124\n",
      "______________\n",
      "epoch 481 train loss 3.172050952911377\n",
      "val loss 3.4869067668914795\n",
      "______________\n",
      "epoch 482 train loss 3.2054178714752197\n",
      "val loss 3.4867568016052246\n",
      "______________\n",
      "epoch 483 train loss 3.2051546573638916\n",
      "val loss 3.486366033554077\n",
      "______________\n",
      "epoch 484 train loss 3.213102102279663\n",
      "val loss 3.485903739929199\n",
      "______________\n",
      "epoch 485 train loss 3.219576835632324\n",
      "val loss 3.4852874279022217\n",
      "______________\n",
      "epoch 486 train loss 3.210608959197998\n",
      "val loss 3.484584093093872\n",
      "______________\n",
      "epoch 487 train loss 3.200307846069336\n",
      "val loss 3.483799934387207\n",
      "______________\n",
      "epoch 488 train loss 3.1856837272644043\n",
      "val loss 3.482964038848877\n",
      "______________\n",
      "epoch 489 train loss 3.188894748687744\n",
      "val loss 3.482130289077759\n",
      "______________\n",
      "epoch 490 train loss 3.240438938140869\n",
      "val loss 3.4813785552978516\n",
      "______________\n",
      "epoch 491 train loss 3.2107796669006348\n",
      "val loss 3.4804842472076416\n",
      "______________\n",
      "epoch 492 train loss 3.1560986042022705\n",
      "val loss 3.4796760082244873\n",
      "______________\n",
      "epoch 493 train loss 3.164858341217041\n",
      "val loss 3.478841543197632\n",
      "______________\n",
      "epoch 494 train loss 3.171212911605835\n",
      "val loss 3.4779341220855713\n",
      "______________\n",
      "epoch 495 train loss 3.186491012573242\n",
      "val loss 3.477005958557129\n",
      "______________\n",
      "epoch 496 train loss 3.1839540004730225\n",
      "val loss 3.4763081073760986\n",
      "______________\n",
      "epoch 497 train loss 3.2022311687469482\n",
      "val loss 3.47580623626709\n",
      "______________\n",
      "epoch 498 train loss 3.2109339237213135\n",
      "val loss 3.4752581119537354\n",
      "______________\n",
      "epoch 499 train loss 3.1979434490203857\n",
      "val loss 3.474860191345215\n",
      "______________\n",
      "epoch 500 train loss 3.1714022159576416\n",
      "val loss 3.474642515182495\n",
      "______________\n",
      "epoch 501 train loss 3.155433177947998\n",
      "val loss 3.4745044708251953\n",
      "______________\n",
      "epoch 502 train loss 3.173154592514038\n",
      "val loss 3.474403142929077\n",
      "______________\n",
      "epoch 503 train loss 3.159364700317383\n",
      "val loss 3.474440336227417\n",
      "______________\n",
      "epoch 504 train loss 3.165879964828491\n",
      "val loss 3.4741597175598145\n",
      "______________\n",
      "epoch 505 train loss 3.1586594581604004\n",
      "val loss 3.4740712642669678\n",
      "______________\n",
      "epoch 506 train loss 3.1622092723846436\n",
      "val loss 3.4740257263183594\n",
      "______________\n",
      "epoch 507 train loss 3.192080020904541\n",
      "val loss 3.4738059043884277\n",
      "______________\n",
      "epoch 508 train loss 3.1800825595855713\n",
      "val loss 3.4734995365142822\n",
      "______________\n",
      "epoch 509 train loss 3.166626214981079\n",
      "val loss 3.4731879234313965\n",
      "______________\n",
      "epoch 510 train loss 3.1546130180358887\n",
      "val loss 3.4729669094085693\n",
      "______________\n",
      "epoch 511 train loss 3.1726837158203125\n",
      "val loss 3.4726979732513428\n",
      "______________\n",
      "epoch 512 train loss 3.176668167114258\n",
      "val loss 3.4724016189575195\n",
      "______________\n",
      "epoch 513 train loss 3.1620116233825684\n",
      "val loss 3.4721739292144775\n",
      "______________\n",
      "epoch 514 train loss 3.1408369541168213\n",
      "val loss 3.4719202518463135\n",
      "______________\n",
      "epoch 515 train loss 3.153238296508789\n",
      "val loss 3.471755027770996\n",
      "______________\n",
      "epoch 516 train loss 3.1699934005737305\n",
      "val loss 3.4715147018432617\n",
      "______________\n",
      "epoch 517 train loss 3.162487268447876\n",
      "val loss 3.471365451812744\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 518 train loss 3.1524322032928467\n",
      "val loss 3.4710755348205566\n",
      "______________\n",
      "epoch 519 train loss 3.15773606300354\n",
      "val loss 3.470646858215332\n",
      "______________\n",
      "epoch 520 train loss 3.166398525238037\n",
      "val loss 3.470114231109619\n",
      "______________\n",
      "epoch 521 train loss 3.129446268081665\n",
      "val loss 3.4695284366607666\n",
      "______________\n",
      "epoch 522 train loss 3.17154860496521\n",
      "val loss 3.4688799381256104\n",
      "______________\n",
      "epoch 523 train loss 3.1813268661499023\n",
      "val loss 3.4683172702789307\n",
      "______________\n",
      "epoch 524 train loss 3.160810708999634\n",
      "val loss 3.4679133892059326\n",
      "______________\n",
      "epoch 525 train loss 3.17592191696167\n",
      "val loss 3.4675371646881104\n",
      "______________\n",
      "epoch 526 train loss 3.1465444564819336\n",
      "val loss 3.4671590328216553\n",
      "______________\n",
      "epoch 527 train loss 3.1513352394104004\n",
      "val loss 3.466595411300659\n",
      "______________\n",
      "epoch 528 train loss 3.1431989669799805\n",
      "val loss 3.465945243835449\n",
      "______________\n",
      "epoch 529 train loss 3.1617319583892822\n",
      "val loss 3.4651882648468018\n",
      "______________\n",
      "epoch 530 train loss 3.1757473945617676\n",
      "val loss 3.464421510696411\n",
      "______________\n",
      "epoch 531 train loss 3.1712536811828613\n",
      "val loss 3.4638030529022217\n",
      "______________\n",
      "epoch 532 train loss 3.1556191444396973\n",
      "val loss 3.4631059169769287\n",
      "______________\n",
      "epoch 533 train loss 3.135784149169922\n",
      "val loss 3.462345838546753\n",
      "______________\n",
      "epoch 534 train loss 3.168816328048706\n",
      "val loss 3.4615817070007324\n",
      "______________\n",
      "epoch 535 train loss 3.1467700004577637\n",
      "val loss 3.4608969688415527\n",
      "______________\n",
      "epoch 536 train loss 3.1031599044799805\n",
      "val loss 3.460156202316284\n",
      "______________\n",
      "epoch 537 train loss 3.1531996726989746\n",
      "val loss 3.4594907760620117\n",
      "______________\n",
      "epoch 538 train loss 3.1589555740356445\n",
      "val loss 3.458864450454712\n",
      "______________\n",
      "epoch 539 train loss 3.1128196716308594\n",
      "val loss 3.458186388015747\n",
      "______________\n",
      "epoch 540 train loss 3.151677131652832\n",
      "val loss 3.4577314853668213\n",
      "______________\n",
      "epoch 541 train loss 3.151183605194092\n",
      "val loss 3.457402467727661\n",
      "______________\n",
      "epoch 542 train loss 3.1419904232025146\n",
      "val loss 3.4570260047912598\n",
      "______________\n",
      "epoch 543 train loss 3.1609749794006348\n",
      "val loss 3.4567744731903076\n",
      "______________\n",
      "epoch 544 train loss 3.1075735092163086\n",
      "val loss 3.456557512283325\n",
      "______________\n",
      "epoch 545 train loss 3.162686347961426\n",
      "val loss 3.456521511077881\n",
      "______________\n",
      "epoch 546 train loss 3.1311473846435547\n",
      "val loss 3.456327199935913\n",
      "______________\n",
      "epoch 547 train loss 3.1156976222991943\n",
      "val loss 3.4560749530792236\n",
      "______________\n",
      "epoch 548 train loss 3.092219114303589\n",
      "val loss 3.4557645320892334\n",
      "______________\n",
      "epoch 549 train loss 3.143144369125366\n",
      "val loss 3.4556262493133545\n",
      "______________\n",
      "epoch 550 train loss 3.1506752967834473\n",
      "val loss 3.455508232116699\n",
      "______________\n",
      "epoch 551 train loss 3.130979537963867\n",
      "val loss 3.455350875854492\n",
      "______________\n",
      "epoch 552 train loss 3.142789363861084\n",
      "val loss 3.455054521560669\n",
      "______________\n",
      "epoch 553 train loss 3.126018762588501\n",
      "val loss 3.454634666442871\n",
      "______________\n",
      "epoch 554 train loss 3.1126272678375244\n",
      "val loss 3.4541215896606445\n",
      "______________\n",
      "epoch 555 train loss 3.10798716545105\n",
      "val loss 3.453518867492676\n",
      "______________\n",
      "epoch 556 train loss 3.12423038482666\n",
      "val loss 3.4528462886810303\n",
      "______________\n",
      "epoch 557 train loss 3.122389078140259\n",
      "val loss 3.452197790145874\n",
      "______________\n",
      "epoch 558 train loss 3.107016086578369\n",
      "val loss 3.451552152633667\n",
      "______________\n",
      "epoch 559 train loss 3.1278700828552246\n",
      "val loss 3.4510505199432373\n",
      "______________\n",
      "epoch 560 train loss 3.1255645751953125\n",
      "val loss 3.4507410526275635\n",
      "______________\n",
      "epoch 561 train loss 3.1355061531066895\n",
      "val loss 3.4505674839019775\n",
      "______________\n",
      "epoch 562 train loss 3.1551592350006104\n",
      "val loss 3.450317144393921\n",
      "______________\n",
      "epoch 563 train loss 3.11971116065979\n",
      "val loss 3.4499764442443848\n",
      "______________\n",
      "epoch 564 train loss 3.1206562519073486\n",
      "val loss 3.4497063159942627\n",
      "______________\n",
      "epoch 565 train loss 3.113757610321045\n",
      "val loss 3.4493887424468994\n",
      "______________\n",
      "epoch 566 train loss 3.1027514934539795\n",
      "val loss 3.44911789894104\n",
      "______________\n",
      "epoch 567 train loss 3.1124160289764404\n",
      "val loss 3.4489898681640625\n",
      "______________\n",
      "epoch 568 train loss 3.0732903480529785\n",
      "val loss 3.4488582611083984\n",
      "______________\n",
      "epoch 569 train loss 3.1276276111602783\n",
      "val loss 3.4486281871795654\n",
      "______________\n",
      "epoch 570 train loss 3.115300416946411\n",
      "val loss 3.448646306991577\n",
      "______________\n",
      "epoch 571 train loss 3.1489038467407227\n",
      "val loss 3.448651075363159\n",
      "______________\n",
      "epoch 572 train loss 3.082892894744873\n",
      "val loss 3.448848009109497\n",
      "______________\n",
      "epoch 573 train loss 3.074619770050049\n",
      "val loss 3.448927640914917\n",
      "______________\n",
      "epoch 574 train loss 3.091489553451538\n",
      "val loss 3.448927402496338\n",
      "______________\n",
      "epoch 575 train loss 3.1292667388916016\n",
      "val loss 3.4488685131073\n",
      "______________\n",
      "epoch 576 train loss 3.1300771236419678\n",
      "val loss 3.448761224746704\n",
      "______________\n",
      "epoch 577 train loss 3.1195547580718994\n",
      "val loss 3.4485955238342285\n",
      "______________\n",
      "epoch 578 train loss 3.1049270629882812\n",
      "val loss 3.4483916759490967\n",
      "______________\n",
      "epoch 579 train loss 3.125169038772583\n",
      "val loss 3.448164463043213\n",
      "______________\n",
      "epoch 580 train loss 3.093426465988159\n",
      "val loss 3.448005437850952\n",
      "______________\n",
      "epoch 581 train loss 3.127570629119873\n",
      "val loss 3.4477431774139404\n",
      "______________\n",
      "epoch 582 train loss 3.1324622631073\n",
      "val loss 3.4474260807037354\n",
      "______________\n",
      "epoch 583 train loss 3.087728500366211\n",
      "val loss 3.446974992752075\n",
      "______________\n",
      "epoch 584 train loss 3.095500946044922\n",
      "val loss 3.4468910694122314\n",
      "______________\n",
      "epoch 585 train loss 3.0510857105255127\n",
      "val loss 3.4468250274658203\n",
      "______________\n",
      "epoch 586 train loss 3.0885536670684814\n",
      "val loss 3.446626901626587\n",
      "______________\n",
      "epoch 587 train loss 3.0847623348236084\n",
      "val loss 3.4461605548858643\n",
      "______________\n",
      "epoch 588 train loss 3.121441602706909\n",
      "val loss 3.4456284046173096\n",
      "______________\n",
      "epoch 589 train loss 3.10469651222229\n",
      "val loss 3.4451866149902344\n",
      "______________\n",
      "epoch 590 train loss 3.092606782913208\n",
      "val loss 3.444798231124878\n",
      "______________\n",
      "epoch 591 train loss 3.1045970916748047\n",
      "val loss 3.444387912750244\n",
      "______________\n",
      "epoch 592 train loss 3.1360392570495605\n",
      "val loss 3.443833351135254\n",
      "______________\n",
      "epoch 593 train loss 3.0969696044921875\n",
      "val loss 3.443201780319214\n",
      "______________\n",
      "epoch 594 train loss 3.0877997875213623\n",
      "val loss 3.4423987865448\n",
      "______________\n",
      "epoch 595 train loss 3.1061384677886963\n",
      "val loss 3.4418373107910156\n",
      "______________\n",
      "epoch 596 train loss 3.0874438285827637\n",
      "val loss 3.4413139820098877\n",
      "______________\n",
      "epoch 597 train loss 3.0853424072265625\n",
      "val loss 3.440594434738159\n",
      "______________\n",
      "epoch 598 train loss 3.072667360305786\n",
      "val loss 3.440176486968994\n",
      "______________\n",
      "epoch 599 train loss 3.0721685886383057\n",
      "val loss 3.439664125442505\n",
      "______________\n",
      "epoch 600 train loss 3.127816677093506\n",
      "val loss 3.439255952835083\n",
      "______________\n",
      "epoch 601 train loss 3.072035312652588\n",
      "val loss 3.438908576965332\n",
      "______________\n",
      "epoch 602 train loss 3.0866036415100098\n",
      "val loss 3.4385900497436523\n",
      "______________\n",
      "epoch 603 train loss 3.07734751701355\n",
      "val loss 3.438361883163452\n",
      "______________\n",
      "epoch 604 train loss 3.072296380996704\n",
      "val loss 3.437897205352783\n",
      "______________\n",
      "epoch 605 train loss 3.0535902976989746\n",
      "val loss 3.4373960494995117\n",
      "______________\n",
      "epoch 606 train loss 3.046718120574951\n",
      "val loss 3.4367215633392334\n",
      "______________\n",
      "epoch 607 train loss 3.0740363597869873\n",
      "val loss 3.4359395503997803\n",
      "______________\n",
      "epoch 608 train loss 3.089578628540039\n",
      "val loss 3.4353487491607666\n",
      "______________\n",
      "epoch 609 train loss 3.0892422199249268\n",
      "val loss 3.4346396923065186\n",
      "______________\n",
      "epoch 610 train loss 3.1083946228027344\n",
      "val loss 3.4341750144958496\n",
      "______________\n",
      "epoch 611 train loss 3.0529026985168457\n",
      "val loss 3.433670997619629\n",
      "______________\n",
      "epoch 612 train loss 3.0740580558776855\n",
      "val loss 3.4332504272460938\n",
      "______________\n",
      "epoch 613 train loss 3.0827105045318604\n",
      "val loss 3.432823896408081\n",
      "______________\n",
      "epoch 614 train loss 3.0550644397735596\n",
      "val loss 3.432633638381958\n",
      "______________\n",
      "epoch 615 train loss 3.0511903762817383\n",
      "val loss 3.432420492172241\n",
      "______________\n",
      "epoch 616 train loss 3.038757801055908\n",
      "val loss 3.4323041439056396\n",
      "______________\n",
      "epoch 617 train loss 3.0766642093658447\n",
      "val loss 3.43205189704895\n",
      "______________\n",
      "epoch 618 train loss 3.0822360515594482\n",
      "val loss 3.431492328643799\n",
      "______________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 619 train loss 3.0360467433929443\n",
      "val loss 3.431000232696533\n",
      "______________\n",
      "epoch 620 train loss 3.03600811958313\n",
      "val loss 3.4303970336914062\n",
      "______________\n",
      "epoch 621 train loss 3.0874831676483154\n",
      "val loss 3.429776430130005\n",
      "______________\n",
      "epoch 622 train loss 3.059547185897827\n",
      "val loss 3.4293129444122314\n",
      "______________\n",
      "epoch 623 train loss 3.056511402130127\n",
      "val loss 3.4288830757141113\n",
      "______________\n",
      "epoch 624 train loss 3.0651261806488037\n",
      "val loss 3.428677558898926\n",
      "______________\n",
      "epoch 625 train loss 3.09053635597229\n",
      "val loss 3.4284474849700928\n",
      "______________\n",
      "epoch 626 train loss 3.0810611248016357\n",
      "val loss 3.4281935691833496\n",
      "______________\n",
      "epoch 627 train loss 3.0577433109283447\n",
      "val loss 3.428241729736328\n",
      "______________\n",
      "epoch 628 train loss 3.0967748165130615\n",
      "val loss 3.428295135498047\n",
      "______________\n",
      "epoch 629 train loss 3.0641674995422363\n",
      "val loss 3.4283084869384766\n",
      "______________\n",
      "epoch 630 train loss 3.0535566806793213\n",
      "val loss 3.428220510482788\n",
      "______________\n",
      "epoch 631 train loss 3.046215295791626\n",
      "val loss 3.4280855655670166\n",
      "______________\n",
      "epoch 632 train loss 3.0932841300964355\n",
      "val loss 3.42814302444458\n",
      "______________\n",
      "epoch 633 train loss 3.063019037246704\n",
      "val loss 3.428339958190918\n",
      "______________\n",
      "epoch 634 train loss 3.0418050289154053\n",
      "val loss 3.4283735752105713\n",
      "______________\n",
      "epoch 635 train loss 3.050950050354004\n",
      "val loss 3.4283223152160645\n",
      "______________\n",
      "epoch 636 train loss 3.0398807525634766\n",
      "val loss 3.4284918308258057\n",
      "______________\n",
      "epoch 637 train loss 3.056089162826538\n",
      "val loss 3.4285473823547363\n",
      "______________\n",
      "epoch 638 train loss 3.0458931922912598\n",
      "val loss 3.4284515380859375\n",
      "______________\n",
      "epoch 639 train loss 3.0176310539245605\n",
      "val loss 3.428130626678467\n",
      "______________\n",
      "epoch 640 train loss 3.049494981765747\n",
      "val loss 3.427659034729004\n",
      "______________\n",
      "epoch 641 train loss 3.063326358795166\n",
      "val loss 3.4270620346069336\n",
      "______________\n",
      "epoch 642 train loss 3.050097703933716\n",
      "val loss 3.426518440246582\n",
      "______________\n",
      "epoch 643 train loss 3.012986183166504\n",
      "val loss 3.425877809524536\n",
      "______________\n",
      "epoch 644 train loss 3.0146188735961914\n",
      "val loss 3.4252865314483643\n",
      "______________\n",
      "epoch 645 train loss 3.054835081100464\n",
      "val loss 3.424546480178833\n",
      "______________\n",
      "epoch 646 train loss 3.0570099353790283\n",
      "val loss 3.4236831665039062\n",
      "______________\n",
      "epoch 647 train loss 3.005581855773926\n",
      "val loss 3.4227726459503174\n",
      "______________\n",
      "epoch 648 train loss 3.0745086669921875\n",
      "val loss 3.4218733310699463\n",
      "______________\n",
      "epoch 649 train loss 3.0794167518615723\n",
      "val loss 3.4210193157196045\n",
      "______________\n",
      "epoch 650 train loss 3.0408928394317627\n",
      "val loss 3.4199681282043457\n",
      "______________\n",
      "epoch 651 train loss 3.043790340423584\n",
      "val loss 3.4190127849578857\n",
      "______________\n",
      "epoch 652 train loss 3.092642307281494\n",
      "val loss 3.4181385040283203\n",
      "______________\n",
      "epoch 653 train loss 3.0710089206695557\n",
      "val loss 3.4174067974090576\n",
      "______________\n",
      "epoch 654 train loss 3.1046276092529297\n",
      "val loss 3.416780948638916\n",
      "______________\n",
      "epoch 655 train loss 3.0422983169555664\n",
      "val loss 3.4161059856414795\n",
      "______________\n",
      "epoch 656 train loss 3.0783135890960693\n",
      "val loss 3.4157285690307617\n",
      "______________\n",
      "epoch 657 train loss 3.0428805351257324\n",
      "val loss 3.4155526161193848\n",
      "______________\n",
      "epoch 658 train loss 3.0391838550567627\n",
      "val loss 3.4155688285827637\n",
      "______________\n",
      "epoch 659 train loss 3.0656120777130127\n",
      "val loss 3.4155821800231934\n",
      "______________\n",
      "epoch 660 train loss 3.0257985591888428\n",
      "val loss 3.4156370162963867\n",
      "______________\n",
      "epoch 661 train loss 3.069211006164551\n",
      "val loss 3.4156646728515625\n",
      "______________\n",
      "epoch 662 train loss 3.066310405731201\n",
      "val loss 3.4158384799957275\n",
      "______________\n",
      "epoch 663 train loss 3.0267508029937744\n",
      "val loss 3.416006088256836\n",
      "______________\n",
      "epoch 664 train loss 3.0469532012939453\n",
      "val loss 3.4161179065704346\n",
      "______________\n",
      "epoch 665 train loss 3.0597786903381348\n",
      "val loss 3.4162206649780273\n",
      "______________\n",
      "epoch 666 train loss 3.0687108039855957\n",
      "val loss 3.416250228881836\n",
      "______________\n",
      "epoch 667 train loss 3.04251766204834\n",
      "val loss 3.416208505630493\n",
      "______________\n",
      "epoch 668 train loss 3.019468069076538\n",
      "val loss 3.41617488861084\n",
      "______________\n",
      "best loss 3.4155526161193848 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9420884200545218, 'roc_macro': -1}, 'nd': {'accuracy': 0.36194620253164556, 'roc_micro': 0.7380236279204061, 'roc_macro': 0.5615300508593192}, 'mod': {'accuracy': 0.36194620253164556, 'roc_micro': 0.7380236279204061, 'roc_macro': 0.5615300508593192}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4265734265734265, 0.6200248756218905, 0.658787255909558, -1, 0.41843971631205673, -1, 0.4581560283687944, -1], 'auc_mean': -0.052252337151784234}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=72, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (disease_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=500, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=500, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=500, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_args = {'hidden_layers': [500, 500], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model2,_,_ = train_state(model_args=t2_args,state=2,use_attention=False)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7e7ebb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "epoch 0 train loss 2.133636951446533\n",
      "val loss 2.132828950881958\n",
      "______________\n",
      "epoch 1 train loss 2.129544496536255\n",
      "val loss 2.109847068786621\n",
      "______________\n",
      "epoch 2 train loss 2.1155524253845215\n",
      "val loss 2.08845853805542\n",
      "______________\n",
      "epoch 3 train loss 2.0969343185424805\n",
      "val loss 2.0688138008117676\n",
      "______________\n",
      "epoch 4 train loss 2.1010801792144775\n",
      "val loss 2.0501344203948975\n",
      "______________\n",
      "epoch 5 train loss 2.0887258052825928\n",
      "val loss 2.0335781574249268\n",
      "______________\n",
      "epoch 6 train loss 2.0928192138671875\n",
      "val loss 2.018505811691284\n",
      "______________\n",
      "epoch 7 train loss 2.0904297828674316\n",
      "val loss 2.004554033279419\n",
      "______________\n",
      "epoch 8 train loss 2.0770952701568604\n",
      "val loss 1.9915950298309326\n",
      "______________\n",
      "epoch 9 train loss 2.0776736736297607\n",
      "val loss 1.9800138473510742\n",
      "______________\n",
      "epoch 10 train loss 2.0622060298919678\n",
      "val loss 1.9694223403930664\n",
      "______________\n",
      "epoch 11 train loss 2.0624523162841797\n",
      "val loss 1.9600071907043457\n",
      "______________\n",
      "epoch 12 train loss 2.06058406829834\n",
      "val loss 1.9515080451965332\n",
      "______________\n",
      "epoch 13 train loss 2.062081813812256\n",
      "val loss 1.9436956644058228\n",
      "______________\n",
      "epoch 14 train loss 2.0421016216278076\n",
      "val loss 1.936273217201233\n",
      "______________\n",
      "epoch 15 train loss 2.0391571521759033\n",
      "val loss 1.9292995929718018\n",
      "______________\n",
      "epoch 16 train loss 2.035398006439209\n",
      "val loss 1.9225748777389526\n",
      "______________\n",
      "epoch 17 train loss 2.0289926528930664\n",
      "val loss 1.91643488407135\n",
      "______________\n",
      "epoch 18 train loss 2.0259079933166504\n",
      "val loss 1.9105329513549805\n",
      "______________\n",
      "epoch 19 train loss 2.0229105949401855\n",
      "val loss 1.9050852060317993\n",
      "______________\n",
      "epoch 20 train loss 2.0185279846191406\n",
      "val loss 1.9000073671340942\n",
      "______________\n",
      "epoch 21 train loss 2.020263671875\n",
      "val loss 1.8950694799423218\n",
      "______________\n",
      "epoch 22 train loss 2.004483222961426\n",
      "val loss 1.890485405921936\n",
      "______________\n",
      "epoch 23 train loss 2.0117475986480713\n",
      "val loss 1.8858497142791748\n",
      "______________\n",
      "epoch 24 train loss 1.9972190856933594\n",
      "val loss 1.881394386291504\n",
      "______________\n",
      "epoch 25 train loss 1.9874176979064941\n",
      "val loss 1.8770984411239624\n",
      "______________\n",
      "epoch 26 train loss 1.9978914260864258\n",
      "val loss 1.8728482723236084\n",
      "______________\n",
      "epoch 27 train loss 1.978634238243103\n",
      "val loss 1.8683305978775024\n",
      "______________\n",
      "epoch 28 train loss 1.9795842170715332\n",
      "val loss 1.8640949726104736\n",
      "______________\n",
      "epoch 29 train loss 1.9645042419433594\n",
      "val loss 1.8598991632461548\n",
      "______________\n",
      "epoch 30 train loss 1.9749832153320312\n",
      "val loss 1.8559927940368652\n",
      "______________\n",
      "epoch 31 train loss 1.9848387241363525\n",
      "val loss 1.852057695388794\n",
      "______________\n",
      "epoch 32 train loss 1.9615740776062012\n",
      "val loss 1.8478080034255981\n",
      "______________\n",
      "epoch 33 train loss 1.962254285812378\n",
      "val loss 1.8432137966156006\n",
      "______________\n",
      "epoch 34 train loss 1.9629162549972534\n",
      "val loss 1.8384356498718262\n",
      "______________\n",
      "epoch 35 train loss 1.9540810585021973\n",
      "val loss 1.8335318565368652\n",
      "______________\n",
      "epoch 36 train loss 1.9481329917907715\n",
      "val loss 1.828444242477417\n",
      "______________\n",
      "epoch 37 train loss 1.95632004737854\n",
      "val loss 1.822893738746643\n",
      "______________\n",
      "epoch 38 train loss 1.9305773973464966\n",
      "val loss 1.8172938823699951\n",
      "______________\n",
      "epoch 39 train loss 1.9348825216293335\n",
      "val loss 1.8114862442016602\n",
      "______________\n",
      "epoch 40 train loss 1.9328266382217407\n",
      "val loss 1.805629849433899\n",
      "______________\n",
      "epoch 41 train loss 1.9321980476379395\n",
      "val loss 1.7995562553405762\n",
      "______________\n",
      "epoch 42 train loss 1.9219653606414795\n",
      "val loss 1.7934815883636475\n",
      "______________\n",
      "epoch 43 train loss 1.9182637929916382\n",
      "val loss 1.7874774932861328\n",
      "______________\n",
      "epoch 44 train loss 1.9160387516021729\n",
      "val loss 1.7815206050872803\n",
      "______________\n",
      "epoch 45 train loss 1.9108350276947021\n",
      "val loss 1.7756836414337158\n",
      "______________\n",
      "epoch 46 train loss 1.9105031490325928\n",
      "val loss 1.7698745727539062\n",
      "______________\n",
      "epoch 47 train loss 1.916834831237793\n",
      "val loss 1.76407790184021\n",
      "______________\n",
      "epoch 48 train loss 1.9053245782852173\n",
      "val loss 1.758573293685913\n",
      "______________\n",
      "epoch 49 train loss 1.9072742462158203\n",
      "val loss 1.7529151439666748\n",
      "______________\n",
      "epoch 50 train loss 1.8840268850326538\n",
      "val loss 1.7474567890167236\n",
      "______________\n",
      "epoch 51 train loss 1.8918561935424805\n",
      "val loss 1.7420382499694824\n",
      "______________\n",
      "epoch 52 train loss 1.876638650894165\n",
      "val loss 1.736576795578003\n",
      "______________\n",
      "epoch 53 train loss 1.8938837051391602\n",
      "val loss 1.7310112714767456\n",
      "______________\n",
      "epoch 54 train loss 1.8808633089065552\n",
      "val loss 1.7254672050476074\n",
      "______________\n",
      "epoch 55 train loss 1.8653013706207275\n",
      "val loss 1.7199163436889648\n",
      "______________\n",
      "epoch 56 train loss 1.876863956451416\n",
      "val loss 1.7143303155899048\n",
      "______________\n",
      "epoch 57 train loss 1.851638913154602\n",
      "val loss 1.7086108922958374\n",
      "______________\n",
      "epoch 58 train loss 1.8561666011810303\n",
      "val loss 1.7027822732925415\n",
      "______________\n",
      "epoch 59 train loss 1.8606929779052734\n",
      "val loss 1.6969493627548218\n",
      "______________\n",
      "epoch 60 train loss 1.8519625663757324\n",
      "val loss 1.6915665864944458\n",
      "______________\n",
      "epoch 61 train loss 1.843275785446167\n",
      "val loss 1.686375379562378\n",
      "______________\n",
      "epoch 62 train loss 1.8645961284637451\n",
      "val loss 1.6811308860778809\n",
      "______________\n",
      "epoch 63 train loss 1.8263964653015137\n",
      "val loss 1.67604660987854\n",
      "______________\n",
      "epoch 64 train loss 1.8611234426498413\n",
      "val loss 1.671294093132019\n",
      "______________\n",
      "epoch 65 train loss 1.8378419876098633\n",
      "val loss 1.6667946577072144\n",
      "______________\n",
      "epoch 66 train loss 1.8313400745391846\n",
      "val loss 1.6622672080993652\n",
      "______________\n",
      "epoch 67 train loss 1.8244251012802124\n",
      "val loss 1.6577378511428833\n",
      "______________\n",
      "epoch 68 train loss 1.827541708946228\n",
      "val loss 1.6527854204177856\n",
      "______________\n",
      "epoch 69 train loss 1.8274972438812256\n",
      "val loss 1.648069143295288\n",
      "______________\n",
      "epoch 70 train loss 1.8221514225006104\n",
      "val loss 1.643358588218689\n",
      "______________\n",
      "epoch 71 train loss 1.8133107423782349\n",
      "val loss 1.6385376453399658\n",
      "______________\n",
      "epoch 72 train loss 1.8183804750442505\n",
      "val loss 1.6336026191711426\n",
      "______________\n",
      "epoch 73 train loss 1.8085589408874512\n",
      "val loss 1.628525972366333\n",
      "______________\n",
      "epoch 74 train loss 1.803679347038269\n",
      "val loss 1.6231212615966797\n",
      "______________\n",
      "epoch 75 train loss 1.8121027946472168\n",
      "val loss 1.6177362203598022\n",
      "______________\n",
      "epoch 76 train loss 1.7886734008789062\n",
      "val loss 1.6126843690872192\n",
      "______________\n",
      "epoch 77 train loss 1.7845901250839233\n",
      "val loss 1.6080000400543213\n",
      "______________\n",
      "epoch 78 train loss 1.7934319972991943\n",
      "val loss 1.603179931640625\n",
      "______________\n",
      "epoch 79 train loss 1.7821996212005615\n",
      "val loss 1.5982630252838135\n",
      "______________\n",
      "epoch 80 train loss 1.7726771831512451\n",
      "val loss 1.593848466873169\n",
      "______________\n",
      "epoch 81 train loss 1.7827026844024658\n",
      "val loss 1.5892279148101807\n",
      "______________\n",
      "epoch 82 train loss 1.78611421585083\n",
      "val loss 1.584739327430725\n",
      "______________\n",
      "epoch 83 train loss 1.7645103931427002\n",
      "val loss 1.580693244934082\n",
      "______________\n",
      "epoch 84 train loss 1.7602128982543945\n",
      "val loss 1.576319932937622\n",
      "______________\n",
      "epoch 85 train loss 1.7883985042572021\n",
      "val loss 1.5720493793487549\n",
      "______________\n",
      "epoch 86 train loss 1.7583389282226562\n",
      "val loss 1.5682193040847778\n",
      "______________\n",
      "epoch 87 train loss 1.7730255126953125\n",
      "val loss 1.5645475387573242\n",
      "______________\n",
      "epoch 88 train loss 1.754237413406372\n",
      "val loss 1.560874581336975\n",
      "______________\n",
      "epoch 89 train loss 1.7471227645874023\n",
      "val loss 1.557506799697876\n",
      "______________\n",
      "epoch 90 train loss 1.7608284950256348\n",
      "val loss 1.5544383525848389\n",
      "______________\n",
      "epoch 91 train loss 1.7613106966018677\n",
      "val loss 1.551285743713379\n",
      "______________\n",
      "epoch 92 train loss 1.7451839447021484\n",
      "val loss 1.5480866432189941\n",
      "______________\n",
      "epoch 93 train loss 1.745863437652588\n",
      "val loss 1.5448336601257324\n",
      "______________\n",
      "epoch 94 train loss 1.729585886001587\n",
      "val loss 1.5418269634246826\n",
      "______________\n",
      "epoch 95 train loss 1.7438632249832153\n",
      "val loss 1.5392788648605347\n",
      "______________\n",
      "epoch 96 train loss 1.7575860023498535\n",
      "val loss 1.5365867614746094\n",
      "______________\n",
      "epoch 97 train loss 1.7334303855895996\n",
      "val loss 1.5339363813400269\n",
      "______________\n",
      "epoch 98 train loss 1.7292956113815308\n",
      "val loss 1.5312572717666626\n",
      "______________\n",
      "epoch 99 train loss 1.7127087116241455\n",
      "val loss 1.5287790298461914\n",
      "______________\n",
      "epoch 100 train loss 1.721086859703064\n",
      "val loss 1.5262938737869263\n",
      "______________\n",
      "epoch 101 train loss 1.7157783508300781\n",
      "val loss 1.523697018623352\n",
      "______________\n",
      "epoch 102 train loss 1.7229528427124023\n",
      "val loss 1.521213173866272\n",
      "______________\n",
      "epoch 103 train loss 1.7364674806594849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss 1.5188090801239014\n",
      "______________\n",
      "epoch 104 train loss 1.7023874521255493\n",
      "val loss 1.5162739753723145\n",
      "______________\n",
      "epoch 105 train loss 1.7149555683135986\n",
      "val loss 1.5139126777648926\n",
      "______________\n",
      "epoch 106 train loss 1.7155201435089111\n",
      "val loss 1.5123188495635986\n",
      "______________\n",
      "epoch 107 train loss 1.7003014087677002\n",
      "val loss 1.5108778476715088\n",
      "______________\n",
      "epoch 108 train loss 1.6958699226379395\n",
      "val loss 1.509464979171753\n",
      "______________\n",
      "epoch 109 train loss 1.7166173458099365\n",
      "val loss 1.5081900358200073\n",
      "______________\n",
      "epoch 110 train loss 1.700044870376587\n",
      "val loss 1.5071276426315308\n",
      "______________\n",
      "epoch 111 train loss 1.6867841482162476\n",
      "val loss 1.5060707330703735\n",
      "______________\n",
      "epoch 112 train loss 1.6948527097702026\n",
      "val loss 1.5049229860305786\n",
      "______________\n",
      "epoch 113 train loss 1.6787575483322144\n",
      "val loss 1.5035303831100464\n",
      "______________\n",
      "epoch 114 train loss 1.6999809741973877\n",
      "val loss 1.5020933151245117\n",
      "______________\n",
      "epoch 115 train loss 1.6964943408966064\n",
      "val loss 1.5008368492126465\n",
      "______________\n",
      "epoch 116 train loss 1.6614742279052734\n",
      "val loss 1.4994810819625854\n",
      "______________\n",
      "epoch 117 train loss 1.685312271118164\n",
      "val loss 1.4981791973114014\n",
      "______________\n",
      "epoch 118 train loss 1.6800849437713623\n",
      "val loss 1.4972167015075684\n",
      "______________\n",
      "epoch 119 train loss 1.6644527912139893\n",
      "val loss 1.4961564540863037\n",
      "______________\n",
      "epoch 120 train loss 1.6617478132247925\n",
      "val loss 1.4944480657577515\n",
      "______________\n",
      "epoch 121 train loss 1.6698760986328125\n",
      "val loss 1.4923880100250244\n",
      "______________\n",
      "epoch 122 train loss 1.680567741394043\n",
      "val loss 1.4903438091278076\n",
      "______________\n",
      "epoch 123 train loss 1.6610276699066162\n",
      "val loss 1.488010048866272\n",
      "______________\n",
      "epoch 124 train loss 1.6761999130249023\n",
      "val loss 1.4856278896331787\n",
      "______________\n",
      "epoch 125 train loss 1.676186203956604\n",
      "val loss 1.4836969375610352\n",
      "______________\n",
      "epoch 126 train loss 1.658388614654541\n",
      "val loss 1.481945276260376\n",
      "______________\n",
      "epoch 127 train loss 1.6548762321472168\n",
      "val loss 1.4801995754241943\n",
      "______________\n",
      "epoch 128 train loss 1.6550533771514893\n",
      "val loss 1.4784188270568848\n",
      "______________\n",
      "epoch 129 train loss 1.6620779037475586\n",
      "val loss 1.47664213180542\n",
      "______________\n",
      "epoch 130 train loss 1.6334534883499146\n",
      "val loss 1.4744420051574707\n",
      "______________\n",
      "epoch 131 train loss 1.6527831554412842\n",
      "val loss 1.4723581075668335\n",
      "______________\n",
      "epoch 132 train loss 1.6702947616577148\n",
      "val loss 1.470307469367981\n",
      "______________\n",
      "epoch 133 train loss 1.652989387512207\n",
      "val loss 1.4681856632232666\n",
      "______________\n",
      "epoch 134 train loss 1.6254944801330566\n",
      "val loss 1.4662450551986694\n",
      "______________\n",
      "epoch 135 train loss 1.634058952331543\n",
      "val loss 1.464341163635254\n",
      "______________\n",
      "epoch 136 train loss 1.6695799827575684\n",
      "val loss 1.4623059034347534\n",
      "______________\n",
      "epoch 137 train loss 1.6504008769989014\n",
      "val loss 1.4604990482330322\n",
      "______________\n",
      "epoch 138 train loss 1.629473090171814\n",
      "val loss 1.4586378335952759\n",
      "______________\n",
      "epoch 139 train loss 1.6418910026550293\n",
      "val loss 1.4573299884796143\n",
      "______________\n",
      "epoch 140 train loss 1.6424473524093628\n",
      "val loss 1.4558724164962769\n",
      "______________\n",
      "epoch 141 train loss 1.6459054946899414\n",
      "val loss 1.4547998905181885\n",
      "______________\n",
      "epoch 142 train loss 1.623083472251892\n",
      "val loss 1.4536919593811035\n",
      "______________\n",
      "epoch 143 train loss 1.6292498111724854\n",
      "val loss 1.4528260231018066\n",
      "______________\n",
      "epoch 144 train loss 1.630103588104248\n",
      "val loss 1.4526245594024658\n",
      "______________\n",
      "epoch 145 train loss 1.632576584815979\n",
      "val loss 1.4523471593856812\n",
      "______________\n",
      "epoch 146 train loss 1.6236958503723145\n",
      "val loss 1.451911211013794\n",
      "______________\n",
      "epoch 147 train loss 1.6195557117462158\n",
      "val loss 1.4515196084976196\n",
      "______________\n",
      "epoch 148 train loss 1.6049565076828003\n",
      "val loss 1.4509565830230713\n",
      "______________\n",
      "epoch 149 train loss 1.625411033630371\n",
      "val loss 1.4503283500671387\n",
      "______________\n",
      "epoch 150 train loss 1.6261818408966064\n",
      "val loss 1.4495482444763184\n",
      "______________\n",
      "epoch 151 train loss 1.6242265701293945\n",
      "val loss 1.4482786655426025\n",
      "______________\n",
      "epoch 152 train loss 1.6093332767486572\n",
      "val loss 1.4468839168548584\n",
      "______________\n",
      "epoch 153 train loss 1.608424425125122\n",
      "val loss 1.4456262588500977\n",
      "______________\n",
      "epoch 154 train loss 1.6075111627578735\n",
      "val loss 1.4443670511245728\n",
      "______________\n",
      "epoch 155 train loss 1.5925047397613525\n",
      "val loss 1.4431021213531494\n",
      "______________\n",
      "epoch 156 train loss 1.6072115898132324\n",
      "val loss 1.442103624343872\n",
      "______________\n",
      "epoch 157 train loss 1.6149940490722656\n",
      "val loss 1.4412614107131958\n",
      "______________\n",
      "epoch 158 train loss 1.5900229215621948\n",
      "val loss 1.4406168460845947\n",
      "______________\n",
      "epoch 159 train loss 1.5752439498901367\n",
      "val loss 1.4401204586029053\n",
      "______________\n",
      "epoch 160 train loss 1.6049275398254395\n",
      "val loss 1.4398902654647827\n",
      "______________\n",
      "epoch 161 train loss 1.5901854038238525\n",
      "val loss 1.439521074295044\n",
      "______________\n",
      "epoch 162 train loss 1.5831708908081055\n",
      "val loss 1.4390591382980347\n",
      "______________\n",
      "epoch 163 train loss 1.6071008443832397\n",
      "val loss 1.438358187675476\n",
      "______________\n",
      "epoch 164 train loss 1.608794927597046\n",
      "val loss 1.4375282526016235\n",
      "______________\n",
      "epoch 165 train loss 1.5726330280303955\n",
      "val loss 1.4369776248931885\n",
      "______________\n",
      "epoch 166 train loss 1.5846716165542603\n",
      "val loss 1.4363477230072021\n",
      "______________\n",
      "epoch 167 train loss 1.6068400144577026\n",
      "val loss 1.4362801313400269\n",
      "______________\n",
      "epoch 168 train loss 1.597475290298462\n",
      "val loss 1.4362372159957886\n",
      "______________\n",
      "epoch 169 train loss 1.6129581928253174\n",
      "val loss 1.4363317489624023\n",
      "______________\n",
      "epoch 170 train loss 1.5892213582992554\n",
      "val loss 1.4361628293991089\n",
      "______________\n",
      "epoch 171 train loss 1.6000722646713257\n",
      "val loss 1.4360435009002686\n",
      "______________\n",
      "epoch 172 train loss 1.5589203834533691\n",
      "val loss 1.4358561038970947\n",
      "______________\n",
      "epoch 173 train loss 1.5775146484375\n",
      "val loss 1.4354705810546875\n",
      "______________\n",
      "epoch 174 train loss 1.594416856765747\n",
      "val loss 1.4350788593292236\n",
      "______________\n",
      "epoch 175 train loss 1.578444480895996\n",
      "val loss 1.4346994161605835\n",
      "______________\n",
      "epoch 176 train loss 1.5854038000106812\n",
      "val loss 1.4342738389968872\n",
      "______________\n",
      "epoch 177 train loss 1.559763789176941\n",
      "val loss 1.433909296989441\n",
      "______________\n",
      "epoch 178 train loss 1.5804805755615234\n",
      "val loss 1.433247447013855\n",
      "______________\n",
      "epoch 179 train loss 1.590681552886963\n",
      "val loss 1.432673454284668\n",
      "______________\n",
      "epoch 180 train loss 1.56941819190979\n",
      "val loss 1.4323036670684814\n",
      "______________\n",
      "epoch 181 train loss 1.5438692569732666\n",
      "val loss 1.432131052017212\n",
      "______________\n",
      "epoch 182 train loss 1.5624973773956299\n",
      "val loss 1.4323123693466187\n",
      "______________\n",
      "epoch 183 train loss 1.5646721124649048\n",
      "val loss 1.4325876235961914\n",
      "______________\n",
      "epoch 184 train loss 1.5570507049560547\n",
      "val loss 1.4329622983932495\n",
      "______________\n",
      "epoch 185 train loss 1.576075792312622\n",
      "val loss 1.433046817779541\n",
      "______________\n",
      "epoch 186 train loss 1.5441814661026\n",
      "val loss 1.4330370426177979\n",
      "______________\n",
      "epoch 187 train loss 1.5719316005706787\n",
      "val loss 1.4330297708511353\n",
      "______________\n",
      "epoch 188 train loss 1.5834978818893433\n",
      "val loss 1.4330852031707764\n",
      "______________\n",
      "epoch 189 train loss 1.539700984954834\n",
      "val loss 1.433118224143982\n",
      "______________\n",
      "epoch 190 train loss 1.5662815570831299\n",
      "val loss 1.4328831434249878\n",
      "______________\n",
      "epoch 191 train loss 1.5588657855987549\n",
      "val loss 1.4325567483901978\n",
      "______________\n",
      "epoch 192 train loss 1.5449869632720947\n",
      "val loss 1.4322237968444824\n",
      "______________\n",
      "best loss 1.432131052017212 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14272387, 'auc': 0.5360576923076923}, 'FT': {'accuracy': -1, 'mse': 0.1773095, 'auc': 0.6685855263157895}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13767363, 'auc': 0.7836538461538463}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EndpointSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=70, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (outcome_layer): Linear(in_features=500, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3_args = {'hidden_layers': [500, 500], 'dropout': 0.9, 'input_dropout': 0.5}\n",
    "model3,_,_ = train_state(model_args=t3_args,state=3,use_attention=False)\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0a9536fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.764965534210205 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6839781628293378, 'roc_macro': 0.6330226813097114}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9510489510489512, 0.9313131313131313, 0.9527363184079602, -1, 0.9092198581560285, -1, 0.9333333333333333, -1], 'auc_mean': 0.20970644903242558}}\n",
      "done 0 2.764965534210205\n",
      "_++++++++++New Best++++____\n",
      "2.764965534210205\n",
      "{'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6839781628293378, 'roc_macro': 0.6330226813097114}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6238666993383974, 'roc_macro': 0.6753406617537051}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9510489510489512, 0.9313131313131313, 0.9527363184079602, -1, 0.9092198581560285, -1, 0.9333333333333333, -1], 'auc_mean': 0.20970644903242558}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 4.025295257568359 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6755281272252552, 'roc_macro': 0.6340827355168788}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5679000245037981, 'roc_macro': 0.559701470027557}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5679000245037981, 'roc_macro': 0.559701470027557}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.766899766899767, 0.8424242424242425, 0.7170398009950248, -1, 0.75177304964539, -1, 0.8880952380952382, -1], 'auc_mean': 0.12077901225745781}}\n",
      "done 1 4.025295257568359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.001817226409912 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6632328507002136, 'roc_macro': 0.5835680340959767}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6071551090419015, 'roc_macro': 0.6562513573383139}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6071551090419015, 'roc_macro': 0.6562513573383139}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9696969696969696, 0.8915824915824916, 0.9427860696517413, -1, 0.9163120567375886, -1, 0.7916666666666667, -1], 'auc_mean': 0.18900553179193225}}\n",
      "done 2 3.001817226409912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.5316758155822754 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6843104676002848, 'roc_macro': 0.6333873764750005}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9582491582491582, 0.9191542288557214, -1, 0.9546099290780142, -1, 0.9392857142857143, -1], 'auc_mean': 0.20538673778293498}}\n",
      "done 3 2.5316758155822754\n",
      "_++++++++++New Best++++____\n",
      "2.5316758155822754\n",
      "{'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6843104676002848, 'roc_macro': 0.6333873764750005}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6154864003920608, 'roc_macro': 0.6619253331209852}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9582491582491582, 0.9191542288557214, -1, 0.9546099290780142, -1, 0.9392857142857143, -1], 'auc_mean': 0.20538673778293498}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.395699977874756 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6678851174934726, 'roc_macro': 0.5876957699624655}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6026954177897574, 'roc_macro': 0.638124254972081}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6026954177897574, 'roc_macro': 0.638124254972081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.7226107226107225, 0.8249158249158249, 0.8575870646766169, -1, 0.9304964539007092, -1, 0.9333333333333333, -1], 'auc_mean': 0.15861792492965085}}\n",
      "done 4 3.395699977874756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.398782730102539 {'pd': {'accuracy': 0.4304388422035481, 'roc_micro': 0.6791834797056728, 'roc_macro': 0.6171084583982819}, 'nd': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'mod': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9207459207459208, 0.901010101010101, 0.9079601990049752, -1, 0.9361702127659575, -1, 0.7976190476190477, -1], 'auc_mean': 0.18293818514325025}}\n",
      "done 5 2.398782730102539\n",
      "_++++++++++New Best++++____\n",
      "2.398782730102539\n",
      "{'pd': {'accuracy': 0.4304388422035481, 'roc_micro': 0.6791834797056728, 'roc_macro': 0.6171084583982819}, 'nd': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'mod': {'accuracy': 0.47556184189847556, 'roc_micro': 0.6729233031119823, 'roc_macro': 0.6738382390556303}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9207459207459208, 0.901010101010101, 0.9079601990049752, -1, 0.9361702127659575, -1, 0.7976190476190477, -1], 'auc_mean': 0.18293818514325025}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.251129150390625 {'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "done 6 2.251129150390625\n",
      "_++++++++++New Best++++____\n",
      "2.251129150390625\n",
      "{'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.520254611968994 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.68112983622122, 'roc_macro': 0.6464487590447383}, 'nd': {'accuracy': 0.4504164702184504, 'roc_micro': 0.6337172261700563, 'roc_macro': 0.6634349949567341}, 'mod': {'accuracy': 0.4504164702184504, 'roc_micro': 0.6337172261700563, 'roc_macro': 0.6634349949567341}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8764568764568764, 0.9481481481481482, 0.9253731343283582, -1, 0.9276595744680851, -1, 0.9369047619047619, -1], 'auc_mean': 0.20181781191327874}}\n",
      "done 7 2.520254611968994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.279262065887451 {'pd': {'accuracy': 0.4637021475256769, 'roc_micro': 0.6813197246617612, 'roc_macro': 0.5885267481288077}, 'nd': {'accuracy': 0.49607103567499605, 'roc_micro': 0.6965449644694928, 'roc_macro': 0.6838083414170372}, 'mod': {'accuracy': 0.49607103567499605, 'roc_micro': 0.6965449644694928, 'roc_macro': 0.6838083414170372}, 'dlts': {'accuracy': [0.9794520547945206, 0.9315068493150684, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9691780821917808, 'auc': [0.9090909090909091, 0.9144781144781146, 0.9104477611940298, -1, 0.9304964539007092, -1, 0.8178571428571428, -1], 'auc_mean': 0.1852962976901132}}\n",
      "done 8 2.279262065887451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.997028350830078 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6793733681462141, 'roc_macro': 0.6386482250527823}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6114677775055133, 'roc_macro': 0.6717222994396908}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6114677775055133, 'roc_macro': 0.6717222994396908}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9533799533799533, 0.9750841750841751, 0.9216417910447761, -1, 0.9049645390070922, -1, 0.8928571428571429, -1], 'auc_mean': 0.20599095017164243}}\n",
      "done 9 2.997028350830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.8466691970825195 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.681604557322573, 'roc_macro': 0.594717942463165}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5880421465327126, 'roc_macro': 0.6352678118982467}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5880421465327126, 'roc_macro': 0.6352678118982467}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8228438228438228, 0.8471380471380472, 0.8550995024875622, -1, 0.8028368794326242, -1, 0.8857142857142857, -1], 'auc_mean': 0.15170406720204277}}\n",
      "done 10 3.8466691970825195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.0380520820617676 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6543080939947781, 'roc_macro': 0.5598462107334532}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6016662582700318, 'roc_macro': 0.6464426274208882}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6016662582700318, 'roc_macro': 0.6464426274208882}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9347319347319346, 0.898989898989899, 0.9378109452736317, -1, 0.9078014184397163, -1, 0.7642857142857142, -1], 'auc_mean': 0.18045248896511196}}\n",
      "done 11 3.0380520820617676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.413274049758911 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6775694279610729, 'roc_macro': 0.6172972181937416}, 'nd': {'accuracy': 0.4266069464089266, 'roc_micro': 0.6321489830923793, 'roc_macro': 0.6658383886644756}, 'mod': {'accuracy': 0.4266069464089266, 'roc_micro': 0.6321489830923793, 'roc_macro': 0.6658383886644756}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079254, 0.9723905723905725, 0.9446517412935324, -1, 0.8921985815602836, -1, 0.9166666666666666, -1], 'auc_mean': 0.20641443591487255}}\n",
      "done 12 2.413274049758911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.300992012023926 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6804177545691906, 'roc_macro': 0.6252601804380816}, 'nd': {'accuracy': 0.4596888260254597, 'roc_micro': 0.6478804214653271, 'roc_macro': 0.6664790523486176}, 'mod': {'accuracy': 0.4596888260254597, 'roc_micro': 0.6478804214653271, 'roc_macro': 0.6664790523486176}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909092, 0.977104377104377, 0.9458955223880597, -1, 0.9177304964539007, -1, 0.8928571428571429, -1], 'auc_mean': 0.2053348059867987}}\n",
      "done 13 2.300992012023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3748905658721924 {'pd': {'accuracy': 0.4165499533146592, 'roc_micro': 0.6802753382387846, 'roc_macro': 0.5898411170141197}, 'nd': {'accuracy': 0.5026716957410027, 'roc_micro': 0.6737074246508209, 'roc_macro': 0.6798814108596717}, 'mod': {'accuracy': 0.5026716957410027, 'roc_micro': 0.6737074246508209, 'roc_macro': 0.6798814108596717}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079254, 0.9232323232323232, 0.8961442786069652, -1, 0.9446808510638298, -1, 0.7869047619047619, -1], 'auc_mean': 0.18454626752697567}}\n",
      "done 14 2.3748905658721924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3364131450653076 {'pd': {'accuracy': 0.3776844070961718, 'roc_micro': 0.6820792784239259, 'roc_macro': 0.6339983152842792}, 'nd': {'accuracy': 0.4676253339619676, 'roc_micro': 0.657730948296986, 'roc_macro': 0.6735513882253011}, 'mod': {'accuracy': 0.4676253339619676, 'roc_micro': 0.657730948296986, 'roc_macro': 0.6735513882253011}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9254079254079255, 0.9622895622895623, 0.9440298507462687, -1, 0.9177304964539007, -1, 0.9023809523809523, -1], 'auc_mean': 0.2064798484098262}}\n",
      "done 15 2.3364131450653076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.2603046894073486 {'pd': {'accuracy': 0.35830999066293184, 'roc_micro': 0.6845478281509614, 'roc_macro': 0.6269651718063419}, 'nd': {'accuracy': 0.48349834983498347, 'roc_micro': 0.6686596422445479, 'roc_macro': 0.6666898922333705}, 'mod': {'accuracy': 0.48349834983498347, 'roc_micro': 0.6686596422445479, 'roc_macro': 0.6666898922333705}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8787878787878788, 0.9696969696969696, 0.9452736318407959, -1, 0.902127659574468, -1, 0.9083333333333334, -1], 'auc_mean': 0.20052743415418073}}\n",
      "done 16 2.2603046894073486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.298572063446045 {'pd': {'accuracy': 0.5053688141923436, 'roc_micro': 0.6820318063137907, 'roc_macro': 0.5856912400747091}, 'nd': {'accuracy': 0.5278170674210277, 'roc_micro': 0.7020828228375398, 'roc_macro': 0.6787409450452929}, 'mod': {'accuracy': 0.5278170674210277, 'roc_micro': 0.7020828228375398, 'roc_macro': 0.6787409450452929}, 'dlts': {'accuracy': [0.9794520547945206, 0.9315068493150684, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9700342465753424, 'auc': [0.8648018648018648, 0.9124579124579125, 0.907960199004975, -1, 0.9319148936170213, -1, 0.8190476190476191, -1], 'auc_mean': 0.1795228111161741}}\n",
      "done 17 2.298572063446045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.4547085762023926 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6776643721813435, 'roc_macro': 0.6204213177441975}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.601568243077677, 'roc_macro': 0.6528773159207941}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.601568243077677, 'roc_macro': 0.6528773159207941}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8811188811188811, 0.9441077441077441, 0.9322139303482587, -1, 0.9148936170212766, -1, 0.9130952380952381, -1], 'auc_mean': 0.19817867633642486}}\n",
      "done 18 3.4547085762023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.4677934646606445 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6800854497982436, 'roc_macro': 0.6314613501574468}, 'nd': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6250918892428327, 'roc_macro': 0.658987148117583}, 'mod': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6250918892428327, 'roc_macro': 0.658987148117583}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8951048951048951, 0.9575757575757575, 0.9247512437810945, -1, 0.9375886524822695, -1, 0.930952380952381, -1], 'auc_mean': 0.2057466162370497}}\n",
      "done 19 2.4677934646606445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6515095233917236 {'pd': {'accuracy': 0.3277310924369748, 'roc_micro': 0.6747211013529552, 'roc_macro': 0.6275076423156724}, 'nd': {'accuracy': 0.3631148829168631, 'roc_micro': 0.6184268561627052, 'roc_macro': 0.6478768815725338}, 'mod': {'accuracy': 0.3631148829168631, 'roc_micro': 0.6184268561627052, 'roc_macro': 0.6478768815725338}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8671328671328671, 0.931986531986532, 0.9353233830845771, -1, 0.9234042553191489, -1, 0.9416666666666668, -1], 'auc_mean': 0.19993921302372397}}\n",
      "done 20 2.6515095233917236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.5779154300689697 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6768098741989081, 'roc_macro': 0.6113316490128552}, 'nd': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6195050232786081, 'roc_macro': 0.656675450153711}, 'mod': {'accuracy': 0.3412698412698412, 'roc_micro': 0.6195050232786081, 'roc_macro': 0.656675450153711}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8601398601398601, 0.9292929292929293, 0.9253731343283582, -1, 0.9560283687943262, -1, 0.9476190476190477, -1], 'auc_mean': 0.2023066675218152}}\n",
      "done 21 2.5779154300689697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.593141794204712 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.676619985758367, 'roc_macro': 0.6053695307193232}, 'nd': {'accuracy': 0.3426056891403426, 'roc_micro': 0.6117618230825779, 'roc_macro': 0.6490095049877659}, 'mod': {'accuracy': 0.3426056891403426, 'roc_micro': 0.6117618230825779, 'roc_macro': 0.6490095049877659}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8717948717948718, 0.9791245791245792, 0.9409203980099502, -1, 0.9460992907801419, -1, 0.9214285714285715, -1], 'auc_mean': 0.20742096389226428}}\n",
      "done 22 2.593141794204712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.356215476989746 {'pd': {'accuracy': 0.4830765639589169, 'roc_micro': 0.6858295751246143, 'roc_macro': 0.6286025078168812}, 'nd': {'accuracy': 0.5119440515480119, 'roc_micro': 0.7045822102425876, 'roc_macro': 0.6924503636460159}, 'mod': {'accuracy': 0.5119440515480119, 'roc_micro': 0.7045822102425876, 'roc_macro': 0.6924503636460159}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8974358974358974, 0.9595959595959596, 0.9291044776119403, -1, 0.9333333333333333, -1, 0.8904761904761904, -1], 'auc_mean': 0.2012432323066651}}\n",
      "done 23 2.356215476989746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.9129796028137207 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6745786850225493, 'roc_macro': 0.607016177388629}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6130360205831904, 'roc_macro': 0.6548680787811222}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6130360205831904, 'roc_macro': 0.6548680787811222}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8974358974358975, 0.936026936026936, 0.9235074626865672, -1, 0.9163120567375886, -1, 0.9107142857142857, -1], 'auc_mean': 0.19799957982515937}}\n",
      "done 24 2.9129796028137207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.988474130630493 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6667932589603608, 'roc_macro': 0.5469005279579185}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5748100955648126, 'roc_macro': 0.5464107148889757}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.5748100955648126, 'roc_macro': 0.5464107148889757}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.45687645687645684, 0.6249158249158249, 0.6921641791044777, -1, 0.7943262411347518, -1, 0.8166666666666668, -1], 'auc_mean': 0.04811867108727223}}\n",
      "done 25 3.988474130630493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6778604984283447 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6774270116306671, 'roc_macro': 0.6261786719100272}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6202401372212692, 'roc_macro': 0.6533659577137838}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6202401372212692, 'roc_macro': 0.6533659577137838}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8741258741258741, 0.9616161616161616, 0.9378109452736318, -1, 0.9163120567375886, -1, 0.9178571428571428, -1], 'auc_mean': 0.20096527257629987}}\n",
      "done 26 2.6778604984283447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.6250922679901123 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.673249465938761, 'roc_macro': 0.6176413083426929}, 'nd': {'accuracy': 0.3855885588558856, 'roc_micro': 0.6152903700073511, 'roc_macro': 0.6553892966936444}, 'mod': {'accuracy': 0.3855885588558856, 'roc_micro': 0.6152903700073511, 'roc_macro': 0.6553892966936444}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8927738927738927, 0.9542087542087542, 0.9539800995024875, -1, 0.899290780141844, -1, 0.9273809523809523, -1], 'auc_mean': 0.20345430987599133}}\n",
      "done 27 2.6250922679901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.7161152362823486 {'pd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6835509138381202, 'roc_macro': 0.6361547246381728}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6163195295270767, 'roc_macro': 0.6741712393886307}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.6163195295270767, 'roc_macro': 0.6741712393886307}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9137529137529138, 0.9683501683501683, 0.9359452736318408, -1, 0.9304964539007092, -1, 0.9011904761904762, -1], 'auc_mean': 0.20621691072826354}}\n",
      "done 28 2.7161152362823486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.3858258724212646 {'pd': {'accuracy': 0.4969654528478058, 'roc_micro': 0.6851174934725849, 'roc_macro': 0.6237181607808212}, 'nd': {'accuracy': 0.5198805594845198, 'roc_micro': 0.7011026709139917, 'roc_macro': 0.6828778105952019}, 'mod': {'accuracy': 0.5198805594845198, 'roc_micro': 0.7011026709139917, 'roc_macro': 0.6828778105952019}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.8951048951048951, 0.9555555555555556, 0.9253731343283582, -1, 0.9432624113475176, -1, 0.8952380952380953, -1], 'auc_mean': 0.20181676144680272}}\n",
      "done 29 2.3858258724212646\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 2.251129150390625\n",
      "{'pd': {'accuracy': 0.375, 'roc_micro': 0.6783764538333729, 'roc_macro': 0.6248571736860679}, 'nd': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'mod': {'accuracy': 0.4801980198019802, 'roc_micro': 0.6757167360940945, 'roc_macro': 0.6780191426930556}, 'dlts': {'accuracy': [0.9794520547945206, 0.9246575342465754, 0.9178082191780822, 1.0, 0.9657534246575342, 1.0, 0.958904109589041, 1.0], 'accuracy_mean': 0.9683219178082192, 'auc': [0.9090909090909091, 0.962962962962963, 0.9353233830845771, -1, 0.9120567375886525, -1, 0.925, -1], 'auc_mean': 0.2055542490908877}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutcomeAttentionSimulator(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=1000, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (resize_layer): Linear(in_features=63, out_features=100, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (nodal_disease_layer): Linear(in_features=1000, out_features=3, bias=True)\n",
       "  (dlt_layers): ModuleList(\n",
       "    (0): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (3): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (4): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (5): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (6): Linear(in_features=1000, out_features=1, bias=True)\n",
       "    (7): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  )\n",
       "  (treatment_layer): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gridsearch_attention_transition_models(state=1,attentions=[True,False]):\n",
    "    model_arglist = [\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [10,10],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [500,500],\n",
    "            'attention_heads': [5,5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for use_attention in attentions:\n",
    "            embed_sizes = [200,400] if use_attention else [0]\n",
    "            for embed_size in embed_sizes:\n",
    "                args['embed_size'] = embed_size\n",
    "                for dropout in [.9,]:\n",
    "                    args['dropout'] = dropout\n",
    "                    for input_dropout in [.5]:\n",
    "                        args['input_dropout'] = input_dropout\n",
    "                    \n",
    "                        model,m_loss,m_metrics = train_state(model_args=args,state=state,use_attention=use_attention,verbose=False)\n",
    "                        print('done',k,m_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print(use_attention)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "# model1 = gridsearch_attention_transition_models(1)\n",
    "# model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "27cdf2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.808809757232666 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9072182055232902, 'roc_macro': -1}, 'nd': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'mod': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2564102564102564, 0.5926616915422885, 0.60431654676259, -1, 0.5035460992907801, -1, 0.5943262411347519, -1], 'auc_mean': -0.05609239560741665}}\n",
      "done 0 3.808809757232666\n",
      "_++++++++++New Best++++____\n",
      "3.808809757232666\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9072182055232902, 'roc_macro': -1}, 'nd': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'mod': {'accuracy': 0.350210970464135, 'roc_micro': 0.7220952335121871, 'roc_macro': 0.47419713120932633}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2564102564102564, 0.5926616915422885, 0.60431654676259, -1, 0.5035460992907801, -1, 0.5943262411347519, -1], 'auc_mean': -0.05609239560741665}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.824561595916748 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9132867132867133, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7394432280262747, 'roc_macro': 0.6098472283685697}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7394432280262747, 'roc_macro': 0.6098472283685697}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.20046620046620045, 0.6057213930348259, 0.48612538540596095, -1, 0.46808510638297873, -1, 0.37163120567375885, -1], 'auc_mean': -0.10849633862953441}}\n",
      "done 1 3.824561595916748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8581931591033936 {'pd': {'accuracy': 0.5, 'roc_micro': 0.934313144482636, 'roc_macro': -1}, 'nd': {'accuracy': 0.3314873417721519, 'roc_micro': 0.7344625971463632, 'roc_macro': 0.5642928287745361}, 'mod': {'accuracy': 0.3314873417721519, 'roc_micro': 0.7344625971463632, 'roc_macro': 0.5642928287745361}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3333333333333333, 0.5174129353233832, 0.6145940390544706, -1, 0.4907801418439717, -1, 0.49503546099290785, -1], 'auc_mean': -0.06860551118149166}}\n",
      "done 2 3.8581931591033936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8618290424346924 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9207775275571886, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7238035658429778, 'roc_macro': 0.5260440382391601}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7238035658429778, 'roc_macro': 0.5260440382391601}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5151515151515151, 0.6822139303482586, 0.5642343268242549, -1, 0.4581560283687944, -1, 0.5829787234042554, -1], 'auc_mean': -0.024658184487865192}}\n",
      "done 3 3.8618290424346924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.7894489765167236 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9281972265023112, 'roc_macro': -1}, 'nd': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'mod': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.543123543123543, 0.4527363184079602, 0.4049331963001027, -1, 0.45390070921985815, -1, 0.33333333333333326, -1], 'auc_mean': -0.10149661245190032}}\n",
      "done 4 3.7894489765167236\n",
      "_++++++++++New Best++++____\n",
      "3.7894489765167236\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9281972265023112, 'roc_macro': -1}, 'nd': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'mod': {'accuracy': 0.36201213080168776, 'roc_micro': 0.7443516758499554, 'roc_macro': 0.5518793007360081}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.543123543123543, 0.4527363184079602, 0.4049331963001027, -1, 0.45390070921985815, -1, 0.33333333333333326, -1], 'auc_mean': -0.10149661245190032}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6160809993743896 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9404053573545099, 'roc_macro': -1}, 'nd': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'mod': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3356643356643356, 0.5522388059701493, 0.5878725590955807, -1, 0.6524822695035462, -1, 0.5049645390070923, -1], 'auc_mean': -0.045847186344912}}\n",
      "done 5 3.6160809993743896\n",
      "_++++++++++New Best++++____\n",
      "3.6160809993743896\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9404053573545099, 'roc_macro': -1}, 'nd': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'mod': {'accuracy': 0.34335443037974683, 'roc_micro': 0.7375183465267919, 'roc_macro': 0.5833610545881888}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3356643356643356, 0.5522388059701493, 0.5878725590955807, -1, 0.6524822695035462, -1, 0.5049645390070923, -1], 'auc_mean': -0.045847186344912}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.81306529045105 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9322745051558612, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7073698900411444, 'roc_macro': 0.5147629160586478}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7073698900411444, 'roc_macro': 0.5147629160586478}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.599067599067599, 0.6411691542288558, 0.763617677286742, -1, 0.4836879432624114, -1, 0.15886524822695036, -1], 'auc_mean': -0.044199047240930184}}\n",
      "done 6 3.81306529045105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8622279167175293 {'pd': {'accuracy': 0.5, 'roc_micro': 0.8979732132274505, 'roc_macro': -1}, 'nd': {'accuracy': 0.33419040084388185, 'roc_micro': 0.7286879526479151, 'roc_macro': 0.5092026416340439}, 'mod': {'accuracy': 0.33419040084388185, 'roc_micro': 0.7286879526479151, 'roc_macro': 0.5092026416340439}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7692307692307692, 0.5062189054726368, 0.5817060637204522, -1, 0.5163120567375886, -1, 0.5531914893617021, -1], 'auc_mean': -0.009167589434606369}}\n",
      "done 7 3.8622279167175293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6245648860931396 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9408320493066256, 'roc_macro': -1}, 'nd': {'accuracy': 0.31955432489451474, 'roc_micro': 0.7354972209523352, 'roc_macro': 0.5626309446812496}, 'mod': {'accuracy': 0.31955432489451474, 'roc_micro': 0.7354972209523352, 'roc_macro': 0.5626309446812496}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2913752913752914, 0.5453980099502488, 0.5971223021582733, -1, 0.6425531914893617, -1, 0.526241134751773, -1], 'auc_mean': -0.049663758784381465}}\n",
      "done 8 3.6245648860931396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.7966322898864746 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9020030816640987, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7119655446211592, 'roc_macro': 0.5892248169306097}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7119655446211592, 'roc_macro': 0.5892248169306097}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.62004662004662, 0.47325870646766177, 0.2744090441932169, -1, 0.49503546099290785, -1, 0.3929078014184397, -1], 'auc_mean': -0.0930427958601442}}\n",
      "done 9 3.7966322898864746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8089020252227783 {'pd': {'accuracy': 0.5, 'roc_micro': 0.924594050017779, 'roc_macro': -1}, 'nd': {'accuracy': 0.328125, 'roc_micro': 0.7050119102042781, 'roc_macro': 0.5038980875490021}, 'mod': {'accuracy': 0.328125, 'roc_micro': 0.7050119102042781, 'roc_macro': 0.5038980875490021}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.49883449883449876, 0.5926616915422886, 0.42754367934224047, -1, 0.5078014184397164, -1, 0.4595744680851064, -1], 'auc_mean': -0.06419803046951866}}\n",
      "done 10 3.8089020252227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.9345345497131348 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9310181344079649, 'roc_macro': -1}, 'nd': {'accuracy': 0.314543776371308, 'roc_micro': 0.7163446500324824, 'roc_macro': 0.5882717422351568}, 'mod': {'accuracy': 0.314543776371308, 'roc_micro': 0.7163446500324824, 'roc_macro': 0.5882717422351568}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.527363184079602, 0.5775950668036999, -1, 0.5517730496453901, -1, 0.6070921985815603, -1], 'auc_mean': -0.044819265408421266}}\n",
      "done 11 3.9345345497131348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8231570720672607 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9286713286713287, 'roc_macro': -1}, 'nd': {'accuracy': 0.3422336497890295, 'roc_micro': 0.7420658790693199, 'roc_macro': 0.4140939960299716}, 'mod': {'accuracy': 0.3422336497890295, 'roc_micro': 0.7420658790693199, 'roc_macro': 0.4140939960299716}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4242424242424242, 0.47450248756218905, 0.6197327852004111, -1, 0.3773049645390071, -1, 0.7078014184397163, -1], 'auc_mean': -0.04955199000203153}}\n",
      "done 12 3.8231570720672607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.9054479598999023 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9255422543558136, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7711797117489956, 'roc_macro': 0.570120584030645}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7711797117489956, 'roc_macro': 0.570120584030645}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7808857808857809, 0.47512437810945274, 0.39465570400822203, -1, 0.4936170212765958, -1, 0.4865248226950355, -1], 'auc_mean': -0.04614903662811411}}\n",
      "done 13 3.9054479598999023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.642094135284424 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9356406305558849, 'roc_macro': -1}, 'nd': {'accuracy': 0.34487078059071735, 'roc_micro': 0.7490916965424316, 'roc_macro': 0.5605770521929059}, 'mod': {'accuracy': 0.34487078059071735, 'roc_micro': 0.7490916965424316, 'roc_macro': 0.5605770521929059}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.32167832167832167, 0.5292288557213931, 0.6063720452209661, -1, 0.6028368794326242, -1, 0.5943262411347519, -1], 'auc_mean': -0.04319470710149288}}\n",
      "done 14 3.642094135284424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8308892250061035 {'pd': {'accuracy': 0.5, 'roc_micro': 0.925115562403698, 'roc_macro': -1}, 'nd': {'accuracy': 0.3447389240506329, 'roc_micro': 0.74370202834388, 'roc_macro': 0.484826693858706}, 'mod': {'accuracy': 0.3447389240506329, 'roc_micro': 0.74370202834388, 'roc_macro': 0.484826693858706}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4662004662004662, 0.5, 0.5118191161356629, -1, 0.5460992907801419, -1, 0.4836879432624114, -1], 'auc_mean': -0.06152414795266471}}\n",
      "done 15 3.8308892250061035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.805161714553833 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9211805144008534, 'roc_macro': -1}, 'nd': {'accuracy': 0.3704509493670886, 'roc_micro': 0.7719256033300449, 'roc_macro': 0.612286278635364}, 'mod': {'accuracy': 0.3704509493670886, 'roc_micro': 0.7719256033300449, 'roc_macro': 0.612286278635364}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5174825174825175, 0.6679104477611941, 0.32476875642343267, -1, 0.5929078014184397, -1, 0.5503546099290781, -1], 'auc_mean': -0.04332198337316723}}\n",
      "done 16 3.805161714553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.622523069381714 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9383430129192842, 'roc_macro': -1}, 'nd': {'accuracy': 0.3371571729957806, 'roc_micro': 0.7438704554750848, 'roc_macro': 0.6040446960797571}, 'mod': {'accuracy': 0.3371571729957806, 'roc_micro': 0.7438704554750848, 'roc_macro': 0.6040446960797571}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.2540792540792541, 0.5180348258706469, 0.5981500513874615, -1, 0.6326241134751773, -1, 0.4539007092198582, -1], 'auc_mean': -0.06790138074595027}}\n",
      "done 17 3.622523069381714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8256046772003174 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9312551854924735, 'roc_macro': -1}, 'nd': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7060224729915064, 'roc_macro': 0.514530854088781}, 'mod': {'accuracy': 0.3375527426160338, 'roc_micro': 0.7060224729915064, 'roc_macro': 0.514530854088781}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.47319347319347316, 0.6853233830845771, 0.4285714285714286, -1, 0.44680851063829785, -1, 0.3290780141843972, -1], 'auc_mean': -0.07962814879097826}}\n",
      "done 18 3.8256046772003174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.86962890625 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9141163920824937, 'roc_macro': -1}, 'nd': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7208440605375233, 'roc_macro': 0.5675430341969976}, 'mod': {'accuracy': 0.3333333333333333, 'roc_micro': 0.7208440605375233, 'roc_macro': 0.5675430341969976}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.5897435897435898, 0.724502487562189, 0.5724563206577594, -1, 0.44539007092198585, -1, 0.41276595744680855, -1], 'auc_mean': -0.031892696708458415}}\n",
      "done 19 3.86962890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6590921878814697 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9298328789854214, 'roc_macro': -1}, 'nd': {'accuracy': 0.3386075949367089, 'roc_micro': 0.7410071942446044, 'roc_macro': 0.577001234775625}, 'mod': {'accuracy': 0.3386075949367089, 'roc_micro': 0.7410071942446044, 'roc_macro': 0.577001234775625}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4405594405594405, 0.6131840796019901, 0.6762589928057554, -1, 0.526241134751773, -1, 0.4794326241134752, -1], 'auc_mean': -0.03304046602094571}}\n",
      "done 20 3.6590921878814697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8690803050994873 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9332227094938959, 'roc_macro': -1}, 'nd': {'accuracy': 0.3358386075949367, 'roc_micro': 0.7272683525420467, 'roc_macro': 0.5248340080657155}, 'mod': {'accuracy': 0.3358386075949367, 'roc_micro': 0.7272683525420467, 'roc_macro': 0.5248340080657155}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.7715617715617715, 0.470771144278607, 0.4295991778006166, -1, 0.5219858156028369, -1, 0.4964539007092199, -1], 'auc_mean': -0.038703523755868524}}\n",
      "done 21 3.8690803050994873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8235793113708496 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9218916676543795, 'roc_macro': -1}, 'nd': {'accuracy': 0.32733386075949367, 'roc_micro': 0.7462284353119512, 'roc_macro': 0.5123345418696029}, 'mod': {'accuracy': 0.32733386075949367, 'roc_micro': 0.7462284353119512, 'roc_macro': 0.5123345418696029}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.20279720279720279, 0.6635572139303483, 0.5704008221993833, -1, 0.44255319148936173, -1, 0.5602836879432624, -1], 'auc_mean': -0.07005098520505519}}\n",
      "done 22 3.8235793113708496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.4627208709716797 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9355458101220813, 'roc_macro': -1}, 'nd': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'mod': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.37296037296037293, 0.5746268656716418, 0.5981500513874615, -1, 0.6397163120567376, -1, 0.38865248226950355, -1], 'auc_mean': -0.05323673945678532}}\n",
      "done 23 3.4627208709716797\n",
      "_++++++++++New Best++++____\n",
      "3.4627208709716797\n",
      "{'pd': {'accuracy': 0.5, 'roc_micro': 0.9355458101220813, 'roc_macro': -1}, 'nd': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'mod': {'accuracy': 0.35851793248945146, 'roc_micro': 0.7635042467698083, 'roc_macro': 0.6375664891289893}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.37296037296037293, 0.5746268656716418, 0.5981500513874615, -1, 0.6397163120567376, -1, 0.38865248226950355, -1], 'auc_mean': -0.05323673945678532}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [10, 10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8075175285339355 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9022164276401564, 'roc_macro': -1}, 'nd': {'accuracy': 0.3323444092827004, 'roc_micro': 0.721265128365535, 'roc_macro': 0.4738785728686643}, 'mod': {'accuracy': 0.3323444092827004, 'roc_micro': 0.721265128365535, 'roc_macro': 0.4738785728686643}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.62004662004662, 0.375, 0.328879753340185, -1, 0.5234042553191489, -1, 0.35602836879432626, -1], 'auc_mean': -0.09958012531246498}}\n",
      "done 24 3.8075175285339355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8069398403167725 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9147327249022166, 'roc_macro': -1}, 'nd': {'accuracy': 0.3229166666666667, 'roc_micro': 0.7139746396862443, 'roc_macro': 0.5077768110351952}, 'mod': {'accuracy': 0.3229166666666667, 'roc_micro': 0.7139746396862443, 'roc_macro': 0.5077768110351952}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.8648018648018647, 0.44340796019900497, 0.40493319630010277, -1, 0.624113475177305, -1, 0.33333333333333337, -1], 'auc_mean': -0.04117627127354864}}\n",
      "done 25 3.8069398403167725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.6829874515533447 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9322982102643119, 'roc_macro': -1}, 'nd': {'accuracy': 0.3604298523206751, 'roc_micro': 0.7450013233560309, 'roc_macro': 0.5937424811281519}, 'mod': {'accuracy': 0.3604298523206751, 'roc_micro': 0.7450013233560309, 'roc_macro': 0.5937424811281519}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.4662004662004662, 0.5764925373134329, 0.6485097636176773, -1, 0.5475177304964539, -1, 0.4269503546099291, -1], 'auc_mean': -0.04179114347025506}}\n",
      "done 26 3.6829874515533447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 3.85282564163208 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9084982813796374, 'roc_macro': -1}, 'nd': {'accuracy': 0.36089135021097046, 'roc_micro': 0.7526767883352181, 'roc_macro': 0.6454314411631485}, 'mod': {'accuracy': 0.36089135021097046, 'roc_micro': 0.7526767883352181, 'roc_macro': 0.6454314411631485}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.45454545454545453, 0.6598258706467661, 0.4840698869475848, -1, 0.4794326241134752, -1, 0.5319148936170213, -1], 'auc_mean': -0.048776408766212254}}\n",
      "done 27 3.85282564163208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.8991506099700928 {'pd': {'accuracy': 0.5, 'roc_micro': 0.9260874718501837, 'roc_macro': -1}, 'nd': {'accuracy': 0.32383966244725737, 'roc_micro': 0.7193041553379371, 'roc_macro': 0.484346802563266}, 'mod': {'accuracy': 0.32383966244725737, 'roc_micro': 0.7193041553379371, 'roc_macro': 0.484346802563266}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.48717948717948717, 0.5690298507462687, 0.4696813977389517, -1, 0.5397163120567376, -1, 0.3588652482269504, -1], 'auc_mean': -0.07194096300645057}}\n",
      "done 28 3.8991506099700928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss 3.4415688514709473 {'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "done 29 3.4415688514709473\n",
      "_++++++++++New Best++++____\n",
      "3.4415688514709473\n",
      "{'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 3.4415688514709473\n",
      "{'pd': {'accuracy': 0.4959349593495935, 'roc_micro': 0.9374659239066019, 'roc_macro': -1}, 'nd': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'mod': {'accuracy': 0.34236550632911394, 'roc_micro': 0.7523639950915522, 'roc_macro': 0.6504770843566575}, 'dlts': {'accuracy': [0.9794520547945206, 0.9178082191780822, 0.952054794520548, 1.0, 0.9657534246575342, 1.0, 0.9657534246575342, 1.0], 'accuracy_mean': 0.9726027397260274, 'auc': [0.3776223776223776, 0.595771144278607, 0.6402877697841727, -1, 0.6624113475177306, -1, 0.3801418439716312, -1], 'auc_mean': -0.04297068960318512}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# model2 = gridsearch_atten/.tion_transition_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c33d908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9533352851867676 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22294936, 'auc': 0.61875}, 'FT': {'accuracy': -1, 'mse': 0.22988118, 'auc': 0.6208881578947368}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.23439899, 'auc': 0.7096153846153845}}\n",
      "done 0 1.9533352851867676\n",
      "_++++++++++New Best++++____\n",
      "1.9533352851867676\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22294936, 'auc': 0.61875}, 'FT': {'accuracy': -1, 'mse': 0.22988118, 'auc': 0.6208881578947368}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.23439899, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9169039726257324 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.23428532, 'auc': 0.5783653846153846}, 'FT': {'accuracy': -1, 'mse': 0.21831562, 'auc': 0.6165021929824561}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.21789795, 'auc': 0.7125}}\n",
      "done 1 1.9169039726257324\n",
      "_++++++++++New Best++++____\n",
      "1.9169039726257324\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.23428532, 'auc': 0.5783653846153846}, 'FT': {'accuracy': -1, 'mse': 0.21831562, 'auc': 0.6165021929824561}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.21789795, 'auc': 0.7125}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5414049625396729 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1648547, 'auc': 0.6644230769230769}, 'FT': {'accuracy': -1, 'mse': 0.18985225, 'auc': 0.6170504385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1474471, 'auc': 0.7243589743589743}}\n",
      "done 2 1.5414049625396729\n",
      "_++++++++++New Best++++____\n",
      "1.5414049625396729\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1648547, 'auc': 0.6644230769230769}, 'FT': {'accuracy': -1, 'mse': 0.18985225, 'auc': 0.6170504385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1474471, 'auc': 0.7243589743589743}}\n",
      "{'hidden_layers': [100], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.674856424331665 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.19408122, 'auc': 0.6682692307692308}, 'FT': {'accuracy': -1, 'mse': 0.19684686, 'auc': 0.6022478070175439}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16715875, 'auc': 0.7548076923076923}}\n",
      "done 3 1.674856424331665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.518134355545044 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14513706, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20396616, 'auc': 0.5858004385964913}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14681251, 'auc': 0.7025641025641025}}\n",
      "done 4 1.518134355545044\n",
      "_++++++++++New Best++++____\n",
      "1.518134355545044\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14513706, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20396616, 'auc': 0.5858004385964913}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14681251, 'auc': 0.7025641025641025}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5087974071502686 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13931565, 'auc': 0.6211538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20392582, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14429918, 'auc': 0.7108974358974359}}\n",
      "done 5 1.5087974071502686\n",
      "_++++++++++New Best++++____\n",
      "1.5087974071502686\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13931565, 'auc': 0.6211538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20392582, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14429918, 'auc': 0.7108974358974359}}\n",
      "{'hidden_layers': [500], 'attention_heads': [1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.483170509338379 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1349846, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20205373, 'auc': 0.603344298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14491129, 'auc': 0.7314102564102564}}\n",
      "done 6 1.483170509338379\n",
      "_++++++++++New Best++++____\n",
      "1.483170509338379\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1349846, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20205373, 'auc': 0.603344298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14491129, 'auc': 0.7314102564102564}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 200, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5140568017959595 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1465887, 'auc': 0.6384615384615385}, 'FT': {'accuracy': -1, 'mse': 0.20255052, 'auc': 0.6222587719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14903975, 'auc': 0.7525641025641026}}\n",
      "done 7 1.5140568017959595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4785480499267578 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12899454, 'auc': 0.6235576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20520449, 'auc': 0.6060855263157896}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14056323, 'auc': 0.7285256410256411}}\n",
      "done 8 1.4785480499267578\n",
      "_++++++++++New Best++++____\n",
      "1.4785480499267578\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12899454, 'auc': 0.6235576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20520449, 'auc': 0.6060855263157896}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14056323, 'auc': 0.7285256410256411}}\n",
      "{'hidden_layers': [1000], 'attention_heads': [10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.887725830078125 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22325234, 'auc': 0.5134615384615385}, 'FT': {'accuracy': -1, 'mse': 0.22919208, 'auc': 0.6014254385964912}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.20300515, 'auc': 0.7384615384615385}}\n",
      "done 9 1.887725830078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9279515743255615 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.21030568, 'auc': 0.6495192307692308}, 'FT': {'accuracy': -1, 'mse': 0.24050061, 'auc': 0.5531798245614035}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.2241059, 'auc': 0.6698717948717948}}\n",
      "done 10 1.9279515743255615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.555857539176941 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16066353, 'auc': 0.6274038461538461}, 'FT': {'accuracy': -1, 'mse': 0.1991347, 'auc': 0.5932017543859649}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14868976, 'auc': 0.7035256410256411}}\n",
      "done 11 1.555857539176941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5066845417022705 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14507481, 'auc': 0.5649038461538461}, 'FT': {'accuracy': -1, 'mse': 0.19716617, 'auc': 0.602796052631579}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.15009356, 'auc': 0.710576923076923}}\n",
      "done 12 1.5066845417022705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.589341640472412 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.17413948, 'auc': 0.5586538461538462}, 'FT': {'accuracy': -1, 'mse': 0.20374537, 'auc': 0.5951206140350878}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14826688, 'auc': 0.7544871794871795}}\n",
      "done 13 1.589341640472412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4861150979995728 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13306338, 'auc': 0.65}, 'FT': {'accuracy': -1, 'mse': 0.20490709, 'auc': 0.600328947368421}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.1420104, 'auc': 0.7141025641025641}}\n",
      "done 14 1.4861150979995728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.506028652191162 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14841402, 'auc': 0.6182692307692308}, 'FT': {'accuracy': -1, 'mse': 0.20488185, 'auc': 0.5877192982456141}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13998102, 'auc': 0.7483974358974359}}\n",
      "done 15 1.506028652191162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5576770305633545 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.154363, 'auc': 0.5822115384615385}, 'FT': {'accuracy': -1, 'mse': 0.21026096, 'auc': 0.5879934210526315}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.15049165, 'auc': 0.7298076923076924}}\n",
      "done 16 1.5576770305633545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5055675506591797 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13160379, 'auc': 0.6264423076923077}, 'FT': {'accuracy': -1, 'mse': 0.2073938, 'auc': 0.581140350877193}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14211161, 'auc': 0.7141025641025642}}\n",
      "done 17 1.5055675506591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.637538194656372 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16827497, 'auc': 0.48413461538461544}, 'FT': {'accuracy': -1, 'mse': 0.21037889, 'auc': 0.5635964912280702}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16129254, 'auc': 0.717948717948718}}\n",
      "done 18 1.637538194656372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.9545180797576904 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.22068177, 'auc': 0.45240384615384616}, 'FT': {'accuracy': -1, 'mse': 0.238595, 'auc': 0.5356359649122807}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.22857483, 'auc': 0.705448717948718}}\n",
      "done 19 1.9545180797576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4690238237380981 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14176321, 'auc': 0.6177884615384615}, 'FT': {'accuracy': -1, 'mse': 0.20021597, 'auc': 0.6066337719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13276392, 'auc': 0.7487179487179487}}\n",
      "done 20 1.4690238237380981\n",
      "_++++++++++New Best++++____\n",
      "1.4690238237380981\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14176321, 'auc': 0.6177884615384615}, 'FT': {'accuracy': -1, 'mse': 0.20021597, 'auc': 0.6066337719298246}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13276392, 'auc': 0.7487179487179487}}\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [10, 10], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "False\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4727905988693237 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.13137068, 'auc': 0.6495192307692308}, 'FT': {'accuracy': -1, 'mse': 0.20992997, 'auc': 0.6019736842105263}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13884372, 'auc': 0.7480769230769231}}\n",
      "done 21 1.4727905988693237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.515777587890625 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.15018119, 'auc': 0.6610576923076923}, 'FT': {'accuracy': -1, 'mse': 0.20404501, 'auc': 0.6041666666666666}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13985752, 'auc': 0.7352564102564103}}\n",
      "done 22 1.515777587890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.5039113759994507 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.1309246, 'auc': 0.626923076923077}, 'FT': {'accuracy': -1, 'mse': 0.20764191, 'auc': 0.5849780701754386}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14242676, 'auc': 0.7169871794871795}}\n",
      "done 23 1.5039113759994507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.6280651092529297 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.16924354, 'auc': 0.6264423076923078}, 'FT': {'accuracy': -1, 'mse': 0.20434348, 'auc': 0.6101973684210527}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.16036619, 'auc': 0.7737179487179487}}\n",
      "done 24 1.6280651092529297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 2.014167547225952 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.2509568, 'auc': 0.5038461538461538}, 'FT': {'accuracy': -1, 'mse': 0.23930772, 'auc': 0.5400219298245614}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.22724013, 'auc': 0.42275641025641025}}\n",
      "done 25 2.014167547225952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4920299053192139 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.14099866, 'auc': 0.6514423076923077}, 'FT': {'accuracy': -1, 'mse': 0.19876012, 'auc': 0.5901864035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14173688, 'auc': 0.7227564102564102}}\n",
      "done 26 1.4920299053192139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.513304352760315 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.15192407, 'auc': 0.6110576923076922}, 'FT': {'accuracy': -1, 'mse': 0.19458365, 'auc': 0.5923793859649122}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14482027, 'auc': 0.7080128205128204}}\n",
      "done 27 1.513304352760315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.455763339996338 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "done 28 1.455763339996338\n",
      "_++++++++++New Best++++____\n",
      "1.455763339996338\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 400, 'dropout': 0.9, 'input_dropout': 0.5}\n",
      "True\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "best loss 1.4676107168197632 {'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12858523, 'auc': 0.6384615384615384}, 'FT': {'accuracy': -1, 'mse': 0.19938947, 'auc': 0.6077302631578947}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.13879225, 'auc': 0.7153846153846154}}\n",
      "done 29 1.4676107168197632\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff 1.455763339996338\n",
      "{'Overall Survival (4 Years)': {'accuracy': -1, 'mse': 0.12546952, 'auc': 0.6596153846153847}, 'FT': {'accuracy': -1, 'mse': 0.20594049, 'auc': 0.6058114035087719}, 'Aspiration rate Post-therapy': {'accuracy': -1, 'mse': 0.14230496, 'auc': 0.7096153846153845}}\n",
      "{'hidden_layers': [500, 500], 'attention_heads': [5, 5], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# model3 = gridsearch_attention_transition_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2937b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_models():\n",
    "    files = Const.tuned_transition_models\n",
    "    decision_file = Const.tuned_decision_model\n",
    "    [model1,model2,model3] = [torch.load(file) for file in files]\n",
    "    decision_model = torch.load(decision_file)\n",
    "    return decision_model, model1,model2,model3\n",
    "_, model1, model2, model3 =load_trained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8af5c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n",
      "/home/evl/andrew/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: DtypeWarning: Columns (55) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "______epoch 0 _____\n",
      "train imitation 2.211329936981201 reward 2.4836373329162598\n",
      "val imitation 2.1203558444976807 reward 1.8343467712402344\n",
      "val loss 3.954702615737915 1000000000.0\n",
      "[{'decision': 0, 'accuracy': 0.4589041095890411, 'auc': 0.49615384615384617}, {'decision': 1, 'accuracy': 0.410958904109589, 'auc': 0.4383223684210526}, {'decision': 2, 'accuracy': 0.3835616438356164, 'auc': 0.5884615384615385}]\n",
      "______epoch 1 _____\n",
      "train imitation 2.2313594818115234 reward 2.487095355987549\n",
      "val imitation 2.111082077026367 reward 1.8335179090499878\n",
      "val loss 3.9446001052856445 3.954702615737915\n",
      "[{'decision': 0, 'accuracy': 0.4726027397260274, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.3972602739726027, 'auc': 0.4429824561403509}, {'decision': 2, 'accuracy': 0.3904109589041096, 'auc': 0.5958333333333333}]\n",
      "______epoch 2 _____\n",
      "train imitation 2.18521785736084 reward 2.4834415912628174\n",
      "val imitation 2.103510618209839 reward 1.8342481851577759\n",
      "val loss 3.9377589225769043 3.9446001052856445\n",
      "[{'decision': 0, 'accuracy': 0.4726027397260274, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.410958904109589, 'auc': 0.4512061403508772}, {'decision': 2, 'accuracy': 0.4315068493150685, 'auc': 0.6044871794871794}]\n",
      "______epoch 3 _____\n",
      "train imitation 2.2054977416992188 reward 2.484614372253418\n",
      "val imitation 2.0945963859558105 reward 1.8336946964263916\n",
      "val loss 3.928291082382202 3.9377589225769043\n",
      "[{'decision': 0, 'accuracy': 0.4931506849315068, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.4246575342465753, 'auc': 0.4649122807017544}, {'decision': 2, 'accuracy': 0.4589041095890411, 'auc': 0.6150641025641026}]\n",
      "______epoch 4 _____\n",
      "train imitation 2.1774253845214844 reward 2.484285593032837\n",
      "val imitation 2.0860965251922607 reward 1.8337342739105225\n",
      "val loss 3.919830799102783 3.928291082382202\n",
      "[{'decision': 0, 'accuracy': 0.5205479452054794, 'auc': 0.5052884615384616}, {'decision': 1, 'accuracy': 0.4383561643835616, 'auc': 0.47478070175438597}, {'decision': 2, 'accuracy': 0.4726027397260274, 'auc': 0.6272435897435897}]\n",
      "______epoch 5 _____\n",
      "train imitation 2.1750235557556152 reward 2.483266592025757\n",
      "val imitation 2.078188180923462 reward 1.8336718082427979\n",
      "val loss 3.9118599891662598 3.919830799102783\n",
      "[{'decision': 0, 'accuracy': 0.5273972602739726, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.4657534246575342, 'auc': 0.4854714912280702}, {'decision': 2, 'accuracy': 0.5136986301369864, 'auc': 0.6384615384615384}]\n",
      "______epoch 6 _____\n",
      "train imitation 2.147907018661499 reward 2.4836935997009277\n",
      "val imitation 2.07071590423584 reward 1.834143877029419\n",
      "val loss 3.904859781265259 3.9118599891662598\n",
      "[{'decision': 0, 'accuracy': 0.5342465753424658, 'auc': 0.5177884615384616}, {'decision': 1, 'accuracy': 0.4931506849315068, 'auc': 0.49917763157894735}, {'decision': 2, 'accuracy': 0.5205479452054794, 'auc': 0.6480769230769231}]\n",
      "______epoch 7 _____\n",
      "train imitation 2.171614170074463 reward 2.4832000732421875\n",
      "val imitation 2.063511848449707 reward 1.8342679738998413\n",
      "val loss 3.897779941558838 3.904859781265259\n",
      "[{'decision': 0, 'accuracy': 0.5753424657534246, 'auc': 0.51875}, {'decision': 1, 'accuracy': 0.5, 'auc': 0.5115131578947368}, {'decision': 2, 'accuracy': 0.547945205479452, 'auc': 0.6576923076923077}]\n",
      "______epoch 8 _____\n",
      "train imitation 2.144622325897217 reward 2.4823966026306152\n",
      "val imitation 2.056295871734619 reward 1.8342679738998413\n",
      "val loss 3.89056396484375 3.897779941558838\n",
      "[{'decision': 0, 'accuracy': 0.6027397260273972, 'auc': 0.5230769230769231}, {'decision': 1, 'accuracy': 0.5136986301369864, 'auc': 0.522203947368421}, {'decision': 2, 'accuracy': 0.5547945205479452, 'auc': 0.6689102564102565}]\n",
      "______epoch 9 _____\n",
      "train imitation 2.1730685234069824 reward 2.483757972717285\n",
      "val imitation 2.049285888671875 reward 1.8340171575546265\n",
      "val loss 3.883303165435791 3.89056396484375\n",
      "[{'decision': 0, 'accuracy': 0.6027397260273972, 'auc': 0.5283653846153846}, {'decision': 1, 'accuracy': 0.5136986301369864, 'auc': 0.5367324561403508}, {'decision': 2, 'accuracy': 0.5958904109589042, 'auc': 0.6794871794871794}]\n",
      "______epoch 10 _____\n",
      "train imitation 2.151646614074707 reward 2.4829678535461426\n",
      "val imitation 2.0426623821258545 reward 1.8340171575546265\n",
      "val loss 3.8766794204711914 3.883303165435791\n",
      "[{'decision': 0, 'accuracy': 0.6301369863013698, 'auc': 0.53125}, {'decision': 1, 'accuracy': 0.541095890410959, 'auc': 0.546875}, {'decision': 2, 'accuracy': 0.636986301369863, 'auc': 0.6881410256410256}]\n",
      "______epoch 11 _____\n",
      "train imitation 2.148426055908203 reward 2.4815828800201416\n",
      "val imitation 2.03619647026062 reward 1.8337763547897339\n",
      "val loss 3.8699727058410645 3.8766794204711914\n",
      "[{'decision': 0, 'accuracy': 0.636986301369863, 'auc': 0.5350961538461538}, {'decision': 1, 'accuracy': 0.5753424657534246, 'auc': 0.5586622807017544}, {'decision': 2, 'accuracy': 0.636986301369863, 'auc': 0.694551282051282}]\n",
      "______epoch 12 _____\n",
      "train imitation 2.146721601486206 reward 2.4824435710906982\n",
      "val imitation 2.030266761779785 reward 1.8337204456329346\n",
      "val loss 3.8639872074127197 3.8699727058410645\n",
      "[{'decision': 0, 'accuracy': 0.636986301369863, 'auc': 0.5384615384615384}, {'decision': 1, 'accuracy': 0.5958904109589042, 'auc': 0.5718201754385965}, {'decision': 2, 'accuracy': 0.6438356164383562, 'auc': 0.7025641025641026}]\n",
      "______epoch 13 _____\n",
      "train imitation 2.121926784515381 reward 2.48220157623291\n",
      "val imitation 2.024796485900879 reward 1.8340349197387695\n",
      "val loss 3.8588314056396484 3.8639872074127197\n",
      "[{'decision': 0, 'accuracy': 0.6438356164383562, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.6095890410958904, 'auc': 0.5819627192982456}, {'decision': 2, 'accuracy': 0.6506849315068494, 'auc': 0.7128205128205128}]\n",
      "______epoch 14 _____\n",
      "train imitation 2.1409435272216797 reward 2.4820191860198975\n",
      "val imitation 2.019683837890625 reward 1.8341045379638672\n",
      "val loss 3.853788375854492 3.8588314056396484\n",
      "[{'decision': 0, 'accuracy': 0.6575342465753424, 'auc': 0.5413461538461539}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.5923793859649122}, {'decision': 2, 'accuracy': 0.678082191780822, 'auc': 0.7192307692307693}]\n",
      "______epoch 15 _____\n",
      "train imitation 2.136880874633789 reward 2.483853340148926\n",
      "val imitation 2.014829397201538 reward 1.8342158794403076\n",
      "val loss 3.8490452766418457 3.853788375854492\n",
      "[{'decision': 0, 'accuracy': 0.6506849315068494, 'auc': 0.5423076923076924}, {'decision': 1, 'accuracy': 0.6301369863013698, 'auc': 0.599780701754386}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.723397435897436}]\n",
      "______epoch 16 _____\n",
      "train imitation 2.1061885356903076 reward 2.483428478240967\n",
      "val imitation 2.0098941326141357 reward 1.8337732553482056\n",
      "val loss 3.843667507171631 3.8490452766418457\n",
      "[{'decision': 0, 'accuracy': 0.6643835616438356, 'auc': 0.5437500000000001}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6107456140350878}, {'decision': 2, 'accuracy': 0.6917808219178082, 'auc': 0.7243589743589743}]\n",
      "______epoch 17 _____\n",
      "train imitation 2.1072559356689453 reward 2.481441020965576\n",
      "val imitation 2.0049667358398438 reward 1.8337732553482056\n",
      "val loss 3.8387398719787598 3.843667507171631\n",
      "[{'decision': 0, 'accuracy': 0.6575342465753424, 'auc': 0.5442307692307693}, {'decision': 1, 'accuracy': 0.6438356164383562, 'auc': 0.6175986842105263}, {'decision': 2, 'accuracy': 0.6917808219178082, 'auc': 0.7291666666666667}]\n",
      "______epoch 18 _____\n",
      "train imitation 2.104343891143799 reward 2.4817311763763428\n",
      "val imitation 2.0001022815704346 reward 1.8340888023376465\n",
      "val loss 3.834191083908081 3.8387398719787598\n",
      "[{'decision': 0, 'accuracy': 0.6712328767123288, 'auc': 0.545673076923077}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6244517543859649}, {'decision': 2, 'accuracy': 0.6917808219178082, 'auc': 0.7342948717948719}]\n",
      "______epoch 19 _____\n",
      "train imitation 2.1097769737243652 reward 2.4805562496185303\n",
      "val imitation 1.9955778121948242 reward 1.8345904350280762\n",
      "val loss 3.8301682472229004 3.834191083908081\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.6575342465753424, 'auc': 0.6299342105263158}, {'decision': 2, 'accuracy': 0.7123287671232876, 'auc': 0.7368589743589744}]\n",
      "______epoch 20 _____\n",
      "train imitation 2.1135687828063965 reward 2.484339475631714\n",
      "val imitation 1.9913239479064941 reward 1.8340232372283936\n",
      "val loss 3.8253471851348877 3.8301682472229004\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.6712328767123288, 'auc': 0.6329495614035088}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7378205128205129}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 21 _____\n",
      "train imitation 2.087005615234375 reward 2.4813249111175537\n",
      "val imitation 1.9872283935546875 reward 1.8340314626693726\n",
      "val loss 3.8212599754333496 3.8253471851348877\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5423076923076924}, {'decision': 1, 'accuracy': 0.678082191780822, 'auc': 0.6373355263157895}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7384615384615385}]\n",
      "______epoch 22 _____\n",
      "train imitation 2.08001446723938 reward 2.4827895164489746\n",
      "val imitation 1.9833742380142212 reward 1.8335046768188477\n",
      "val loss 3.8168787956237793 3.8212599754333496\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5427884615384615}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6417214912280702}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7397435897435898}]\n",
      "______epoch 23 _____\n",
      "train imitation 2.080533504486084 reward 2.483095645904541\n",
      "val imitation 1.9794373512268066 reward 1.8330190181732178\n",
      "val loss 3.8124563694000244 3.8168787956237793\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5451923076923076}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6472039473684211}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7410256410256411}]\n",
      "______epoch 24 _____\n",
      "train imitation 2.080048084259033 reward 2.48279070854187\n",
      "val imitation 1.9755916595458984 reward 1.8330190181732178\n",
      "val loss 3.808610677719116 3.8124563694000244\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5451923076923076}, {'decision': 1, 'accuracy': 0.6917808219178082, 'auc': 0.6535087719298246}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7451923076923077}]\n",
      "______epoch 25 _____\n",
      "train imitation 2.066206216812134 reward 2.480741500854492\n",
      "val imitation 1.9719030857086182 reward 1.8330190181732178\n",
      "val loss 3.804922103881836 3.808610677719116\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5432692307692307}, {'decision': 1, 'accuracy': 0.6986301369863014, 'auc': 0.6570723684210527}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7458333333333333}]\n",
      "______epoch 26 _____\n",
      "train imitation 2.070082187652588 reward 2.4826433658599854\n",
      "val imitation 1.9683609008789062 reward 1.8329248428344727\n",
      "val loss 3.801285743713379 3.804922103881836\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5442307692307693}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.6606359649122807}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7471153846153846}]\n",
      "______epoch 27 _____\n",
      "train imitation 2.0609216690063477 reward 2.4813148975372314\n",
      "val imitation 1.9650161266326904 reward 1.8329248428344727\n",
      "val loss 3.797940969467163 3.801285743713379\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.7054794520547946, 'auc': 0.662280701754386}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7455128205128205}]\n",
      "______epoch 28 _____\n",
      "train imitation 2.0670907497406006 reward 2.480661630630493\n",
      "val imitation 1.961800217628479 reward 1.8325812816619873\n",
      "val loss 3.794381618499756 3.797940969467163\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5466346153846153}, {'decision': 1, 'accuracy': 0.7123287671232876, 'auc': 0.665296052631579}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7451923076923077}]\n",
      "______epoch 29 _____\n",
      "train imitation 2.0468127727508545 reward 2.481659412384033\n",
      "val imitation 1.958719253540039 reward 1.8323628902435303\n",
      "val loss 3.7910821437835693 3.794381618499756\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5480769230769231}, {'decision': 1, 'accuracy': 0.7123287671232876, 'auc': 0.6724232456140351}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7451923076923077}]\n",
      "______epoch 30 _____\n",
      "train imitation 2.0523948669433594 reward 2.4803552627563477\n",
      "val imitation 1.9553272724151611 reward 1.8323628902435303\n",
      "val loss 3.7876901626586914 3.7910821437835693\n",
      "[{'decision': 0, 'accuracy': 0.684931506849315, 'auc': 0.5485576923076922}, {'decision': 1, 'accuracy': 0.7123287671232876, 'auc': 0.6735197368421053}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7461538461538462}]\n",
      "______epoch 31 _____\n",
      "train imitation 2.0497071743011475 reward 2.48095703125\n",
      "val imitation 1.9519169330596924 reward 1.8323628902435303\n",
      "val loss 3.7842798233032227 3.7876901626586914\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5451923076923078}, {'decision': 1, 'accuracy': 0.726027397260274, 'auc': 0.6757127192982456}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.7490384615384615}]\n",
      "______epoch 32 _____\n",
      "train imitation 2.0582854747772217 reward 2.4802486896514893\n",
      "val imitation 1.9486948251724243 reward 1.8321868181228638\n",
      "val loss 3.780881643295288 3.7842798233032227\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5451923076923078}, {'decision': 1, 'accuracy': 0.726027397260274, 'auc': 0.6759868421052632}, {'decision': 2, 'accuracy': 0.6986301369863014, 'auc': 0.7490384615384615}]\n",
      "______epoch 33 _____\n",
      "train imitation 2.0430145263671875 reward 2.480551242828369\n",
      "val imitation 1.945177435874939 reward 1.8320732116699219\n",
      "val loss 3.7772507667541504 3.780881643295288\n",
      "[{'decision': 0, 'accuracy': 0.678082191780822, 'auc': 0.5447115384615384}, {'decision': 1, 'accuracy': 0.7328767123287672, 'auc': 0.6803728070175439}, {'decision': 2, 'accuracy': 0.7054794520547946, 'auc': 0.75}]\n",
      "______epoch 34 _____\n",
      "train imitation 2.0327723026275635 reward 2.4798381328582764\n",
      "val imitation 1.9413012266159058 reward 1.8320732116699219\n",
      "val loss 3.773374557495117 3.7772507667541504\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.545673076923077}, {'decision': 1, 'accuracy': 0.7328767123287672, 'auc': 0.6847587719298245}, {'decision': 2, 'accuracy': 0.7123287671232876, 'auc': 0.7512820512820513}]\n",
      "______epoch 35 _____\n",
      "train imitation 2.030153751373291 reward 2.4827377796173096\n",
      "val imitation 1.9374512434005737 reward 1.8320732116699219\n",
      "val loss 3.769524574279785 3.773374557495117\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.7123287671232876, 'auc': 0.7512820512820513}]\n",
      "______epoch 36 _____\n",
      "train imitation 2.046192169189453 reward 2.481654644012451\n",
      "val imitation 1.9335594177246094 reward 1.8320732116699219\n",
      "val loss 3.7656326293945312 3.769524574279785\n",
      "[{'decision': 0, 'accuracy': 0.6917808219178082, 'auc': 0.5442307692307693}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6875}, {'decision': 2, 'accuracy': 0.7123287671232876, 'auc': 0.7532051282051282}]\n",
      "______epoch 37 _____\n",
      "train imitation 2.0352141857147217 reward 2.480544090270996\n",
      "val imitation 1.9294142723083496 reward 1.832292914390564\n",
      "val loss 3.761707305908203 3.7656326293945312\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5442307692307692}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6907894736842105}, {'decision': 2, 'accuracy': 0.7191780821917808, 'auc': 0.7532051282051282}]\n",
      "______epoch 38 _____\n",
      "train imitation 2.032377004623413 reward 2.4825823307037354\n",
      "val imitation 1.9253098964691162 reward 1.8323562145233154\n",
      "val loss 3.7576661109924316 3.761707305908203\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5427884615384616}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6918859649122807}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.753525641025641}]\n",
      "______epoch 39 _____\n",
      "train imitation 2.0270395278930664 reward 2.479405403137207\n",
      "val imitation 1.9211840629577637 reward 1.8316673040390015\n",
      "val loss 3.7528514862060547 3.7576661109924316\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6921600877192983}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.755448717948718}]\n",
      "______epoch 40 _____\n",
      "train imitation 2.01863694190979 reward 2.481295585632324\n",
      "val imitation 1.9167280197143555 reward 1.8315874338150024\n",
      "val loss 3.7483153343200684 3.7528514862060547\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5423076923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6954495614035088}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.7564102564102564}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 41 _____\n",
      "train imitation 2.0078206062316895 reward 2.4788262844085693\n",
      "val imitation 1.9121582508087158 reward 1.8314732313156128\n",
      "val loss 3.743631362915039 3.7483153343200684\n",
      "[{'decision': 0, 'accuracy': 0.6986301369863014, 'auc': 0.5418269230769232}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6970942982456141}, {'decision': 2, 'accuracy': 0.726027397260274, 'auc': 0.7567307692307692}]\n",
      "______epoch 42 _____\n",
      "train imitation 2.016968250274658 reward 2.4794843196868896\n",
      "val imitation 1.906798243522644 reward 1.8312925100326538\n",
      "val loss 3.738090753555298 3.743631362915039\n",
      "[{'decision': 0, 'accuracy': 0.7123287671232876, 'auc': 0.5413461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6987390350877194}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.7564102564102564}]\n",
      "______epoch 43 _____\n",
      "train imitation 2.022209644317627 reward 2.4815211296081543\n",
      "val imitation 1.9016683101654053 reward 1.8311307430267334\n",
      "val loss 3.7327990531921387 3.738090753555298\n",
      "[{'decision': 0, 'accuracy': 0.7123287671232876, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7003837719298245}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.7557692307692307}]\n",
      "______epoch 44 _____\n",
      "train imitation 1.9951106309890747 reward 2.4792656898498535\n",
      "val imitation 1.8960466384887695 reward 1.830413818359375\n",
      "val loss 3.7264604568481445 3.7327990531921387\n",
      "[{'decision': 0, 'accuracy': 0.7123287671232876, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7036732456140351}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7567307692307692}]\n",
      "______epoch 45 _____\n",
      "train imitation 1.9879028797149658 reward 2.479936361312866\n",
      "val imitation 1.8901156187057495 reward 1.8297570943832397\n",
      "val loss 3.7198727130889893 3.7264604568481445\n",
      "[{'decision': 0, 'accuracy': 0.726027397260274, 'auc': 0.5399038461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7055921052631579}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7557692307692309}]\n",
      "______epoch 46 _____\n",
      "train imitation 1.989537239074707 reward 2.4814162254333496\n",
      "val imitation 1.8847405910491943 reward 1.8296308517456055\n",
      "val loss 3.7143714427948 3.7198727130889893\n",
      "[{'decision': 0, 'accuracy': 0.7397260273972602, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7077850877192983}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7570512820512821}]\n",
      "______epoch 47 _____\n",
      "train imitation 1.9951967000961304 reward 2.478764772415161\n",
      "val imitation 1.8796536922454834 reward 1.8298399448394775\n",
      "val loss 3.709493637084961 3.7143714427948\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5379807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.709703947368421}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7586538461538461}]\n",
      "______epoch 48 _____\n",
      "train imitation 1.9930057525634766 reward 2.4808614253997803\n",
      "val imitation 1.874239444732666 reward 1.8298399448394775\n",
      "val loss 3.7040793895721436 3.709493637084961\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5375000000000001}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.712171052631579}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7580128205128205}]\n",
      "______epoch 49 _____\n",
      "train imitation 2.0042152404785156 reward 2.4798500537872314\n",
      "val imitation 1.868432879447937 reward 1.8298399448394775\n",
      "val loss 3.698272705078125 3.7040793895721436\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5341346153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7129934210526315}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7599358974358974}]\n",
      "______epoch 50 _____\n",
      "train imitation 1.980839729309082 reward 2.4821910858154297\n",
      "val imitation 1.8623182773590088 reward 1.8298168182373047\n",
      "val loss 3.6921350955963135 3.698272705078125\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5341346153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.715734649122807}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.760897435897436}]\n",
      "______epoch 51 _____\n",
      "train imitation 1.9765625 reward 2.478029251098633\n",
      "val imitation 1.8567103147506714 reward 1.8291783332824707\n",
      "val loss 3.6858887672424316 3.6921350955963135\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5355769230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7176535087719299}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7625}]\n",
      "______epoch 52 _____\n",
      "train imitation 1.9798083305358887 reward 2.4797706604003906\n",
      "val imitation 1.8506715297698975 reward 1.8288155794143677\n",
      "val loss 3.6794872283935547 3.6858887672424316\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.71875}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7637820512820512}]\n",
      "______epoch 53 _____\n",
      "train imitation 1.9868638515472412 reward 2.4813284873962402\n",
      "val imitation 1.8447082042694092 reward 1.8285658359527588\n",
      "val loss 3.673274040222168 3.6794872283935547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5317307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7209429824561404}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7634615384615384}]\n",
      "______epoch 54 _____\n",
      "train imitation 1.972640872001648 reward 2.479849338531494\n",
      "val imitation 1.8380271196365356 reward 1.8284039497375488\n",
      "val loss 3.666430950164795 3.673274040222168\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7223135964912282}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7637820512820512}]\n",
      "______epoch 55 _____\n",
      "train imitation 1.983499526977539 reward 2.479712724685669\n",
      "val imitation 1.8314743041992188 reward 1.8284039497375488\n",
      "val loss 3.6598782539367676 3.666430950164795\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7236842105263158}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.7631410256410257}]\n",
      "______epoch 56 _____\n",
      "train imitation 1.9680148363113403 reward 2.4801886081695557\n",
      "val imitation 1.8252370357513428 reward 1.8284039497375488\n",
      "val loss 3.6536409854888916 3.6598782539367676\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.7328767123287672, 'auc': 0.7641025641025642}]\n",
      "______epoch 57 _____\n",
      "train imitation 1.9604905843734741 reward 2.480412006378174\n",
      "val imitation 1.8190855979919434 reward 1.8284039497375488\n",
      "val loss 3.647489547729492 3.6536409854888916\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5307692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7657051282051281}]\n",
      "______epoch 58 _____\n",
      "train imitation 1.9576421976089478 reward 2.4792416095733643\n",
      "val imitation 1.8130040168762207 reward 1.8279128074645996\n",
      "val loss 3.6409168243408203 3.647489547729492\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.53125}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.7397260273972602, 'auc': 0.7666666666666666}]\n",
      "______epoch 59 _____\n",
      "train imitation 1.9753141403198242 reward 2.4782509803771973\n",
      "val imitation 1.8069705963134766 reward 1.8279128074645996\n",
      "val loss 3.634883403778076 3.6409168243408203\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.7602739726027398, 'auc': 0.7685897435897436}]\n",
      "______epoch 60 _____\n",
      "train imitation 1.9565579891204834 reward 2.4818100929260254\n",
      "val imitation 1.8011879920959473 reward 1.8279128074645996\n",
      "val loss 3.629100799560547 3.634883403778076\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.53125}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.7602739726027398, 'auc': 0.7682692307692308}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 61 _____\n",
      "train imitation 1.9529986381530762 reward 2.480656385421753\n",
      "val imitation 1.7958595752716064 reward 1.8275448083877563\n",
      "val loss 3.6234045028686523 3.629100799560547\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5307692307692309}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7689102564102565}]\n",
      "______epoch 62 _____\n",
      "train imitation 1.9598884582519531 reward 2.4786102771759033\n",
      "val imitation 1.7911829948425293 reward 1.827378511428833\n",
      "val loss 3.6185615062713623 3.6234045028686523\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5298076923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7711538461538462}]\n",
      "______epoch 63 _____\n",
      "train imitation 1.9693411588668823 reward 2.4784295558929443\n",
      "val imitation 1.7863849401474 reward 1.8270325660705566\n",
      "val loss 3.613417625427246 3.6185615062713623\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5288461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7717948717948718}]\n",
      "______epoch 64 _____\n",
      "train imitation 1.943953514099121 reward 2.4774606227874756\n",
      "val imitation 1.7812323570251465 reward 1.826308250427246\n",
      "val loss 3.6075406074523926 3.613417625427246\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5269230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7717948717948718}]\n",
      "______epoch 65 _____\n",
      "train imitation 1.950972318649292 reward 2.4794704914093018\n",
      "val imitation 1.7760639190673828 reward 1.826308250427246\n",
      "val loss 3.602372169494629 3.6075406074523926\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5264423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7727564102564102}]\n",
      "______epoch 66 _____\n",
      "train imitation 1.9552478790283203 reward 2.4801738262176514\n",
      "val imitation 1.771254301071167 reward 1.8261276483535767\n",
      "val loss 3.597382068634033 3.602372169494629\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5264423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7740384615384615}]\n",
      "______epoch 67 _____\n",
      "train imitation 1.9499270915985107 reward 2.480818748474121\n",
      "val imitation 1.7664477825164795 reward 1.8258216381072998\n",
      "val loss 3.5922694206237793 3.597382068634033\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5283653846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7319078947368421}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7737179487179487}]\n",
      "______epoch 68 _____\n",
      "train imitation 1.9376333951950073 reward 2.4805400371551514\n",
      "val imitation 1.7614245414733887 reward 1.825356364250183\n",
      "val loss 3.5867810249328613 3.5922694206237793\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5293269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7743589743589744}]\n",
      "______epoch 69 _____\n",
      "train imitation 1.9376987218856812 reward 2.479886293411255\n",
      "val imitation 1.755929708480835 reward 1.8249728679656982\n",
      "val loss 3.580902576446533 3.5867810249328613\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5298076923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7746794871794872}]\n",
      "______epoch 70 _____\n",
      "train imitation 1.9486305713653564 reward 2.479754686355591\n",
      "val imitation 1.7502802610397339 reward 1.8251382112503052\n",
      "val loss 3.575418472290039 3.580902576446533\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5307692307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7759615384615385}]\n",
      "______epoch 71 _____\n",
      "train imitation 1.9391052722930908 reward 2.478297472000122\n",
      "val imitation 1.7444965839385986 reward 1.824707269668579\n",
      "val loss 3.5692038536071777 3.575418472290039\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.53125}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7321820175438596}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7766025641025641}]\n",
      "______epoch 72 _____\n",
      "train imitation 1.9308643341064453 reward 2.4798154830932617\n",
      "val imitation 1.7387404441833496 reward 1.824707269668579\n",
      "val loss 3.5634477138519287 3.5692038536071777\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7324561403508772}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7772435897435898}]\n",
      "______epoch 73 _____\n",
      "train imitation 1.9251470565795898 reward 2.4809656143188477\n",
      "val imitation 1.7328448295593262 reward 1.8248200416564941\n",
      "val loss 3.5576648712158203 3.5634477138519287\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5322115384615385}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7769230769230769}]\n",
      "______epoch 74 _____\n",
      "train imitation 1.9288544654846191 reward 2.479471206665039\n",
      "val imitation 1.7261542081832886 reward 1.8248200416564941\n",
      "val loss 3.5509743690490723 3.5576648712158203\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5331730769230769}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7330043859649122}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7785256410256409}]\n",
      "______epoch 75 _____\n",
      "train imitation 1.9255306720733643 reward 2.4782533645629883\n",
      "val imitation 1.7195465564727783 reward 1.8249562978744507\n",
      "val loss 3.5445027351379395 3.5509743690490723\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5350961538461538}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7330043859649122}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7785256410256409}]\n",
      "______epoch 76 _____\n",
      "train imitation 1.9184376001358032 reward 2.4775044918060303\n",
      "val imitation 1.713102102279663 reward 1.823934555053711\n",
      "val loss 3.537036657333374 3.5445027351379395\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7671232876712328, 'auc': 0.7778846153846153}]\n",
      "______epoch 77 _____\n",
      "train imitation 1.922555923461914 reward 2.479487419128418\n",
      "val imitation 1.7072184085845947 reward 1.823934555053711\n",
      "val loss 3.5311529636383057 3.537036657333374\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.7801282051282051}]\n",
      "______epoch 78 _____\n",
      "train imitation 1.9264261722564697 reward 2.480396032333374\n",
      "val imitation 1.701361894607544 reward 1.823934555053711\n",
      "val loss 3.525296449661255 3.5311529636383057\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.780448717948718}]\n",
      "______epoch 79 _____\n",
      "train imitation 1.915431022644043 reward 2.479936361312866\n",
      "val imitation 1.6959136724472046 reward 1.8230290412902832\n",
      "val loss 3.5189428329467773 3.525296449661255\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5379807692307692}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.780448717948718}]\n",
      "______epoch 80 _____\n",
      "train imitation 1.9227548837661743 reward 2.477815628051758\n",
      "val imitation 1.6914654970169067 reward 1.8229308128356934\n",
      "val loss 3.5143961906433105 3.5189428329467773\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7817307692307692}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 81 _____\n",
      "train imitation 1.9147106409072876 reward 2.479743003845215\n",
      "val imitation 1.6882283687591553 reward 1.8229308128356934\n",
      "val loss 3.5111591815948486 3.5143961906433105\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5375}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.782051282051282}]\n",
      "______epoch 82 _____\n",
      "train imitation 1.9073703289031982 reward 2.477687120437622\n",
      "val imitation 1.6846082210540771 reward 1.822169542312622\n",
      "val loss 3.506777763366699 3.5111591815948486\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5384615384615384}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7830128205128205}]\n",
      "______epoch 83 _____\n",
      "train imitation 1.9004974365234375 reward 2.4785196781158447\n",
      "val imitation 1.681611180305481 reward 1.821700096130371\n",
      "val loss 3.5033111572265625 3.506777763366699\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5394230769230769}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7354714912280701}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7833333333333333}]\n",
      "______epoch 84 _____\n",
      "train imitation 1.9416120052337646 reward 2.4798202514648438\n",
      "val imitation 1.6782464981079102 reward 1.821372151374817\n",
      "val loss 3.4996185302734375 3.5033111572265625\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5389423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7360197368421052}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.783974358974359}]\n",
      "______epoch 85 _____\n",
      "train imitation 1.8993034362792969 reward 2.4795398712158203\n",
      "val imitation 1.6742982864379883 reward 1.821372151374817\n",
      "val loss 3.4956703186035156 3.4996185302734375\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5399038461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7836538461538461}]\n",
      "______epoch 86 _____\n",
      "train imitation 1.9048635959625244 reward 2.480412006378174\n",
      "val imitation 1.670081615447998 reward 1.8212755918502808\n",
      "val loss 3.4913573265075684 3.4956703186035156\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7846153846153846}]\n",
      "______epoch 87 _____\n",
      "train imitation 1.8993858098983765 reward 2.4793004989624023\n",
      "val imitation 1.6649283170700073 reward 1.8212755918502808\n",
      "val loss 3.486203908920288 3.4913573265075684\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5399038461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7849358974358974}]\n",
      "______epoch 88 _____\n",
      "train imitation 1.8967492580413818 reward 2.4792754650115967\n",
      "val imitation 1.6594855785369873 reward 1.8211604356765747\n",
      "val loss 3.4806461334228516 3.486203908920288\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5408653846153847}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7384868421052632}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7849358974358974}]\n",
      "______epoch 89 _____\n",
      "train imitation 1.9005975723266602 reward 2.4808526039123535\n",
      "val imitation 1.6547818183898926 reward 1.8211604356765747\n",
      "val loss 3.4759421348571777 3.4806461334228516\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5408653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7849358974358974}]\n",
      "______epoch 90 _____\n",
      "train imitation 1.8955591917037964 reward 2.47794771194458\n",
      "val imitation 1.650195598602295 reward 1.8213582038879395\n",
      "val loss 3.4715538024902344 3.4759421348571777\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.541826923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7855769230769231}]\n",
      "______epoch 91 _____\n",
      "train imitation 1.8743104934692383 reward 2.4815640449523926\n",
      "val imitation 1.6451082229614258 reward 1.8214356899261475\n",
      "val loss 3.4665439128875732 3.4715538024902344\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5432692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7401315789473685}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7862179487179487}]\n",
      "______epoch 92 _____\n",
      "train imitation 1.8930573463439941 reward 2.4788479804992676\n",
      "val imitation 1.640589714050293 reward 1.8213156461715698\n",
      "val loss 3.4619054794311523 3.4665439128875732\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5432692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7398574561403509}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7868589743589745}]\n",
      "______epoch 93 _____\n",
      "train imitation 1.892687439918518 reward 2.481888771057129\n",
      "val imitation 1.6356918811798096 reward 1.8213156461715698\n",
      "val loss 3.45700740814209 3.4619054794311523\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5432692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7409539473684211}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7875}]\n",
      "______epoch 94 _____\n",
      "train imitation 1.887850046157837 reward 2.4789061546325684\n",
      "val imitation 1.6306304931640625 reward 1.8213156461715698\n",
      "val loss 3.451946258544922 3.45700740814209\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5427884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7417763157894736}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7884615384615385}]\n",
      "______epoch 95 _____\n",
      "train imitation 1.8762061595916748 reward 2.4805712699890137\n",
      "val imitation 1.6262409687042236 reward 1.8213156461715698\n",
      "val loss 3.447556495666504 3.451946258544922\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5423076923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7423245614035087}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7897435897435897}]\n",
      "______epoch 96 _____\n",
      "train imitation 1.889801263809204 reward 2.4799842834472656\n",
      "val imitation 1.621209979057312 reward 1.8213081359863281\n",
      "val loss 3.4425182342529297 3.447556495666504\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5427884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7428728070175439}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.789423076923077}]\n",
      "______epoch 97 _____\n",
      "train imitation 1.8893558979034424 reward 2.480299711227417\n",
      "val imitation 1.6153614521026611 reward 1.8206677436828613\n",
      "val loss 3.4360291957855225 3.4425182342529297\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5442307692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7897435897435897}]\n",
      "______epoch 98 _____\n",
      "train imitation 1.8582535982131958 reward 2.4802980422973633\n",
      "val imitation 1.6089906692504883 reward 1.8203397989273071\n",
      "val loss 3.429330348968506 3.4360291957855225\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5437500000000001}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7417763157894737}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.789423076923077}]\n",
      "______epoch 99 _____\n",
      "train imitation 1.8837852478027344 reward 2.4797067642211914\n",
      "val imitation 1.602150797843933 reward 1.820525884628296\n",
      "val loss 3.4226765632629395 3.429330348968506\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5447115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7420504385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7897435897435897}]\n",
      "______epoch 100 _____\n",
      "train imitation 1.868581771850586 reward 2.481712579727173\n",
      "val imitation 1.5952755212783813 reward 1.820525884628296\n",
      "val loss 3.415801525115967 3.4226765632629395\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7423245614035088}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7913461538461539}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 101 _____\n",
      "train imitation 1.864612102508545 reward 2.479301691055298\n",
      "val imitation 1.5884876251220703 reward 1.820681095123291\n",
      "val loss 3.4091687202453613 3.415801525115967\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5471153846153847}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7415021929824561}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.7910256410256411}]\n",
      "______epoch 102 _____\n",
      "train imitation 1.8459141254425049 reward 2.481466293334961\n",
      "val imitation 1.5819952487945557 reward 1.820906639099121\n",
      "val loss 3.4029018878936768 3.4091687202453613\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5475961538461539}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7401315789473685}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.7903846153846155}]\n",
      "______epoch 103 _____\n",
      "train imitation 1.8533976078033447 reward 2.48114275932312\n",
      "val imitation 1.5772480964660645 reward 1.820906639099121\n",
      "val loss 3.3981547355651855 3.4029018878936768\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.791025641025641}]\n",
      "______epoch 104 _____\n",
      "train imitation 1.863120198249817 reward 2.4814674854278564\n",
      "val imitation 1.5730212926864624 reward 1.8213560581207275\n",
      "val loss 3.3943772315979004 3.3981547355651855\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5495192307692308}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7913461538461539}]\n",
      "______epoch 105 _____\n",
      "train imitation 1.8666844367980957 reward 2.4805479049682617\n",
      "val imitation 1.570522427558899 reward 1.8213250637054443\n",
      "val loss 3.391847610473633 3.3943772315979004\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7387609649122807}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7919871794871796}]\n",
      "______epoch 106 _____\n",
      "train imitation 1.8671069145202637 reward 2.4832100868225098\n",
      "val imitation 1.5688202381134033 reward 1.8215057849884033\n",
      "val loss 3.3903260231018066 3.391847610473633\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7384868421052632}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7913461538461538}]\n",
      "______epoch 107 _____\n",
      "train imitation 1.8583860397338867 reward 2.4804513454437256\n",
      "val imitation 1.5681543350219727 reward 1.8215057849884033\n",
      "val loss 3.389660120010376 3.3903260231018066\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5485576923076924}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7379385964912281}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.7913461538461538}]\n",
      "______epoch 108 _____\n",
      "train imitation 1.8470791578292847 reward 2.4795165061950684\n",
      "val imitation 1.5682919025421143 reward 1.8214370012283325\n",
      "val loss 3.3897290229797363 3.389660120010376\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5475961538461539}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7379385964912282}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.7916666666666667}]\n",
      "______epoch 109 _____\n",
      "train imitation 1.8583673238754272 reward 2.4834232330322266\n",
      "val imitation 1.5685065984725952 reward 1.8211090564727783\n",
      "val loss 3.389615535736084 3.389660120010376\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5480769230769231}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7376644736842105}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7923076923076924}]\n",
      "______epoch 110 _____\n",
      "train imitation 1.845466136932373 reward 2.482576608657837\n",
      "val imitation 1.5689719915390015 reward 1.8209128379821777\n",
      "val loss 3.3898849487304688 3.389615535736084\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5471153846153847}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7916666666666667}]\n",
      "______epoch 111 _____\n",
      "train imitation 1.8556382656097412 reward 2.481236219406128\n",
      "val imitation 1.5682063102722168 reward 1.8209997415542603\n",
      "val loss 3.3892059326171875 3.389615535736084\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5480769230769231}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7916666666666667}]\n",
      "______epoch 112 _____\n",
      "train imitation 1.8511179685592651 reward 2.479187250137329\n",
      "val imitation 1.5661182403564453 reward 1.8210680484771729\n",
      "val loss 3.387186288833618 3.3892059326171875\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.791025641025641}]\n",
      "______epoch 113 _____\n",
      "train imitation 1.8163821697235107 reward 2.481698989868164\n",
      "val imitation 1.5638749599456787 reward 1.8210680484771729\n",
      "val loss 3.3849430084228516 3.387186288833618\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7365679824561403}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7916666666666666}]\n",
      "______epoch 114 _____\n",
      "train imitation 1.8430993556976318 reward 2.4810962677001953\n",
      "val imitation 1.5603675842285156 reward 1.8209351301193237\n",
      "val loss 3.381302833557129 3.3849430084228516\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7368421052631579}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7910256410256411}]\n",
      "______epoch 115 _____\n",
      "train imitation 1.8523569107055664 reward 2.481060266494751\n",
      "val imitation 1.5556565523147583 reward 1.8208047151565552\n",
      "val loss 3.3764612674713135 3.381302833557129\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7913461538461539}]\n",
      "______epoch 116 _____\n",
      "train imitation 1.83988618850708 reward 2.482128143310547\n",
      "val imitation 1.5483276844024658 reward 1.820866584777832\n",
      "val loss 3.369194269180298 3.3764612674713135\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.55}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7926282051282052}]\n",
      "______epoch 117 _____\n",
      "train imitation 1.849861979484558 reward 2.4811899662017822\n",
      "val imitation 1.541960597038269 reward 1.820736289024353\n",
      "val loss 3.362696886062622 3.369194269180298\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5509615384615385}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7926282051282052}]\n",
      "______epoch 118 _____\n",
      "train imitation 1.8377676010131836 reward 2.48221492767334\n",
      "val imitation 1.5364408493041992 reward 1.8211357593536377\n",
      "val loss 3.357576608657837 3.362696886062622\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5504807692307693}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.773972602739726, 'auc': 0.792948717948718}]\n",
      "______epoch 119 _____\n",
      "train imitation 1.830173373222351 reward 2.4813787937164307\n",
      "val imitation 1.5292457342147827 reward 1.820927619934082\n",
      "val loss 3.3501734733581543 3.357576608657837\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5504807692307693}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7935897435897437}]\n",
      "______epoch 120 _____\n",
      "train imitation 1.8274942636489868 reward 2.480459451675415\n",
      "val imitation 1.5224624872207642 reward 1.820927619934082\n",
      "val loss 3.3433899879455566 3.3501734733581543\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.733826754385965}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7945512820512821}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 121 _____\n",
      "train imitation 1.8165132999420166 reward 2.4799251556396484\n",
      "val imitation 1.5162453651428223 reward 1.820652723312378\n",
      "val loss 3.3368980884552 3.3433899879455566\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5495192307692308}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.733826754385965}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.796474358974359}]\n",
      "______epoch 122 _____\n",
      "train imitation 1.811678409576416 reward 2.4807376861572266\n",
      "val imitation 1.5089974403381348 reward 1.820652723312378\n",
      "val loss 3.3296501636505127 3.3368980884552\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5495192307692308}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.796474358974359}]\n",
      "______epoch 123 _____\n",
      "train imitation 1.823563814163208 reward 2.4807283878326416\n",
      "val imitation 1.5024187564849854 reward 1.820196270942688\n",
      "val loss 3.322615146636963 3.3296501636505127\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5490384615384616}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7971153846153847}]\n",
      "______epoch 124 _____\n",
      "train imitation 1.8198020458221436 reward 2.4813172817230225\n",
      "val imitation 1.4986391067504883 reward 1.820196270942688\n",
      "val loss 3.3188352584838867 3.322615146636963\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5485576923076922}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7974358974358975}]\n",
      "______epoch 125 _____\n",
      "train imitation 1.838394045829773 reward 2.47977352142334\n",
      "val imitation 1.4965640306472778 reward 1.8198683261871338\n",
      "val loss 3.316432476043701 3.3188352584838867\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5480769230769231}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7974358974358975}]\n",
      "______epoch 126 _____\n",
      "train imitation 1.8003835678100586 reward 2.481992244720459\n",
      "val imitation 1.4953504800796509 reward 1.8196678161621094\n",
      "val loss 3.3150181770324707 3.316432476043701\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5466346153846154}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7974358974358974}]\n",
      "______epoch 127 _____\n",
      "train imitation 1.820934534072876 reward 2.480835437774658\n",
      "val imitation 1.4952107667922974 reward 1.8195961713790894\n",
      "val loss 3.3148069381713867 3.3150181770324707\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5466346153846154}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.798076923076923}]\n",
      "______epoch 128 _____\n",
      "train imitation 1.7968859672546387 reward 2.480489492416382\n",
      "val imitation 1.4954211711883545 reward 1.8194808959960938\n",
      "val loss 3.3149020671844482 3.3148069381713867\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5475961538461539}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7980769230769231}]\n",
      "______epoch 129 _____\n",
      "train imitation 1.8094724416732788 reward 2.4815104007720947\n",
      "val imitation 1.4946002960205078 reward 1.8194444179534912\n",
      "val loss 3.314044713973999 3.3148069381713867\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5471153846153847}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7335526315789475}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.798397435897436}]\n",
      "______epoch 130 _____\n",
      "train imitation 1.821042776107788 reward 2.4805235862731934\n",
      "val imitation 1.4942480325698853 reward 1.8194444179534912\n",
      "val loss 3.313692569732666 3.314044713973999\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5475961538461539}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7974358974358975}]\n",
      "______epoch 131 _____\n",
      "train imitation 1.7812185287475586 reward 2.480264186859131\n",
      "val imitation 1.492890477180481 reward 1.8193881511688232\n",
      "val loss 3.3122787475585938 3.313692569732666\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5471153846153847}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7974358974358975}]\n",
      "______epoch 132 _____\n",
      "train imitation 1.8046553134918213 reward 2.47735857963562\n",
      "val imitation 1.4889633655548096 reward 1.8193881511688232\n",
      "val loss 3.308351516723633 3.3122787475585938\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7974358974358975}]\n",
      "______epoch 133 _____\n",
      "train imitation 1.7967650890350342 reward 2.480325937271118\n",
      "val imitation 1.483965277671814 reward 1.8193881511688232\n",
      "val loss 3.3033533096313477 3.308351516723633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5466346153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7980769230769231}]\n",
      "______epoch 134 _____\n",
      "train imitation 1.7943586111068726 reward 2.4836435317993164\n",
      "val imitation 1.477565050125122 reward 1.8193014860153198\n",
      "val loss 3.2968664169311523 3.3033533096313477\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5466346153846154}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564103}]\n",
      "______epoch 135 _____\n",
      "train imitation 1.8017642498016357 reward 2.481318235397339\n",
      "val imitation 1.4722037315368652 reward 1.8196395635604858\n",
      "val loss 3.2918434143066406 3.2968664169311523\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7967948717948719}]\n",
      "______epoch 136 _____\n",
      "train imitation 1.7869389057159424 reward 2.4804141521453857\n",
      "val imitation 1.4665309190750122 reward 1.820814847946167\n",
      "val loss 3.2873458862304688 3.2918434143066406\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5451923076923078}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.796474358974359}]\n",
      "______epoch 137 _____\n",
      "train imitation 1.8220627307891846 reward 2.4814372062683105\n",
      "val imitation 1.4634917974472046 reward 1.820814847946167\n",
      "val loss 3.284306526184082 3.2873458862304688\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5461538461538462}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7961538461538462}]\n",
      "______epoch 138 _____\n",
      "train imitation 1.8069254159927368 reward 2.4826831817626953\n",
      "val imitation 1.4625797271728516 reward 1.8205492496490479\n",
      "val loss 3.2831289768218994 3.284306526184082\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5456730769230769}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7961538461538461}]\n",
      "______epoch 139 _____\n",
      "train imitation 1.7720965147018433 reward 2.4814748764038086\n",
      "val imitation 1.4620249271392822 reward 1.8210539817810059\n",
      "val loss 3.283078908920288 3.2831289768218994\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5442307692307693}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7357456140350876}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7958333333333334}]\n",
      "______epoch 140 _____\n",
      "train imitation 1.7746148109436035 reward 2.483294725418091\n",
      "val imitation 1.4622955322265625 reward 1.821095585823059\n",
      "val loss 3.283390998840332 3.283078908920288\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.54375}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7945512820512821}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 141 _____\n",
      "train imitation 1.7764440774917603 reward 2.4810028076171875\n",
      "val imitation 1.462841510772705 reward 1.820778250694275\n",
      "val loss 3.2836198806762695 3.283078908920288\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5427884615384615}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7935897435897435}]\n",
      "______epoch 142 _____\n",
      "train imitation 1.7846417427062988 reward 2.4798669815063477\n",
      "val imitation 1.4622647762298584 reward 1.8213344812393188\n",
      "val loss 3.283599376678467 3.283078908920288\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5423076923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7939102564102564}]\n",
      "______epoch 143 _____\n",
      "train imitation 1.7904568910598755 reward 2.482544422149658\n",
      "val imitation 1.4611116647720337 reward 1.8210201263427734\n",
      "val loss 3.2821316719055176 3.283078908920288\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.541826923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7942307692307692}]\n",
      "______epoch 144 _____\n",
      "train imitation 1.7773897647857666 reward 2.4825944900512695\n",
      "val imitation 1.4620730876922607 reward 1.8210562467575073\n",
      "val loss 3.2831292152404785 3.2821316719055176\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5403846153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7942307692307693}]\n",
      "______epoch 145 _____\n",
      "train imitation 1.7788505554199219 reward 2.4809324741363525\n",
      "val imitation 1.46151864528656 reward 1.8210346698760986\n",
      "val loss 3.282553195953369 3.2821316719055176\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5403846153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7935897435897435}]\n",
      "______epoch 146 _____\n",
      "train imitation 1.7765796184539795 reward 2.4815328121185303\n",
      "val imitation 1.4598665237426758 reward 1.8210415840148926\n",
      "val loss 3.2809081077575684 3.2821316719055176\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5399038461538461}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7939102564102564}]\n",
      "______epoch 147 _____\n",
      "train imitation 1.7790071964263916 reward 2.48115873336792\n",
      "val imitation 1.4565653800964355 reward 1.8210415840148926\n",
      "val loss 3.277606964111328 3.2809081077575684\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5384615384615384}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7939102564102565}]\n",
      "______epoch 148 _____\n",
      "train imitation 1.787663221359253 reward 2.485243558883667\n",
      "val imitation 1.451251745223999 reward 1.8211992979049683\n",
      "val loss 3.2724509239196777 3.277606964111328\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5379807692307692}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7942307692307692}]\n",
      "______epoch 149 _____\n",
      "train imitation 1.7713041305541992 reward 2.4822678565979004\n",
      "val imitation 1.4455952644348145 reward 1.8207082748413086\n",
      "val loss 3.266303539276123 3.2724509239196777\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5365384615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7362938596491229}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7942307692307693}]\n",
      "______epoch 150 _____\n",
      "train imitation 1.794564962387085 reward 2.482011556625366\n",
      "val imitation 1.4421064853668213 reward 1.8207082748413086\n",
      "val loss 3.26281476020813 3.266303539276123\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5370192307692307}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7362938596491229}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7942307692307693}]\n",
      "______epoch 151 _____\n",
      "train imitation 1.7752232551574707 reward 2.483588695526123\n",
      "val imitation 1.4423409700393677 reward 1.820784091949463\n",
      "val loss 3.263124942779541 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5355769230769231}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7362938596491228}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7948717948717949}]\n",
      "______epoch 152 _____\n",
      "train imitation 1.7583948373794556 reward 2.482428550720215\n",
      "val imitation 1.445578694343567 reward 1.820784091949463\n",
      "val loss 3.2663626670837402 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5360576923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280701}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7948717948717949}]\n",
      "______epoch 153 _____\n",
      "train imitation 1.755638599395752 reward 2.483069896697998\n",
      "val imitation 1.448148488998413 reward 1.820784091949463\n",
      "val loss 3.268932580947876 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5346153846153846}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7942307692307693}]\n",
      "______epoch 154 _____\n",
      "train imitation 1.7580928802490234 reward 2.4814538955688477\n",
      "val imitation 1.4488050937652588 reward 1.820784091949463\n",
      "val loss 3.2695891857147217 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5331730769230769}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7935897435897437}]\n",
      "______epoch 155 _____\n",
      "train imitation 1.7675373554229736 reward 2.4820122718811035\n",
      "val imitation 1.4512735605239868 reward 1.820784091949463\n",
      "val loss 3.27205753326416 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7939102564102564}]\n",
      "______epoch 156 _____\n",
      "train imitation 1.7607899904251099 reward 2.4819953441619873\n",
      "val imitation 1.4515535831451416 reward 1.8213932514190674\n",
      "val loss 3.272946834564209 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5326923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7942307692307692}]\n",
      "______epoch 157 _____\n",
      "train imitation 1.737440824508667 reward 2.4812815189361572\n",
      "val imitation 1.4505746364593506 reward 1.8210126161575317\n",
      "val loss 3.271587371826172 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5317307692307692}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7939102564102564}]\n",
      "______epoch 158 _____\n",
      "train imitation 1.7492015361785889 reward 2.4828619956970215\n",
      "val imitation 1.4487946033477783 reward 1.8203141689300537\n",
      "val loss 3.269108772277832 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.53125}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7942307692307692}]\n",
      "______epoch 159 _____\n",
      "train imitation 1.7579249143600464 reward 2.4814326763153076\n",
      "val imitation 1.447793960571289 reward 1.8203800916671753\n",
      "val loss 3.268174171447754 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5302884615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7939102564102565}]\n",
      "______epoch 160 _____\n",
      "train imitation 1.76446533203125 reward 2.481436252593994\n",
      "val imitation 1.4437813758850098 reward 1.8198890686035156\n",
      "val loss 3.2636704444885254 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5302884615384614}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7951923076923078}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 161 _____\n",
      "train imitation 1.760594129562378 reward 2.4829838275909424\n",
      "val imitation 1.4400111436843872 reward 1.8198890686035156\n",
      "val loss 3.2599000930786133 3.26281476020813\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5298076923076922}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7951923076923078}]\n",
      "______epoch 162 _____\n",
      "train imitation 1.752781629562378 reward 2.481311559677124\n",
      "val imitation 1.4357887506484985 reward 1.8187434673309326\n",
      "val loss 3.2545323371887207 3.2599000930786133\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5298076923076922}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7958333333333334}]\n",
      "______epoch 163 _____\n",
      "train imitation 1.740387201309204 reward 2.4812569618225098\n",
      "val imitation 1.4304805994033813 reward 1.8183276653289795\n",
      "val loss 3.2488083839416504 3.2545323371887207\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5302884615384614}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7958333333333334}]\n",
      "______epoch 164 _____\n",
      "train imitation 1.7296169996261597 reward 2.484745740890503\n",
      "val imitation 1.422903299331665 reward 1.8184051513671875\n",
      "val loss 3.2413084506988525 3.2488083839416504\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5317307692307691}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.796474358974359}]\n",
      "______epoch 165 _____\n",
      "train imitation 1.7536637783050537 reward 2.483445167541504\n",
      "val imitation 1.4167048931121826 reward 1.8174769878387451\n",
      "val loss 3.2341818809509277 3.2413084506988525\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5312499999999999}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7980769230769231}]\n",
      "______epoch 166 _____\n",
      "train imitation 1.7560675144195557 reward 2.4825241565704346\n",
      "val imitation 1.4138280153274536 reward 1.8174283504486084\n",
      "val loss 3.2312564849853516 3.2341818809509277\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5302884615384614}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7321820175438596}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7987179487179488}]\n",
      "______epoch 167 _____\n",
      "train imitation 1.741100549697876 reward 2.4815032482147217\n",
      "val imitation 1.411630392074585 reward 1.8174283504486084\n",
      "val loss 3.2290587425231934 3.2312564849853516\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5302884615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 168 _____\n",
      "train imitation 1.7264653444290161 reward 2.482112407684326\n",
      "val imitation 1.41239595413208 reward 1.8174283504486084\n",
      "val loss 3.2298243045806885 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5302884615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7999999999999999}]\n",
      "______epoch 169 _____\n",
      "train imitation 1.7175041437149048 reward 2.4828152656555176\n",
      "val imitation 1.4154324531555176 reward 1.8174257278442383\n",
      "val loss 3.232858180999756 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5274038461538462}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 170 _____\n",
      "train imitation 1.7312568426132202 reward 2.4821066856384277\n",
      "val imitation 1.417091965675354 reward 1.8175126314163208\n",
      "val loss 3.234604597091675 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5254807692307691}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508772}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589743}]\n",
      "______epoch 171 _____\n",
      "train imitation 1.7392373085021973 reward 2.4813950061798096\n",
      "val imitation 1.421805500984192 reward 1.8172900676727295\n",
      "val loss 3.239095687866211 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5225961538461538}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.798397435897436}]\n",
      "______epoch 172 _____\n",
      "train imitation 1.7212114334106445 reward 2.480984926223755\n",
      "val imitation 1.4268033504486084 reward 1.8170897960662842\n",
      "val loss 3.2438931465148926 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5187499999999999}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.798397435897436}]\n",
      "______epoch 173 _____\n",
      "train imitation 1.7061471939086914 reward 2.4836056232452393\n",
      "val imitation 1.4320242404937744 reward 1.8169986009597778\n",
      "val loss 3.249022960662842 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5177884615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7974358974358975}]\n",
      "______epoch 174 _____\n",
      "train imitation 1.731870412826538 reward 2.4830422401428223\n",
      "val imitation 1.4352599382400513 reward 1.8169445991516113\n",
      "val loss 3.252204418182373 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5153846153846153}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7319078947368421}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7974358974358975}]\n",
      "______epoch 175 _____\n",
      "train imitation 1.7140827178955078 reward 2.4825680255889893\n",
      "val imitation 1.4383736848831177 reward 1.8169445991516113\n",
      "val loss 3.2553181648254395 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5134615384615385}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7321820175438597}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7971153846153847}]\n",
      "______epoch 176 _____\n",
      "train imitation 1.700239658355713 reward 2.4828076362609863\n",
      "val imitation 1.439739465713501 reward 1.8169445991516113\n",
      "val loss 3.2566840648651123 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5120192307692308}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7974358974358975}]\n",
      "______epoch 177 _____\n",
      "train imitation 1.7345523834228516 reward 2.481289863586426\n",
      "val imitation 1.4438890218734741 reward 1.815979242324829\n",
      "val loss 3.2598681449890137 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5110576923076924}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7958333333333334}]\n",
      "______epoch 178 _____\n",
      "train imitation 1.7614425420761108 reward 2.482095956802368\n",
      "val imitation 1.4444239139556885 reward 1.815979242324829\n",
      "val loss 3.2604031562805176 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5100961538461538}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7951923076923078}]\n",
      "______epoch 179 _____\n",
      "train imitation 1.7326791286468506 reward 2.4792163372039795\n",
      "val imitation 1.4429941177368164 reward 1.8158246278762817\n",
      "val loss 3.2588186264038086 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5110576923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7330043859649122}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7961538461538461}]\n",
      "______epoch 180 _____\n",
      "train imitation 1.7088563442230225 reward 2.4800474643707275\n",
      "val imitation 1.4373762607574463 reward 1.8158576488494873\n",
      "val loss 3.2532339096069336 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5110576923076924}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7961538461538461}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 181 _____\n",
      "train imitation 1.727980613708496 reward 2.480835199356079\n",
      "val imitation 1.4322185516357422 reward 1.815735936164856\n",
      "val loss 3.2479543685913086 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5100961538461538}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7971153846153846}]\n",
      "______epoch 182 _____\n",
      "train imitation 1.7439889907836914 reward 2.4816370010375977\n",
      "val imitation 1.4265334606170654 reward 1.8155872821807861\n",
      "val loss 3.2421207427978516 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7324561403508772}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7974358974358975}]\n",
      "______epoch 183 _____\n",
      "train imitation 1.7169439792633057 reward 2.4829564094543457\n",
      "val imitation 1.4235923290252686 reward 1.8155872821807861\n",
      "val loss 3.2391796112060547 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5110576923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564103}]\n",
      "______epoch 184 _____\n",
      "train imitation 1.7392480373382568 reward 2.484003782272339\n",
      "val imitation 1.4207348823547363 reward 1.8155872821807861\n",
      "val loss 3.2363221645355225 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5110576923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7335526315789475}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564102}]\n",
      "______epoch 185 _____\n",
      "train imitation 1.724975824356079 reward 2.481079339981079\n",
      "val imitation 1.4189283847808838 reward 1.8155872821807861\n",
      "val loss 3.23451566696167 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5149038461538461}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7977564102564103}]\n",
      "______epoch 186 _____\n",
      "train imitation 1.7401986122131348 reward 2.483158826828003\n",
      "val imitation 1.4211945533752441 reward 1.8155872821807861\n",
      "val loss 3.2367818355560303 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5144230769230769}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7971153846153846}]\n",
      "______epoch 187 _____\n",
      "train imitation 1.7046988010406494 reward 2.4814138412475586\n",
      "val imitation 1.4246773719787598 reward 1.8155872821807861\n",
      "val loss 3.240264654159546 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5144230769230769}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7977564102564103}]\n",
      "______epoch 188 _____\n",
      "train imitation 1.7117235660552979 reward 2.482640027999878\n",
      "val imitation 1.4261465072631836 reward 1.815709114074707\n",
      "val loss 3.2418556213378906 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5134615384615384}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7376644736842105}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7980769230769231}]\n",
      "______epoch 189 _____\n",
      "train imitation 1.7176775932312012 reward 2.4824209213256836\n",
      "val imitation 1.4288899898529053 reward 1.815709114074707\n",
      "val loss 3.2445991039276123 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5125}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7382127192982456}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7971153846153847}]\n",
      "______epoch 190 _____\n",
      "train imitation 1.7038698196411133 reward 2.4826419353485107\n",
      "val imitation 1.4309964179992676 reward 1.815709114074707\n",
      "val loss 3.2467055320739746 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7977564102564103}]\n",
      "______epoch 191 _____\n",
      "train imitation 1.694540023803711 reward 2.481687307357788\n",
      "val imitation 1.4295024871826172 reward 1.815709114074707\n",
      "val loss 3.245211601257324 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7368421052631579}, {'decision': 2, 'accuracy': 0.7808219178082192, 'auc': 0.7974358974358975}]\n",
      "______epoch 192 _____\n",
      "train imitation 1.7093541622161865 reward 2.4813292026519775\n",
      "val imitation 1.4252305030822754 reward 1.815682291984558\n",
      "val loss 3.240912914276123 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7980769230769231}]\n",
      "______epoch 193 _____\n",
      "train imitation 1.7317979335784912 reward 2.4822096824645996\n",
      "val imitation 1.4219930171966553 reward 1.815682291984558\n",
      "val loss 3.237675189971924 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7977564102564103}]\n",
      "______epoch 194 _____\n",
      "train imitation 1.719306230545044 reward 2.4816346168518066\n",
      "val imitation 1.4199914932250977 reward 1.815682291984558\n",
      "val loss 3.2356739044189453 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7983974358974358}]\n",
      "______epoch 195 _____\n",
      "train imitation 1.7044353485107422 reward 2.482534408569336\n",
      "val imitation 1.4155415296554565 reward 1.8155605792999268\n",
      "val loss 3.2311019897460938 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384615}]\n",
      "______epoch 196 _____\n",
      "train imitation 1.7019137144088745 reward 2.4831504821777344\n",
      "val imitation 1.4109230041503906 reward 1.8155605792999268\n",
      "val loss 3.2264835834503174 3.2290587425231934\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7993589743589743}]\n",
      "______epoch 197 _____\n",
      "train imitation 1.6958563327789307 reward 2.482128620147705\n",
      "val imitation 1.4076284170150757 reward 1.815682291984558\n",
      "val loss 3.223310708999634 3.2264835834503174\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8006410256410257}]\n",
      "______epoch 198 _____\n",
      "train imitation 1.7136013507843018 reward 2.482158899307251\n",
      "val imitation 1.407045841217041 reward 1.8158308267593384\n",
      "val loss 3.22287654876709 3.223310708999634\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5091346153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8016025641025641}]\n",
      "______epoch 199 _____\n",
      "train imitation 1.716805100440979 reward 2.4829540252685547\n",
      "val imitation 1.407379388809204 reward 1.8162306547164917\n",
      "val loss 3.2236099243164062 3.22287654876709\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5091346153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8016025641025641}]\n",
      "______epoch 200 _____\n",
      "train imitation 1.70463228225708 reward 2.478933811187744\n",
      "val imitation 1.406688928604126 reward 1.8163851499557495\n",
      "val loss 3.223073959350586 3.22287654876709\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8016025641025641}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 201 _____\n",
      "train imitation 1.7105761766433716 reward 2.481346845626831\n",
      "val imitation 1.4056450128555298 reward 1.8159854412078857\n",
      "val loss 3.221630573272705 3.22287654876709\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421052}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8025641025641026}]\n",
      "______epoch 202 _____\n",
      "train imitation 1.6771354675292969 reward 2.48415207862854\n",
      "val imitation 1.4048759937286377 reward 1.8159854412078857\n",
      "val loss 3.2208614349365234 3.221630573272705\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5091346153846154}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7371162280701755}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8032051282051282}]\n",
      "______epoch 203 _____\n",
      "train imitation 1.6865496635437012 reward 2.480445384979248\n",
      "val imitation 1.4042752981185913 reward 1.8159854412078857\n",
      "val loss 3.2202606201171875 3.2208614349365234\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5081730769230769}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8035256410256411}]\n",
      "______epoch 204 _____\n",
      "train imitation 1.7121086120605469 reward 2.4826505184173584\n",
      "val imitation 1.4059572219848633 reward 1.8161823749542236\n",
      "val loss 3.222139596939087 3.2202606201171875\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8032051282051282}]\n",
      "______epoch 205 _____\n",
      "train imitation 1.667987585067749 reward 2.4827589988708496\n",
      "val imitation 1.407424807548523 reward 1.8161823749542236\n",
      "val loss 3.223607063293457 3.2202606201171875\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7371162280701754}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8028846153846154}]\n",
      "______epoch 206 _____\n",
      "train imitation 1.678665280342102 reward 2.483187675476074\n",
      "val imitation 1.4078004360198975 reward 1.8161498308181763\n",
      "val loss 3.2239503860473633 3.2202606201171875\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8028846153846154}]\n",
      "______epoch 207 _____\n",
      "train imitation 1.698819875717163 reward 2.4839935302734375\n",
      "val imitation 1.4066078662872314 reward 1.8161498308181763\n",
      "val loss 3.2227578163146973 3.2202606201171875\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7360197368421053}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8025641025641026}]\n",
      "______epoch 208 _____\n",
      "train imitation 1.6712701320648193 reward 2.4816627502441406\n",
      "val imitation 1.4024004936218262 reward 1.8161498308181763\n",
      "val loss 3.218550205230713 3.2202606201171875\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8025641025641026}]\n",
      "______epoch 209 _____\n",
      "train imitation 1.6734344959259033 reward 2.482548713684082\n",
      "val imitation 1.395850419998169 reward 1.8161784410476685\n",
      "val loss 3.212028980255127 3.218550205230713\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.8025641025641026}]\n",
      "______epoch 210 _____\n",
      "train imitation 1.6661128997802734 reward 2.4838578701019287\n",
      "val imitation 1.3897408246994019 reward 1.8162410259246826\n",
      "val loss 3.205981731414795 3.212028980255127\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.801923076923077}]\n",
      "______epoch 211 _____\n",
      "train imitation 1.6827216148376465 reward 2.483018636703491\n",
      "val imitation 1.382872462272644 reward 1.8172105550765991\n",
      "val loss 3.200083017349243 3.205981731414795\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5091346153846154}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.801923076923077}]\n",
      "______epoch 212 _____\n",
      "train imitation 1.6573433876037598 reward 2.4835124015808105\n",
      "val imitation 1.3766709566116333 reward 1.8170888423919678\n",
      "val loss 3.1937599182128906 3.200083017349243\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5100961538461538}, {'decision': 1, 'accuracy': 0.8082191780821918, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.801923076923077}]\n",
      "______epoch 213 _____\n",
      "train imitation 1.664546012878418 reward 2.4826347827911377\n",
      "val imitation 1.371954083442688 reward 1.8170888423919678\n",
      "val loss 3.1890430450439453 3.1937599182128906\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8025641025641026}]\n",
      "______epoch 214 _____\n",
      "train imitation 1.6633802652359009 reward 2.484769344329834\n",
      "val imitation 1.3706378936767578 reward 1.8168799877166748\n",
      "val loss 3.1875178813934326 3.1890430450439453\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5081730769230769}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8025641025641026}]\n",
      "______epoch 215 _____\n",
      "train imitation 1.6723408699035645 reward 2.483140230178833\n",
      "val imitation 1.3737553358078003 reward 1.8168171644210815\n",
      "val loss 3.190572500228882 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8006410256410257}]\n",
      "______epoch 216 _____\n",
      "train imitation 1.6730775833129883 reward 2.4831199645996094\n",
      "val imitation 1.3771979808807373 reward 1.8168171644210815\n",
      "val loss 3.1940150260925293 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8006410256410257}]\n",
      "______epoch 217 _____\n",
      "train imitation 1.6836512088775635 reward 2.4845523834228516\n",
      "val imitation 1.381028175354004 reward 1.8168171644210815\n",
      "val loss 3.197845458984375 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8003205128205129}]\n",
      "______epoch 218 _____\n",
      "train imitation 1.6748261451721191 reward 2.4823200702667236\n",
      "val imitation 1.3826024532318115 reward 1.8167020082473755\n",
      "val loss 3.1993045806884766 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794871}]\n",
      "______epoch 219 _____\n",
      "train imitation 1.6727367639541626 reward 2.484086036682129\n",
      "val imitation 1.382874846458435 reward 1.8168401718139648\n",
      "val loss 3.1997151374816895 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794871}]\n",
      "______epoch 220 _____\n",
      "train imitation 1.6758995056152344 reward 2.483410596847534\n",
      "val imitation 1.385133147239685 reward 1.8168401718139648\n",
      "val loss 3.2019734382629395 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794871}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 221 _____\n",
      "train imitation 1.6674991846084595 reward 2.482182502746582\n",
      "val imitation 1.389969825744629 reward 1.8169028759002686\n",
      "val loss 3.2068727016448975 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384615}]\n",
      "______epoch 222 _____\n",
      "train imitation 1.6804496049880981 reward 2.484210252761841\n",
      "val imitation 1.3938969373703003 reward 1.8167219161987305\n",
      "val loss 3.2106189727783203 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384615}]\n",
      "______epoch 223 _____\n",
      "train imitation 1.6675317287445068 reward 2.4845800399780273\n",
      "val imitation 1.3937088251113892 reward 1.8167524337768555\n",
      "val loss 3.210461139678955 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7987179487179488}]\n",
      "______epoch 224 _____\n",
      "train imitation 1.700554609298706 reward 2.4828715324401855\n",
      "val imitation 1.392603874206543 reward 1.8165671825408936\n",
      "val loss 3.2091710567474365 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 225 _____\n",
      "train imitation 1.669937014579773 reward 2.4874472618103027\n",
      "val imitation 1.3869385719299316 reward 1.8165671825408936\n",
      "val loss 3.203505754470825 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 226 _____\n",
      "train imitation 1.6699646711349487 reward 2.482086658477783\n",
      "val imitation 1.381947636604309 reward 1.8165671825408936\n",
      "val loss 3.198514938354492 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8022435897435898}]\n",
      "______epoch 227 _____\n",
      "train imitation 1.6782974004745483 reward 2.4839799404144287\n",
      "val imitation 1.3795498609542847 reward 1.8164455890655518\n",
      "val loss 3.195995330810547 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.8022435897435898}]\n",
      "______epoch 228 _____\n",
      "train imitation 1.6831965446472168 reward 2.482370615005493\n",
      "val imitation 1.378988265991211 reward 1.8161964416503906\n",
      "val loss 3.1951847076416016 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8019230769230768}]\n",
      "______epoch 229 _____\n",
      "train imitation 1.673036813735962 reward 2.4828133583068848\n",
      "val imitation 1.3766889572143555 reward 1.8161964416503906\n",
      "val loss 3.192885398864746 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.8013698630136986, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.801923076923077}]\n",
      "______epoch 230 _____\n",
      "train imitation 1.6501400470733643 reward 2.483659029006958\n",
      "val imitation 1.3760287761688232 reward 1.8161964416503906\n",
      "val loss 3.192225217819214 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.7945205479452054, 'auc': 0.7362938596491229}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801923076923077}]\n",
      "______epoch 231 _____\n",
      "train imitation 1.659635305404663 reward 2.4825377464294434\n",
      "val imitation 1.374961018562317 reward 1.8161964416503906\n",
      "val loss 3.191157341003418 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7371162280701755}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8032051282051282}]\n",
      "______epoch 232 _____\n",
      "train imitation 1.6621372699737549 reward 2.484959363937378\n",
      "val imitation 1.3733530044555664 reward 1.8161964416503906\n",
      "val loss 3.189549446105957 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7393092105263158}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8022435897435898}]\n",
      "______epoch 233 _____\n",
      "train imitation 1.6480052471160889 reward 2.4833173751831055\n",
      "val imitation 1.3721203804016113 reward 1.816381812095642\n",
      "val loss 3.188502311706543 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.8082191780821918, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7395833333333334}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8028846153846154}]\n",
      "______epoch 234 _____\n",
      "train imitation 1.6844427585601807 reward 2.483415126800537\n",
      "val imitation 1.374552607536316 reward 1.816285252571106\n",
      "val loss 3.190837860107422 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5052884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8022435897435898}]\n",
      "______epoch 235 _____\n",
      "train imitation 1.653961181640625 reward 2.4843451976776123\n",
      "val imitation 1.3766118288040161 reward 1.816285252571106\n",
      "val loss 3.192897081375122 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7398574561403508}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8025641025641026}]\n",
      "______epoch 236 _____\n",
      "train imitation 1.6430667638778687 reward 2.483917236328125\n",
      "val imitation 1.3789713382720947 reward 1.816285252571106\n",
      "val loss 3.1952567100524902 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7390350877192983}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8032051282051282}]\n",
      "______epoch 237 _____\n",
      "train imitation 1.6318931579589844 reward 2.4844794273376465\n",
      "val imitation 1.3774749040603638 reward 1.8165627717971802\n",
      "val loss 3.194037675857544 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7368421052631579}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8038461538461539}]\n",
      "______epoch 238 _____\n",
      "train imitation 1.6331393718719482 reward 2.484710693359375\n",
      "val imitation 1.3741683959960938 reward 1.816080927848816\n",
      "val loss 3.190249443054199 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 239 _____\n",
      "train imitation 1.6749286651611328 reward 2.4850566387176514\n",
      "val imitation 1.3741188049316406 reward 1.8162564039230347\n",
      "val loss 3.190375328063965 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 240 _____\n",
      "train imitation 1.62760329246521 reward 2.483032464981079\n",
      "val imitation 1.3714319467544556 reward 1.8162564039230347\n",
      "val loss 3.1876883506774902 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7321820175438596}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8051282051282052}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 241 _____\n",
      "train imitation 1.6327741146087646 reward 2.4851958751678467\n",
      "val imitation 1.3673179149627686 reward 1.816159725189209\n",
      "val loss 3.1834776401519775 3.1875178813934326\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.805128205128205}]\n",
      "______epoch 242 _____\n",
      "train imitation 1.628965139389038 reward 2.4849343299865723\n",
      "val imitation 1.366400957107544 reward 1.8164238929748535\n",
      "val loss 3.1828248500823975 3.1834776401519775\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8060897435897436}]\n",
      "______epoch 243 _____\n",
      "train imitation 1.6580678224563599 reward 2.483529567718506\n",
      "val imitation 1.3684332370758057 reward 1.8164238929748535\n",
      "val loss 3.184857130050659 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.805448717948718}]\n",
      "______epoch 244 _____\n",
      "train imitation 1.6351540088653564 reward 2.484349012374878\n",
      "val imitation 1.3730170726776123 reward 1.8169100284576416\n",
      "val loss 3.189927101135254 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8057692307692308}]\n",
      "______epoch 245 _____\n",
      "train imitation 1.6294870376586914 reward 2.484415292739868\n",
      "val imitation 1.3770017623901367 reward 1.8168061971664429\n",
      "val loss 3.193808078765869 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49759615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8060897435897436}]\n",
      "______epoch 246 _____\n",
      "train imitation 1.6421539783477783 reward 2.483630895614624\n",
      "val imitation 1.383162260055542 reward 1.8162809610366821\n",
      "val loss 3.1994433403015137 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8057692307692308}]\n",
      "______epoch 247 _____\n",
      "train imitation 1.636319875717163 reward 2.487144947052002\n",
      "val imitation 1.3828446865081787 reward 1.8169331550598145\n",
      "val loss 3.199777841567993 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7299890350877193}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8051282051282052}]\n",
      "______epoch 248 _____\n",
      "train imitation 1.623247504234314 reward 2.487631320953369\n",
      "val imitation 1.3814222812652588 reward 1.8169331550598145\n",
      "val loss 3.1983554363250732 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7297149122807017}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8048076923076923}]\n",
      "______epoch 249 _____\n",
      "train imitation 1.6324762105941772 reward 2.48506760597229\n",
      "val imitation 1.3791134357452393 reward 1.8168061971664429\n",
      "val loss 3.1959195137023926 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.805448717948718}]\n",
      "______epoch 250 _____\n",
      "train imitation 1.6024116277694702 reward 2.4867942333221436\n",
      "val imitation 1.3746445178985596 reward 1.816749930381775\n",
      "val loss 3.191394329071045 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8048076923076923}]\n",
      "______epoch 251 _____\n",
      "train imitation 1.63074791431427 reward 2.4852068424224854\n",
      "val imitation 1.371305227279663 reward 1.8167791366577148\n",
      "val loss 3.188084363937378 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.728344298245614}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8051282051282052}]\n",
      "______epoch 252 _____\n",
      "train imitation 1.6166528463363647 reward 2.483949899673462\n",
      "val imitation 1.3678841590881348 reward 1.8165366649627686\n",
      "val loss 3.1844208240509033 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8041666666666667}]\n",
      "______epoch 253 _____\n",
      "train imitation 1.6217799186706543 reward 2.4842443466186523\n",
      "val imitation 1.3631229400634766 reward 1.8165366649627686\n",
      "val loss 3.179659605026245 3.1828248500823975\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8038461538461539}]\n",
      "______epoch 254 _____\n",
      "train imitation 1.6256208419799805 reward 2.484144687652588\n",
      "val imitation 1.3609323501586914 reward 1.8166403770446777\n",
      "val loss 3.177572727203369 3.179659605026245\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8051282051282052}]\n",
      "______epoch 255 _____\n",
      "train imitation 1.6321901082992554 reward 2.484523057937622\n",
      "val imitation 1.3568611145019531 reward 1.8165366649627686\n",
      "val loss 3.1733977794647217 3.177572727203369\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5043269230769232}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8057692307692307}]\n",
      "______epoch 256 _____\n",
      "train imitation 1.6130164861679077 reward 2.4833791255950928\n",
      "val imitation 1.3513901233673096 reward 1.816380500793457\n",
      "val loss 3.1677706241607666 3.1733977794647217\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8060897435897436}]\n",
      "______epoch 257 _____\n",
      "train imitation 1.641463279724121 reward 2.4832510948181152\n",
      "val imitation 1.3501886129379272 reward 1.8160481452941895\n",
      "val loss 3.1662368774414062 3.1677706241607666\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8064102564102564}]\n",
      "______epoch 258 _____\n",
      "train imitation 1.6222153902053833 reward 2.4844372272491455\n",
      "val imitation 1.3515794277191162 reward 1.8162331581115723\n",
      "val loss 3.1678125858306885 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7327302631578947}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8060897435897436}]\n",
      "______epoch 259 _____\n",
      "train imitation 1.6428627967834473 reward 2.4841043949127197\n",
      "val imitation 1.3576774597167969 reward 1.8161741495132446\n",
      "val loss 3.173851490020752 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8044871794871795}]\n",
      "______epoch 260 _____\n",
      "train imitation 1.655304193496704 reward 2.486220121383667\n",
      "val imitation 1.3668371438980103 reward 1.816388487815857\n",
      "val loss 3.183225631713867 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7357456140350878}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.8038461538461539}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 261 _____\n",
      "train imitation 1.6027308702468872 reward 2.4834914207458496\n",
      "val imitation 1.3723275661468506 reward 1.816253662109375\n",
      "val loss 3.1885812282562256 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7376644736842105}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8025641025641026}]\n",
      "______epoch 262 _____\n",
      "train imitation 1.5955513715744019 reward 2.4875967502593994\n",
      "val imitation 1.3750556707382202 reward 1.816253662109375\n",
      "val loss 3.1913094520568848 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8022435897435898}]\n",
      "______epoch 263 _____\n",
      "train imitation 1.6182931661605835 reward 2.4860429763793945\n",
      "val imitation 1.3775629997253418 reward 1.816253662109375\n",
      "val loss 3.193816661834717 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7368421052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8012820512820513}]\n",
      "______epoch 264 _____\n",
      "train imitation 1.613182544708252 reward 2.4855194091796875\n",
      "val imitation 1.3752400875091553 reward 1.816253662109375\n",
      "val loss 3.1914937496185303 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7376644736842105}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.801923076923077}]\n",
      "______epoch 265 _____\n",
      "train imitation 1.6357851028442383 reward 2.483476161956787\n",
      "val imitation 1.3738958835601807 reward 1.816253662109375\n",
      "val loss 3.1901495456695557 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4995192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.737390350877193}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.801923076923077}]\n",
      "______epoch 266 _____\n",
      "train imitation 1.5934243202209473 reward 2.484870672225952\n",
      "val imitation 1.3692631721496582 reward 1.8163690567016602\n",
      "val loss 3.1856322288513184 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7365679824561404}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8025641025641026}]\n",
      "______epoch 267 _____\n",
      "train imitation 1.585719108581543 reward 2.4850947856903076\n",
      "val imitation 1.363027572631836 reward 1.8163690567016602\n",
      "val loss 3.179396629333496 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4985576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7354714912280702}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8032051282051282}]\n",
      "______epoch 268 _____\n",
      "train imitation 1.6358646154403687 reward 2.483828544616699\n",
      "val imitation 1.3595099449157715 reward 1.8163126707077026\n",
      "val loss 3.1758227348327637 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7354714912280701}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641026}]\n",
      "______epoch 269 _____\n",
      "train imitation 1.620589256286621 reward 2.4837164878845215\n",
      "val imitation 1.3604525327682495 reward 1.8161276578903198\n",
      "val loss 3.1765801906585693 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7349232456140351}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8022435897435897}]\n",
      "______epoch 270 _____\n",
      "train imitation 1.6169334650039673 reward 2.484118938446045\n",
      "val imitation 1.3616341352462769 reward 1.8155434131622314\n",
      "val loss 3.1771774291992188 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4971153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7341008771929824}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.801923076923077}]\n",
      "______epoch 271 _____\n",
      "train imitation 1.5905303955078125 reward 2.4835450649261475\n",
      "val imitation 1.36383855342865 reward 1.815503716468811\n",
      "val loss 3.179342269897461 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49567307692307694}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7338267543859649}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801923076923077}]\n",
      "______epoch 272 _____\n",
      "train imitation 1.5886234045028687 reward 2.486217498779297\n",
      "val imitation 1.3641120195388794 reward 1.8153883218765259\n",
      "val loss 3.1795003414154053 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49567307692307694}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.801923076923077}]\n",
      "______epoch 273 _____\n",
      "train imitation 1.5870299339294434 reward 2.484696626663208\n",
      "val imitation 1.361547827720642 reward 1.8153883218765259\n",
      "val loss 3.176936149597168 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49567307692307694}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8032051282051282}]\n",
      "______epoch 274 _____\n",
      "train imitation 1.603201150894165 reward 2.482362747192383\n",
      "val imitation 1.3575752973556519 reward 1.8153883218765259\n",
      "val loss 3.1729636192321777 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49423076923076925}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641026}]\n",
      "______epoch 275 _____\n",
      "train imitation 1.601049780845642 reward 2.484066963195801\n",
      "val imitation 1.356419324874878 reward 1.8155232667922974\n",
      "val loss 3.171942710876465 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4913461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.801923076923077}]\n",
      "______epoch 276 _____\n",
      "train imitation 1.5814785957336426 reward 2.4844753742218018\n",
      "val imitation 1.357515573501587 reward 1.8155945539474487\n",
      "val loss 3.173110008239746 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4913461538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8012820512820513}]\n",
      "______epoch 277 _____\n",
      "train imitation 1.603941559791565 reward 2.486111640930176\n",
      "val imitation 1.3583407402038574 reward 1.8155945539474487\n",
      "val loss 3.1739354133605957 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8003205128205129}]\n",
      "______epoch 278 _____\n",
      "train imitation 1.6135069131851196 reward 2.4850411415100098\n",
      "val imitation 1.3591105937957764 reward 1.8155945539474487\n",
      "val loss 3.1747050285339355 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49086538461538465}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8003205128205129}]\n",
      "______epoch 279 _____\n",
      "train imitation 1.5784785747528076 reward 2.4841580390930176\n",
      "val imitation 1.3572821617126465 reward 1.8154597282409668\n",
      "val loss 3.1727418899536133 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4918269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8006410256410257}]\n",
      "______epoch 280 _____\n",
      "train imitation 1.5857253074645996 reward 2.484752893447876\n",
      "val imitation 1.3552544116973877 reward 1.8154597282409668\n",
      "val loss 3.1707141399383545 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4966346153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017545}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8003205128205129}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 281 _____\n",
      "train imitation 1.5937196016311646 reward 2.4814929962158203\n",
      "val imitation 1.3543092012405396 reward 1.815332055091858\n",
      "val loss 3.1696412563323975 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.4985576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7330043859649122}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8}]\n",
      "______epoch 282 _____\n",
      "train imitation 1.5923165082931519 reward 2.4835963249206543\n",
      "val imitation 1.3559592962265015 reward 1.815332055091858\n",
      "val loss 3.1712913513183594 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7335526315789473}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8006410256410257}]\n",
      "______epoch 283 _____\n",
      "train imitation 1.6047074794769287 reward 2.4842631816864014\n",
      "val imitation 1.3614331483840942 reward 1.8154473304748535\n",
      "val loss 3.176880359649658 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49615384615384617}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7332785087719298}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8003205128205129}]\n",
      "______epoch 284 _____\n",
      "train imitation 1.5816978216171265 reward 2.484553813934326\n",
      "val imitation 1.3692458868026733 reward 1.815332055091858\n",
      "val loss 3.1845779418945312 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4932692307692308}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.7876712328767124, 'auc': 0.7996794871794872}]\n",
      "______epoch 285 _____\n",
      "train imitation 1.5903072357177734 reward 2.4828622341156006\n",
      "val imitation 1.3763023614883423 reward 1.8154597282409668\n",
      "val loss 3.1917619705200195 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4908653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736843}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384616}]\n",
      "______epoch 286 _____\n",
      "train imitation 1.603549599647522 reward 2.483689785003662\n",
      "val imitation 1.3765943050384521 reward 1.815735936164856\n",
      "val loss 3.1923303604125977 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4923076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7987179487179488}]\n",
      "______epoch 287 _____\n",
      "train imitation 1.5936994552612305 reward 2.4855563640594482\n",
      "val imitation 1.3754537105560303 reward 1.8157763481140137\n",
      "val loss 3.191230058670044 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7299890350877194}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7999999999999999}]\n",
      "______epoch 288 _____\n",
      "train imitation 1.6254624128341675 reward 2.483461856842041\n",
      "val imitation 1.3684245347976685 reward 1.8157763481140137\n",
      "val loss 3.1842007637023926 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49423076923076925}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8006410256410257}]\n",
      "______epoch 289 _____\n",
      "train imitation 1.5644441843032837 reward 2.4840962886810303\n",
      "val imitation 1.360285997390747 reward 1.8157641887664795\n",
      "val loss 3.1760501861572266 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4966346153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7321820175438596}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.801923076923077}]\n",
      "______epoch 290 _____\n",
      "train imitation 1.593820333480835 reward 2.4847540855407715\n",
      "val imitation 1.3538594245910645 reward 1.8154879808425903\n",
      "val loss 3.1693472862243652 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49759615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7330043859649122}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8012820512820513}]\n",
      "______epoch 291 _____\n",
      "train imitation 1.5618562698364258 reward 2.484539747238159\n",
      "val imitation 1.3473371267318726 reward 1.8154879808425903\n",
      "val loss 3.162825107574463 3.1662368774414062\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n",
      "______epoch 292 _____\n",
      "train imitation 1.5718932151794434 reward 2.485325813293457\n",
      "val imitation 1.3438516855239868 reward 1.8159373998641968\n",
      "val loss 3.1597890853881836 3.162825107574463\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7351973684210527}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8016025641025641}]\n",
      "______epoch 293 _____\n",
      "train imitation 1.5621960163116455 reward 2.486454963684082\n",
      "val imitation 1.3430166244506836 reward 1.815840721130371\n",
      "val loss 3.1588573455810547 3.1597890853881836\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7346491228070176}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801923076923077}]\n",
      "______epoch 294 _____\n",
      "train imitation 1.5858047008514404 reward 2.485342264175415\n",
      "val imitation 1.3451220989227295 reward 1.8158042430877686\n",
      "val loss 3.160926342010498 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.8013698630136986, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.734375}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8022435897435898}]\n",
      "______epoch 295 _____\n",
      "train imitation 1.586355209350586 reward 2.487291097640991\n",
      "val imitation 1.3509492874145508 reward 1.8154879808425903\n",
      "val loss 3.1664371490478516 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 296 _____\n",
      "train imitation 1.5614147186279297 reward 2.485121250152588\n",
      "val imitation 1.3578128814697266 reward 1.815394401550293\n",
      "val loss 3.1732072830200195 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4961538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641026}]\n",
      "______epoch 297 _____\n",
      "train imitation 1.5990703105926514 reward 2.486318826675415\n",
      "val imitation 1.3613134622573853 reward 1.815394401550293\n",
      "val loss 3.1767077445983887 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4966346153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 298 _____\n",
      "train imitation 1.560802698135376 reward 2.487424850463867\n",
      "val imitation 1.3593426942825317 reward 1.815976619720459\n",
      "val loss 3.175319194793701 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4971153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7321820175438597}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8032051282051282}]\n",
      "______epoch 299 _____\n",
      "train imitation 1.5849418640136719 reward 2.4857800006866455\n",
      "val imitation 1.3559784889221191 reward 1.815976619720459\n",
      "val loss 3.171955108642578 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8032051282051282}]\n",
      "______epoch 300 _____\n",
      "train imitation 1.5688929557800293 reward 2.487877607345581\n",
      "val imitation 1.354516863822937 reward 1.815976619720459\n",
      "val loss 3.1704936027526855 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8028846153846154}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 301 _____\n",
      "train imitation 1.548879623413086 reward 2.4856514930725098\n",
      "val imitation 1.3518351316452026 reward 1.8162614107131958\n",
      "val loss 3.1680965423583984 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49999999999999994}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7327302631578948}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8019230769230768}]\n",
      "______epoch 302 _____\n",
      "train imitation 1.5642406940460205 reward 2.484699249267578\n",
      "val imitation 1.3538289070129395 reward 1.8162614107131958\n",
      "val loss 3.1700901985168457 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8022435897435897}]\n",
      "______epoch 303 _____\n",
      "train imitation 1.5970975160598755 reward 2.483247756958008\n",
      "val imitation 1.3597296476364136 reward 1.817083477973938\n",
      "val loss 3.1768131256103516 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7319078947368421}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8028846153846153}]\n",
      "______epoch 304 _____\n",
      "train imitation 1.568718671798706 reward 2.4863243103027344\n",
      "val imitation 1.3664727210998535 reward 1.817083477973938\n",
      "val loss 3.183556079864502 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8032051282051282}]\n",
      "______epoch 305 _____\n",
      "train imitation 1.5814974308013916 reward 2.489037275314331\n",
      "val imitation 1.375098705291748 reward 1.817083477973938\n",
      "val loss 3.1921820640563965 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4956730769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 306 _____\n",
      "train imitation 1.5505973100662231 reward 2.4858508110046387\n",
      "val imitation 1.3804125785827637 reward 1.816926121711731\n",
      "val loss 3.197338581085205 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49567307692307694}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8032051282051281}]\n",
      "______epoch 307 _____\n",
      "train imitation 1.5820095539093018 reward 2.485363245010376\n",
      "val imitation 1.3833779096603394 reward 1.816926121711731\n",
      "val loss 3.2003040313720703 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49615384615384617}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n",
      "______epoch 308 _____\n",
      "train imitation 1.5815081596374512 reward 2.484900951385498\n",
      "val imitation 1.3798103332519531 reward 1.816926121711731\n",
      "val loss 3.1967363357543945 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4966346153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8009615384615385}]\n",
      "______epoch 309 _____\n",
      "train imitation 1.5818328857421875 reward 2.4849750995635986\n",
      "val imitation 1.377410650253296 reward 1.8163440227508545\n",
      "val loss 3.1937546730041504 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49759615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8012820512820513}]\n",
      "______epoch 310 _____\n",
      "train imitation 1.5696862936019897 reward 2.4873158931732178\n",
      "val imitation 1.3761346340179443 reward 1.8163440227508545\n",
      "val loss 3.192478656768799 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4975961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8012820512820513}]\n",
      "______epoch 311 _____\n",
      "train imitation 1.5535554885864258 reward 2.4854342937469482\n",
      "val imitation 1.369862675666809 reward 1.8163440227508545\n",
      "val loss 3.186206817626953 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49663461538461545}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 312 _____\n",
      "train imitation 1.545068383216858 reward 2.48620343208313\n",
      "val imitation 1.3619338274002075 reward 1.8162391185760498\n",
      "val loss 3.178173065185547 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.49759615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 313 _____\n",
      "train imitation 1.5394282341003418 reward 2.4867136478424072\n",
      "val imitation 1.3583643436431885 reward 1.8162391185760498\n",
      "val loss 3.1746034622192383 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4990384615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8032051282051282}]\n",
      "______epoch 314 _____\n",
      "train imitation 1.5683221817016602 reward 2.485639810562134\n",
      "val imitation 1.3549456596374512 reward 1.8165555000305176\n",
      "val loss 3.1715011596679688 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8035256410256411}]\n",
      "______epoch 315 _____\n",
      "train imitation 1.5616087913513184 reward 2.4887585639953613\n",
      "val imitation 1.3531244993209839 reward 1.8169450759887695\n",
      "val loss 3.170069694519043 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8038461538461539}]\n",
      "______epoch 316 _____\n",
      "train imitation 1.5534040927886963 reward 2.4872617721557617\n",
      "val imitation 1.3500208854675293 reward 1.8175272941589355\n",
      "val loss 3.167548179626465 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8038461538461539}]\n",
      "______epoch 317 _____\n",
      "train imitation 1.5714200735092163 reward 2.485233783721924\n",
      "val imitation 1.3481309413909912 reward 1.8175272941589355\n",
      "val loss 3.1656582355499268 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8041666666666667}]\n",
      "______epoch 318 _____\n",
      "train imitation 1.5665282011032104 reward 2.483893394470215\n",
      "val imitation 1.345930814743042 reward 1.8175272941589355\n",
      "val loss 3.1634581089019775 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8041666666666667}]\n",
      "______epoch 319 _____\n",
      "train imitation 1.5435433387756348 reward 2.4854073524475098\n",
      "val imitation 1.3464066982269287 reward 1.8175272941589355\n",
      "val loss 3.1639339923858643 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8041666666666667}]\n",
      "______epoch 320 _____\n",
      "train imitation 1.5370945930480957 reward 2.4860048294067383\n",
      "val imitation 1.3487433195114136 reward 1.817083477973938\n",
      "val loss 3.1658267974853516 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.728344298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8044871794871795}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 321 _____\n",
      "train imitation 1.569706916809082 reward 2.4874837398529053\n",
      "val imitation 1.3504629135131836 reward 1.817083477973938\n",
      "val loss 3.167546272277832 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8041666666666667}]\n",
      "______epoch 322 _____\n",
      "train imitation 1.5390405654907227 reward 2.484449863433838\n",
      "val imitation 1.3527305126190186 reward 1.8170077800750732\n",
      "val loss 3.169738292694092 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8044871794871795}]\n",
      "______epoch 323 _____\n",
      "train imitation 1.548518419265747 reward 2.4866487979888916\n",
      "val imitation 1.354429841041565 reward 1.8170077800750732\n",
      "val loss 3.1714377403259277 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8041666666666667}]\n",
      "______epoch 324 _____\n",
      "train imitation 1.5345325469970703 reward 2.4865293502807617\n",
      "val imitation 1.3558320999145508 reward 1.8171355724334717\n",
      "val loss 3.1729676723480225 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8038461538461539}]\n",
      "______epoch 325 _____\n",
      "train imitation 1.5493390560150146 reward 2.4851810932159424\n",
      "val imitation 1.3540658950805664 reward 1.8171355724334717\n",
      "val loss 3.171201467514038 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7286184210526315}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8041666666666666}]\n",
      "______epoch 326 _____\n",
      "train imitation 1.5304551124572754 reward 2.483351945877075\n",
      "val imitation 1.349907398223877 reward 1.8167461156845093\n",
      "val loss 3.166653633117676 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8048076923076922}]\n",
      "______epoch 327 _____\n",
      "train imitation 1.5988134145736694 reward 2.487799644470215\n",
      "val imitation 1.3500356674194336 reward 1.8167461156845093\n",
      "val loss 3.1667819023132324 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8048076923076922}]\n",
      "______epoch 328 _____\n",
      "train imitation 1.563828706741333 reward 2.483790159225464\n",
      "val imitation 1.3522764444351196 reward 1.8167461156845093\n",
      "val loss 3.169022560119629 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8048076923076922}]\n",
      "______epoch 329 _____\n",
      "train imitation 1.5541436672210693 reward 2.4867589473724365\n",
      "val imitation 1.3521569967269897 reward 1.8167461156845093\n",
      "val loss 3.168903112411499 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526315}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8044871794871794}]\n",
      "______epoch 330 _____\n",
      "train imitation 1.5283708572387695 reward 2.4850077629089355\n",
      "val imitation 1.3518556356430054 reward 1.8161638975143433\n",
      "val loss 3.1680195331573486 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8048076923076922}]\n",
      "______epoch 331 _____\n",
      "train imitation 1.5494693517684937 reward 2.4848482608795166\n",
      "val imitation 1.352871060371399 reward 1.8161605596542358\n",
      "val loss 3.1690316200256348 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8044871794871795}]\n",
      "______epoch 332 _____\n",
      "train imitation 1.5242581367492676 reward 2.486071825027466\n",
      "val imitation 1.3528475761413574 reward 1.8161605596542358\n",
      "val loss 3.169008255004883 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7236842105263157}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 333 _____\n",
      "train imitation 1.5441142320632935 reward 2.485917091369629\n",
      "val imitation 1.3499070405960083 reward 1.8161605596542358\n",
      "val loss 3.166067600250244 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7239583333333334}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8048076923076923}]\n",
      "______epoch 334 _____\n",
      "train imitation 1.5239741802215576 reward 2.4841907024383545\n",
      "val imitation 1.3456310033798218 reward 1.8161605596542358\n",
      "val loss 3.1617915630340576 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7231359649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 335 _____\n",
      "train imitation 1.5437642335891724 reward 2.487074613571167\n",
      "val imitation 1.3438811302185059 reward 1.8159914016723633\n",
      "val loss 3.159872531890869 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7242324561403508}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 336 _____\n",
      "train imitation 1.525048851966858 reward 2.4848153591156006\n",
      "val imitation 1.3413711786270142 reward 1.8159914016723633\n",
      "val loss 3.157362461090088 3.1588573455810547\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7239583333333333}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8051282051282052}]\n",
      "______epoch 337 _____\n",
      "train imitation 1.57269287109375 reward 2.4842000007629395\n",
      "val imitation 1.3411487340927124 reward 1.8159914016723633\n",
      "val loss 3.1571402549743652 3.157362461090088\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.805448717948718}]\n",
      "______epoch 338 _____\n",
      "train imitation 1.520423173904419 reward 2.4850826263427734\n",
      "val imitation 1.34063720703125 reward 1.815351128578186\n",
      "val loss 3.1559882164001465 3.1571402549743652\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8057692307692308}]\n",
      "______epoch 339 _____\n",
      "train imitation 1.5257132053375244 reward 2.485630989074707\n",
      "val imitation 1.3431288003921509 reward 1.8155235052108765\n",
      "val loss 3.1586523056030273 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8048076923076922}]\n",
      "______epoch 340 _____\n",
      "train imitation 1.5605922937393188 reward 2.4865403175354004\n",
      "val imitation 1.3507486581802368 reward 1.8155544996261597\n",
      "val loss 3.1663031578063965 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8048076923076923}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 341 _____\n",
      "train imitation 1.5364893674850464 reward 2.486945867538452\n",
      "val imitation 1.3562774658203125 reward 1.8155544996261597\n",
      "val loss 3.1718320846557617 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49855769230769226}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8048076923076923}]\n",
      "______epoch 342 _____\n",
      "train imitation 1.5275366306304932 reward 2.486246109008789\n",
      "val imitation 1.3564453125 reward 1.8153746128082275\n",
      "val loss 3.1718199253082275 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8051282051282052}]\n",
      "______epoch 343 _____\n",
      "train imitation 1.4875723123550415 reward 2.4854416847229004\n",
      "val imitation 1.3537235260009766 reward 1.8153746128082275\n",
      "val loss 3.169098138809204 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8048076923076923}]\n",
      "______epoch 344 _____\n",
      "train imitation 1.5206940174102783 reward 2.4864416122436523\n",
      "val imitation 1.3507797718048096 reward 1.8153746128082275\n",
      "val loss 3.166154384613037 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754387}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8048076923076923}]\n",
      "______epoch 345 _____\n",
      "train imitation 1.5284013748168945 reward 2.4857821464538574\n",
      "val imitation 1.3457789421081543 reward 1.815295696258545\n",
      "val loss 3.161074638366699 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5014423076923078}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8044871794871794}]\n",
      "______epoch 346 _____\n",
      "train imitation 1.5408222675323486 reward 2.487302303314209\n",
      "val imitation 1.3453152179718018 reward 1.815295696258545\n",
      "val loss 3.1606109142303467 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5014423076923078}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8041666666666666}]\n",
      "______epoch 347 _____\n",
      "train imitation 1.5226457118988037 reward 2.486091375350952\n",
      "val imitation 1.346623182296753 reward 1.815295696258545\n",
      "val loss 3.161918878555298 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.803525641025641}]\n",
      "______epoch 348 _____\n",
      "train imitation 1.504088044166565 reward 2.4864907264709473\n",
      "val imitation 1.3466020822525024 reward 1.815295696258545\n",
      "val loss 3.161897659301758 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8038461538461538}]\n",
      "______epoch 349 _____\n",
      "train imitation 1.553678035736084 reward 2.485323905944824\n",
      "val imitation 1.3491184711456299 reward 1.815295696258545\n",
      "val loss 3.164414167404175 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 350 _____\n",
      "train imitation 1.5238683223724365 reward 2.48502254486084\n",
      "val imitation 1.3522398471832275 reward 1.8153746128082275\n",
      "val loss 3.167614459991455 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4995192307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8022435897435897}]\n",
      "______epoch 351 _____\n",
      "train imitation 1.521571397781372 reward 2.4885036945343018\n",
      "val imitation 1.3545058965682983 reward 1.815430998802185\n",
      "val loss 3.1699368953704834 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8022435897435897}]\n",
      "______epoch 352 _____\n",
      "train imitation 1.522464394569397 reward 2.4873175621032715\n",
      "val imitation 1.3536540269851685 reward 1.81532621383667\n",
      "val loss 3.168980121612549 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.803525641025641}]\n",
      "______epoch 353 _____\n",
      "train imitation 1.550999641418457 reward 2.4835927486419678\n",
      "val imitation 1.3517054319381714 reward 1.8152469396591187\n",
      "val loss 3.16695237159729 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8041666666666666}]\n",
      "______epoch 354 _____\n",
      "train imitation 1.509519338607788 reward 2.485111951828003\n",
      "val imitation 1.3507862091064453 reward 1.8152719736099243\n",
      "val loss 3.16605806350708 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8038461538461539}]\n",
      "______epoch 355 _____\n",
      "train imitation 1.561750888824463 reward 2.486114978790283\n",
      "val imitation 1.3488941192626953 reward 1.8152719736099243\n",
      "val loss 3.16416597366333 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 356 _____\n",
      "train imitation 1.499882698059082 reward 2.4886362552642822\n",
      "val imitation 1.3493354320526123 reward 1.8147993087768555\n",
      "val loss 3.1641347408294678 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8025641025641026}]\n",
      "______epoch 357 _____\n",
      "train imitation 1.5208110809326172 reward 2.484365463256836\n",
      "val imitation 1.3515989780426025 reward 1.8147993087768555\n",
      "val loss 3.166398286819458 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8025641025641026}]\n",
      "______epoch 358 _____\n",
      "train imitation 1.5087382793426514 reward 2.4850027561187744\n",
      "val imitation 1.3514372110366821 reward 1.8147993087768555\n",
      "val loss 3.166236400604248 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n",
      "______epoch 359 _____\n",
      "train imitation 1.5385594367980957 reward 2.487304449081421\n",
      "val imitation 1.353015422821045 reward 1.8147993087768555\n",
      "val loss 3.1678147315979004 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.4985576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8016025641025641}]\n",
      "______epoch 360 _____\n",
      "train imitation 1.5121406316757202 reward 2.487717866897583\n",
      "val imitation 1.3499979972839355 reward 1.8147993087768555\n",
      "val loss 3.164797306060791 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 361 _____\n",
      "train imitation 1.521606683731079 reward 2.48628306388855\n",
      "val imitation 1.3443107604980469 reward 1.8147993087768555\n",
      "val loss 3.1591100692749023 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n",
      "______epoch 362 _____\n",
      "train imitation 1.4798014163970947 reward 2.4858055114746094\n",
      "val imitation 1.3415648937225342 reward 1.815063714981079\n",
      "val loss 3.1566286087036133 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n",
      "______epoch 363 _____\n",
      "train imitation 1.5243706703186035 reward 2.487980842590332\n",
      "val imitation 1.3435436487197876 reward 1.8155362606048584\n",
      "val loss 3.1590800285339355 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526315}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 364 _____\n",
      "train imitation 1.5064783096313477 reward 2.4878952503204346\n",
      "val imitation 1.3477063179016113 reward 1.8155362606048584\n",
      "val loss 3.1632425785064697 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8028846153846154}]\n",
      "______epoch 365 _____\n",
      "train imitation 1.5321941375732422 reward 2.488487482070923\n",
      "val imitation 1.3531948328018188 reward 1.815063714981079\n",
      "val loss 3.1682586669921875 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8028846153846154}]\n",
      "______epoch 366 _____\n",
      "train imitation 1.5239272117614746 reward 2.4863791465759277\n",
      "val imitation 1.355704665184021 reward 1.815063714981079\n",
      "val loss 3.1707682609558105 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8016025641025641}]\n",
      "______epoch 367 _____\n",
      "train imitation 1.5153428316116333 reward 2.4854588508605957\n",
      "val imitation 1.3578815460205078 reward 1.8155362606048584\n",
      "val loss 3.173417806625366 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641026}]\n",
      "______epoch 368 _____\n",
      "train imitation 1.4682729244232178 reward 2.486236333847046\n",
      "val imitation 1.3581315279006958 reward 1.8155362606048584\n",
      "val loss 3.1736679077148438 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8019230769230768}]\n",
      "______epoch 369 _____\n",
      "train imitation 1.5058456659317017 reward 2.487929582595825\n",
      "val imitation 1.3569941520690918 reward 1.8154209852218628\n",
      "val loss 3.172415256500244 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641025}]\n",
      "______epoch 370 _____\n",
      "train imitation 1.5095956325531006 reward 2.485215187072754\n",
      "val imitation 1.3593778610229492 reward 1.8154209852218628\n",
      "val loss 3.1747989654541016 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.4971153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846154}]\n",
      "______epoch 371 _____\n",
      "train imitation 1.5204026699066162 reward 2.4877843856811523\n",
      "val imitation 1.3609222173690796 reward 1.8154209852218628\n",
      "val loss 3.1763432025909424 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.4971153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8019230769230768}]\n",
      "______epoch 372 _____\n",
      "train imitation 1.494448184967041 reward 2.486133575439453\n",
      "val imitation 1.3588563203811646 reward 1.8154209852218628\n",
      "val loss 3.1742773056030273 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.49759615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8022435897435898}]\n",
      "______epoch 373 _____\n",
      "train imitation 1.521228313446045 reward 2.4868922233581543\n",
      "val imitation 1.351940393447876 reward 1.815500020980835\n",
      "val loss 3.167440414428711 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4985576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.801923076923077}]\n",
      "______epoch 374 _____\n",
      "train imitation 1.4977604150772095 reward 2.4861929416656494\n",
      "val imitation 1.3420064449310303 reward 1.815500020980835\n",
      "val loss 3.1575064659118652 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5004807692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8016025641025641}]\n",
      "______epoch 375 _____\n",
      "train imitation 1.4845352172851562 reward 2.4864633083343506\n",
      "val imitation 1.3350049257278442 reward 1.815500020980835\n",
      "val loss 3.1505050659179688 3.1559882164001465\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8022435897435898}]\n",
      "______epoch 376 _____\n",
      "train imitation 1.5183438062667847 reward 2.485168218612671\n",
      "val imitation 1.3345978260040283 reward 1.815500020980835\n",
      "val loss 3.1500978469848633 3.1505050659179688\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8025641025641026}]\n",
      "______epoch 377 _____\n",
      "train imitation 1.5006914138793945 reward 2.48636794090271\n",
      "val imitation 1.338475227355957 reward 1.8150272369384766\n",
      "val loss 3.1535024642944336 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8022435897435898}]\n",
      "______epoch 378 _____\n",
      "train imitation 1.476285457611084 reward 2.486821413040161\n",
      "val imitation 1.3438467979431152 reward 1.8150272369384766\n",
      "val loss 3.158874034881592 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4985576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.801923076923077}]\n",
      "______epoch 379 _____\n",
      "train imitation 1.5068421363830566 reward 2.48710298538208\n",
      "val imitation 1.3529291152954102 reward 1.8153218030929565\n",
      "val loss 3.1682510375976562 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.4951923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8009615384615385}]\n",
      "______epoch 380 _____\n",
      "train imitation 1.4888744354248047 reward 2.487414598464966\n",
      "val imitation 1.3635112047195435 reward 1.8153218030929565\n",
      "val loss 3.1788330078125 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49375}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7253289473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8003205128205129}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 381 _____\n",
      "train imitation 1.4848202466964722 reward 2.4863293170928955\n",
      "val imitation 1.371838927268982 reward 1.8150551319122314\n",
      "val loss 3.186893939971924 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49278846153846156}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7253289473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.798397435897436}]\n",
      "______epoch 382 _____\n",
      "train imitation 1.5106942653656006 reward 2.4885127544403076\n",
      "val imitation 1.3705193996429443 reward 1.8142356872558594\n",
      "val loss 3.1847550868988037 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4932692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7990384615384616}]\n",
      "______epoch 383 _____\n",
      "train imitation 1.4967862367630005 reward 2.4863035678863525\n",
      "val imitation 1.3623034954071045 reward 1.8147608041763306\n",
      "val loss 3.1770644187927246 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.4947115384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7245065789473685}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7999999999999999}]\n",
      "______epoch 384 _____\n",
      "train imitation 1.4741075038909912 reward 2.485766887664795\n",
      "val imitation 1.3511568307876587 reward 1.8147608041763306\n",
      "val loss 3.1659176349639893 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49567307692307694}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.724780701754386}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.8009615384615385}]\n",
      "______epoch 385 _____\n",
      "train imitation 1.5054702758789062 reward 2.487367868423462\n",
      "val imitation 1.344625473022461 reward 1.8147608041763306\n",
      "val loss 3.159386157989502 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n",
      "______epoch 386 _____\n",
      "train imitation 1.495055913925171 reward 2.484612464904785\n",
      "val imitation 1.3427667617797852 reward 1.8147608041763306\n",
      "val loss 3.157527446746826 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.49951923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n",
      "______epoch 387 _____\n",
      "train imitation 1.4964383840560913 reward 2.484377861022949\n",
      "val imitation 1.3447049856185913 reward 1.8147608041763306\n",
      "val loss 3.159465789794922 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5009615384615385}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n",
      "______epoch 388 _____\n",
      "train imitation 1.472463846206665 reward 2.485999584197998\n",
      "val imitation 1.3515663146972656 reward 1.8147608041763306\n",
      "val loss 3.1663269996643066 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8006410256410257}]\n",
      "______epoch 389 _____\n",
      "train imitation 1.4956485033035278 reward 2.4864914417266846\n",
      "val imitation 1.3593181371688843 reward 1.8151344060897827\n",
      "val loss 3.174452543258667 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4971153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 390 _____\n",
      "train imitation 1.4529184103012085 reward 2.485164165496826\n",
      "val imitation 1.3642982244491577 reward 1.8152308464050293\n",
      "val loss 3.1795291900634766 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7990384615384616}]\n",
      "______epoch 391 _____\n",
      "train imitation 1.4836562871932983 reward 2.4845356941223145\n",
      "val imitation 1.3658417463302612 reward 1.8152308464050293\n",
      "val loss 3.18107271194458 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.4980769230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7990384615384615}]\n",
      "______epoch 392 _____\n",
      "train imitation 1.4682539701461792 reward 2.4842684268951416\n",
      "val imitation 1.3643931150436401 reward 1.8152437210083008\n",
      "val loss 3.1796369552612305 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.49903846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7983974358974358}]\n",
      "______epoch 393 _____\n",
      "train imitation 1.504676103591919 reward 2.486639976501465\n",
      "val imitation 1.3577251434326172 reward 1.8152437210083008\n",
      "val loss 3.172968864440918 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8003205128205128}]\n",
      "______epoch 394 _____\n",
      "train imitation 1.476332426071167 reward 2.4884495735168457\n",
      "val imitation 1.350272536277771 reward 1.8156070709228516\n",
      "val loss 3.165879726409912 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n",
      "______epoch 395 _____\n",
      "train imitation 1.4680551290512085 reward 2.485349178314209\n",
      "val imitation 1.3477206230163574 reward 1.815873622894287\n",
      "val loss 3.1635942459106445 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801923076923077}]\n",
      "______epoch 396 _____\n",
      "train imitation 1.500893473625183 reward 2.4859166145324707\n",
      "val imitation 1.3514299392700195 reward 1.815848469734192\n",
      "val loss 3.167278289794922 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8022435897435898}]\n",
      "______epoch 397 _____\n",
      "train imitation 1.4766554832458496 reward 2.485558032989502\n",
      "val imitation 1.3540797233581543 reward 1.815713882446289\n",
      "val loss 3.1697936058044434 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.801923076923077}]\n",
      "______epoch 398 _____\n",
      "train imitation 1.485999584197998 reward 2.485975503921509\n",
      "val imitation 1.3555049896240234 reward 1.8157267570495605\n",
      "val loss 3.171231746673584 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8016025641025641}]\n",
      "______epoch 399 _____\n",
      "train imitation 1.4998618364334106 reward 2.488089084625244\n",
      "val imitation 1.3601641654968262 reward 1.8152437210083008\n",
      "val loss 3.175407886505127 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8019230769230768}]\n",
      "______epoch 400 _____\n",
      "train imitation 1.4822242259979248 reward 2.4885621070861816\n",
      "val imitation 1.3635066747665405 reward 1.8148396015167236\n",
      "val loss 3.1783461570739746 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8009615384615385}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 401 _____\n",
      "train imitation 1.491098403930664 reward 2.4856679439544678\n",
      "val imitation 1.3627839088439941 reward 1.8148137331008911\n",
      "val loss 3.1775975227355957 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8006410256410257}]\n",
      "______epoch 402 _____\n",
      "train imitation 1.4603866338729858 reward 2.489161968231201\n",
      "val imitation 1.3581416606903076 reward 1.8149206638336182\n",
      "val loss 3.173062324523926 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5014423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8025641025641026}]\n",
      "______epoch 403 _____\n",
      "train imitation 1.4654566049575806 reward 2.4838881492614746\n",
      "val imitation 1.349307656288147 reward 1.8149206638336182\n",
      "val loss 3.1642284393310547 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8032051282051282}]\n",
      "______epoch 404 _____\n",
      "train imitation 1.4868979454040527 reward 2.4846770763397217\n",
      "val imitation 1.337085485458374 reward 1.8149206638336182\n",
      "val loss 3.152006149291992 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 405 _____\n",
      "train imitation 1.4996079206466675 reward 2.4875502586364746\n",
      "val imitation 1.3346102237701416 reward 1.8149206638336182\n",
      "val loss 3.1495308876037598 3.1500978469848633\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 406 _____\n",
      "train imitation 1.4290330410003662 reward 2.486462354660034\n",
      "val imitation 1.3345433473587036 reward 1.8149206638336182\n",
      "val loss 3.1494641304016113 3.1495308876037598\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n",
      "______epoch 407 _____\n",
      "train imitation 1.4857653379440308 reward 2.485806941986084\n",
      "val imitation 1.338262677192688 reward 1.8146860599517822\n",
      "val loss 3.1529488563537598 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8028846153846154}]\n",
      "______epoch 408 _____\n",
      "train imitation 1.4767100811004639 reward 2.4882421493530273\n",
      "val imitation 1.3465020656585693 reward 1.8146860599517822\n",
      "val loss 3.1611881256103516 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8022435897435898}]\n",
      "______epoch 409 _____\n",
      "train imitation 1.4481837749481201 reward 2.4862163066864014\n",
      "val imitation 1.3546772003173828 reward 1.8146860599517822\n",
      "val loss 3.169363260269165 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8009615384615385}]\n",
      "______epoch 410 _____\n",
      "train imitation 1.4780163764953613 reward 2.488308906555176\n",
      "val imitation 1.3611260652542114 reward 1.81460702419281\n",
      "val loss 3.1757330894470215 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245613}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8009615384615385}]\n",
      "______epoch 411 _____\n",
      "train imitation 1.4426734447479248 reward 2.486440658569336\n",
      "val imitation 1.3610507249832153 reward 1.81460702419281\n",
      "val loss 3.1756577491760254 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7261513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7996794871794872}]\n",
      "______epoch 412 _____\n",
      "train imitation 1.477981448173523 reward 2.4863851070404053\n",
      "val imitation 1.3651516437530518 reward 1.814550518989563\n",
      "val loss 3.1797022819519043 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.725328947368421}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7996794871794872}]\n",
      "______epoch 413 _____\n",
      "train imitation 1.4412938356399536 reward 2.4857935905456543\n",
      "val imitation 1.3664436340332031 reward 1.814550518989563\n",
      "val loss 3.1809940338134766 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8}]\n",
      "______epoch 414 _____\n",
      "train imitation 1.431771159172058 reward 2.4865312576293945\n",
      "val imitation 1.3626611232757568 reward 1.814550518989563\n",
      "val loss 3.1772117614746094 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8006410256410256}]\n",
      "______epoch 415 _____\n",
      "train imitation 1.4620678424835205 reward 2.4865620136260986\n",
      "val imitation 1.3567302227020264 reward 1.8151023387908936\n",
      "val loss 3.17183256149292 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8016025641025641}]\n",
      "______epoch 416 _____\n",
      "train imitation 1.4566853046417236 reward 2.4862143993377686\n",
      "val imitation 1.3538302183151245 reward 1.8151153326034546\n",
      "val loss 3.168945550918579 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8022435897435898}]\n",
      "______epoch 417 _____\n",
      "train imitation 1.471564769744873 reward 2.485583543777466\n",
      "val imitation 1.3542729616165161 reward 1.8149938583374023\n",
      "val loss 3.169266700744629 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8025641025641026}]\n",
      "______epoch 418 _____\n",
      "train imitation 1.4665369987487793 reward 2.4864420890808105\n",
      "val imitation 1.3585015535354614 reward 1.8149938583374023\n",
      "val loss 3.173495292663574 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8012820512820513}]\n",
      "______epoch 419 _____\n",
      "train imitation 1.459770917892456 reward 2.4867897033691406\n",
      "val imitation 1.3596909046173096 reward 1.8149938583374023\n",
      "val loss 3.174684762954712 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.801602564102564}]\n",
      "______epoch 420 _____\n",
      "train imitation 1.4669177532196045 reward 2.487558126449585\n",
      "val imitation 1.361938714981079 reward 1.8151280879974365\n",
      "val loss 3.1770668029785156 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5072115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8016025641025641}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 421 _____\n",
      "train imitation 1.4907805919647217 reward 2.48705792427063\n",
      "val imitation 1.367345929145813 reward 1.8151280879974365\n",
      "val loss 3.182474136352539 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7996794871794872}]\n",
      "______epoch 422 _____\n",
      "train imitation 1.4473872184753418 reward 2.4878182411193848\n",
      "val imitation 1.368731141090393 reward 1.8146554231643677\n",
      "val loss 3.1833865642547607 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7987179487179488}]\n",
      "______epoch 423 _____\n",
      "train imitation 1.4611220359802246 reward 2.4862561225891113\n",
      "val imitation 1.3684329986572266 reward 1.8146554231643677\n",
      "val loss 3.1830883026123047 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.798397435897436}]\n",
      "______epoch 424 _____\n",
      "train imitation 1.464850902557373 reward 2.4864485263824463\n",
      "val imitation 1.3660529851913452 reward 1.8146554231643677\n",
      "val loss 3.180708408355713 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7987179487179488}]\n",
      "______epoch 425 _____\n",
      "train imitation 1.4692753553390503 reward 2.4852700233459473\n",
      "val imitation 1.3645786046981812 reward 1.8146554231643677\n",
      "val loss 3.179234027862549 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7999999999999999}]\n",
      "______epoch 426 _____\n",
      "train imitation 1.440484881401062 reward 2.4851300716400146\n",
      "val imitation 1.3609952926635742 reward 1.8151280879974365\n",
      "val loss 3.1761233806610107 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5072115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794871}]\n",
      "______epoch 427 _____\n",
      "train imitation 1.4528921842575073 reward 2.4857866764068604\n",
      "val imitation 1.3583848476409912 reward 1.8150066137313843\n",
      "val loss 3.173391342163086 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794871}]\n",
      "______epoch 428 _____\n",
      "train imitation 1.45108962059021 reward 2.48850679397583\n",
      "val imitation 1.354962944984436 reward 1.8150066137313843\n",
      "val loss 3.1699695587158203 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7996794871794871}]\n",
      "______epoch 429 _____\n",
      "train imitation 1.433429479598999 reward 2.4867563247680664\n",
      "val imitation 1.355412244796753 reward 1.8150066137313843\n",
      "val loss 3.1704187393188477 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7993589743589743}]\n",
      "______epoch 430 _____\n",
      "train imitation 1.4203534126281738 reward 2.4869658946990967\n",
      "val imitation 1.3559281826019287 reward 1.8152185678482056\n",
      "val loss 3.171146869659424 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.798397435897436}]\n",
      "______epoch 431 _____\n",
      "train imitation 1.4541752338409424 reward 2.4860358238220215\n",
      "val imitation 1.3586511611938477 reward 1.8152185678482056\n",
      "val loss 3.1738696098327637 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.798076923076923}]\n",
      "______epoch 432 _____\n",
      "train imitation 1.4615223407745361 reward 2.4852170944213867\n",
      "val imitation 1.3599755764007568 reward 1.8152185678482056\n",
      "val loss 3.175194263458252 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7964743589743589}]\n",
      "______epoch 433 _____\n",
      "train imitation 1.439387559890747 reward 2.4872994422912598\n",
      "val imitation 1.3583548069000244 reward 1.815224051475525\n",
      "val loss 3.1735787391662598 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7971153846153847}]\n",
      "______epoch 434 _____\n",
      "train imitation 1.4186125993728638 reward 2.4865305423736572\n",
      "val imitation 1.3522568941116333 reward 1.815224051475525\n",
      "val loss 3.167480945587158 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5048076923076924}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7974358974358975}]\n",
      "______epoch 435 _____\n",
      "train imitation 1.4496222734451294 reward 2.486379384994507\n",
      "val imitation 1.3457691669464111 reward 1.815224051475525\n",
      "val loss 3.1609930992126465 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7987179487179487}]\n",
      "______epoch 436 _____\n",
      "train imitation 1.4641207456588745 reward 2.486392021179199\n",
      "val imitation 1.3395092487335205 reward 1.815224051475525\n",
      "val loss 3.154733180999756 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7983974358974358}]\n",
      "______epoch 437 _____\n",
      "train imitation 1.4462472200393677 reward 2.4865167140960693\n",
      "val imitation 1.3367283344268799 reward 1.815224051475525\n",
      "val loss 3.1519522666931152 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5052884615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7291666666666667}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7987179487179487}]\n",
      "______epoch 438 _____\n",
      "train imitation 1.4452767372131348 reward 2.484065055847168\n",
      "val imitation 1.3389308452606201 reward 1.8151274919509888\n",
      "val loss 3.1540584564208984 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7945205479452054, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564102}]\n",
      "______epoch 439 _____\n",
      "train imitation 1.469698429107666 reward 2.4841132164001465\n",
      "val imitation 1.3462424278259277 reward 1.8151274919509888\n",
      "val loss 3.161369800567627 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7980769230769231}]\n",
      "______epoch 440 _____\n",
      "train imitation 1.446091890335083 reward 2.487898111343384\n",
      "val imitation 1.3537904024124146 reward 1.8151274919509888\n",
      "val loss 3.1689178943634033 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7974358974358975}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 441 _____\n",
      "train imitation 1.452100157737732 reward 2.485997438430786\n",
      "val imitation 1.3591127395629883 reward 1.815011978149414\n",
      "val loss 3.1741247177124023 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564103}]\n",
      "______epoch 442 _____\n",
      "train imitation 1.4558651447296143 reward 2.4872870445251465\n",
      "val imitation 1.3615901470184326 reward 1.815011978149414\n",
      "val loss 3.1766021251678467 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564103}]\n",
      "______epoch 443 _____\n",
      "train imitation 1.43950617313385 reward 2.483926773071289\n",
      "val imitation 1.3617024421691895 reward 1.8151274919509888\n",
      "val loss 3.1768298149108887 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7974358974358975}]\n",
      "______epoch 444 _____\n",
      "train imitation 1.414697289466858 reward 2.486168622970581\n",
      "val imitation 1.3575692176818848 reward 1.8151274919509888\n",
      "val loss 3.172696590423584 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7974358974358975}]\n",
      "______epoch 445 _____\n",
      "train imitation 1.4510151147842407 reward 2.4858479499816895\n",
      "val imitation 1.3484917879104614 reward 1.8151274919509888\n",
      "val loss 3.16361927986145 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5100961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7980769230769231}]\n",
      "______epoch 446 _____\n",
      "train imitation 1.427954912185669 reward 2.4832851886749268\n",
      "val imitation 1.341562271118164 reward 1.8151274919509888\n",
      "val loss 3.1566896438598633 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7977564102564103}]\n",
      "______epoch 447 _____\n",
      "train imitation 1.4476628303527832 reward 2.4834859371185303\n",
      "val imitation 1.335708498954773 reward 1.815531611442566\n",
      "val loss 3.151240110397339 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5110576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384616}]\n",
      "______epoch 448 _____\n",
      "train imitation 1.442091703414917 reward 2.4873034954071045\n",
      "val imitation 1.3378801345825195 reward 1.815531611442566\n",
      "val loss 3.153411865234375 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7996794871794872}]\n",
      "______epoch 449 _____\n",
      "train imitation 1.408982515335083 reward 2.4886977672576904\n",
      "val imitation 1.3445796966552734 reward 1.815531611442566\n",
      "val loss 3.160111427307129 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7990384615384616}]\n",
      "______epoch 450 _____\n",
      "train imitation 1.4188034534454346 reward 2.4870848655700684\n",
      "val imitation 1.3551065921783447 reward 1.8155059814453125\n",
      "val loss 3.1706125736236572 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7993589743589744}]\n",
      "______epoch 451 _____\n",
      "train imitation 1.411590576171875 reward 2.4855270385742188\n",
      "val imitation 1.3666090965270996 reward 1.815198302268982\n",
      "val loss 3.181807518005371 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5033653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 452 _____\n",
      "train imitation 1.4008140563964844 reward 2.4872381687164307\n",
      "val imitation 1.3726612329483032 reward 1.815198302268982\n",
      "val loss 3.187859535217285 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7990384615384616}]\n",
      "______epoch 453 _____\n",
      "train imitation 1.4363962411880493 reward 2.4864110946655273\n",
      "val imitation 1.374762773513794 reward 1.815198302268982\n",
      "val loss 3.1899609565734863 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7534246575342466, 'auc': 0.5024038461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7269736842105263}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 454 _____\n",
      "train imitation 1.4586154222488403 reward 2.485272169113159\n",
      "val imitation 1.367331624031067 reward 1.8158643245697021\n",
      "val loss 3.1831960678100586 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5038461538461538}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7272478070175439}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 455 _____\n",
      "train imitation 1.4430816173553467 reward 2.4873154163360596\n",
      "val imitation 1.3577531576156616 reward 1.8162683248519897\n",
      "val loss 3.1740214824676514 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 456 _____\n",
      "train imitation 1.4088152647018433 reward 2.4866111278533936\n",
      "val imitation 1.3500919342041016 reward 1.8156280517578125\n",
      "val loss 3.165719985961914 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5081730769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 457 _____\n",
      "train imitation 1.4213216304779053 reward 2.48667573928833\n",
      "val imitation 1.347489356994629 reward 1.815531611442566\n",
      "val loss 3.1630210876464844 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7990384615384616}]\n",
      "______epoch 458 _____\n",
      "train imitation 1.4024043083190918 reward 2.4862048625946045\n",
      "val imitation 1.3474164009094238 reward 1.8162683248519897\n",
      "val loss 3.163684844970703 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7999999999999999}]\n",
      "______epoch 459 _____\n",
      "train imitation 1.4101591110229492 reward 2.4865939617156982\n",
      "val imitation 1.3514509201049805 reward 1.8162683248519897\n",
      "val loss 3.1677193641662598 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8003205128205129}]\n",
      "______epoch 460 _____\n",
      "train imitation 1.4210333824157715 reward 2.487351655960083\n",
      "val imitation 1.3562681674957275 reward 1.8158386945724487\n",
      "val loss 3.1721067428588867 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8012820512820513}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 461 _____\n",
      "train imitation 1.4180757999420166 reward 2.4864275455474854\n",
      "val imitation 1.3613919019699097 reward 1.815321683883667\n",
      "val loss 3.176713466644287 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5057692307692309}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7275219298245614}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8006410256410257}]\n",
      "______epoch 462 _____\n",
      "train imitation 1.4571363925933838 reward 2.4854960441589355\n",
      "val imitation 1.3703134059906006 reward 1.8152425289154053\n",
      "val loss 3.185555934906006 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5019230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8006410256410257}]\n",
      "______epoch 463 _____\n",
      "train imitation 1.441050410270691 reward 2.487823724746704\n",
      "val imitation 1.3735852241516113 reward 1.8152425289154053\n",
      "val loss 3.1888277530670166 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5028846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 464 _____\n",
      "train imitation 1.418663740158081 reward 2.4848244190216064\n",
      "val imitation 1.3760600090026855 reward 1.8152425289154053\n",
      "val loss 3.191302537918091 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5024038461538463}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7258771929824561}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7996794871794872}]\n",
      "______epoch 465 _____\n",
      "train imitation 1.430161476135254 reward 2.4844865798950195\n",
      "val imitation 1.3730952739715576 reward 1.8152425289154053\n",
      "val loss 3.188337802886963 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5033653846153847}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7266995614035088}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384615}]\n",
      "______epoch 466 _____\n",
      "train imitation 1.4296680688858032 reward 2.485785961151123\n",
      "val imitation 1.3678898811340332 reward 1.8152425289154053\n",
      "val loss 3.1831324100494385 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7264254385964912}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 467 _____\n",
      "train imitation 1.4724920988082886 reward 2.48707914352417\n",
      "val imitation 1.3673769235610962 reward 1.8155097961425781\n",
      "val loss 3.1828866004943848 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5057692307692307}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7999999999999999}]\n",
      "______epoch 468 _____\n",
      "train imitation 1.3888888359069824 reward 2.485659122467041\n",
      "val imitation 1.3655815124511719 reward 1.8155097961425781\n",
      "val loss 3.18109130859375 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7996794871794871}]\n",
      "______epoch 469 _____\n",
      "train imitation 1.3659073114395142 reward 2.485689163208008\n",
      "val imitation 1.3657479286193848 reward 1.8155097961425781\n",
      "val loss 3.181257724761963 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5062500000000001}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385964}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384615}]\n",
      "______epoch 470 _____\n",
      "train imitation 1.442537546157837 reward 2.485074281692505\n",
      "val imitation 1.362835168838501 reward 1.8151216506958008\n",
      "val loss 3.1779568195343018 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5052884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8009615384615385}]\n",
      "______epoch 471 _____\n",
      "train imitation 1.3922746181488037 reward 2.485398530960083\n",
      "val imitation 1.3624593019485474 reward 1.8151209354400635\n",
      "val loss 3.1775803565979004 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7602739726027398, 'auc': 0.5052884615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.8006410256410257}]\n",
      "______epoch 472 _____\n",
      "train imitation 1.424086332321167 reward 2.484191417694092\n",
      "val imitation 1.3567802906036377 reward 1.8151209354400635\n",
      "val loss 3.171901226043701 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8009615384615385}]\n",
      "______epoch 473 _____\n",
      "train imitation 1.404982566833496 reward 2.486024856567383\n",
      "val imitation 1.3537545204162598 reward 1.8150227069854736\n",
      "val loss 3.1687772274017334 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8012820512820513}]\n",
      "______epoch 474 _____\n",
      "train imitation 1.3776201009750366 reward 2.4862375259399414\n",
      "val imitation 1.3473626375198364 reward 1.8150227069854736\n",
      "val loss 3.1623854637145996 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7288925438596491}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8025641025641025}]\n",
      "______epoch 475 _____\n",
      "train imitation 1.4319628477096558 reward 2.485751152038574\n",
      "val imitation 1.3396432399749756 reward 1.8151209354400635\n",
      "val loss 3.154764175415039 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5120192307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8025641025641025}]\n",
      "______epoch 476 _____\n",
      "train imitation 1.4080920219421387 reward 2.487710475921631\n",
      "val imitation 1.3354110717773438 reward 1.8151209354400635\n",
      "val loss 3.1505320072174072 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5115384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8032051282051282}]\n",
      "______epoch 477 _____\n",
      "train imitation 1.4215946197509766 reward 2.485455274581909\n",
      "val imitation 1.3371661901474 reward 1.8153624534606934\n",
      "val loss 3.152528762817383 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5115384615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8028846153846153}]\n",
      "______epoch 478 _____\n",
      "train imitation 1.4001169204711914 reward 2.4837777614593506\n",
      "val imitation 1.3441617488861084 reward 1.8153375387191772\n",
      "val loss 3.159499168395996 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5115384615384616}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8009615384615384}]\n",
      "______epoch 479 _____\n",
      "train imitation 1.3664551973342896 reward 2.487959384918213\n",
      "val imitation 1.3519275188446045 reward 1.8154840469360352\n",
      "val loss 3.1674115657806396 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.510576923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7313596491228069}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 480 _____\n",
      "train imitation 1.4354314804077148 reward 2.4861185550689697\n",
      "val imitation 1.3566933870315552 reward 1.8154840469360352\n",
      "val loss 3.172177314758301 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7316337719298245}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.798397435897436}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 481 _____\n",
      "train imitation 1.400996446609497 reward 2.483564853668213\n",
      "val imitation 1.363287329673767 reward 1.8152425289154053\n",
      "val loss 3.178529739379883 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7308114035087718}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.798397435897436}]\n",
      "______epoch 482 _____\n",
      "train imitation 1.3719781637191772 reward 2.4844346046447754\n",
      "val imitation 1.363943099975586 reward 1.8151441812515259\n",
      "val loss 3.1790871620178223 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7308114035087719}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7987179487179487}]\n",
      "______epoch 483 _____\n",
      "train imitation 1.3932750225067139 reward 2.486706018447876\n",
      "val imitation 1.3636590242385864 reward 1.815140962600708\n",
      "val loss 3.178800106048584 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5091346153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 484 _____\n",
      "train imitation 1.4207792282104492 reward 2.486689805984497\n",
      "val imitation 1.3583085536956787 reward 1.815140962600708\n",
      "val loss 3.1734495162963867 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7990384615384616}]\n",
      "______epoch 485 _____\n",
      "train imitation 1.4087375402450562 reward 2.4871580600738525\n",
      "val imitation 1.3512094020843506 reward 1.815140962600708\n",
      "val loss 3.1663503646850586 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5096153846153847}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.730811403508772}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589743}]\n",
      "______epoch 486 _____\n",
      "train imitation 1.3976287841796875 reward 2.485412120819092\n",
      "val imitation 1.3435972929000854 reward 1.8153825998306274\n",
      "val loss 3.158979892730713 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5100961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.731359649122807}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8003205128205128}]\n",
      "______epoch 487 _____\n",
      "train imitation 1.3803809881210327 reward 2.484060049057007\n",
      "val imitation 1.3378022909164429 reward 1.8156672716140747\n",
      "val loss 3.1534695625305176 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5110576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7321820175438597}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8009615384615385}]\n",
      "______epoch 488 _____\n",
      "train imitation 1.3889374732971191 reward 2.4828596115112305\n",
      "val imitation 1.33665931224823 reward 1.8156672716140747\n",
      "val loss 3.1523265838623047 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5105769230769232}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8012820512820513}]\n",
      "______epoch 489 _____\n",
      "train imitation 1.409886360168457 reward 2.4865219593048096\n",
      "val imitation 1.340519905090332 reward 1.8156672716140747\n",
      "val loss 3.156187057495117 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5091346153846155}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8009615384615385}]\n",
      "______epoch 490 _____\n",
      "train imitation 1.3913979530334473 reward 2.4866831302642822\n",
      "val imitation 1.3439545631408691 reward 1.815746545791626\n",
      "val loss 3.159701108932495 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5091346153846155}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.730811403508772}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8006410256410257}]\n",
      "______epoch 491 _____\n",
      "train imitation 1.4172937870025635 reward 2.4848408699035645\n",
      "val imitation 1.3492225408554077 reward 1.8152987957000732\n",
      "val loss 3.1645212173461914 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5086538461538462}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8016025641025641}]\n",
      "______epoch 492 _____\n",
      "train imitation 1.3719741106033325 reward 2.4843218326568604\n",
      "val imitation 1.3569910526275635 reward 1.8149313926696777\n",
      "val loss 3.171922445297241 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5096153846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8}]\n",
      "______epoch 493 _____\n",
      "train imitation 1.3917908668518066 reward 2.484138250350952\n",
      "val imitation 1.368926763534546 reward 1.8151729106903076\n",
      "val loss 3.1840996742248535 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5067307692307692}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7996794871794871}]\n",
      "______epoch 494 _____\n",
      "train imitation 1.4040024280548096 reward 2.4858617782592773\n",
      "val imitation 1.3719006776809692 reward 1.8151729106903076\n",
      "val loss 3.1870737075805664 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7288925438596492}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7990384615384616}]\n",
      "______epoch 495 _____\n",
      "train imitation 1.4045705795288086 reward 2.4843502044677734\n",
      "val imitation 1.3709450960159302 reward 1.8151729106903076\n",
      "val loss 3.1861181259155273 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5072115384615384}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7280701754385965}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8}]\n",
      "______epoch 496 _____\n",
      "train imitation 1.3668642044067383 reward 2.4848296642303467\n",
      "val imitation 1.3661880493164062 reward 1.8156434297561646\n",
      "val loss 3.1818313598632812 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.508173076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7286184210526316}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8009615384615385}]\n",
      "______epoch 497 _____\n",
      "train imitation 1.399735450744629 reward 2.483139753341675\n",
      "val imitation 1.360568642616272 reward 1.8157415390014648\n",
      "val loss 3.1763100624084473 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5086538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8003205128205128}]\n",
      "______epoch 498 _____\n",
      "train imitation 1.4151160717010498 reward 2.4836103916168213\n",
      "val imitation 1.354233980178833 reward 1.8151469230651855\n",
      "val loss 3.1693809032440186 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.773972602739726, 'auc': 0.5100961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7294407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8009615384615385}]\n",
      "______epoch 499 _____\n",
      "train imitation 1.373507022857666 reward 2.4845547676086426\n",
      "val imitation 1.3502367734909058 reward 1.8150486946105957\n",
      "val loss 3.165285587310791 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7808219178082192, 'auc': 0.5100961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7291666666666666}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.8006410256410257}]\n",
      "______epoch 500 _____\n",
      "train imitation 1.3766223192214966 reward 2.4858624935150146\n",
      "val imitation 1.3508732318878174 reward 1.8147412538528442\n",
      "val loss 3.165614604949951 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923077}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7297149122807018}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801602564102564}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______epoch 501 _____\n",
      "train imitation 1.3956347703933716 reward 2.485196352005005\n",
      "val imitation 1.3496893644332886 reward 1.8147412538528442\n",
      "val loss 3.164430618286133 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5072115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.801923076923077}]\n",
      "______epoch 502 _____\n",
      "train imitation 1.4084450006484985 reward 2.484103202819824\n",
      "val imitation 1.3517454862594604 reward 1.814578890800476\n",
      "val loss 3.1663243770599365 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5076923076923078}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7305372807017544}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8012820512820513}]\n",
      "______epoch 503 _____\n",
      "train imitation 1.3505301475524902 reward 2.485971689224243\n",
      "val imitation 1.3511030673980713 reward 1.8145538568496704\n",
      "val loss 3.1656570434570312 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5072115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7310855263157895}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8003205128205129}]\n",
      "______epoch 504 _____\n",
      "train imitation 1.3685243129730225 reward 2.481861114501953\n",
      "val imitation 1.353561282157898 reward 1.815462589263916\n",
      "val loss 3.1690239906311035 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5067307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7305372807017543}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.8}]\n",
      "______epoch 505 _____\n",
      "train imitation 1.3598252534866333 reward 2.483577251434326\n",
      "val imitation 1.3585879802703857 reward 1.815462589263916\n",
      "val loss 3.1740505695343018 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.50625}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.731907894736842}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7993589743589744}]\n",
      "______epoch 506 _____\n",
      "train imitation 1.3620123863220215 reward 2.486121416091919\n",
      "val imitation 1.3633493185043335 reward 1.816044807434082\n",
      "val loss 3.179394245147705 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5062500000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7324561403508771}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.798397435897436}]\n",
      "______epoch 507 _____\n",
      "train imitation 1.3975229263305664 reward 2.484769344329834\n",
      "val imitation 1.3714109659194946 reward 1.8161914348602295\n",
      "val loss 3.1876025199890137 3.1494641304016113\n",
      "[{'decision': 0, 'accuracy': 0.7671232876712328, 'auc': 0.5048076923076923}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7327302631578947}, {'decision': 2, 'accuracy': 0.7945205479452054, 'auc': 0.7958333333333334}]\n",
      "++++++++++Final+++++++++++\n",
      "best tensor(3.1495, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.7876712328767124, 'auc': 0.5043269230769231}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.8035256410256411}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def shuffle_col(v,col=None):\n",
    "    if col is None:\n",
    "        col = np.random.choice([i for i in range(v.shape[1])])\n",
    "    idx = torch.randperm(v.shape[0])\n",
    "    vv = torch.clone(v)\n",
    "    vv[:,col] = vv[idx,col]\n",
    "    return vv\n",
    "    \n",
    "def train_decision_model(\n",
    "    tmodel1,\n",
    "    tmodel2,\n",
    "    tmodel3,\n",
    "    use_default_split=True,\n",
    "    use_bagging_split=False,\n",
    "    lr=.0001,\n",
    "    epochs=10000,\n",
    "    patience=100,\n",
    "    weights=[3,1,1], #realtive weight of survival, feeding tube, and aspiration\n",
    "    imitation_weight=1,\n",
    "    shufflecol_chance = 0.1,\n",
    "    reward_weight=10,\n",
    "    split=.7,\n",
    "    resample_training=False,\n",
    "    save_path='../data/models/',\n",
    "    file_suffix='',\n",
    "    use_attention=False,\n",
    "    verbose=True,\n",
    "    threshold_decisions=True,\n",
    "    use_smote=True,\n",
    "    **model_kwargs,\n",
    "):\n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    tmodel3.eval()\n",
    "    \n",
    "    train_ids, test_ids = get_tt_split(use_default_split=use_default_split,use_bagging_split=use_bagging_split,resample_training=resample_training)\n",
    "\n",
    "    if use_smote:\n",
    "        dataset = DTDataset(use_smote=True,smote_ids = train_ids)\n",
    "        train_ids = [i for i in dataset.processed_df.index.values if i not in test_ids]\n",
    "    else:\n",
    "        dataset = DTDataset()\n",
    "\n",
    "    data = dataset.processed_df.copy()\n",
    "    \n",
    "    \n",
    "    def get_dlt(state):\n",
    "        if state == 2:\n",
    "            return data[Const.dlt2].copy()\n",
    "        d = data[Const.dlt1].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_pd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.primary_disease_states2].copy()\n",
    "        d = data[Const.primary_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_nd(state):\n",
    "        if state == 2:\n",
    "            return data[Const.nodal_disease_states2].copy()\n",
    "        d = data[Const.nodal_disease_states].copy()\n",
    "        if state < 1:\n",
    "            d.values[:,:] = 0\n",
    "        return d\n",
    "    \n",
    "    def get_cc(state):\n",
    "        res = data[Const.ccs].copy()\n",
    "        if state == 1:\n",
    "            res.values[:,:] = np.zeros(res.values.shape)\n",
    "        return res\n",
    "    \n",
    "    def get_mod(state):\n",
    "        res = data[Const.modifications].copy()\n",
    "        return res\n",
    "        \n",
    "    outcomedf = data[Const.outcomes]\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    \n",
    "    def formatdf(d,dids=train_ids):\n",
    "        d = df_to_torch(d.loc[dids])\n",
    "        return d\n",
    "    \n",
    "    def makegrad(v):\n",
    "        if not v.requires_grad:\n",
    "            v.requires_grad=True\n",
    "        return v\n",
    "    \n",
    "    if use_attention:\n",
    "        model = DecisionAttentionModel(baseline.shape[1],**model_kwargs)\n",
    "    else:\n",
    "        model = DecisionModel(baseline.shape[1],**model_kwargs)\n",
    "\n",
    "    hashcode = str(hash(','.join([str(i) for i in train_ids])))\n",
    "    \n",
    "    save_file = save_path + 'model_' + model.identifier +'_hash' + hashcode + file_suffix + '.tar'\n",
    "    model.fit_normalizer(df_to_torch(baseline.loc[train_ids]))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    def outcome_loss(ypred):\n",
    "        #convert survival to death\n",
    "        loss = torch.mul(torch.mean(-1*(ypred[:,0] - 1)),weights[0])\n",
    "        for i,weight in enumerate(weights[1:]):\n",
    "            newloss = torch.mean(ypred[:,i])*weight\n",
    "            loss = torch.add(loss,torch.mul(newloss,weight))\n",
    "        return loss\n",
    "    \n",
    "    mse = torch.nn.MSELoss()\n",
    "    nllloss = torch.nn.NLLLoss()\n",
    "    bce = torch.nn.BCELoss()\n",
    "    \n",
    "    def compare_decisions(d1,d2,d3,ids):\n",
    "#         ypred = np.concatenate([dd.cpu().detach().numpy().reshape(-1,1) for dd in [d1,d2,d3]],axis=1)\n",
    "        ytrue = df_to_torch(outcomedf.loc[ids])\n",
    "        dloss = bce(d1.view(-1),ytrue[:,0])\n",
    "        dloss += bce(d2.view(-1),ytrue[:,1])\n",
    "        dloss += bce(d3,view(-1),ytrue[:,2])\n",
    "        return dloss\n",
    "        \n",
    "    def remove_decisions(df):\n",
    "        cols = [c for c in df.columns if c not in Const.decisions ]\n",
    "        ddf = df[cols]\n",
    "        return ddf\n",
    "    \n",
    "    makeinput = lambda step,dids: df_to_torch(remove_decisions(dataset.get_input_state(step=step,ids=dids)))\n",
    "    threshold = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "\n",
    "    \n",
    "    #save the inputs from the whole dataset for future reference\n",
    "    full_data = []\n",
    "    for mstep in [0,1,2]:\n",
    "        full_data_step = [baseline, get_dlt(min(mstep,1)),\n",
    "                     get_dlt(mstep),get_pd(mstep),get_nd(mstep),get_cc(mstep),get_mod(mstep)]\n",
    "        full_data_step = torch.cat([formatdf(fd,train_ids+test_ids) for fd in full_data_step],axis=1)\n",
    "        full_data.append(full_data_step)\n",
    "    full_data = torch.stack(full_data)\n",
    "    model.save_memory(full_data)\n",
    "\n",
    "    def step(train=True):\n",
    "        if train:\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            ids = train_ids\n",
    "        else:\n",
    "            ids = test_ids\n",
    "            model.eval()\n",
    "            \n",
    "            \n",
    "        ytrain = df_to_torch(outcomedf.loc[ids])\n",
    "        #imitation losses and decision 1\n",
    "        xxtrained = [baseline, get_dlt(0),get_dlt(0),get_pd(0),get_nd(0),get_cc(0),get_mod(0)]\n",
    "        xxtrain = [formatdf(xx,ids) for xx in xxtrained]\n",
    "        o1 = model(torch.cat(xxtrain,axis=1),position=0)\n",
    "            \n",
    "        decision1_imitation = o1[:,3]\n",
    "        decision1 = o1[:,0]\n",
    "        if threshold_decisions:\n",
    "            decision1 = threshold(decision1)\n",
    "#         imitation_loss1 = bce(threshold(decision1_imitation),ytrain[:,0])\n",
    "        imitation_loss1 = bce(decision1_imitation,ytrain[:,0])\n",
    "        \n",
    "        x1_imitation = [baseline, get_dlt(1),get_dlt(0),get_pd(1),get_nd(1),get_cc(1),get_mod(1)]\n",
    "        x1_imitation = [formatdf(xx1,ids) for xx1 in x1_imitation]\n",
    "        decision2_imitation = model(torch.cat(x1_imitation,axis=1),position=1)[:,4]\n",
    "        \n",
    "#         imitation_loss2 =  bce(threshold(decision2_imitation),ytrain[:,1])\n",
    "        imitation_loss2 =  bce(decision2_imitation,ytrain[:,1])\n",
    "        \n",
    "        x2_imitation = [baseline, get_dlt(1),get_dlt(2),get_pd(2),get_nd(2),get_cc(2),get_mod(2)]\n",
    "#         if model.keys is None:\n",
    "#             keyvals = torch.cat([formatdf(xxx,train_ids+test_ids) for xxx in x2_imitation],axis=1)\n",
    "#             model.set_keys(keyvals)\n",
    "            \n",
    "        x2_imitation = [formatdf(xx2,ids) for xx2 in x2_imitation]\n",
    "        \n",
    "        decision3_imitation = model(torch.cat(x2_imitation,axis=1),position=2)[:,5]\n",
    "        \n",
    "#         imitation_loss3 = bce(threshold(decision3_imitation),ytrain[:,2])\n",
    "        imitation_loss3 = bce(decision3_imitation,ytrain[:,2])\n",
    "        \n",
    "        #reward decisions\n",
    "        xx1 = makeinput(1,ids)\n",
    "        xx2 = makeinput(2,ids)\n",
    "        xx3 = makeinput(3,ids)\n",
    "\n",
    "        baseline_train_base = formatdf(baseline,ids)\n",
    "            \n",
    "        baseline_train = torch.clone(baseline_train_base)\n",
    "        if train and shufflecol_chance > 0.0001:\n",
    "            for col in range(baseline_train_base.shape[1]): \n",
    "                if np.random.random() < shufflecol_chance:\n",
    "                    baseline_train = shuffle_col(baseline_train,col)\n",
    "                    \n",
    "        \n",
    "        xi1 = torch.cat([xx1,decision1.view(-1,1)],axis=1)\n",
    "        [ypd1, ynd1, ymod, ydlt1] = tmodel1(xi1)\n",
    "        #this outputs log likelihoods (except for dlts) -> convert to probability\n",
    "        ypd1 = torch.exp(ypd1)\n",
    "        ynd1 = torch.exp(ynd1)\n",
    "        ymod = torch.exp(ymod)\n",
    "        x1 = [baseline_train,ydlt1,formatdf(get_dlt(0),ids),ypd1,ynd1,formatdf(get_cc(1),ids),ymod]\n",
    "        \n",
    "        decision2 = model(torch.cat(x1,axis=1),position=1)[:,1] \n",
    "        if threshold_decisions:\n",
    "            decision2 = threshold(decision2)\n",
    "            \n",
    "        xi2 = torch.cat([xx2,decision1.view(-1,1),decision2.view(-1,1)],axis=1)\n",
    "        [ypd2,ynd2,ycc,ydlt2] = tmodel2(xi2)\n",
    "        ypd2 = torch.exp(ypd2)\n",
    "        ynd2 = torch.exp(ynd2)\n",
    "        ycc = torch.exp(ycc)\n",
    "        x2 = [baseline_train,ydlt1,ydlt2,ypd2,ynd2,ycc,ymod]\n",
    "            \n",
    "        decision3 = model(torch.cat(x2,axis=1),position=2)[:,2]\n",
    "        if threshold_decisions:\n",
    "            decision3 = threshold(decision3)\n",
    "            \n",
    "        \n",
    "        xi3 = torch.cat([xx3,decision1.view(-1,1),decision2.view(-1,1),decision3.view(-1,1)],axis=1)\n",
    "        outcomes = tmodel3(xi3)\n",
    "\n",
    "        reward_loss = outcome_loss(outcomes)\n",
    "        loss = torch.add(imitation_loss1,imitation_loss2)\n",
    "        loss = torch.add(loss,imitation_loss3)\n",
    "        loss = torch.mul(loss,imitation_weight/3)\n",
    "        loss = torch.add(loss,torch.mul(reward_loss,reward_weight))\n",
    "        losses = [imitation_loss1+imitation_loss2+imitation_loss3,reward_loss]\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return losses\n",
    "        else:\n",
    "            scores = []\n",
    "            for i,decision in enumerate([decision1_imitation,decision2_imitation,decision3_imitation]):\n",
    "                dec = decision.cpu().detach().numpy()\n",
    "                dec0 = (dec > .5).astype(int)\n",
    "                out = ytrain[:,i].cpu().detach().numpy()\n",
    "                acc = accuracy_score(out,dec > .5)\n",
    "                auc = roc_auc_score(out,dec)\n",
    "                scores.append({'decision': i,'accuracy': acc,'auc': auc})\n",
    "            return losses, scores\n",
    "        \n",
    "    best_val_loss = torch.tensor(1000000000.0)\n",
    "    steps_since_improvement = 0\n",
    "    best_val_score = {}\n",
    "    for epoch in range(epochs):\n",
    "        losses = step(True)\n",
    "        val_losses,val_metrics = step(False)\n",
    "        vl = val_losses[0] + val_losses[1]\n",
    "        if verbose:\n",
    "            print('______epoch',str(epoch),'_____')\n",
    "            print('train imitation',losses[0].item(),'reward',losses[1].item())\n",
    "            print('val imitation',val_losses[0].item(),'reward',val_losses[1].item())\n",
    "            print('val loss',vl.item(),best_val_loss.item())\n",
    "            print(val_metrics)\n",
    "        if vl < best_val_loss:\n",
    "            best_val_loss = vl\n",
    "            best_val_score = val_metrics\n",
    "            steps_since_improvement = 0\n",
    "            torch.save(model.state_dict(),save_file)\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    print('++++++++++Final+++++++++++')\n",
    "    print('best',best_val_loss)\n",
    "    print(best_val_score)\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "    model.eval()\n",
    "    return model, best_val_score, best_val_loss\n",
    "\n",
    "from Models import *\n",
    "args = {\n",
    "    'hidden_layers': [500], \n",
    "    'attention_heads': [2], \n",
    "    'embed_size': 210, \n",
    "    'dropout': 0.9, \n",
    "    'input_dropout': 0.5, \n",
    "    'shufflecol_chance': 0.25,\n",
    "}\n",
    "decision_model, _, _ = train_decision_model(model1,model2,model3,lr=.0001,use_attention=True,**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062ec356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "done 0 tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "curr best 100000000000\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6634615384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6461074561403509}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.728525641025641}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.5, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6639254385964912}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7371794871794872}]\n",
      "done 1 tensor(2.8300, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "done 2 tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7922, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6519230769230769}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6787280701754387}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7544871794871795}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 0, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.664423076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7730769230769231}]\n",
      "done 3 tensor(2.7685, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6596153846153846}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7025767543859649}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7615384615384615}]\n",
      "done 4 tensor(2.8643, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5918269230769231}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6866776315789473}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7685897435897436}]\n",
      "done 5 tensor(2.7816, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461538}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6636513157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7413461538461539}]\n",
      "done 6 tensor(2.8555, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8490, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65625}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.690515350877193}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7644230769230769}]\n",
      "done 7 tensor(2.8490, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7657, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6721153846153847}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6551535087719298}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7262820512820514}]\n",
      "done 8 tensor(2.7657, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7742, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6697115384615385}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7580128205128205}]\n",
      "done 9 tensor(2.7742, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017545}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7666666666666666}]\n",
      "done 10 tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7624, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6504807692307693}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7305372807017545}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7666666666666666}]\n",
      "{'hidden_layers': [100, 100], 'attention_heads': [1, 1], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8505, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6495192307692308}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.7256030701754386}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7403846153846154}]\n",
      "done 11 tensor(2.8505, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8421, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.621984649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7413461538461539}]\n",
      "done 12 tensor(2.8421, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8222, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6509615384615385}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7173076923076923}]\n",
      "done 13 tensor(2.8222, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8562, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6658653846153846}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6987390350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7708333333333334}]\n",
      "done 14 tensor(2.8562, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8358, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.6711538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6631030701754386}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7442307692307693}]\n",
      "done 15 tensor(2.8358, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8148, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8767123287671232, 'auc': 0.6326923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6493969298245614}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7602564102564102}]\n",
      "done 16 tensor(2.8148, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8188, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7316337719298246}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7458333333333333}]\n",
      "done 17 tensor(2.8188, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7478, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7201206140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7685897435897435}]\n",
      "done 18 tensor(2.7478, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7967, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6230769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6918859649122807}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7387820512820513}]\n",
      "done 19 tensor(2.7967, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7939, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6302884615384616}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6927083333333334}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7576923076923077}]\n",
      "done 20 tensor(2.7939, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.9093, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6201923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6403508771929824}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6964743589743589}]\n",
      "done 21 tensor(2.9093, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8112, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6274038461538463}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7149122807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7701923076923077}]\n",
      "done 22 tensor(2.8112, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8290, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6990131578947368}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "done 23 tensor(2.8290, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7542, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6485576923076923}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6765350877192982}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7634615384615384}]\n",
      "done 24 tensor(2.7542, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8557, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.5990384615384615}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.665296052631579}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7291666666666666}]\n",
      "done 25 tensor(2.8557, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7972, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6389423076923076}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7143640350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7548076923076923}]\n",
      "done 26 tensor(2.7972, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7995, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7069627192982456}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7663461538461539}]\n",
      "done 27 tensor(2.7995, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6370192307692308}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.7053179824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7365384615384616}]\n",
      "done 28 tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7918, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6461538461538461}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.680921052631579}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7323717948717948}]\n",
      "done 29 tensor(2.7918, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7197, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6500000000000001}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7450657894736842}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7612179487179488}]\n",
      "done 30 tensor(2.7197, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6379807692307692}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7020285087719298}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7551282051282051}]\n",
      "done 31 tensor(2.8120, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8274, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7461538461538462}]\n",
      "done 32 tensor(2.8274, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7998, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6807692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.65625}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7503205128205128}]\n",
      "done 33 tensor(2.7998, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8270, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6552884615384615}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.6883223684210527}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7490384615384615}]\n",
      "done 34 tensor(2.8270, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8275, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6528846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6858552631578947}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7266025641025642}]\n",
      "done 35 tensor(2.8275, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7048076923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6976425438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7676282051282052}]\n",
      "done 36 tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7185, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7048076923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6976425438596491}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7676282051282052}]\n",
      "{'hidden_layers': [300], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.5, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8375, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.706140350877193}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7682692307692308}]\n",
      "done 37 tensor(2.8375, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7286, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6610576923076924}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7456140350877194}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7724358974358975}]\n",
      "done 38 tensor(2.7286, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7758, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6721153846153846}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6992872807017544}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7788461538461539}]\n",
      "done 39 tensor(2.7758, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8136, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.708173076923077}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.727796052631579}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7576923076923077}]\n",
      "done 40 tensor(2.8136, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7640, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6716346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6447368421052632}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7176282051282051}]\n",
      "done 41 tensor(2.7640, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8083, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6749999999999999}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.7214912280701754}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.742948717948718}]\n",
      "done 42 tensor(2.8083, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8376, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6879807692307692}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6864035087719298}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7663461538461538}]\n",
      "done 43 tensor(2.8376, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7753, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6605769230769231}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6896929824561404}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7695512820512821}]\n",
      "done 44 tensor(2.7753, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7879, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6745192307692308}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7154605263157895}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7301282051282052}]\n",
      "done 45 tensor(2.7879, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "done 46 tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.7150, grad_fn=<AddBackward0>)\n",
      "_++++++++++New Best++++____\n",
      "tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "{'hidden_layers': [600], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.1}\n",
      "___________\n",
      "++++++++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7263, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692309}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7025767543859649}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7384615384615385}]\n",
      "done 47 tensor(2.7263, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7956, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6341346153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6735197368421053}, {'decision': 2, 'accuracy': 0.8013698630136986, 'auc': 0.7419871794871795}]\n",
      "done 48 tensor(2.7956, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8560, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6812500000000001}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6822916666666667}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6852564102564103}]\n",
      "done 49 tensor(2.8560, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8169, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.65}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7094298245614035}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7442307692307693}]\n",
      "done 50 tensor(2.8169, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7564, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6158653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6669407894736842}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.6746794871794872}]\n",
      "done 51 tensor(2.7564, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7691, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7153846153846154}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7519230769230769}]\n",
      "done 52 tensor(2.7691, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7305, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6908653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7203947368421053}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7201923076923077}]\n",
      "done 53 tensor(2.7305, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7444, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.670673076923077}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7302631578947368}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7769230769230769}]\n",
      "done 54 tensor(2.7444, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8291, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6649038461538462}, {'decision': 1, 'accuracy': 0.7534246575342466, 'auc': 0.7250548245614035}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7631410256410257}]\n",
      "done 55 tensor(2.8291, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7556, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6471153846153845}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6647478070175439}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7413461538461539}]\n",
      "done 56 tensor(2.7556, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8389, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6908653846153846}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.659265350877193}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7477564102564103}]\n",
      "done 57 tensor(2.8389, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8019, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6576923076923077}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7113486842105263}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.760576923076923}]\n",
      "done 58 tensor(2.8019, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8001, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6749999999999999}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6705043859649122}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7564102564102564}]\n",
      "done 59 tensor(2.8001, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7223, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6711538461538461}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7083333333333333}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7391025641025641}]\n",
      "done 60 tensor(2.7223, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7080, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7466346153846155}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6759868421052632}, {'decision': 2, 'accuracy': 0.8356164383561644, 'auc': 0.7176282051282051}]\n",
      "done 61 tensor(2.7080, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7356, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6591346153846153}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6641995614035088}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7442307692307693}]\n",
      "done 62 tensor(2.7356, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8151, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8835616438356164, 'auc': 0.7024038461538461}, {'decision': 1, 'accuracy': 0.7465753424657534, 'auc': 0.6979166666666667}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7666666666666666}]\n",
      "done 63 tensor(2.8151, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7464, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6475961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6677631578947368}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7403846153846154}]\n",
      "done 64 tensor(2.7464, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7897, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6725961538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6729714912280702}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7580128205128205}]\n",
      "done 65 tensor(2.7897, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7963, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6394230769230769}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7069627192982456}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7685897435897435}]\n",
      "done 66 tensor(2.7963, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8113, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6615384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6729714912280702}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7753205128205127}]\n",
      "done 67 tensor(2.8113, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7493, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6610576923076923}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7283442982456141}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.7721153846153846}]\n",
      "done 68 tensor(2.7493, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8051, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7038461538461539}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7080592105263157}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7243589743589745}]\n",
      "done 69 tensor(2.8051, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7407, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6682692307692307}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6940789473684211}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7259615384615384}]\n",
      "done 70 tensor(2.7407, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7586, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6086538461538462}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6650219298245614}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7307692307692308}]\n",
      "done 71 tensor(2.7586, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7063, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6875}, {'decision': 1, 'accuracy': 0.7397260273972602, 'auc': 0.7135416666666666}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7589743589743589}]\n",
      "done 72 tensor(2.7063, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7378, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6586538461538463}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.7110745614035088}, {'decision': 2, 'accuracy': 0.8287671232876712, 'auc': 0.778525641025641}]\n",
      "done 73 tensor(2.7378, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7615, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6956730769230769}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.7012061403508771}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7439102564102564}]\n",
      "done 74 tensor(2.7615, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7420, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6240384615384615}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6998355263157895}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7509615384615385}]\n",
      "done 75 tensor(2.7420, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7639, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6331730769230769}, {'decision': 1, 'accuracy': 0.7876712328767124, 'auc': 0.6959978070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7471153846153846}]\n",
      "done 76 tensor(2.7639, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8025, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6735576923076924}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6910635964912281}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7528846153846154}]\n",
      "done 77 tensor(2.8025, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8040, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6557692307692308}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.6803728070175439}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7336538461538462}]\n",
      "done 78 tensor(2.8040, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7637, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6427884615384616}, {'decision': 1, 'accuracy': 0.7602739726027398, 'auc': 0.6836622807017544}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7541666666666667}]\n",
      "done 79 tensor(2.7637, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7725, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.7211538461538463}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6992872807017545}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7246794871794873}]\n",
      "done 80 tensor(2.7725, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7330, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6413461538461538}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.6949013157894737}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7794871794871795}]\n",
      "done 81 tensor(2.7330, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.7552, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.68125}, {'decision': 1, 'accuracy': 0.773972602739726, 'auc': 0.7044956140350876}, {'decision': 2, 'accuracy': 0.821917808219178, 'auc': 0.7625}]\n",
      "done 82 tensor(2.7552, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/DigitalTwinVis/python/Preprocessing.py:182: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:189: DtypeWarning: Columns (55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_file)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:203: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.means = self.processed_df.mean(axis=0)\n",
      "/data/DigitalTwinVis/python/Preprocessing.py:204: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  self.stds = self.processed_df.std(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++Final+++++++++++\n",
      "best tensor(2.8200, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6600961538461538}, {'decision': 1, 'accuracy': 0.7671232876712328, 'auc': 0.6880482456140351}, {'decision': 2, 'accuracy': 0.8082191780821918, 'auc': 0.7612179487179487}]\n",
      "done 83 tensor(2.8200, grad_fn=<AddBackward0>)\n",
      "curr best tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "_________\n",
      "+++++++++++\n",
      "best stuff tensor(2.6872, grad_fn=<AddBackward0>)\n",
      "[{'decision': 0, 'accuracy': 0.8904109589041096, 'auc': 0.6817307692307693}, {'decision': 1, 'accuracy': 0.7808219178082192, 'auc': 0.7075109649122806}, {'decision': 2, 'accuracy': 0.815068493150685, 'auc': 0.7807692307692308}]\n",
      "{'hidden_layers': [600], 'attention_heads': [3], 'embed_size': 210, 'dropout': 0.9, 'input_dropout': 0.5, 'shufflecol_chance': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionAttentionModel(\n",
       "  (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=210, out_features=600, bias=True)\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.9, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       "  (final_layer): Linear(in_features=600, out_features=6, bias=True)\n",
       "  (resize_layer): Linear(in_features=97, out_features=210, bias=True)\n",
       "  (attentions): ModuleList(\n",
       "    (0): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=210, out_features=210, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): LayerNorm((210,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gridsearch_decision_model(m1,m2,m3):\n",
    "    model_arglist = [\n",
    "\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [50,50],\n",
    "            'attention_heads': [1,1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [100,100],\n",
    "            'attention_heads': [2,2],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600],\n",
    "            'attention_heads': [3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [300,300],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [600,600],\n",
    "            'attention_heads': [3,3],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [1],\n",
    "        },\n",
    "        {\n",
    "            'hidden_layers': [1000],\n",
    "            'attention_heads': [5],\n",
    "        },\n",
    "    ]\n",
    "    best_loss = 100000000000\n",
    "    best_metrics = {}\n",
    "    best_args = {}\n",
    "    best_model = None\n",
    "    k = 0\n",
    "    for margs in model_arglist:\n",
    "        args = {k:v for k,v in margs.items()}\n",
    "        for embed_size in [0,120,210]:\n",
    "            #embed_size = 0 skips the firt layer that makes the sizes right\n",
    "            if embed_size == 0 and args['attention_heads'][0] != 1:\n",
    "                continue\n",
    "            args['embed_size'] = embed_size\n",
    "            for dropout in [.5,.9]:\n",
    "                args['dropout'] = dropout\n",
    "                for input_dropout in [.5]:\n",
    "                    args['input_dropout'] = input_dropout\n",
    "                    for shufflecol_chance in [.1,.5]:\n",
    "                        args['shufflecol_chance'] = shufflecol_chance\n",
    "                        model,m_metrics,m_loss = train_decision_model(m1,m2,m3,use_attention=True,verbose=False,**args)\n",
    "                        print('done',k,m_loss)\n",
    "                        print('curr best',best_loss)\n",
    "                        k+=1\n",
    "                        if m_loss < best_loss:\n",
    "                            best_loss = m_loss\n",
    "                            best_metrics  = m_metrics\n",
    "                            best_model = model\n",
    "                            best_args = args\n",
    "                            print('_++++++++++New Best++++____')\n",
    "                            print(best_loss)\n",
    "                            print(best_metrics)\n",
    "                            print(best_args)\n",
    "                            print('___________')\n",
    "                            print('++++++++')\n",
    "                            print()\n",
    "    print('_________')\n",
    "    print('+++++++++++')\n",
    "    print('best stuff',best_loss)\n",
    "    print(best_metrics)\n",
    "    print(best_args)\n",
    "    return best_model\n",
    "\n",
    "from Models import *\n",
    "decision_model = gridsearch_decision_model(model1,model2,model3)\n",
    "decision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e098f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_decision_model_statedecisions_input119_dims500_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(decision_model,'../data/models/final_decision_model_' + decision_model.identifier + '.pt')\n",
    "print('../data/models/final_decision_model_' + decision_model.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "91af46a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/models/final_transition1_model_state1_input50_dims1000_dropout0.5,0.9.pt\n",
      "../data/models/final_transition2_model_state2_input72_dims500,500_dropout0.5,0.9.pt\n",
      "../data/models/final_outcome_model_state1_input70_dims500,500_dropout0.5,0.9.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model1,'../data/models/final_transition1_model_' + model1.identifier + '.pt')\n",
    "torch.save(model2,'../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "torch.save(model3,'../data/models/final_outcome_model_' + model3.identifier + '.pt')\n",
    "print('../data/models/final_transition1_model_' + model1.identifier + '.pt')\n",
    "print('../data/models/final_transition2_model_' + model2.identifier + '.pt')\n",
    "print('../data/models/final_outcome_model_' + model3.identifier + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "xatt = []\n",
    "for att,xxdf in zip(list(attributions),xdf):\n",
    "    new = pd.DataFrame(att.cpu().detach().numpy(),columns=xxdf.columns,index=xxdf.index)\n",
    "    xatt.append(new)\n",
    "attributions = pd.concat(xatt,axis=1)\n",
    "attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ca3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions.sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.subplots(1,1,figsize=(100,100))\n",
    "sns.heatmap(data=attributions.T,ax=fig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakup_state_models(state_model):\n",
    "    #for state 1 and 2\n",
    "    models = {}\n",
    "    models['pd'] = lambda x: state_model(x)[0]\n",
    "    models['nd'] = lambda x: state_model(x)[1]\n",
    "    models['chemo'] = lambda x: state_model(x)[2]\n",
    "    for i,dlt in enumerate(Const.dlt1):\n",
    "        models[dlt] = lambda x: state_model(x)[3][:,i]\n",
    "    return models\n",
    "\n",
    "def breakup_outcome_models(omodel):\n",
    "    models = {}\n",
    "    for i,name in enumerate(Const.outcomes):\n",
    "        models[name] = lambda x: omodel(x)[:,i].reshape(-1,1)\n",
    "    return models\n",
    "\n",
    "def get_all_models(m1,m2,m3):\n",
    "    state1_models = breakup_state_models(m1)\n",
    "    state2_models = breakup_state_models(m2)\n",
    "    state3_models = breakup_outcome_models(m3)\n",
    "    all_models = {}\n",
    "    for i,sm in enumerate([state1_models,state2_models,state3_models]):\n",
    "        for ii,m in sm.items():\n",
    "            all_models[ii +  '_state' + str(i+1)] = m\n",
    "    return all_models\n",
    "\n",
    "all_models = get_all_models(model,model2,model3)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ytrue(name,df):\n",
    "    outcomes=None\n",
    "    value = None\n",
    "    if name == 'pd_state1':\n",
    "        outcomes = df[Const.primary_disease_states]\n",
    "    elif name == 'pd_state2':\n",
    "        outcomes = df[Const.primary_disease_states2]\n",
    "    elif name == 'nd_state1':\n",
    "        outcomes = df[Const.nodal_disease_states]\n",
    "    elif name == 'nd_state2':\n",
    "        outcomes = df[Const.nodal_disease_states2]\n",
    "    elif name == 'chemo_state1':\n",
    "        outcomes = df[Const.modifications]\n",
    "    elif name == 'chemo_state2':\n",
    "        outcomes = df[Const.ccs]   \n",
    "    if outcomes is not None:\n",
    "        value = outcomes.idxmax(axis=1)\n",
    "    if 'DLT' in name:\n",
    "        newname = name.replace('_state', ' ').replace('1','').strip()\n",
    "        value = df[newname]\n",
    "    if name.replace('_state3','') in Const.outcomes:\n",
    "        value = df[name.replace('_state3','')]\n",
    "    if value is None:\n",
    "        print(name,df.columns)\n",
    "    return value\n",
    "\n",
    "def check_impact_of_decisions(model_dict,data):\n",
    "    results = []\n",
    "    #todo: this is wrong fix it\n",
    "    ids = []\n",
    "    df = data.get_data()\n",
    "    outcomedict = {step: pd.concat(data.get_intermediate_outcomes(step=step),axis=1) for step in [1,2,3]}\n",
    "    for decision in Const.decisions:\n",
    "        for name, model in model_dict.items():\n",
    "            step = int(name[-1])\n",
    "            subset0 = dataset.get_input_state(step=step,fixed={decision: 0})\n",
    "            subset1 = dataset.get_input_state(step=step,fixed={decision: 1})\n",
    "            outcomes = outcomedict[step]\n",
    "            ids = subset0.index.values\n",
    "            x0 = df_to_torch(subset0)\n",
    "            x1 = df_to_torch(subset1)\n",
    "            y0 = model(x0).detach().cpu().numpy()\n",
    "            y1 = model(x1).detach().cpu().numpy()\n",
    "            original = data.get_input_state(step=step)\n",
    "            xx = df_to_torch(original)\n",
    "            yy = model(xx).detach().cpu().numpy()\n",
    "            ytrue = get_ytrue(name,outcomes)\n",
    "            if \"DLT\" in name:\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                change = y0 - y1\n",
    "                decision_change = (y0 != y1).astype(int)\n",
    "            elif y0.shape[1] == 1:\n",
    "                change = y1 - y0\n",
    "                decision_change = np.abs((y0 > .5).astype(int) - (y1 > .5).astype(int))\n",
    "            else:\n",
    "                index = np.unravel_index(np.argmax(yy, axis=1), yy.shape)\n",
    "                change = (y0[index] - y1[index]).reshape(-1,1)\n",
    "                decision_change =  (y0.argmax(axis=1).reshape(-1,1) != y1.argmax(axis=1).reshape(-1,1)).astype(int)\n",
    "                yy = yy.argmax(axis=1).reshape(-1,1)\n",
    "                y1 = y1.argmax(axis=1).reshape(-1,1)\n",
    "                y0 = y0.argmax(axis=1).reshape(-1,1)\n",
    "            outcome = name.replace('_state','')\n",
    "            for ii,pid in enumerate(ids):\n",
    "                oo = ytrue.loc[pid]\n",
    "                onew = y0[ii][0]\n",
    "                original_decision = df.loc[pid,decision]\n",
    "                if original_decision > 0:\n",
    "                    onew = y0[ii][0]\n",
    "                oname = Const.name_dict.get(name)\n",
    "                if oname is not None:\n",
    "                    onew = oname[onew]\n",
    "                entry = {'id': pid, 'decision': decision,'outcome': outcome,'original_choice': original_decision, 'original_result': oo, 'alt_result': onew, 'change': change[ii][0], 'decision_change': decision_change[ii][0]}\n",
    "                results.append(entry)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "test = check_impact_of_decisions(all_models,dataset)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db23ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_data()['SD Primary 2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ce1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test[test.outcome == 'pd2'].original_result == 'SD Primary 2').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_impact_of_decisions(all_models,dataset).to_csv('../data/decision_impacts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321249c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
