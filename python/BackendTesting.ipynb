{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28cb8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from Constants import *\n",
    "import simplejson\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "from DeepSurvivalModels import *\n",
    "from Utils import load_models\n",
    "from SymptomPrediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b5afd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model,transition_model1,transition_model2, outcome_model,survival_model = load_models()\n",
    "survival_model.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f42e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymptomPredictor(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=27, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final_layer): Linear(in_features=10, out_features=112, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp, _, mdasi = load_mdasi_stuff()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15bd4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "decision_model.set_device(device)\n",
    "transition_model1.set_device(device)\n",
    "transition_model2.set_device(device)\n",
    "outcome_model.set_device(device)\n",
    "survival_model.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6f5a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpv</th>\n",
       "      <th>age</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <th>FDM (months)</th>\n",
       "      <th>...</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>6_contra</th>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <th>RPLN_contra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6.03</td>\n",
       "      <td>4.70</td>\n",
       "      <td>6.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20.95</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>69.93</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>72.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>59.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>49.57</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>143.20</td>\n",
       "      <td>143.20</td>\n",
       "      <td>143.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>48.71</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>144.37</td>\n",
       "      <td>144.37</td>\n",
       "      <td>144.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>77.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.33</td>\n",
       "      <td>148.37</td>\n",
       "      <td>148.37</td>\n",
       "      <td>136.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.12</td>\n",
       "      <td>152.60</td>\n",
       "      <td>152.60</td>\n",
       "      <td>152.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>49.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.12</td>\n",
       "      <td>155.53</td>\n",
       "      <td>155.53</td>\n",
       "      <td>155.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpv    age  packs_per_year  gender  Aspiration rate Pre-therapy  \\\n",
       "id                                                                       \n",
       "3        1  55.97             0.0       1                            0   \n",
       "5        0  20.95            38.0       1                            0   \n",
       "6        1  69.93            35.0       0                            1   \n",
       "7        1  72.32             0.0       1                            0   \n",
       "8        1  59.73             0.0       1                            0   \n",
       "...    ...    ...             ...     ...                          ...   \n",
       "10201    1  49.57            30.0       1                            0   \n",
       "10202    0  48.71            30.0       1                            0   \n",
       "10203    1  77.12             0.0       1                            0   \n",
       "10204    0  45.95             5.0       1                            0   \n",
       "10205    1  49.73             0.0       1                            0   \n",
       "\n",
       "       total_dose  dose_fraction  OS (Calculated)  \\\n",
       "id                                                  \n",
       "3           66.00           2.20             6.03   \n",
       "5           72.00           1.80             7.33   \n",
       "6           70.00           2.12             7.47   \n",
       "7           70.00           2.12             7.80   \n",
       "8           66.00           2.20             8.07   \n",
       "...           ...            ...              ...   \n",
       "10201       70.00           2.12           143.20   \n",
       "10202       72.00           1.71           144.37   \n",
       "10203       70.00           2.33           148.37   \n",
       "10204       69.96           2.12           152.60   \n",
       "10205       69.96           2.12           155.53   \n",
       "\n",
       "       Locoregional control (Time)  FDM (months)  ...  4_ipsi  4_contra  \\\n",
       "id                                                ...                     \n",
       "3                             4.70          6.03  ...     0.0       0.0   \n",
       "5                             7.33          7.33  ...     0.0       0.0   \n",
       "6                             7.47          7.47  ...     0.0       0.0   \n",
       "7                             7.80          7.80  ...     0.0       0.0   \n",
       "8                             8.07          8.07  ...     0.0       0.0   \n",
       "...                            ...           ...  ...     ...       ...   \n",
       "10201                       143.20        143.20  ...     0.0       0.0   \n",
       "10202                       144.37        144.37  ...     0.0       0.0   \n",
       "10203                       148.37        136.03  ...     0.0       0.0   \n",
       "10204                       152.60        152.60  ...     0.0       0.0   \n",
       "10205                       155.53        155.53  ...     0.0       0.0   \n",
       "\n",
       "       5A_ipsi  5A_contra  5B_ipsi  5B_contra  6_ipsi  6_contra  RPLN_ipsi  \\\n",
       "id                                                                           \n",
       "3          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "5          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "6          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "7          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "8          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "...        ...        ...      ...        ...     ...       ...        ...   \n",
       "10201      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10202      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10203      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10204      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10205      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "\n",
       "       RPLN_contra  \n",
       "id                  \n",
       "3              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "...            ...  \n",
       "10201          0.0  \n",
       "10202          0.0  \n",
       "10203          0.0  \n",
       "10204          0.0  \n",
       "10205          0.0  \n",
       "\n",
       "[536 rows x 109 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset()\n",
    "newdf = data.processed_df.copy()\n",
    "for c in newdf.columns:\n",
    "    if newdf[c].dtype == np.float64:\n",
    "        newdf[c] = newdf[c].astype(np.float32).apply(lambda x: np.round(x,2))\n",
    "data.processed_df = newdf\n",
    "data.processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6056f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1A_contra</th>\n",
       "      <th>1A_ipsi</th>\n",
       "      <th>1B_contra</th>\n",
       "      <th>1B_ipsi</th>\n",
       "      <th>2A_contra</th>\n",
       "      <th>2A_ipsi</th>\n",
       "      <th>2B_contra</th>\n",
       "      <th>2B_ipsi</th>\n",
       "      <th>3_contra</th>\n",
       "      <th>3_ipsi</th>\n",
       "      <th>...</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>gender</th>\n",
       "      <th>hpv</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>subsite_BOT</th>\n",
       "      <th>subsite_GPS</th>\n",
       "      <th>subsite_NOS</th>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <th>total_dose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1A_contra  1A_ipsi  1B_contra  1B_ipsi  2A_contra  2A_ipsi  2B_contra  \\\n",
       "id                                                                             \n",
       "3            0.0      0.0        0.0      0.0        1.0      0.0        1.0   \n",
       "5            0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "6            0.0      0.0        0.0      0.0        1.0      1.0        1.0   \n",
       "7            0.0      0.0        1.0      0.0        0.0      0.0        0.0   \n",
       "8            0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "...          ...      ...        ...      ...        ...      ...        ...   \n",
       "10201        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10202        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10203        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10204        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10205        0.0      0.0        0.0      0.0        0.0      0.0        0.0   \n",
       "\n",
       "       2B_ipsi  3_contra  3_ipsi  ...  dose_fraction  gender  hpv  \\\n",
       "id                                ...                               \n",
       "3          0.0       0.0     0.0  ...           2.20       1    1   \n",
       "5          1.0       0.0     0.0  ...           1.80       1    0   \n",
       "6          1.0       1.0     1.0  ...           2.12       0    1   \n",
       "7          0.0       0.0     0.0  ...           2.12       1    1   \n",
       "8          1.0       0.0     0.0  ...           2.20       1    1   \n",
       "...        ...       ...     ...  ...            ...     ...  ...   \n",
       "10201      1.0       0.0     0.0  ...           2.12       1    1   \n",
       "10202      1.0       0.0     0.0  ...           1.71       1    0   \n",
       "10203      1.0       0.0     1.0  ...           2.33       1    1   \n",
       "10204      1.0       0.0     1.0  ...           2.12       1    0   \n",
       "10205      0.0       0.0     1.0  ...           2.12       1    1   \n",
       "\n",
       "       packs_per_year  subsite_BOT  subsite_GPS  subsite_NOS  \\\n",
       "id                                                             \n",
       "3                 0.0            1            0            0   \n",
       "5                38.0            1            0            0   \n",
       "6                35.0            1            0            0   \n",
       "7                 0.0            0            0            1   \n",
       "8                 0.0            0            0            0   \n",
       "...               ...          ...          ...          ...   \n",
       "10201            30.0            1            0            0   \n",
       "10202            30.0            0            0            1   \n",
       "10203             0.0            0            0            0   \n",
       "10204             5.0            0            0            0   \n",
       "10205             0.0            1            0            0   \n",
       "\n",
       "       subsite_Soft palate  subsite_Tonsil  total_dose  \n",
       "id                                                      \n",
       "3                        0               0       66.00  \n",
       "5                        0               0       72.00  \n",
       "6                        0               0       70.00  \n",
       "7                        0               0       70.00  \n",
       "8                        0               1       66.00  \n",
       "...                    ...             ...         ...  \n",
       "10201                    0               0       70.00  \n",
       "10202                    0               0       72.00  \n",
       "10203                    0               1       70.00  \n",
       "10204                    0               1       69.96  \n",
       "10205                    0               0       69.96  \n",
       "\n",
       "[536 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)\n",
    "\n",
    "def get_decision_input(dataset,state=0,ids=None):\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    dlt1 = dataset.get_state('dlt1')\n",
    "    dlt2 = dataset.get_state('dlt2')\n",
    "    pd1 = dataset.get_state('pd_states1')\n",
    "    pd2 = dataset.get_state('pd_states2')\n",
    "    nd1 = dataset.get_state('nd_states1')\n",
    "    nd2 = dataset.get_state('nd_states2')\n",
    "    modifications = dataset.get_state('modifications')\n",
    "    ccs = dataset.get_state('ccs')\n",
    "    if state < 2:\n",
    "        pd = pd1.copy()\n",
    "        nd = nd1.copy()\n",
    "        dlt2.values[:,:] = np.zeros(dlt2.shape)\n",
    "        ccs.values[:,:] = np.zeros(ccs.shape)\n",
    "        if state < 1:\n",
    "            dlt1.values[:,:] = np.zeros(dlt1.shape)\n",
    "            modifications.values[:,:] = np.zeros(modifications.shape)\n",
    "            pd.values[:,:] = np.zeros(pd.shape)\n",
    "            nd.values[:,:] = np.zeros(nd.shape)\n",
    "    else:\n",
    "        pd = pd2.copy()\n",
    "        nd = nd2.copy()\n",
    "        \n",
    "    output = [baseline, dlt1, dlt2, pd, nd,ccs,modifications]\n",
    "    if ids is not None:\n",
    "        output = [o.loc[ids] for o in output]\n",
    "    return output\n",
    "test_patient_id=7\n",
    "get_decision_input(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d795eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1A_contra',\n",
       "  '1A_ipsi',\n",
       "  '1B_contra',\n",
       "  '1B_ipsi',\n",
       "  '2A_contra',\n",
       "  '2A_ipsi',\n",
       "  '2B_contra',\n",
       "  '2B_ipsi',\n",
       "  '3_contra',\n",
       "  '3_ipsi',\n",
       "  '4_contra',\n",
       "  '4_ipsi',\n",
       "  '5A_contra',\n",
       "  '5A_ipsi',\n",
       "  '5B_contra',\n",
       "  '5B_ipsi',\n",
       "  '6_contra',\n",
       "  '6_ipsi',\n",
       "  'AJCC_1',\n",
       "  'AJCC_2',\n",
       "  'AJCC_3',\n",
       "  'AJCC_4',\n",
       "  'African American/Black',\n",
       "  'Asian',\n",
       "  'Aspiration rate Pre-therapy',\n",
       "  'DLT_Infection (Pneumonia)',\n",
       "  'DLT_Infection (Pneumonia) 2',\n",
       "  'DLT_Nephrological',\n",
       "  'DLT_Nephrological 2',\n",
       "  'DLT_Vascular',\n",
       "  'DLT_Vascular 2',\n",
       "  'Hispanic/Latino',\n",
       "  'N-category_0',\n",
       "  'N-category_1',\n",
       "  'N-category_2',\n",
       "  'N-category_3',\n",
       "  'Pathological Grade_0',\n",
       "  'Pathological Grade_1',\n",
       "  'Pathological Grade_2',\n",
       "  'Pathological Grade_3',\n",
       "  'Pathological Grade_4',\n",
       "  'RPLN_contra',\n",
       "  'RPLN_ipsi',\n",
       "  'T-category_1',\n",
       "  'T-category_2',\n",
       "  'T-category_3',\n",
       "  'T-category_4',\n",
       "  'White/Caucasion',\n",
       "  'age',\n",
       "  'bilateral',\n",
       "  'dose_fraction',\n",
       "  'gender',\n",
       "  'hpv',\n",
       "  'packs_per_year',\n",
       "  'subsite_BOT',\n",
       "  'subsite_GPS',\n",
       "  'subsite_NOS',\n",
       "  'subsite_Soft palate',\n",
       "  'subsite_Tonsil',\n",
       "  'total_dose'],\n",
       " ['DLT_Dermatological',\n",
       "  'DLT_Gastrointestinal',\n",
       "  'DLT_Other',\n",
       "  'DLT_Hematological',\n",
       "  'DLT_Neurological'],\n",
       " ['DLT_Dermatological 2',\n",
       "  'DLT_Gastrointestinal 2',\n",
       "  'DLT_Other 2',\n",
       "  'DLT_Hematological 2',\n",
       "  'DLT_Neurological 2'],\n",
       " ['CR Primary', 'PR Primary', 'SD Primary'],\n",
       " ['CR Nodal', 'PR Nodal', 'SD Nodal'],\n",
       " ['cc_none', 'cc_platinum', 'cc_cetuximab', 'cc_others'],\n",
       " ['no_dose_adjustment',\n",
       "  'dose_modified',\n",
       "  'dose_delayed',\n",
       "  'dose_cancelled',\n",
       "  'dose_delayed_&_modified',\n",
       "  'regiment_modification']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_inputkey_order(dataset,state=0):\n",
    "    return [list(f.columns) for f in get_decision_input(dataset,state=state)]\n",
    "\n",
    "get_inputkey_order(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a507552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpv': 1,\n",
       " 'age': 72.32,\n",
       " 'packs_per_year': 0.0,\n",
       " 'gender': 1,\n",
       " 'Aspiration rate Pre-therapy': 0,\n",
       " 'total_dose': 70.0,\n",
       " 'dose_fraction': 2.12,\n",
       " 'OS (Calculated)': 7.8,\n",
       " 'Locoregional control (Time)': 7.8,\n",
       " 'FDM (months)': 7.8,\n",
       " 'time_to_event': 6.0,\n",
       " 'Overall Survival (1=alive, 0=dead)': 0,\n",
       " 'LRC': 1,\n",
       " 'DC': 1,\n",
       " 'bilateral': False,\n",
       " 'White/Caucasion': True,\n",
       " 'Hispanic/Latino': False,\n",
       " 'African American/Black': False,\n",
       " 'Asian': False,\n",
       " 'cc_none': 1,\n",
       " 'cc_platinum': 0,\n",
       " 'cc_cetuximab': 0,\n",
       " 'cc_others': 0,\n",
       " 'no_dose_adjustment': 1,\n",
       " 'dose_modified': 0,\n",
       " 'dose_delayed': 0,\n",
       " 'dose_cancelled': 0,\n",
       " 'dose_delayed_&_modified': 0,\n",
       " 'regiment_modification': 0,\n",
       " 'T-category_1': 1,\n",
       " 'T-category_2': 0,\n",
       " 'T-category_3': 0,\n",
       " 'T-category_4': 0,\n",
       " 'N-category_0': 0,\n",
       " 'N-category_1': 0,\n",
       " 'N-category_2': 1,\n",
       " 'N-category_3': 0,\n",
       " 'AJCC_1': 0,\n",
       " 'AJCC_2': 1,\n",
       " 'AJCC_3': 0,\n",
       " 'AJCC_4': 0,\n",
       " 'Pathological Grade_0': 1,\n",
       " 'Pathological Grade_1': 0,\n",
       " 'Pathological Grade_2': 0,\n",
       " 'Pathological Grade_3': 0,\n",
       " 'Pathological Grade_4': 0,\n",
       " 'subsite_BOT': 0,\n",
       " 'subsite_GPS': 0,\n",
       " 'subsite_NOS': 1,\n",
       " 'subsite_Soft palate': 0,\n",
       " 'subsite_Tonsil': 0,\n",
       " 'treatment_CC': 0,\n",
       " 'treatment_IC+CC': 0,\n",
       " 'treatment_IC+Radiation alone': 0,\n",
       " 'treatment_Radiation alone': 1,\n",
       " 'DLT_Dermatological': 0.0,\n",
       " 'DLT_Neurological': 0.0,\n",
       " 'DLT_Gastrointestinal': 0.0,\n",
       " 'DLT_Hematological': 0.0,\n",
       " 'DLT_Nephrological': 0,\n",
       " 'DLT_Vascular': 0,\n",
       " 'DLT_Infection (Pneumonia)': 0,\n",
       " 'DLT_Other': 0.0,\n",
       " 'DLT_Dermatological 2': 0.0,\n",
       " 'DLT_Neurological 2': 0.0,\n",
       " 'DLT_Gastrointestinal 2': 0.0,\n",
       " 'DLT_Hematological 2': 0.0,\n",
       " 'DLT_Nephrological 2': 0,\n",
       " 'DLT_Vascular 2': 0,\n",
       " 'DLT_Infection (Pneumonia) 2': 0,\n",
       " 'DLT_Other 2': 0.0,\n",
       " 'CR Primary': 0,\n",
       " 'PR Primary': 0,\n",
       " 'SD Primary': 0,\n",
       " 'CR Nodal': 0,\n",
       " 'PR Nodal': 0,\n",
       " 'SD Nodal': 0,\n",
       " 'CR Primary 2': 0,\n",
       " 'PR Primary 2': 0,\n",
       " 'SD Primary 2': 0,\n",
       " 'CR Nodal 2': 0,\n",
       " 'PR Nodal 2': 0,\n",
       " 'SD Nodal 2': 0,\n",
       " 'Decision 1 (Induction Chemo) Y/N': 0,\n",
       " 'Decision 2 (CC / RT alone)': 0,\n",
       " 'Decision 3 Neck Dissection (Y/N)': 0,\n",
       " 'Overall Survival (4 Years)': 0,\n",
       " 'FT': 1,\n",
       " 'Aspiration rate Post-therapy': 0,\n",
       " '1A_ipsi': 0.0,\n",
       " '1A_contra': 0.0,\n",
       " '1B_ipsi': 0.0,\n",
       " '1B_contra': 1.0,\n",
       " '2A_ipsi': 0.0,\n",
       " '2A_contra': 0.0,\n",
       " '2B_ipsi': 0.0,\n",
       " '2B_contra': 0.0,\n",
       " '3_ipsi': 0.0,\n",
       " '3_contra': 0.0,\n",
       " '4_ipsi': 0.0,\n",
       " '4_contra': 0.0,\n",
       " '5A_ipsi': 0.0,\n",
       " '5A_contra': 0.0,\n",
       " '5B_ipsi': 0.0,\n",
       " '5B_contra': 0.0,\n",
       " '6_ipsi': 0.0,\n",
       " '6_contra': 0.0,\n",
       " 'RPLN_ipsi': 0.0,\n",
       " 'RPLN_contra': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_patient(d,pid=7,clear_transitions=True):\n",
    "    tp = d.processed_df.loc[pid].to_dict()\n",
    "    if clear_transitions:\n",
    "        for v in Const.primary_disease_states + Const.nodal_disease_states:\n",
    "            tp[v] = 0\n",
    "            tp[v + ' 2'] = 0\n",
    "    return tp \n",
    "test_patient = get_test_patient(data)\n",
    "test_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca3cb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [210, 1326, 1237, 300, 217, 419, 95, 36, 1213, 326],\n",
       " 'dists': [10.411657637487844,\n",
       "  10.610095943143657,\n",
       "  11.06157815134213,\n",
       "  11.636424474042284,\n",
       "  12.073060129393431,\n",
       "  12.212691495256948,\n",
       "  12.365511924050711,\n",
       "  12.463391159171282,\n",
       "  12.527598835556905,\n",
       "  12.556216638408957],\n",
       " 'symptoms': {'choke': {'ratings': [[0.641221374,\n",
       "     0.0,\n",
       "     0.399753958,\n",
       "     0.395729452],\n",
       "    [0.0, 2.180908442, 0.826929212, 1.194316268],\n",
       "    [0.0, 0.0, 0.0, 0.190721899],\n",
       "    [1.0, 3.0, 1.0, 0.0],\n",
       "    [0.0, 2.0, 1.0, 0.0],\n",
       "    [0.0, 2.142912626, 2.0, 1.0],\n",
       "    [1.0, 5.0, 0.0, 8.0],\n",
       "    [0.0, 3.0, 1.0, 1.217005014],\n",
       "    [0.641221374, 0.0, 0.433015466, 0.607653797],\n",
       "    [3.0, 4.071236134, 0.0, 2.0]],\n",
       "   'means': [0.6282442748, 2.1395057202, 0.6659698636, 1.460542643]},\n",
       "  'drymouth': {'ratings': [[0.945638432, 10.0, 5.89109087, 7.00032568],\n",
       "    [0.0, 4.599039555, 4.078390598, 4.400919914],\n",
       "    [0.0, 5.0, 2.0, 3.301947355],\n",
       "    [0.0, 2.0, 1.0, 1.0],\n",
       "    [1.0, 8.0, 4.0, 2.0],\n",
       "    [0.0, 4.804407597, 8.0, 7.0],\n",
       "    [0.0, 7.0, 6.0, 4.0],\n",
       "    [0.0, 3.0, 2.0, 3.789712667],\n",
       "    [0.945638432, 10.0, 6.739617348, 6.271075249],\n",
       "    [0.0, 4.804407597, 4.0, 6.0]],\n",
       "   'means': [0.2891276864, 5.9207854749, 4.3709098816, 4.4763980865]}},\n",
       " 'dates': [0, 7, 12, 27]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from ClusterPredictions.py\n",
    "test_patient = get_test_patient(data,7)\n",
    "get_knn_predictions(test_patient,sp,mdasi,symptom_subset=['choke','drymouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bef88125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(536, 1000), (536, 1000), (536, 1000)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings(dataset,dm,states=[0,1,2],use_saved_memory=True,decimals=2):\n",
    "    embeddings = []\n",
    "    inputs = []\n",
    "    decisions_optimal = [[] for i in states]\n",
    "    decisions_imitation = [[] for i in states]\n",
    "    for i,state in enumerate(states):\n",
    "        x = get_decision_input(dataset,state=state)\n",
    "        x = torch.cat([df_to_torch(f) for f in x],axis=1).to(dm.get_device())\n",
    "        print(x.shape)\n",
    "        embedding = dm.get_embedding(x,position = state,use_saved_memory=True)\n",
    "        inputs.append(x.cpu().detach().numpy())\n",
    "        decision = dm(x,position=state).cpu().detach().numpy()\n",
    "        decisions_optimal[i].append(decision[:,state])\n",
    "        decisions_imitation[i].append(decision[:,state+3])\n",
    "        embedding = embedding.cpu().detach().numpy()\n",
    "        if decimals is not None:\n",
    "            embedding = np.round(embedding,decimals)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings,np.array(decisions_optimal).reshape(len(states),-1).T, np.array(decisions_imitation).reshape(len(states),-1).T, inputs\n",
    "embeddings, decisions_optimal, decisions_imitation, testinputs = get_embeddings(data,decision_model)\n",
    "[e.shape for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1789c54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <th>FDM (months)</th>\n",
       "      <th>time_to_event</th>\n",
       "      <th>OS (Calculated)_5%</th>\n",
       "      <th>Locoregional control (Time)_5%</th>\n",
       "      <th>FDM (months)_5%</th>\n",
       "      <th>time_to_event_5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.478271</td>\n",
       "      <td>1060.589966</td>\n",
       "      <td>2004.874512</td>\n",
       "      <td>49.507156</td>\n",
       "      <td>255.353928</td>\n",
       "      <td>879.507080</td>\n",
       "      <td>1654.452271</td>\n",
       "      <td>42.698605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>245.843048</td>\n",
       "      <td>911.368835</td>\n",
       "      <td>1745.499512</td>\n",
       "      <td>34.479568</td>\n",
       "      <td>218.709457</td>\n",
       "      <td>849.597961</td>\n",
       "      <td>1569.658813</td>\n",
       "      <td>32.860043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>329.097778</td>\n",
       "      <td>1238.492188</td>\n",
       "      <td>2055.133057</td>\n",
       "      <td>48.247662</td>\n",
       "      <td>285.955994</td>\n",
       "      <td>1094.309448</td>\n",
       "      <td>1656.599365</td>\n",
       "      <td>40.931019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OS (Calculated)  Locoregional control (Time)  FDM (months)  time_to_event  \\\n",
       "id                                                                              \n",
       "3        276.478271                  1060.589966   2004.874512      49.507156   \n",
       "5        245.843048                   911.368835   1745.499512      34.479568   \n",
       "7        329.097778                  1238.492188   2055.133057      48.247662   \n",
       "\n",
       "    OS (Calculated)_5%  Locoregional control (Time)_5%  FDM (months)_5%  \\\n",
       "id                                                                        \n",
       "3           255.353928                      879.507080      1654.452271   \n",
       "5           218.709457                      849.597961      1569.658813   \n",
       "7           285.955994                     1094.309448      1656.599365   \n",
       "\n",
       "    time_to_event_5%  \n",
       "id                    \n",
       "3          42.698605  \n",
       "5          32.860043  \n",
       "7          40.931019  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed\n",
    "def get_predictions(dataset,m1,m2,m3,sm3,states=[0,1,2],ids=None):\n",
    "    outcomes = {}\n",
    "    def add_outcomes(names, array,suffix=''):\n",
    "        for i,name in enumerate(names):\n",
    "            outcomes[name+suffix] = array[:,i]\n",
    "    for model,state in zip([m1,m2,m3],states):\n",
    "        x = dataset.get_input_state(step=state+1,ids=ids)\n",
    "        x = df_to_torch(x).to(model.get_device())\n",
    "        yout = model(x)\n",
    "        y = yout['predictions']\n",
    "        y_lower = yout['5%']\n",
    "        y_upper = yout['95%']\n",
    "        if state < 2:\n",
    "            y = [yy.cpu().detach().numpy() for yy in y]\n",
    "            y_lower = [yy.cpu().detach().numpy() for yy in y_lower]\n",
    "            y_upper = [yy.cpu().detach().numpy() for yy in y_upper]\n",
    "        else:\n",
    "            y = y.cpu().detach().numpy()\n",
    "            y_lower = y_lower.cpu().detach().numpy()\n",
    "            y_upper = y_upper.cpu().detach().numpy()\n",
    "        if state == 0:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                [pds, nd, mod, dlts] = values\n",
    "                add_outcomes(Const.primary_disease_states,pds,suffixes)\n",
    "                add_outcomes(Const.nodal_disease_states,nd,suffixes)\n",
    "                add_outcomes(Const.modifications,mod,suffixes)\n",
    "                add_outcomes(Const.dlt1,dlts,suffixes)\n",
    "        elif state == 1:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                [pd2, nd2, cc, dlts2] = values\n",
    "                add_outcomes(Const.primary_disease_states2,pd2,suffixes)\n",
    "                add_outcomes(Const.nodal_disease_states2,nd2,suffixes)\n",
    "                add_outcomes(Const.dlt2,dlts2,suffixes)\n",
    "        else:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                add_outcomes(Const.outcomes,values,suffixes)\n",
    "        if state == 2: #timeseries outcomes\n",
    "            survival = sm3.time_to_event(x,n_samples=20)\n",
    "            s = survival['predictions']\n",
    "            s_lower = survival['5%']\n",
    "            s_upper= survival['95%']\n",
    "            names = survival['order']\n",
    "            for suffixes,values in zip(['','_5%','_95%'],[s,s_lower,s_upper]):\n",
    "                values = torch.stack(values,axis=1).cpu().detach().numpy()\n",
    "                add_outcomes(names,values,suffixes)\n",
    "    if ids is None:\n",
    "        ids = dataset.processed_df.index.values\n",
    "    outcomes = pd.DataFrame(outcomes,ids)\n",
    "    outcomes.index.name = 'id'\n",
    "    return outcomes\n",
    "prediction_df = get_predictions(data,transition_model1,transition_model2,outcome_model,survival_model,ids=[3,5,7])\n",
    "prediction_df[Const.timeseries_outcomes + [c+'_5%' for c in Const.timeseries_outcomes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ce07c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_state0</th>\n",
       "      <th>embeddings_state1</th>\n",
       "      <th>embeddings_state2</th>\n",
       "      <th>decision0_optimal</th>\n",
       "      <th>decision0_imitation</th>\n",
       "      <th>inputs0</th>\n",
       "      <th>decision1_optimal</th>\n",
       "      <th>decision1_imitation</th>\n",
       "      <th>inputs1</th>\n",
       "      <th>decision2_optimal</th>\n",
       "      <th>decision2_imitation</th>\n",
       "      <th>inputs2</th>\n",
       "      <th>pca_state0</th>\n",
       "      <th>pca_state1</th>\n",
       "      <th>pca_state2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.316692</td>\n",
       "      <td>0.975234</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.014228</td>\n",
       "      <td>0.046543</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.238401</td>\n",
       "      <td>0.009295</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.48599806, -0.5067524]</td>\n",
       "      <td>[-0.4611578, -0.4542863]</td>\n",
       "      <td>[0.4950279, -0.45573425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.431012</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.285786</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[1.2279857, -0.2638627]</td>\n",
       "      <td>[1.0930555, -0.049006347]</td>\n",
       "      <td>[-1.0168164, 0.2946523]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.152556</td>\n",
       "      <td>0.780169</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.550291</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.814472</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.6808401, -0.6142947]</td>\n",
       "      <td>[1.5080665, -0.62427104]</td>\n",
       "      <td>[-1.4530879, -0.14535163]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.382589</td>\n",
       "      <td>0.974404</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.038130</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.167591</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.22417434, -0.59941584]</td>\n",
       "      <td>[0.32101038, -0.8630784]</td>\n",
       "      <td>[-0.6066542, -0.69495326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0...</td>\n",
       "      <td>[0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0...</td>\n",
       "      <td>[0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0...</td>\n",
       "      <td>0.646277</td>\n",
       "      <td>0.926530</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.267861</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.827730</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-1.7481061, 0.70407486]</td>\n",
       "      <td>[-1.7501675, 0.87835765]</td>\n",
       "      <td>[2.0707154, 0.6257535]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>[0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.343991</td>\n",
       "      <td>0.961293</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.040806</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.076424</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.13142826, -0.6250572]</td>\n",
       "      <td>[0.24083416, -0.6654044]</td>\n",
       "      <td>[-0.37384632, -0.4156536]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>[0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.231363</td>\n",
       "      <td>0.662527</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.581702</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.6399173, -0.50798917]</td>\n",
       "      <td>[0.6126189, -0.21000423]</td>\n",
       "      <td>[-0.58370227, 0.019878915]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>[0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.597669</td>\n",
       "      <td>0.947900</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.080840</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.036060</td>\n",
       "      <td>0.026733</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.05236334, 0.1410638]</td>\n",
       "      <td>[0.0546041, 0.066014394]</td>\n",
       "      <td>[-0.11206166, 0.18491487]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>[0.51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78, 0.0...</td>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72, 0.0...</td>\n",
       "      <td>[0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, ...</td>\n",
       "      <td>0.869228</td>\n",
       "      <td>0.968241</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>0.021405</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.019984</td>\n",
       "      <td>0.097320</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-0.09948424, 0.9421311]</td>\n",
       "      <td>[0.042801976, 0.9283188]</td>\n",
       "      <td>[-0.35316196, 0.8810963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>[0.57, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.670887</td>\n",
       "      <td>0.923345</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.154901</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.082597</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.16059673, 0.5734292]</td>\n",
       "      <td>[0.23386106, 0.64711577]</td>\n",
       "      <td>[-0.1040514, 0.5437524]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       embeddings_state0  \\\n",
       "3      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5      [0.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "6      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7      [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "8      [0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0...   \n",
       "...                                                  ...   \n",
       "10201  [0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10202  [0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10203  [0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10204  [0.51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78, 0.0...   \n",
       "10205  [0.57, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                       embeddings_state1  \\\n",
       "3      [0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5      [0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "6      [0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7      [0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "8      [0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0...   \n",
       "...                                                  ...   \n",
       "10201  [0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10202  [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10203  [0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10204  [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72, 0.0...   \n",
       "10205  [0.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                       embeddings_state2  decision0_optimal  \\\n",
       "3      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.316692   \n",
       "5      [0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.206143   \n",
       "6      [0.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.152556   \n",
       "7      [0.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.382589   \n",
       "8      [0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0...           0.646277   \n",
       "...                                                  ...                ...   \n",
       "10201  [0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.343991   \n",
       "10202  [0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.231363   \n",
       "10203  [0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.597669   \n",
       "10204  [0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, ...           0.869228   \n",
       "10205  [0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.670887   \n",
       "\n",
       "       decision0_imitation                                            inputs0  \\\n",
       "3                 0.975234  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "5                 0.431012  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "6                 0.780169  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7                 0.974404  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8                 0.926530  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "...                    ...                                                ...   \n",
       "10201             0.961293  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10202             0.662527  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10203             0.947900  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10204             0.968241  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10205             0.923345  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "       decision1_optimal  decision1_imitation  \\\n",
       "3               0.014228             0.046543   \n",
       "5               0.002773             0.740242   \n",
       "6               0.001058             0.550291   \n",
       "7               0.005391             0.038130   \n",
       "8               0.267861             0.013551   \n",
       "...                  ...                  ...   \n",
       "10201           0.004293             0.040806   \n",
       "10202           0.006591             0.581702   \n",
       "10203           0.013460             0.080840   \n",
       "10204           0.020048             0.021405   \n",
       "10205           0.016314             0.154901   \n",
       "\n",
       "                                                 inputs1  decision2_optimal  \\\n",
       "3      [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...           0.238401   \n",
       "5      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.005234   \n",
       "6      [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...           0.001898   \n",
       "7      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0.007590   \n",
       "8      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.827730   \n",
       "...                                                  ...                ...   \n",
       "10201  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.028569   \n",
       "10202  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.019213   \n",
       "10203  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.036060   \n",
       "10204  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.019984   \n",
       "10205  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0.082597   \n",
       "\n",
       "       decision2_imitation                                            inputs2  \\\n",
       "3                 0.009295  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "5                 0.285786  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "6                 0.814472  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7                 0.167591  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8                 0.001123  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "...                    ...                                                ...   \n",
       "10201             0.076424  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10202             0.064822  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10203             0.026733  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10204             0.097320  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10205             0.040203  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                      pca_state0                 pca_state1  \\\n",
       "3      [-0.48599806, -0.5067524]   [-0.4611578, -0.4542863]   \n",
       "5        [1.2279857, -0.2638627]  [1.0930555, -0.049006347]   \n",
       "6        [1.6808401, -0.6142947]   [1.5080665, -0.62427104]   \n",
       "7      [0.22417434, -0.59941584]   [0.32101038, -0.8630784]   \n",
       "8       [-1.7481061, 0.70407486]   [-1.7501675, 0.87835765]   \n",
       "...                          ...                        ...   \n",
       "10201   [0.13142826, -0.6250572]   [0.24083416, -0.6654044]   \n",
       "10202   [0.6399173, -0.50798917]   [0.6126189, -0.21000423]   \n",
       "10203    [0.05236334, 0.1410638]   [0.0546041, 0.066014394]   \n",
       "10204   [-0.09948424, 0.9421311]   [0.042801976, 0.9283188]   \n",
       "10205    [0.16059673, 0.5734292]   [0.23386106, 0.64711577]   \n",
       "\n",
       "                       pca_state2  \n",
       "3        [0.4950279, -0.45573425]  \n",
       "5         [-1.0168164, 0.2946523]  \n",
       "6       [-1.4530879, -0.14535163]  \n",
       "7       [-0.6066542, -0.69495326]  \n",
       "8          [2.0707154, 0.6257535]  \n",
       "...                           ...  \n",
       "10201   [-0.37384632, -0.4156536]  \n",
       "10202  [-0.58370227, 0.019878915]  \n",
       "10203   [-0.11206166, 0.18491487]  \n",
       "10204    [-0.35316196, 0.8810963]  \n",
       "10205     [-0.1040514, 0.5437524]  \n",
       "\n",
       "[536 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def get_embedding_pcas(dataset,decision_model,embeddings=None,components=2):\n",
    "    if embeddings is None:\n",
    "        embeddings, _, _, _ = get_embeddings(dataset,decision_model,states=[0,1,2])\n",
    "    pcas = [PCA(components,whiten=True).fit(e) for e in embeddings]\n",
    "    return pcas\n",
    "\n",
    "def get_embedding_df(dataset,dm,states=[0,1,2],pcas=None,**kwargs):\n",
    "    embeddings, decisions_opt, decisions_im, embedding_inputs = get_embeddings(dataset,dm,\n",
    "                                                                                      states=states,**kwargs)\n",
    "    values = {'embeddings_state'+str(i): [np.array(ee) for ee in e] for i,e in zip(states,embeddings)}\n",
    "    newdf = pd.DataFrame(values,index=dataset.processed_df.index.values)\n",
    "    for ii in states:\n",
    "        opt = decisions_opt[:,ii]\n",
    "        im = decisions_im[:,ii]\n",
    "        newdf['decision'+str(ii)+\"_optimal\"] = opt\n",
    "        newdf['decision'+str(ii)+'_imitation'] = im\n",
    "        newdf['inputs'+str(ii)] = [np.array(ee) for ee in embedding_inputs[ii]]\n",
    "    \n",
    "    if pcas is None:\n",
    "        pcas = get_embedding_pcas(dataset,dm,embeddings=embeddings)\n",
    "    reductions = [ipca.fit_transform(e) for ipca,e in zip(pcas,embeddings)]\n",
    "    for state,r in enumerate(reductions):\n",
    "        newdf['pca_state'+str(state)] = [np.array(rr) for rr in r]\n",
    "    return newdf\n",
    "\n",
    "embedding_df = get_embedding_df(data,decision_model)\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77caefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7] ['hpv', 'age']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"3\": {\"hpv\": 1, \"age\": 55.97}, \"7\": {\"hpv\": 1, \"age\": 72.32}}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import simplejson\n",
    "import pickle\n",
    "def np_converter(obj):\n",
    "    #converts stuff to vanilla python  for json since it gives an error with np.int64 and arrays\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return np.round(float(obj),3)\n",
    "    elif isinstance(obj, float):\n",
    "        return round(float(obj),3)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, datetime.datetime) or isinstance(obj, datetime.time):\n",
    "        return obj.__str__()\n",
    "    print('np_converter cant encode obj of type', obj,type(obj))\n",
    "    return obj\n",
    "\n",
    "def jsonify_np_dict(d):\n",
    "    return simplejson.dumps(d,default=np_converter)\n",
    "\n",
    "\n",
    "def get_dataset_jsons(dataset,ids=None,fields=None):\n",
    "    df = dataset.processed_df.copy()\n",
    "    print(ids,fields)\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        df = df.loc[ids]\n",
    "    if fields is not None and len(fields) > 0:\n",
    "        df = df[fields]\n",
    "    pdict = df.to_dict(orient='index')\n",
    "    return jsonify_np_dict(pdict)\n",
    "\n",
    "\n",
    "get_dataset_jsons(data,fields=['hpv','age'],ids=[3,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682381e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings_state0', 'embeddings_state1', 'embeddings_state2', 'decision0_optimal', 'decision0_imitation', 'decision1_optimal', 'decision1_imitation', 'decision2_optimal', 'decision2_imitation', 'pca_state0', 'pca_state1', 'pca_state2'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding_json(dataset,decisionmodel,embed_df = None,precision=4,ids=None,fields=None):\n",
    "    if embed_df is None:\n",
    "        embed_df = get_embedding_df(dataset,decisionmodel)\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        embed_df = embed_df.loc[ids]\n",
    "        \n",
    "    for c in embed_df.columns:\n",
    "        if 'embed' in c:\n",
    "            embed_df[c] = embed_df[c].apply(lambda x: [round(float(xx),precision) for xx in x.astype(float)])\n",
    "    to_keep = [c for c in embed_df if 'input' not in c]\n",
    "    if fields is not None and len(fields) > 0:\n",
    "        to_keep = [k for k in to_keep if k in fields]\n",
    "    \n",
    "    edict = embed_df[to_keep].to_dict(orient='index')\n",
    "    return edict\n",
    "    return jsonify_np_dict(edict)\n",
    "\n",
    "get_embedding_json(data,decision_model,ids=[3,7])[3].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ee110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot_embedding(dataset,dmodel,decision=0,ax=None,use_optimal=False):\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "#     embeddings, decisions_optimal, decisions_imitation,inputs = get_embeddings(dataset,dmodel,states=[decision])\n",
    "#     pca = PCA(2)\n",
    "#     coords = pca.fit_transform(embeddings[0])\n",
    "#     marks = data.get_state('decision'+ str(decision+1))\n",
    "#     if use_optimal:\n",
    "#         predicted = (decisions_optimal > .5).ravel().astype(int)\n",
    "#     else:\n",
    "#         predicted = (decisions_imitation > .5).ravel().astype(int)\n",
    "#     size = [400 for i in marks]\n",
    "#     sns.scatterplot(data=coords,\n",
    "#                     x=coords[:,0],\n",
    "#                     y=coords[:,1],\n",
    "#                     style=marks,\n",
    "#                     hue=predicted,\n",
    "#                     ax=ax,\n",
    "#                     palette='colorblind',\n",
    "#                     sizes=size,\n",
    "#                    )\n",
    "# plot_embedding(data,decision_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axes = plt.subplots(2,3,figsize=(30,20))\n",
    "# for ii,opt in enumerate([True,False]):\n",
    "#     for i in range(3):\n",
    "#         plot_embedding(data,decision_model,use_optimal=opt,decision=i,ax=axes[ii,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6baa4b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1A_contra': 0,\n",
       "  '1A_ipsi': 0,\n",
       "  '1B_contra': 0,\n",
       "  '1B_ipsi': 0,\n",
       "  '2A_contra': 0,\n",
       "  '2A_ipsi': 0,\n",
       "  '2B_contra': 0,\n",
       "  '2B_ipsi': 0,\n",
       "  '3_contra': 0,\n",
       "  '3_ipsi': 0,\n",
       "  '4_contra': 0,\n",
       "  '4_ipsi': 0,\n",
       "  '5A_contra': 0,\n",
       "  '5A_ipsi': 0,\n",
       "  '5B_contra': 0,\n",
       "  '5B_ipsi': 0,\n",
       "  '6_contra': 0,\n",
       "  '6_ipsi': 0,\n",
       "  'AJCC_1': 0.0,\n",
       "  'AJCC_2': 0.0,\n",
       "  'AJCC_3': 0.0,\n",
       "  'AJCC_4': 0.0,\n",
       "  'African American/Black': 0.0,\n",
       "  'Asian': 0.0,\n",
       "  'Aspiration rate Pre-therapy': 0.0,\n",
       "  'DLT_Infection (Pneumonia)': 0.0,\n",
       "  'DLT_Infection (Pneumonia) 2': 0.0,\n",
       "  'DLT_Nephrological': 0.0,\n",
       "  'DLT_Nephrological 2': 0.0,\n",
       "  'DLT_Vascular': 0.0,\n",
       "  'DLT_Vascular 2': 0.0,\n",
       "  'Hispanic/Latino': 0.0,\n",
       "  'N-category_0': 0.0,\n",
       "  'N-category_1': 0.0,\n",
       "  'N-category_2': 0.0,\n",
       "  'N-category_3': 0.0,\n",
       "  'Pathological Grade_0': 0.0,\n",
       "  'Pathological Grade_1': 0.0,\n",
       "  'Pathological Grade_2': 0.0,\n",
       "  'Pathological Grade_3': 1.0,\n",
       "  'Pathological Grade_4': 0.0,\n",
       "  'RPLN_contra': 0,\n",
       "  'RPLN_ipsi': 0,\n",
       "  'T-category_1': 0.0,\n",
       "  'T-category_2': 0.0,\n",
       "  'T-category_3': 0.0,\n",
       "  'T-category_4': 0.0,\n",
       "  'White/Caucasion': 1.0,\n",
       "  'age': 58.155,\n",
       "  'bilateral': 0.0,\n",
       "  'dose_fraction': 2.12,\n",
       "  'gender': 1.0,\n",
       "  'hpv': 1.0,\n",
       "  'packs_per_year': 3.0,\n",
       "  'subsite_BOT': 0.0,\n",
       "  'subsite_GPS': 0.0,\n",
       "  'subsite_NOS': 0.0,\n",
       "  'subsite_Soft palate': 0.0,\n",
       "  'subsite_Tonsil': 0.0,\n",
       "  'total_dose': 70.0}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_input(dataset,state=0,ids=None):\n",
    "    output = get_decision_input(dataset,state=state,ids=ids)\n",
    "    output = [o.median().to_dict() for o in output]\n",
    "    output = [{k: (0 if '_ipsi' in k or '_contra' in k else v) for k,v in output[0].items()}]\n",
    "    return output\n",
    "\n",
    "get_default_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e1c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpv': 1.0,\n",
       " 'age': 58.155,\n",
       " 'packs_per_year': 3.0,\n",
       " 'gender': 1.0,\n",
       " 'Aspiration rate Pre-therapy': 0.0,\n",
       " 'total_dose': 70.0,\n",
       " 'dose_fraction': 2.12,\n",
       " 'OS (Calculated)': 76.72,\n",
       " 'Locoregional control (Time)': 74.315,\n",
       " 'FDM (months)': 75.765,\n",
       " 'time_to_event': 57.22,\n",
       " 'Overall Survival (1=alive, 0=dead)': 1.0,\n",
       " 'LRC': 1.0,\n",
       " 'DC': 1.0,\n",
       " 'bilateral': 0.0,\n",
       " 'White/Caucasion': 1.0,\n",
       " 'Hispanic/Latino': 0.0,\n",
       " 'African American/Black': 0.0,\n",
       " 'Asian': 0.0,\n",
       " 'cc_none': 0,\n",
       " 'cc_platinum': 0,\n",
       " 'cc_cetuximab': 0,\n",
       " 'cc_others': 0,\n",
       " 'no_dose_adjustment': 0,\n",
       " 'dose_modified': 0,\n",
       " 'dose_delayed': 0,\n",
       " 'dose_cancelled': 0,\n",
       " 'dose_delayed_&_modified': 0,\n",
       " 'regiment_modification': 0,\n",
       " 'T-category_1': 0.0,\n",
       " 'T-category_2': 0.0,\n",
       " 'T-category_3': 0.0,\n",
       " 'T-category_4': 0.0,\n",
       " 'N-category_0': 0.0,\n",
       " 'N-category_1': 0.0,\n",
       " 'N-category_2': 0.0,\n",
       " 'N-category_3': 0.0,\n",
       " 'AJCC_1': 0.0,\n",
       " 'AJCC_2': 0.0,\n",
       " 'AJCC_3': 0.0,\n",
       " 'AJCC_4': 0.0,\n",
       " 'Pathological Grade_0': 0.0,\n",
       " 'Pathological Grade_1': 0.0,\n",
       " 'Pathological Grade_2': 0.0,\n",
       " 'Pathological Grade_3': 1.0,\n",
       " 'Pathological Grade_4': 0.0,\n",
       " 'subsite_BOT': 0.0,\n",
       " 'subsite_GPS': 0.0,\n",
       " 'subsite_NOS': 0.0,\n",
       " 'subsite_Soft palate': 0.0,\n",
       " 'subsite_Tonsil': 0.0,\n",
       " 'treatment_CC': 1.0,\n",
       " 'treatment_IC+CC': 0.0,\n",
       " 'treatment_IC+Radiation alone': 0.0,\n",
       " 'treatment_Radiation alone': 0.0,\n",
       " 'DLT_Dermatological': 0.0,\n",
       " 'DLT_Neurological': 1,\n",
       " 'DLT_Gastrointestinal': 0.0,\n",
       " 'DLT_Hematological': 0.0,\n",
       " 'DLT_Nephrological': 0.0,\n",
       " 'DLT_Vascular': 0.0,\n",
       " 'DLT_Infection (Pneumonia)': 0.0,\n",
       " 'DLT_Other': 0.0,\n",
       " 'DLT_Dermatological 2': 0.0,\n",
       " 'DLT_Neurological 2': 0.0,\n",
       " 'DLT_Gastrointestinal 2': 0.0,\n",
       " 'DLT_Hematological 2': 0.0,\n",
       " 'DLT_Nephrological 2': 0.0,\n",
       " 'DLT_Vascular 2': 0.0,\n",
       " 'DLT_Infection (Pneumonia) 2': 0.0,\n",
       " 'DLT_Other 2': 0.0,\n",
       " 'CR Primary': 0,\n",
       " 'PR Primary': 0,\n",
       " 'SD Primary': 0,\n",
       " 'CR Nodal': 0,\n",
       " 'PR Nodal': 0,\n",
       " 'SD Nodal': 0,\n",
       " 'CR Primary 2': 0,\n",
       " 'PR Primary 2': 0,\n",
       " 'SD Primary 2': 0,\n",
       " 'CR Nodal 2': 0,\n",
       " 'PR Nodal 2': 0,\n",
       " 'SD Nodal 2': 0,\n",
       " 'Decision 1 (Induction Chemo) Y/N': 0.0,\n",
       " 'Decision 2 (CC / RT alone)': 1.0,\n",
       " 'Decision 3 Neck Dissection (Y/N)': 0.0,\n",
       " 'Overall Survival (4 Years)': 1.0,\n",
       " 'FT': 0.0,\n",
       " 'Aspiration rate Post-therapy': 0.0,\n",
       " '1A_ipsi': 0.0,\n",
       " '1A_contra': 0.0,\n",
       " '1B_ipsi': 0.0,\n",
       " '1B_contra': 0.0,\n",
       " '2A_ipsi': 1.0,\n",
       " '2A_contra': 0.0,\n",
       " '2B_ipsi': 1.0,\n",
       " '2B_contra': 0.0,\n",
       " '3_ipsi': 0.0,\n",
       " '3_contra': 0.0,\n",
       " '4_ipsi': 0.0,\n",
       " '4_contra': 0.0,\n",
       " '5A_ipsi': 0.0,\n",
       " '5A_contra': 0.0,\n",
       " '5B_ipsi': 0.0,\n",
       " '5B_contra': 0.0,\n",
       " '6_ipsi': 0.0,\n",
       " '6_contra': 0.0,\n",
       " 'RPLN_ipsi': 0.0,\n",
       " 'RPLN_contra': 0.0,\n",
       " 'no_dose_adjustment 2': 0,\n",
       " 'dose_modified 2': 0,\n",
       " 'dose_delayed 2': 0,\n",
       " 'dose_cancelled 2': 0,\n",
       " 'dose_delayed_&_modified 2': 0,\n",
       " 'regiment_modification 2': 0,\n",
       " 'cc_none 2': 0,\n",
       " 'cc_platinum 2': 0,\n",
       " 'cc_cetuximab 2': 0,\n",
       " 'cc_others 2': 0,\n",
       " 'ln_cluster_3': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_patient(dataset,input_dict,zero_transitions=True):\n",
    "    #converts patient input features into data input type\n",
    "    baselines = dataset.processed_df.median().to_dict()\n",
    "    #set all basline transition states to 0 so my lazy way of checking for fixed values works\n",
    "    if zero_transitions:\n",
    "        to_zero = (Const.primary_disease_states \n",
    "            + Const.nodal_disease_states \n",
    "            + list(Const.modification_types.values()) \n",
    "            + list(Const.cc_types.values()))\n",
    "        for k in to_zero:\n",
    "            baselines[k] = 0\n",
    "            baselines[k+' 2'] = 0\n",
    "    for k,v in input_dict.items():\n",
    "        baselines[k] = v\n",
    "    return baselines\n",
    "\n",
    "format_patient(data,{'ln_cluster_3': 1,'DLT_Neurological': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3859d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,\n",
       "         20.9500,  0.0000,  1.8000,  1.0000,  0.0000, 38.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, 72.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_model_input(dataset,fdict,state=0,ttype=torch.FloatTensor,concat=True,zero_transition_states=True):\n",
    "    fdict = format_patient(dataset,fdict)\n",
    "    order = get_inputkey_order(dataset,state=state)\n",
    "    inputs = [torch.tensor([fdict[k] for k in ordersubset]).type(ttype).view(1,-1) for ordersubset in order]\n",
    "    \n",
    "    #this is assuming the order is baseline, dlt1, dlt2, primary progression, nodal progression, cc type, dose modification\n",
    "    def zeroinput(position):\n",
    "        return torch.zeros(inputs[position].shape).type(ttype)\n",
    "    if zero_transition_states:\n",
    "        if state == 0 or state == 1:\n",
    "            inputs[2] = zeroinput(2)\n",
    "            inputs[5] = zeroinput(5)\n",
    "        if state < 1:\n",
    "            inputs[1] = zeroinput(1)\n",
    "            inputs[3] = zeroinput(3)\n",
    "            inputs[4] = zeroinput(4)\n",
    "            inputs[6] =zeroinput(6)\n",
    "    if concat:\n",
    "        inputs = torch.cat(inputs,axis=1)\n",
    "    #currently at this line its baseline, dlt1, dlt2, pd, nd, cc, modifications\n",
    "    return inputs\n",
    "# decision_model(*dict_to_model_input(data,data.processed_df.iloc[7].to_dict(),state=0),position=0)\n",
    "dict_to_model_input(data,data.processed_df.loc[5].to_dict(),state=1,concat=True,zero_transition_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389fa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_df(dataset,state=0):\n",
    "#     df = dataset.processed_df.copy()\n",
    "#     order = get_inputkey_order(dataset,state=state)\n",
    "#     inputs = [df[o] for o in order]\n",
    "#     df = pd.concat(inputs,axis=1)\n",
    "# input_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9426800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,\n",
       "         20.9500,  0.0000,  1.8000,  1.0000,  0.0000, 38.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, 72.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_model_input(data,data.processed_df.loc[5].to_dict(),state=1,concat=True,zero_transition_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4683c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "4467690121.803214\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "32046856.533909716\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "121997551.51705799\n"
     ]
    }
   ],
   "source": [
    "def calculateMahalanobis(y=None, data=None, cov=None):\n",
    "  \n",
    "    y_mu = y - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.T)\n",
    "    inv_covmat = np.linalg.pinv(cov)\n",
    "    left = np.dot(y_mu, inv_covmat)\n",
    "    mahal = np.dot(left, y_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "def get_neighbors_and_embedding(pdata,dataset,decisionmodel,embedding_df=None,state=2,max_neighbors=10,pcas=None):\n",
    "    decisionmodel.eval()\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "        \n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    \n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    inputs = dict_to_model_input(dataset,pdata,state=state,zero_transition_states=False).to(decisionmodel.get_device())\n",
    "    \n",
    "    \n",
    "    embedding = decisionmodel.get_embedding(inputs,position=state,use_saved_memory=True)[0].view(1,-1).cpu().detach().numpy()\n",
    "\n",
    "    mDist = calculateMahalanobis(embedding,embeddings)\n",
    "    dists = cdist(embedding,embeddings).ravel()\n",
    "    \n",
    "    max_neighbors = min(len(dists),max_neighbors)\n",
    "    min_positions = np.argsort(dists)[:max_neighbors]\n",
    "    neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "    min_dists = dists[min_positions]\n",
    "    similarities = 1/(1+min_dists)\n",
    "    # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "    if pcas is not None:\n",
    "        pPca = pcas[state].transform(embedding)[0]\n",
    "        return neighbor_ids, similarities,embedding[0],pPca, mDist[0]\n",
    "    return neighbor_ids, similarities, embedding[0], mDist[0]\n",
    "\n",
    "for state in [0,1,2]:\n",
    "    print(get_neighbors_and_embedding(test_patient,data,decision_model,state=state)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81624da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_neighbors_and_embedding(pdata,dataset,decisionmodel,embedding_df=None,state=2,max_neighbors=10,pcas=None):\n",
    "    decisionmodel.eval()\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "        \n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    \n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    inputs = dict_to_model_input(dataset,pdata,state=state,zero_transition_states=False).to(decisionmodel.get_device())\n",
    "    \n",
    "    \n",
    "    embedding = decisionmodel.get_embedding(inputs,position=state,use_saved_memory=True)[0].view(1,-1).cpu().detach().numpy()\n",
    "\n",
    "    mDist = calculateMahalanobis(embedding,embeddings)\n",
    "    dists = cdist(embedding,embeddings).ravel()\n",
    "    \n",
    "    max_neighbors = min(len(dists),max_neighbors)\n",
    "    min_positions = np.argsort(dists)[:max_neighbors]\n",
    "    neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "    min_dists = dists[min_positions]\n",
    "    similarities = 1/(1+min_dists)\n",
    "    # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "    if pcas is not None:\n",
    "        pPca = pcas[state].transform(embedding)[0]\n",
    "        return neighbor_ids, similarities,embedding[0],pPca, mDist[0]\n",
    "    return neighbor_ids, similarities, embedding[0], mDist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "238e68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4482766483.702977, 32499502.488495767, 121491300.24156018]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_mahalanobis_distances(dataset=None,decision_model=None,state=1,embedding_df=None):\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decision_model)\n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    dists =calculateMahalanobis(embeddings,embeddings) \n",
    "    return np.array(dists)\n",
    "\n",
    "def get_mdist_outlier_threshold(dataset=None,decision_model=None,embedding_df=None):\n",
    "    return [m.mean() + 2*m.std() for m in [test_mahalanobis_distances(dataset,decision_model,s,embedding_df) for s in [0,1,2]]]\n",
    "\n",
    "get_mdist_outlier_threshold(data,decision_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5265678d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12737.732894577895, 16202.081833605214, 20707.517071292412]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_inputs(dataset,states=[0,1,2],decimals=2):\n",
    "    inputs = []\n",
    "    for i,state in enumerate(states):\n",
    "        x = get_decision_input(dataset,state=state)\n",
    "        inputs.append(np.concatenate([xx.values for xx in x],axis=1))\n",
    "    return inputs\n",
    "\n",
    "def alt_mahalanobis_distances(dataset,state=1):\n",
    "    inputs = get_inputs(dataset,states=[state])[0].astype(float)\n",
    "    dists =calculateMahalanobis(inputs,inputs) \n",
    "    return np.array(dists)\n",
    "\n",
    "def alt_mdist_outlier_threshold(dataset):\n",
    "    return [m.mean() + 2*m.std() for m in [alt_mahalanobis_distances(dataset,s) for s in [0,1,2]]]\n",
    "\n",
    "alt_mdist_outlier_threshold(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61f3741d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.48251408e+09, 4.48242751e+09, 4.48251394e+09, 4.48251384e+09,\n",
       "        4.48247881e+09, 4.48300997e+09, 4.48239666e+09, 4.48249018e+09,\n",
       "        4.48254010e+09, 4.48253659e+09, 4.48259716e+09, 4.48249894e+09,\n",
       "        4.48247624e+09, 4.48231756e+09, 4.48249712e+09, 4.48245912e+09,\n",
       "        4.48255362e+09, 4.48245595e+09, 4.48247782e+09, 4.48251034e+09,\n",
       "        4.48190730e+09, 4.48249038e+09, 4.48249884e+09, 4.48248053e+09,\n",
       "        4.48248426e+09, 4.48252651e+09, 4.48257471e+09, 4.48283273e+09,\n",
       "        4.48250854e+09, 4.48249348e+09, 4.48249858e+09, 4.48249767e+09,\n",
       "        4.48251721e+09, 4.48245557e+09, 4.48249279e+09, 4.48245415e+09,\n",
       "        4.48243367e+09, 4.48250922e+09, 4.48249841e+09, 4.48250012e+09,\n",
       "        4.48249710e+09, 4.48249891e+09, 4.48250190e+09, 4.48248290e+09,\n",
       "        4.48249657e+09, 4.48240869e+09, 4.48240992e+09, 4.48252387e+09,\n",
       "        4.48251603e+09, 4.48253339e+09, 4.48249901e+09, 4.48240337e+09,\n",
       "        4.48240398e+09, 4.48249836e+09, 4.48243531e+09, 4.48242895e+09,\n",
       "        4.48240358e+09, 4.48246281e+09, 4.48246530e+09, 4.48254574e+09,\n",
       "        4.48250234e+09, 4.48250986e+09, 4.48245523e+09, 4.48257733e+09,\n",
       "        4.48239061e+09, 4.48251182e+09, 4.48253925e+09, 4.48248431e+09,\n",
       "        4.48248245e+09, 4.48254016e+09, 4.48251498e+09, 4.48251004e+09,\n",
       "        4.48251745e+09, 4.48241965e+09, 4.48240654e+09, 4.48247951e+09,\n",
       "        4.48316777e+09, 4.48262556e+09, 4.48250398e+09, 4.48257895e+09,\n",
       "        4.48253581e+09, 4.48260222e+09, 4.48241383e+09, 4.48256460e+09,\n",
       "        4.48230753e+09, 4.48238656e+09, 4.48254332e+09, 4.48253504e+09,\n",
       "        4.48252493e+09, 4.48261151e+09, 4.48245815e+09, 4.48258782e+09,\n",
       "        4.48249471e+09, 4.48221151e+09, 4.48254281e+09, 4.48243043e+09,\n",
       "        4.48256438e+09, 4.48252052e+09, 4.48321604e+09, 4.48236516e+09,\n",
       "        4.48252045e+09, 4.48251190e+09, 4.48250875e+09, 4.48250515e+09,\n",
       "        4.48247807e+09, 4.48249282e+09, 4.48242771e+09, 4.48189204e+09,\n",
       "        4.48248869e+09, 4.48249287e+09, 4.48264857e+09, 4.48247565e+09,\n",
       "        4.48257979e+09, 4.48250152e+09, 4.48230496e+09, 4.48254700e+09,\n",
       "        4.48252282e+09, 4.48255944e+09, 4.48243387e+09, 4.48230408e+09,\n",
       "        4.48270534e+09, 4.48295988e+09, 4.48253392e+09, 4.48254800e+09,\n",
       "        4.48248774e+09, 4.48245924e+09, 4.48255909e+09, 4.48244130e+09,\n",
       "        4.48231685e+09, 4.48232295e+09, 4.48261335e+09, 4.48245289e+09,\n",
       "        4.48251129e+09, 4.48243468e+09, 4.48260619e+09, 4.48244573e+09,\n",
       "        4.48256950e+09, 4.48251309e+09, 4.48247473e+09, 4.48247383e+09,\n",
       "        4.48250764e+09, 4.48268134e+09, 4.48256871e+09, 4.48254903e+09,\n",
       "        4.48244682e+09, 4.48250272e+09, 4.48246454e+09, 4.48246768e+09,\n",
       "        4.48253335e+09, 4.48278150e+09, 4.48249592e+09, 4.48250572e+09,\n",
       "        4.48245600e+09, 4.48257741e+09, 4.48258455e+09, 4.48237205e+09,\n",
       "        4.48245486e+09, 4.48255433e+09, 4.48249819e+09, 4.48245291e+09,\n",
       "        4.48247338e+09, 4.48223073e+09, 4.48255003e+09, 4.48255511e+09,\n",
       "        4.48251231e+09, 4.48251753e+09, 4.48205707e+09, 4.48248709e+09,\n",
       "        4.48251330e+09, 4.48250292e+09, 4.48253781e+09, 4.48245789e+09,\n",
       "        4.48243306e+09, 4.48265391e+09, 4.48268818e+09, 4.48252694e+09,\n",
       "        4.48224779e+09, 4.48247775e+09, 4.48262766e+09, 4.48252403e+09,\n",
       "        4.48251003e+09, 4.48244489e+09, 4.48251360e+09, 4.48260204e+09,\n",
       "        4.48239565e+09, 4.48244656e+09, 4.48218155e+09, 4.48243631e+09,\n",
       "        4.48254770e+09, 4.48262881e+09, 4.48260175e+09, 4.48244960e+09,\n",
       "        4.48251658e+09, 4.48245871e+09, 4.48259365e+09, 4.48259412e+09,\n",
       "        4.48256160e+09, 4.48230203e+09, 4.48263971e+09, 4.48246479e+09,\n",
       "        4.48239882e+09, 4.48254994e+09, 4.48207616e+09, 4.48248282e+09,\n",
       "        4.48245838e+09, 4.48252501e+09, 4.48226591e+09, 4.48251189e+09,\n",
       "        4.48259345e+09, 4.48248405e+09, 4.48219655e+09, 4.48203397e+09,\n",
       "        4.48232916e+09, 4.48253826e+09, 4.48248521e+09, 4.48253154e+09,\n",
       "        4.48252108e+09, 4.48246891e+09, 4.48246500e+09, 4.48243885e+09,\n",
       "        4.48253502e+09, 4.48248765e+09, 4.48249844e+09, 4.48250273e+09,\n",
       "        4.48264244e+09, 4.48241545e+09, 4.48243918e+09, 4.48249640e+09,\n",
       "        4.48246033e+09, 4.48256295e+09, 4.48181830e+09, 4.48249826e+09,\n",
       "        4.48263934e+09, 4.48249407e+09, 4.48261641e+09, 4.48244755e+09,\n",
       "        4.48243111e+09, 4.48261914e+09, 4.48251743e+09, 4.48244389e+09,\n",
       "        4.48241863e+09, 4.48254995e+09, 4.48265076e+09, 4.48251721e+09,\n",
       "        4.48250119e+09, 4.48247818e+09, 4.48236102e+09, 4.48254361e+09,\n",
       "        4.48241480e+09, 4.48238766e+09, 4.48232230e+09, 4.48244670e+09,\n",
       "        4.48235409e+09, 4.48247391e+09, 4.48240734e+09, 4.48243863e+09,\n",
       "        4.48257795e+09, 4.48268526e+09, 4.48250213e+09, 4.48254371e+09,\n",
       "        4.48239105e+09, 4.48226803e+09, 4.48248568e+09, 4.48255185e+09,\n",
       "        4.48269378e+09, 4.48244363e+09, 4.48251532e+09, 4.48249365e+09,\n",
       "        4.48252864e+09, 4.48246829e+09, 4.48246618e+09, 4.48247835e+09,\n",
       "        4.48278545e+09, 4.48280499e+09, 4.48254242e+09, 4.48240888e+09,\n",
       "        4.48222228e+09, 4.48250698e+09, 4.48250069e+09, 4.48246470e+09,\n",
       "        4.48248769e+09, 4.48248089e+09, 4.48244304e+09, 4.48263246e+09,\n",
       "        4.48250381e+09, 4.48252863e+09, 4.48257847e+09, 4.48253056e+09,\n",
       "        4.48240117e+09, 4.48249874e+09, 4.48223210e+09, 4.48244377e+09,\n",
       "        4.48261454e+09, 4.48252412e+09, 4.48235225e+09, 4.48260183e+09,\n",
       "        4.48224038e+09, 4.48248878e+09, 4.48231879e+09, 4.48245203e+09,\n",
       "        4.48245211e+09, 4.48262980e+09, 4.48256807e+09, 4.48251259e+09,\n",
       "        4.48255123e+09, 4.48254361e+09, 4.48249759e+09, 4.48246497e+09,\n",
       "        4.48249096e+09, 4.48242131e+09, 4.48229002e+09, 4.48244417e+09,\n",
       "        4.48252844e+09, 4.48265916e+09, 4.48251053e+09, 4.48261499e+09,\n",
       "        4.48262772e+09, 4.48284984e+09, 4.48248394e+09, 4.48251352e+09,\n",
       "        4.48244853e+09, 4.48241005e+09, 4.48241175e+09, 4.48275027e+09,\n",
       "        4.48239689e+09, 4.48250226e+09, 4.48249204e+09, 4.48251890e+09,\n",
       "        4.48244642e+09, 4.48249712e+09, 4.48264406e+09, 4.48247626e+09,\n",
       "        4.48253243e+09, 4.48243138e+09, 4.48260678e+09, 4.48250608e+09,\n",
       "        4.48259790e+09, 4.48252782e+09, 4.48243557e+09, 4.48259148e+09,\n",
       "        4.48251775e+09, 4.48246876e+09, 4.48251340e+09, 4.48253508e+09,\n",
       "        4.48229116e+09, 4.48250036e+09, 4.48251652e+09, 4.48247261e+09,\n",
       "        4.48251504e+09, 4.48242003e+09, 4.48255109e+09, 4.48249260e+09,\n",
       "        4.48241499e+09, 4.48253215e+09, 4.48249153e+09, 4.48249785e+09,\n",
       "        4.48241230e+09, 4.48245248e+09, 4.48250825e+09, 4.48255663e+09,\n",
       "        4.48294327e+09, 4.48244694e+09, 4.48243772e+09, 4.48247610e+09,\n",
       "        4.48246939e+09, 4.48229702e+09, 4.48249191e+09, 4.48250077e+09,\n",
       "        4.48249449e+09, 4.48260351e+09, 4.48248590e+09, 4.48251067e+09,\n",
       "        4.48243581e+09, 4.48251704e+09, 4.48222050e+09, 4.48235134e+09,\n",
       "        4.48242541e+09, 4.48288978e+09, 4.48245755e+09, 4.48251328e+09,\n",
       "        4.48247023e+09, 4.48245513e+09, 4.48250818e+09, 4.48249920e+09,\n",
       "        4.48240711e+09, 4.48247155e+09, 4.48259316e+09, 4.48257428e+09,\n",
       "        4.48250741e+09, 4.48260888e+09, 4.48252953e+09, 4.48250003e+09,\n",
       "        4.48232746e+09, 4.48240575e+09, 4.48264412e+09, 4.48246624e+09,\n",
       "        4.48243993e+09, 4.48264850e+09, 4.48250177e+09, 4.48223702e+09,\n",
       "        4.48248580e+09, 4.48267970e+09, 4.48251674e+09, 4.48257145e+09,\n",
       "        4.48241933e+09, 4.48253507e+09, 4.48249548e+09, 4.48252412e+09,\n",
       "        4.48247083e+09, 4.48245847e+09, 4.48248541e+09, 4.48315112e+09,\n",
       "        4.48245132e+09, 4.48234585e+09, 4.48244595e+09, 4.48236447e+09,\n",
       "        4.48254372e+09, 4.48249682e+09, 4.48250340e+09, 4.48259391e+09,\n",
       "        4.48245533e+09, 4.48270668e+09, 4.48237504e+09, 4.48253190e+09,\n",
       "        4.48251053e+09, 4.48252878e+09, 4.48253126e+09, 4.48250279e+09,\n",
       "        4.48231561e+09, 4.48272697e+09, 4.48249791e+09, 4.48251053e+09,\n",
       "        4.48261762e+09, 4.48259291e+09, 4.48273659e+09, 4.48256818e+09,\n",
       "        4.48257001e+09, 4.48251924e+09, 4.48262843e+09, 4.48225935e+09,\n",
       "        4.48253139e+09, 4.48236386e+09, 4.48278609e+09, 4.48222162e+09,\n",
       "        4.48251561e+09, 4.48254705e+09, 4.48267532e+09, 4.48294155e+09,\n",
       "        4.48246193e+09, 4.48250266e+09, 4.48277330e+09, 4.48231753e+09,\n",
       "        4.48256061e+09, 4.48256152e+09, 4.48246214e+09, 4.48249780e+09,\n",
       "        4.48229841e+09, 4.48252518e+09, 4.48249218e+09, 4.48240711e+09,\n",
       "        4.48247076e+09, 4.48248145e+09, 4.48250653e+09, 4.48243723e+09,\n",
       "        4.48243637e+09, 4.48250960e+09, 4.48240923e+09, 4.48255618e+09,\n",
       "        4.48247939e+09, 4.48250693e+09, 4.48242642e+09, 4.48253299e+09,\n",
       "        4.48253748e+09, 4.48256006e+09, 4.48244089e+09, 4.48253655e+09,\n",
       "        4.48255927e+09, 4.48247947e+09, 4.48220201e+09, 4.48245513e+09,\n",
       "        4.48259982e+09, 4.48243276e+09, 4.48256560e+09, 4.48259446e+09,\n",
       "        4.48269888e+09, 4.48267501e+09, 4.48251976e+09, 4.48267374e+09,\n",
       "        4.48247208e+09, 4.48249807e+09, 4.48228623e+09, 4.48267747e+09,\n",
       "        4.48250812e+09, 4.48258768e+09, 4.48273436e+09, 4.48250511e+09,\n",
       "        4.48255709e+09, 4.48254380e+09, 4.48240894e+09, 4.48253132e+09,\n",
       "        4.48268491e+09, 4.48264262e+09, 4.48229968e+09, 4.48255254e+09,\n",
       "        4.48257801e+09, 4.48227024e+09, 4.48244364e+09, 4.48244436e+09,\n",
       "        4.48248181e+09, 4.48277871e+09, 4.48256985e+09, 4.48246611e+09,\n",
       "        4.48256017e+09, 4.48234607e+09, 4.48248665e+09, 4.48244060e+09,\n",
       "        4.48260578e+09, 4.48263259e+09, 4.48246716e+09, 4.48259000e+09,\n",
       "        4.48193366e+09, 4.48257241e+09, 4.48238637e+09, 4.48250526e+09,\n",
       "        4.48244874e+09, 4.48271916e+09, 4.48254831e+09, 4.48238865e+09,\n",
       "        4.48250346e+09, 4.48253863e+09, 4.48259928e+09, 4.48249789e+09,\n",
       "        4.48244408e+09, 4.48263086e+09, 4.48246665e+09, 4.48244644e+09]),\n",
       " array([32473786.05654093, 32472707.43823142, 32478298.25824123,\n",
       "        32485630.97604414, 32472616.08334291, 32512520.98370643,\n",
       "        32476818.2582719 , 32474965.07808953, 32484469.28885654,\n",
       "        32472560.71156829, 32467072.27309876, 32476784.27065601,\n",
       "        32482782.21944651, 32461624.14253064, 32470556.03147238,\n",
       "        32474674.37674171, 32476164.93629991, 32478737.83481317,\n",
       "        32469390.53423908, 32472126.61631926, 32437004.80274562,\n",
       "        32477923.28551293, 32476383.99402171, 32474609.44061428,\n",
       "        32464162.76965778, 32477061.14923438, 32494553.74520554,\n",
       "        32499627.97014867, 32477488.2378808 , 32472384.72366192,\n",
       "        32475215.38733082, 32476713.68866889, 32470500.94997497,\n",
       "        32474699.788213  , 32479131.18378548, 32476277.97395712,\n",
       "        32481300.95688353, 32478031.7970187 , 32476238.65580956,\n",
       "        32474925.89352445, 32475916.79467611, 32477140.60591903,\n",
       "        32481612.19089393, 32482076.45978434, 32482207.79702933,\n",
       "        32460204.70489958, 32446221.12568609, 32474354.62803856,\n",
       "        32474926.49654614, 32473232.68256703, 32476526.88220028,\n",
       "        32474150.24868493, 32471968.8407751 , 32476452.62140524,\n",
       "        32478776.54540381, 32474544.63620967, 32467948.44970478,\n",
       "        32481650.54135981, 32476124.36569046, 32473928.91165059,\n",
       "        32479566.32488231, 32468046.39669187, 32475849.79734429,\n",
       "        32478770.68856766, 32462002.91800541, 32477265.52809124,\n",
       "        32480557.7521746 , 32479226.27741594, 32478269.31603372,\n",
       "        32475887.1210343 , 32475633.47309562, 32478719.50099122,\n",
       "        32483544.91417325, 32476774.49675025, 32478372.7112556 ,\n",
       "        32476532.17194718, 32430566.84159664, 32477559.35969662,\n",
       "        32479682.3603809 , 32458893.68428386, 32475694.13740396,\n",
       "        32476360.05157309, 32477515.99812799, 32479185.84081748,\n",
       "        32490987.80415461, 32481090.82668289, 32471894.3462496 ,\n",
       "        32479174.53909567, 32477781.43291914, 32479855.14310528,\n",
       "        32472680.55955308, 32486700.30520897, 32479770.17957157,\n",
       "        32494732.32244069, 32475450.33002219, 32488406.1584536 ,\n",
       "        32480661.94445787, 32474072.83384079, 32469912.09242   ,\n",
       "        32434232.94748454, 32480075.85866062, 32469385.61953581,\n",
       "        32466642.65989442, 32475799.36575839, 32483480.71373728,\n",
       "        32479661.58631974, 32494440.67711889, 32454353.20164163,\n",
       "        32472351.24484803, 32473320.66518549, 32457947.71837158,\n",
       "        32478775.84025647, 32487661.18575784, 32460727.55489847,\n",
       "        32461232.87080692, 32468257.80568014, 32475508.32602839,\n",
       "        32465799.38470547, 32480718.24037832, 32478931.90395024,\n",
       "        32475803.51470072, 32453004.54505717, 32473629.23319796,\n",
       "        32476838.52828407, 32478778.4500195 , 32476996.03253687,\n",
       "        32483889.33207814, 32480565.34667027, 32476319.46704695,\n",
       "        32484688.20064232, 32497461.9239699 , 32479031.16190667,\n",
       "        32479849.36469325, 32479424.24867953, 32475858.56208925,\n",
       "        32474268.46907827, 32473550.68117749, 32474887.906579  ,\n",
       "        32470021.85167646, 32479740.93898323, 32477797.25316116,\n",
       "        32444926.87774459, 32480704.52441694, 32477482.79152012,\n",
       "        32485741.87147098, 32483521.18538629, 32481981.20188534,\n",
       "        32478259.3324304 , 32472969.65051892, 32466000.36592318,\n",
       "        32474596.46225845, 32473197.09776552, 32477355.64726826,\n",
       "        32473646.4849792 , 32481686.48098884, 32489847.80971114,\n",
       "        32469518.0830149 , 32476959.48844379, 32472617.26302956,\n",
       "        32467374.4729621 , 32479221.60515286, 32457889.46712876,\n",
       "        32466180.17046387, 32474849.33676873, 32481819.79404092,\n",
       "        32478621.1197726 , 32468601.60569075, 32481999.48417234,\n",
       "        32478592.36277714, 32473873.87395925, 32472239.32969827,\n",
       "        32478106.39472651, 32472991.28347121, 32492177.9016898 ,\n",
       "        32478153.62261958, 32480346.76509306, 32520934.98651777,\n",
       "        32475788.2637133 , 32474373.04540007, 32510001.72775185,\n",
       "        32473416.06274217, 32471873.1781277 , 32481761.34261302,\n",
       "        32483775.70340977, 32477138.1952947 , 32483613.43055641,\n",
       "        32495018.21385223, 32481950.89315628, 32471728.97018397,\n",
       "        32479954.36299951, 32482340.85168565, 32472797.38975552,\n",
       "        32483798.60155256, 32467472.02007879, 32481505.55023525,\n",
       "        32480786.26693516, 32483764.78528979, 32465468.8557398 ,\n",
       "        32481963.61863387, 32485660.1675887 , 32485793.40785964,\n",
       "        32476082.85912665, 32525430.1250247 , 32481346.79938209,\n",
       "        32480814.33341179, 32476869.35786034, 32473486.22599383,\n",
       "        32477684.79664706, 32500325.36165738, 32480080.16751415,\n",
       "        32494715.74913942, 32491321.83218619, 32464828.4883499 ,\n",
       "        32490434.0383005 , 32445428.79752747, 32481884.94466217,\n",
       "        32473314.01213774, 32482045.99763052, 32466386.68988265,\n",
       "        32474839.01103839, 32477166.53307725, 32480841.50028346,\n",
       "        32471340.81493082, 32482929.62156925, 32489522.54524825,\n",
       "        32456415.35542969, 32458731.13763489, 32474310.66311118,\n",
       "        32475362.46692988, 32477129.30843139, 32420774.95573443,\n",
       "        32476067.97169375, 32499292.9644503 , 32474244.34465918,\n",
       "        32452969.35208734, 32475754.03498843, 32498745.34120308,\n",
       "        32469273.66856236, 32471015.94645374, 32477544.37050899,\n",
       "        32483290.65635089, 32485417.59495041, 32428305.65070622,\n",
       "        32478105.5358287 , 32469082.19821957, 32475955.38145667,\n",
       "        32458170.98531599, 32479321.25338728, 32512776.5569581 ,\n",
       "        32494285.91984374, 32474937.66867657, 32473787.13363925,\n",
       "        32472875.65289242, 32470966.49488401, 32473125.74336371,\n",
       "        32491365.27652524, 32486753.08495891, 32429245.31059099,\n",
       "        32479060.26887323, 32472005.01266524, 32477022.4250454 ,\n",
       "        32470404.31006109, 32472291.02150809, 32480724.34146338,\n",
       "        32488837.12067331, 32467828.93374071, 32457720.49669319,\n",
       "        32480859.39212634, 32481761.73181032, 32479091.22582936,\n",
       "        32477120.93942899, 32551139.13033496, 32485295.53679702,\n",
       "        32476566.87282263, 32474892.512589  , 32475459.97285955,\n",
       "        32471885.3752089 , 32481047.72175615, 32475720.58472201,\n",
       "        32473646.05680542, 32474585.29521449, 32484508.24230407,\n",
       "        32497257.46140376, 32472173.0916403 , 32475094.85035428,\n",
       "        32476245.38632469, 32476639.50710659, 32475062.16532926,\n",
       "        32476833.82895014, 32462529.86996574, 32465771.15802028,\n",
       "        32479100.78367545, 32479072.1570895 , 32476146.87862488,\n",
       "        32478080.34691557, 32484142.23278697, 32468954.68028909,\n",
       "        32479328.43169703, 32494928.90740204, 32475020.79490795,\n",
       "        32475997.30645215, 32478113.88179124, 32474051.46442775,\n",
       "        32480120.21525285, 32474560.84774511, 32482025.25653528,\n",
       "        32480041.90379242, 32468773.91874916, 32485272.56538543,\n",
       "        32471088.57619085, 32471669.56066491, 32479115.45289991,\n",
       "        32477602.1173084 , 32456625.74668797, 32476502.98141104,\n",
       "        32466720.59508451, 32458195.2301519 , 32491871.89443077,\n",
       "        32475329.27513193, 32464896.11921319, 32477094.97257264,\n",
       "        32478310.67579944, 32475264.72493763, 32482599.46593897,\n",
       "        32475379.8866843 , 32472935.72130657, 32475418.4918576 ,\n",
       "        32484065.10475126, 32466431.337139  , 32481260.90411438,\n",
       "        32493504.69493879, 32471570.47855666, 32476503.74569112,\n",
       "        32496211.17059939, 32484084.09375048, 32476148.56850725,\n",
       "        32487386.20523355, 32484371.69645048, 32475579.06744344,\n",
       "        32474942.53233081, 32476750.07185774, 32472633.93583023,\n",
       "        32470856.31670872, 32470442.63893623, 32473266.20099281,\n",
       "        32477999.83539179, 32480328.01383429, 32487417.04617747,\n",
       "        32468657.83542392, 32481234.11241617, 32468414.79219412,\n",
       "        32476697.90482253, 32464769.18155679, 32488973.94390413,\n",
       "        32480880.21843063, 32476466.7618948 , 32485771.82373844,\n",
       "        32475898.90840148, 32473788.09890554, 32475780.299042  ,\n",
       "        32465102.979275  , 32477776.64554911, 32479538.38411808,\n",
       "        32474022.62570574, 32473821.95639896, 32511576.80315932,\n",
       "        32474998.22389165, 32471887.93204679, 32475120.95932819,\n",
       "        32455619.73423585, 32474323.90346751, 32466299.6502706 ,\n",
       "        32481674.22772721, 32480378.45655555, 32496247.84350116,\n",
       "        32475647.98907195, 32468638.75442868, 32483624.91922353,\n",
       "        32466323.0954713 , 32490845.80346039, 32479940.71958919,\n",
       "        32479903.57747853, 32495289.38760998, 32475142.19523912,\n",
       "        32476930.16980355, 32473782.43455091, 32476661.76795088,\n",
       "        32485752.72673951, 32482265.60951986, 32457749.46144226,\n",
       "        32487951.29707747, 32474993.08378012, 32476812.34684293,\n",
       "        32473222.91552468, 32471105.33024903, 32487958.51890095,\n",
       "        32477638.52926993, 32477164.32403225, 32497778.12373621,\n",
       "        32479171.10246303, 32474974.99028668, 32468852.78458143,\n",
       "        32467263.99205109, 32472919.40559931, 32479822.39699669,\n",
       "        32469584.05396151, 32472390.59302094, 32475250.40045913,\n",
       "        32468795.00165175, 32470057.04337247, 32476806.34351842,\n",
       "        32483358.08954512, 32471251.47515249, 32454013.20640661,\n",
       "        32482214.23920964, 32482427.5818001 , 32472305.01348493,\n",
       "        32473828.5959203 , 32477354.5222431 , 32479416.97828327,\n",
       "        32480143.38166354, 32478649.14600959, 32471953.0207493 ,\n",
       "        32480360.35881337, 32482694.92787547, 32495012.79486596,\n",
       "        32467744.23900972, 32483191.11486859, 32478002.70148769,\n",
       "        32480846.12358115, 32477640.10556226, 32480736.1496338 ,\n",
       "        32480210.48537468, 32474933.35196167, 32467929.85540344,\n",
       "        32482696.37072127, 32471581.35194907, 32465473.77572893,\n",
       "        32475224.76035926, 32481566.51132434, 32484425.77607542,\n",
       "        32492196.72305101, 32478313.32639795, 32495490.23747739,\n",
       "        32460532.75484398, 32469165.02421764, 32482916.40451348,\n",
       "        32488190.02674091, 32474864.20395933, 32476300.71191767,\n",
       "        32461559.14271874, 32484264.36207049, 32483440.06831106,\n",
       "        32476054.0186848 , 32497398.57687495, 32475454.13318569,\n",
       "        32476301.55112311, 32477734.0555108 , 32485424.2833305 ,\n",
       "        32480638.07034394, 32472531.49191102, 32469924.46310192,\n",
       "        32485124.9805655 , 32476756.39131612, 32473875.98672241,\n",
       "        32484355.04334195, 32450296.27967387, 32492616.61178259,\n",
       "        32477796.9978333 , 32481717.45670149, 32467651.57922292,\n",
       "        32475691.69991785, 32472300.10991097, 32482467.23038539,\n",
       "        32497719.54998875, 32463477.75353623, 32471392.835682  ,\n",
       "        32477350.065637  , 32527397.57051012, 32459243.53221174,\n",
       "        32474967.26138282, 32472995.37104094, 32475056.03141432,\n",
       "        32495086.17847595, 32466967.40494744, 32471745.76467474,\n",
       "        32460002.3261734 , 32491124.73530352, 32476218.31194969,\n",
       "        32476053.86342141, 32442047.11919579, 32469072.06254399,\n",
       "        32478963.16934624, 32476146.89278906, 32467127.79806825,\n",
       "        32483706.66359157, 32472549.66554969, 32476543.02857438,\n",
       "        32470623.21999646, 32484845.48635666, 32477401.64092159,\n",
       "        32488014.42564484, 32470386.65583159, 32478319.05379381,\n",
       "        32467399.61012681, 32474847.59061028, 32480688.74467708,\n",
       "        32474365.18110319, 32484937.32091722, 32497230.20084457,\n",
       "        32472789.00869486, 32472579.83087241, 32460818.51178512,\n",
       "        32472384.36202832, 32473691.2119514 , 32475965.5505994 ,\n",
       "        32480574.57158829, 32508771.99696125, 32472476.70555521,\n",
       "        32486246.3763952 , 32481183.98517433, 32472674.63952851,\n",
       "        32478402.10389339, 32466494.67606891, 32469158.53025096,\n",
       "        32471857.29781444, 32472986.2198059 , 32465895.1351079 ,\n",
       "        32482333.55606624, 32472820.57774789, 32474137.73763099,\n",
       "        32480420.88949481, 32476824.71744164, 32468528.70011719,\n",
       "        32481087.28344596, 32469312.54989047]),\n",
       " array([1.21438343e+08, 1.21438541e+08, 1.21459106e+08, 1.21410039e+08,\n",
       "        1.21451567e+08, 1.21415209e+08, 1.21453389e+08, 1.21450891e+08,\n",
       "        1.21446980e+08, 1.21468829e+08, 1.21448817e+08, 1.21447257e+08,\n",
       "        1.21439001e+08, 1.21472485e+08, 1.21439625e+08, 1.21448190e+08,\n",
       "        1.21441608e+08, 1.21433551e+08, 1.21440442e+08, 1.21434890e+08,\n",
       "        1.21373141e+08, 1.21454497e+08, 1.21448811e+08, 1.21442205e+08,\n",
       "        1.21450911e+08, 1.21428962e+08, 1.21447510e+08, 1.21471546e+08,\n",
       "        1.21439181e+08, 1.21441609e+08, 1.21439959e+08, 1.21448856e+08,\n",
       "        1.21471022e+08, 1.21415183e+08, 1.21445969e+08, 1.21443762e+08,\n",
       "        1.21419886e+08, 1.21445573e+08, 1.21446666e+08, 1.21439292e+08,\n",
       "        1.21446642e+08, 1.21447297e+08, 1.21440693e+08, 1.21439413e+08,\n",
       "        1.21443821e+08, 1.21416340e+08, 1.21477096e+08, 1.21445686e+08,\n",
       "        1.21444663e+08, 1.21447086e+08, 1.21446766e+08, 1.21450663e+08,\n",
       "        1.21460526e+08, 1.21446890e+08, 1.21454115e+08, 1.21455141e+08,\n",
       "        1.21515061e+08, 1.21421883e+08, 1.21446556e+08, 1.21439852e+08,\n",
       "        1.21448369e+08, 1.21445037e+08, 1.21447315e+08, 1.21450268e+08,\n",
       "        1.21471454e+08, 1.21453583e+08, 1.21448800e+08, 1.21463666e+08,\n",
       "        1.21453121e+08, 1.21453640e+08, 1.21446624e+08, 1.21443805e+08,\n",
       "        1.21450490e+08, 1.21474694e+08, 1.21440641e+08, 1.21426652e+08,\n",
       "        1.21523952e+08, 1.21439346e+08, 1.21461845e+08, 1.21455270e+08,\n",
       "        1.21434383e+08, 1.21394557e+08, 1.21464957e+08, 1.21446624e+08,\n",
       "        1.21508091e+08, 1.21451609e+08, 1.21441619e+08, 1.21452524e+08,\n",
       "        1.21403719e+08, 1.21427181e+08, 1.21457178e+08, 1.21452555e+08,\n",
       "        1.21450051e+08, 1.21456416e+08, 1.21432545e+08, 1.21435766e+08,\n",
       "        1.21470490e+08, 1.21450624e+08, 1.21367514e+08, 1.21447078e+08,\n",
       "        1.21416650e+08, 1.21440063e+08, 1.21468489e+08, 1.21443630e+08,\n",
       "        1.21407402e+08, 1.21434338e+08, 1.21432777e+08, 1.21491917e+08,\n",
       "        1.21431555e+08, 1.21450852e+08, 1.21463684e+08, 1.21438684e+08,\n",
       "        1.21500129e+08, 1.21442831e+08, 1.21414171e+08, 1.21456912e+08,\n",
       "        1.21453867e+08, 1.21458534e+08, 1.21439291e+08, 1.21441046e+08,\n",
       "        1.21432007e+08, 1.21465456e+08, 1.21425987e+08, 1.21466562e+08,\n",
       "        1.21453112e+08, 1.21446819e+08, 1.21444025e+08, 1.21436763e+08,\n",
       "        1.21441561e+08, 1.21457952e+08, 1.21469650e+08, 1.21437208e+08,\n",
       "        1.21455331e+08, 1.21456903e+08, 1.21428312e+08, 1.21462101e+08,\n",
       "        1.21434020e+08, 1.21440582e+08, 1.21438586e+08, 1.21458098e+08,\n",
       "        1.21433086e+08, 1.21373214e+08, 1.21444945e+08, 1.21439452e+08,\n",
       "        1.21458534e+08, 1.21467224e+08, 1.21450706e+08, 1.21448229e+08,\n",
       "        1.21441500e+08, 1.21460021e+08, 1.21429161e+08, 1.21454918e+08,\n",
       "        1.21431521e+08, 1.21471502e+08, 1.21451997e+08, 1.21520891e+08,\n",
       "        1.21412268e+08, 1.21471987e+08, 1.21445034e+08, 1.21467182e+08,\n",
       "        1.21460091e+08, 1.21475893e+08, 1.21470533e+08, 1.21461068e+08,\n",
       "        1.21442924e+08, 1.21460699e+08, 1.21424938e+08, 1.21430869e+08,\n",
       "        1.21458327e+08, 1.21451731e+08, 1.21443449e+08, 1.21460779e+08,\n",
       "        1.21420600e+08, 1.21432350e+08, 1.21500930e+08, 1.21462117e+08,\n",
       "        1.21468686e+08, 1.21440659e+08, 1.21435897e+08, 1.21439288e+08,\n",
       "        1.21459569e+08, 1.21423844e+08, 1.21453459e+08, 1.21436089e+08,\n",
       "        1.21458578e+08, 1.21448721e+08, 1.21445480e+08, 1.21452810e+08,\n",
       "        1.21465690e+08, 1.21461796e+08, 1.21455225e+08, 1.21421096e+08,\n",
       "        1.21460771e+08, 1.21413983e+08, 1.21452124e+08, 1.21420429e+08,\n",
       "        1.21456163e+08, 1.21429737e+08, 1.21430988e+08, 1.21443233e+08,\n",
       "        1.21445297e+08, 1.21435768e+08, 1.21468893e+08, 1.21447294e+08,\n",
       "        1.21450644e+08, 1.21457795e+08, 1.21547779e+08, 1.21456552e+08,\n",
       "        1.21457286e+08, 1.21417490e+08, 1.21404358e+08, 1.21464619e+08,\n",
       "        1.21454591e+08, 1.21447836e+08, 1.21434527e+08, 1.21465273e+08,\n",
       "        1.21446795e+08, 1.21434235e+08, 1.21464415e+08, 1.21448006e+08,\n",
       "        1.21442049e+08, 1.21456706e+08, 1.21444272e+08, 1.21457388e+08,\n",
       "        1.21458791e+08, 1.21473816e+08, 1.21457220e+08, 1.21458100e+08,\n",
       "        1.21444584e+08, 1.21446118e+08, 1.21440883e+08, 1.21446554e+08,\n",
       "        1.21430221e+08, 1.21449087e+08, 1.21438045e+08, 1.21466969e+08,\n",
       "        1.21461086e+08, 1.21435277e+08, 1.21445983e+08, 1.21458665e+08,\n",
       "        1.21468074e+08, 1.21448935e+08, 1.21369892e+08, 1.21445311e+08,\n",
       "        1.21436198e+08, 1.21433526e+08, 1.21487540e+08, 1.21442285e+08,\n",
       "        1.21435619e+08, 1.21432962e+08, 1.21509175e+08, 1.21454739e+08,\n",
       "        1.21423560e+08, 1.21461443e+08, 1.21455229e+08, 1.21449817e+08,\n",
       "        1.21440812e+08, 1.21509777e+08, 1.21453000e+08, 1.21447997e+08,\n",
       "        1.21419427e+08, 1.21439408e+08, 1.21453316e+08, 1.21452090e+08,\n",
       "        1.21471128e+08, 1.21469629e+08, 1.21417265e+08, 1.21458970e+08,\n",
       "        1.21449484e+08, 1.21449780e+08, 1.21437770e+08, 1.21436337e+08,\n",
       "        1.21455205e+08, 1.21462643e+08, 1.21407578e+08, 1.21459643e+08,\n",
       "        1.21461142e+08, 1.21450177e+08, 1.21465172e+08, 1.21445192e+08,\n",
       "        1.21469798e+08, 1.21431610e+08, 1.21484903e+08, 1.21434642e+08,\n",
       "        1.21462364e+08, 1.21437731e+08, 1.21451836e+08, 1.21436043e+08,\n",
       "        1.21405951e+08, 1.21428886e+08, 1.21456144e+08, 1.21451833e+08,\n",
       "        1.21446356e+08, 1.21448207e+08, 1.21447251e+08, 1.21466826e+08,\n",
       "        1.21439493e+08, 1.21457164e+08, 1.21440386e+08, 1.21446600e+08,\n",
       "        1.21439840e+08, 1.21443923e+08, 1.21445700e+08, 1.21444668e+08,\n",
       "        1.21456143e+08, 1.21458080e+08, 1.21425005e+08, 1.21429135e+08,\n",
       "        1.21451899e+08, 1.21437936e+08, 1.21469630e+08, 1.21460898e+08,\n",
       "        1.21421554e+08, 1.21416480e+08, 1.21451045e+08, 1.21431387e+08,\n",
       "        1.21442206e+08, 1.21331765e+08, 1.21470840e+08, 1.21468286e+08,\n",
       "        1.21448401e+08, 1.21450351e+08, 1.21451319e+08, 1.21431443e+08,\n",
       "        1.21421242e+08, 1.21442087e+08, 1.21442898e+08, 1.21447270e+08,\n",
       "        1.21459823e+08, 1.21447255e+08, 1.21470758e+08, 1.21439001e+08,\n",
       "        1.21464681e+08, 1.21472991e+08, 1.21444439e+08, 1.21446982e+08,\n",
       "        1.21425498e+08, 1.21445115e+08, 1.21456641e+08, 1.21453426e+08,\n",
       "        1.21448596e+08, 1.21471123e+08, 1.21456316e+08, 1.21446364e+08,\n",
       "        1.21425329e+08, 1.21409179e+08, 1.21442015e+08, 1.21440058e+08,\n",
       "        1.21445557e+08, 1.21429940e+08, 1.21446429e+08, 1.21478202e+08,\n",
       "        1.21420808e+08, 1.21362574e+08, 1.21443301e+08, 1.21452543e+08,\n",
       "        1.21432964e+08, 1.21437137e+08, 1.21413330e+08, 1.21442621e+08,\n",
       "        1.21459004e+08, 1.21477128e+08, 1.21454069e+08, 1.21448104e+08,\n",
       "        1.21462241e+08, 1.21433377e+08, 1.21440678e+08, 1.21437065e+08,\n",
       "        1.21448293e+08, 1.21440944e+08, 1.21446584e+08, 1.21454028e+08,\n",
       "        1.21452114e+08, 1.21456044e+08, 1.21441688e+08, 1.21377285e+08,\n",
       "        1.21424325e+08, 1.21433064e+08, 1.21433482e+08, 1.21470982e+08,\n",
       "        1.21437247e+08, 1.21435033e+08, 1.21436047e+08, 1.21439976e+08,\n",
       "        1.21463073e+08, 1.21460430e+08, 1.21453474e+08, 1.21431736e+08,\n",
       "        1.21393984e+08, 1.21510499e+08, 1.21442500e+08, 1.21440252e+08,\n",
       "        1.21431640e+08, 1.21450598e+08, 1.21444311e+08, 1.21451969e+08,\n",
       "        1.21433095e+08, 1.21433972e+08, 1.21427916e+08, 1.21440571e+08,\n",
       "        1.21441436e+08, 1.21451461e+08, 1.21438136e+08, 1.21425618e+08,\n",
       "        1.21464304e+08, 1.21462242e+08, 1.21445785e+08, 1.21462361e+08,\n",
       "        1.21468960e+08, 1.21420665e+08, 1.21448384e+08, 1.21522983e+08,\n",
       "        1.21471506e+08, 1.21450676e+08, 1.21440567e+08, 1.21464731e+08,\n",
       "        1.21460332e+08, 1.21446306e+08, 1.21446062e+08, 1.21457746e+08,\n",
       "        1.21436936e+08, 1.21436392e+08, 1.21444802e+08, 1.21465462e+08,\n",
       "        1.21441556e+08, 1.21437460e+08, 1.21431075e+08, 1.21438753e+08,\n",
       "        1.21433161e+08, 1.21515780e+08, 1.21438275e+08, 1.21474283e+08,\n",
       "        1.21461443e+08, 1.21461006e+08, 1.21466471e+08, 1.21454577e+08,\n",
       "        1.21437620e+08, 1.21445619e+08, 1.21458118e+08, 1.21430958e+08,\n",
       "        1.21434677e+08, 1.21437278e+08, 1.21462251e+08, 1.21439519e+08,\n",
       "        1.21471703e+08, 1.21472467e+08, 1.21444666e+08, 1.21442203e+08,\n",
       "        1.21449776e+08, 1.21438812e+08, 1.21466003e+08, 1.21426356e+08,\n",
       "        1.21456732e+08, 1.21456511e+08, 1.21459360e+08, 1.21445811e+08,\n",
       "        1.21466030e+08, 1.21437347e+08, 1.21454804e+08, 1.21439915e+08,\n",
       "        1.21457395e+08, 1.21468848e+08, 1.21458383e+08, 1.21485491e+08,\n",
       "        1.21417485e+08, 1.21453401e+08, 1.21521269e+08, 1.21434975e+08,\n",
       "        1.21454989e+08, 1.21439560e+08, 1.21523501e+08, 1.21441898e+08,\n",
       "        1.21434000e+08, 1.21451603e+08, 1.21438551e+08, 1.21454017e+08,\n",
       "        1.21478471e+08, 1.21461014e+08, 1.21472878e+08, 1.21432895e+08,\n",
       "        1.21430455e+08, 1.21431546e+08, 1.21402246e+08, 1.21453924e+08,\n",
       "        1.21381378e+08, 1.21447415e+08, 1.21452450e+08, 1.21435934e+08,\n",
       "        1.21453089e+08, 1.21446518e+08, 1.21410442e+08, 1.21442815e+08,\n",
       "        1.21434558e+08, 1.21442611e+08, 1.21459681e+08, 1.21440699e+08,\n",
       "        1.21440761e+08, 1.21449883e+08, 1.21443087e+08, 1.21467092e+08,\n",
       "        1.21432138e+08, 1.21425119e+08, 1.21482628e+08, 1.21492464e+08,\n",
       "        1.21417594e+08, 1.21443831e+08, 1.21455112e+08, 1.21431708e+08,\n",
       "        1.21488434e+08, 1.21467211e+08, 1.21466104e+08, 1.21452657e+08,\n",
       "        1.21433987e+08, 1.21441630e+08, 1.21460918e+08, 1.21466291e+08,\n",
       "        1.21452542e+08, 1.21404748e+08, 1.21483107e+08, 1.21430105e+08,\n",
       "        1.21346070e+08, 1.21439353e+08, 1.21443488e+08, 1.21425781e+08,\n",
       "        1.21409291e+08, 1.21461584e+08, 1.21446322e+08, 1.21434145e+08,\n",
       "        1.21446233e+08, 1.21475174e+08, 1.21436645e+08, 1.21458705e+08,\n",
       "        1.21441912e+08, 1.21450863e+08, 1.21447352e+08, 1.21460668e+08])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_mahalanobis_distances(data,decision_model,s,embedding_df) for s in [0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4dc0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dictify(keys,values):\n",
    "    return {k:v for k,v in zip(keys,values)}\n",
    "\n",
    "def get_neighbors_and_embeddings_from_sim(embeddings,dataset,decisionmodel,\n",
    "                                         embedding_df=None,max_neighbors=100,\n",
    "                                          pcas=None,\n",
    "                                          pca_components=2,\n",
    "                                         ):\n",
    "    #this is get_embeddings_and_neighbors, but uses the optimal model from get_stuff_For_patient embeddings\n",
    "    #instead of just kinda not simulation anyhting. adds 1 second on my UIC workstation to the simulation\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    embed_arrays = [np.stack(embedding_df['embeddings_state'+str(s)].values) for s in embeddings.keys()]\n",
    "    if pcas is None:\n",
    "        pcas = [PCA(pca_components,whiten=True).fit(e) for e in embed_arrays]\n",
    "    i = 0\n",
    "    results = {}\n",
    "    for state, embedding in embeddings.items():\n",
    "        embedding_array = embed_arrays[i]\n",
    "        mdist = calculateMahalanobis(embedding.reshape(1,-1),embedding_array)\n",
    "        \n",
    "        dists = cdist(embedding,embedding_array).ravel()\n",
    "        max_neighbors = min(len(dists),max_neighbors)\n",
    "        min_positions = np.argsort(dists)[:max_neighbors]\n",
    "        neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "        min_dists = dists[min_positions]\n",
    "        similarities = 1/(1+min_dists)\n",
    "        # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "        pPca = pcas[i].transform(embedding)[0]\n",
    "        entry = {\n",
    "            'neighbors': neighbor_ids, \n",
    "            'similarities': similarities,\n",
    "            'embedding': embedding[0],\n",
    "            'pca': pPca, \n",
    "            'mahalanobisDistance': mdist[0]\n",
    "        }\n",
    "        results[state] = entry\n",
    "        i+=1\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_default_model_inputs(dataset):\n",
    "    res = []\n",
    "    for state in [0,1,2]:\n",
    "        xin = get_default_input(dataset,state)[0]\n",
    "        xin = dict_to_model_input(dataset,xin,state)\n",
    "        res.append(xin)\n",
    "    return res\n",
    "get_default_model_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab629d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "Decision 2 (CC / RT alone)\n",
      "5.200063943862915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'OS (Calculated)': [[1.0,\n",
       "   0.993,\n",
       "   0.985,\n",
       "   0.976,\n",
       "   0.968,\n",
       "   0.96,\n",
       "   0.951,\n",
       "   0.943,\n",
       "   0.935,\n",
       "   0.927,\n",
       "   0.918],\n",
       "  [1.0, 0.999, 0.996, 0.992, 0.986, 0.98, 0.973, 0.965, 0.957, 0.949, 0.94],\n",
       "  [0.999,\n",
       "   0.988,\n",
       "   0.975,\n",
       "   0.964,\n",
       "   0.954,\n",
       "   0.944,\n",
       "   0.934,\n",
       "   0.924,\n",
       "   0.914,\n",
       "   0.903,\n",
       "   0.891],\n",
       "  [1.0, 0.999, 0.997, 0.993, 0.987, 0.98, 0.972, 0.964, 0.956, 0.947, 0.938],\n",
       "  [0.997, 0.984, 0.969, 0.954, 0.94, 0.925, 0.911, 0.897, 0.884, 0.87, 0.856],\n",
       "  [0.992, 0.968, 0.95, 0.935, 0.922, 0.909, 0.897, 0.885, 0.873, 0.861, 0.85],\n",
       "  [0.996, 0.982, 0.969, 0.958, 0.948, 0.938, 0.929, 0.919, 0.909, 0.9, 0.89],\n",
       "  [1.0, 0.998, 0.992, 0.986, 0.978, 0.97, 0.962, 0.953, 0.945, 0.936, 0.926],\n",
       "  [0.992,\n",
       "   0.978,\n",
       "   0.969,\n",
       "   0.962,\n",
       "   0.957,\n",
       "   0.952,\n",
       "   0.947,\n",
       "   0.941,\n",
       "   0.936,\n",
       "   0.929,\n",
       "   0.923],\n",
       "  [1.0, 0.999, 0.997, 0.992, 0.986, 0.979, 0.97, 0.961, 0.951, 0.94, 0.929],\n",
       "  [0.999,\n",
       "   0.991,\n",
       "   0.984,\n",
       "   0.978,\n",
       "   0.972,\n",
       "   0.966,\n",
       "   0.959,\n",
       "   0.953,\n",
       "   0.945,\n",
       "   0.937,\n",
       "   0.927],\n",
       "  [0.997,\n",
       "   0.986,\n",
       "   0.976,\n",
       "   0.968,\n",
       "   0.961,\n",
       "   0.955,\n",
       "   0.949,\n",
       "   0.942,\n",
       "   0.935,\n",
       "   0.929,\n",
       "   0.921],\n",
       "  [1.0, 0.995, 0.984, 0.972, 0.96, 0.948, 0.936, 0.925, 0.913, 0.902, 0.892],\n",
       "  [0.997, 0.983, 0.968, 0.954, 0.942, 0.929, 0.917, 0.905, 0.893, 0.88, 0.868],\n",
       "  [0.997, 0.983, 0.97, 0.958, 0.945, 0.933, 0.922, 0.91, 0.898, 0.887, 0.876],\n",
       "  [0.998, 0.99, 0.982, 0.973, 0.965, 0.957, 0.949, 0.941, 0.933, 0.925, 0.916],\n",
       "  [1.0, 0.992, 0.98, 0.967, 0.954, 0.942, 0.93, 0.918, 0.906, 0.894, 0.883],\n",
       "  [0.999,\n",
       "   0.994,\n",
       "   0.986,\n",
       "   0.979,\n",
       "   0.972,\n",
       "   0.965,\n",
       "   0.957,\n",
       "   0.949,\n",
       "   0.941,\n",
       "   0.933,\n",
       "   0.924],\n",
       "  [1.0, 0.998, 0.995, 0.99, 0.983, 0.976, 0.968, 0.959, 0.949, 0.939, 0.927],\n",
       "  [1.0, 0.999, 0.996, 0.992, 0.986, 0.98, 0.973, 0.966, 0.958, 0.949, 0.94]],\n",
       " 'Locoregional control (Time)': [[0.994,\n",
       "   0.977,\n",
       "   0.963,\n",
       "   0.952,\n",
       "   0.942,\n",
       "   0.932,\n",
       "   0.924,\n",
       "   0.916,\n",
       "   0.909,\n",
       "   0.902,\n",
       "   0.896],\n",
       "  [0.998, 0.99, 0.983, 0.976, 0.97, 0.964, 0.959, 0.953, 0.948, 0.943, 0.938],\n",
       "  [0.998, 0.987, 0.977, 0.968, 0.959, 0.951, 0.944, 0.937, 0.93, 0.923, 0.917],\n",
       "  [0.997, 0.984, 0.971, 0.96, 0.949, 0.939, 0.93, 0.922, 0.913, 0.906, 0.898],\n",
       "  [0.988, 0.956, 0.932, 0.912, 0.897, 0.883, 0.871, 0.86, 0.85, 0.84, 0.832],\n",
       "  [0.989, 0.965, 0.946, 0.932, 0.921, 0.91, 0.901, 0.893, 0.885, 0.878, 0.871],\n",
       "  [0.996, 0.978, 0.961, 0.948, 0.936, 0.925, 0.916, 0.906, 0.898, 0.89, 0.882],\n",
       "  [0.988, 0.969, 0.956, 0.947, 0.938, 0.93, 0.922, 0.915, 0.908, 0.902, 0.895],\n",
       "  [0.996, 0.986, 0.977, 0.969, 0.961, 0.954, 0.947, 0.94, 0.933, 0.927, 0.921],\n",
       "  [0.992,\n",
       "   0.976,\n",
       "   0.962,\n",
       "   0.951,\n",
       "   0.942,\n",
       "   0.933,\n",
       "   0.924,\n",
       "   0.917,\n",
       "   0.909,\n",
       "   0.902,\n",
       "   0.896],\n",
       "  [0.986, 0.961, 0.943, 0.929, 0.918, 0.908, 0.899, 0.891, 0.884, 0.877, 0.87],\n",
       "  [0.999, 0.993, 0.985, 0.976, 0.968, 0.96, 0.953, 0.945, 0.938, 0.931, 0.925],\n",
       "  [0.994,\n",
       "   0.975,\n",
       "   0.959,\n",
       "   0.946,\n",
       "   0.935,\n",
       "   0.926,\n",
       "   0.917,\n",
       "   0.909,\n",
       "   0.901,\n",
       "   0.894,\n",
       "   0.887],\n",
       "  [1.0, 0.996, 0.99, 0.984, 0.978, 0.972, 0.966, 0.96, 0.955, 0.949, 0.944],\n",
       "  [0.994, 0.972, 0.953, 0.937, 0.924, 0.911, 0.9, 0.89, 0.88, 0.871, 0.863],\n",
       "  [0.99, 0.974, 0.964, 0.956, 0.948, 0.942, 0.936, 0.93, 0.925, 0.919, 0.914],\n",
       "  [0.988, 0.964, 0.946, 0.933, 0.921, 0.911, 0.902, 0.893, 0.885, 0.878, 0.87],\n",
       "  [0.995,\n",
       "   0.985,\n",
       "   0.976,\n",
       "   0.967,\n",
       "   0.959,\n",
       "   0.952,\n",
       "   0.945,\n",
       "   0.938,\n",
       "   0.931,\n",
       "   0.924,\n",
       "   0.918],\n",
       "  [0.998, 0.987, 0.975, 0.965, 0.955, 0.947, 0.938, 0.931, 0.923, 0.916, 0.91],\n",
       "  [0.99, 0.97, 0.954, 0.943, 0.932, 0.923, 0.915, 0.907, 0.9, 0.893, 0.887]],\n",
       " 'FDM (months)': [[0.998,\n",
       "   0.99,\n",
       "   0.982,\n",
       "   0.976,\n",
       "   0.969,\n",
       "   0.964,\n",
       "   0.958,\n",
       "   0.953,\n",
       "   0.948,\n",
       "   0.943,\n",
       "   0.939],\n",
       "  [0.995,\n",
       "   0.982,\n",
       "   0.972,\n",
       "   0.964,\n",
       "   0.958,\n",
       "   0.952,\n",
       "   0.946,\n",
       "   0.941,\n",
       "   0.937,\n",
       "   0.932,\n",
       "   0.928],\n",
       "  [1.0, 0.998, 0.995, 0.991, 0.987, 0.982, 0.978, 0.974, 0.97, 0.966, 0.961],\n",
       "  [0.998, 0.989, 0.98, 0.973, 0.967, 0.961, 0.956, 0.951, 0.946, 0.942, 0.938],\n",
       "  [0.994,\n",
       "   0.979,\n",
       "   0.967,\n",
       "   0.957,\n",
       "   0.949,\n",
       "   0.941,\n",
       "   0.935,\n",
       "   0.928,\n",
       "   0.923,\n",
       "   0.917,\n",
       "   0.912],\n",
       "  [0.996, 0.989, 0.984, 0.98, 0.976, 0.972, 0.968, 0.965, 0.961, 0.958, 0.955],\n",
       "  [0.989, 0.976, 0.967, 0.961, 0.956, 0.952, 0.947, 0.943, 0.94, 0.936, 0.932],\n",
       "  [0.996, 0.983, 0.972, 0.963, 0.955, 0.948, 0.941, 0.935, 0.93, 0.924, 0.919],\n",
       "  [0.999,\n",
       "   0.995,\n",
       "   0.992,\n",
       "   0.989,\n",
       "   0.987,\n",
       "   0.984,\n",
       "   0.982,\n",
       "   0.979,\n",
       "   0.977,\n",
       "   0.974,\n",
       "   0.972],\n",
       "  [0.999, 0.995, 0.99, 0.985, 0.981, 0.976, 0.971, 0.967, 0.962, 0.958, 0.954],\n",
       "  [0.999, 0.993, 0.985, 0.979, 0.972, 0.967, 0.961, 0.956, 0.95, 0.945, 0.941],\n",
       "  [0.996,\n",
       "   0.988,\n",
       "   0.982,\n",
       "   0.976,\n",
       "   0.972,\n",
       "   0.967,\n",
       "   0.963,\n",
       "   0.959,\n",
       "   0.956,\n",
       "   0.952,\n",
       "   0.948],\n",
       "  [0.998, 0.992, 0.986, 0.981, 0.975, 0.97, 0.966, 0.961, 0.956, 0.952, 0.947],\n",
       "  [1.0, 0.998, 0.994, 0.99, 0.986, 0.981, 0.977, 0.972, 0.968, 0.964, 0.959],\n",
       "  [0.998,\n",
       "   0.991,\n",
       "   0.985,\n",
       "   0.979,\n",
       "   0.974,\n",
       "   0.969,\n",
       "   0.965,\n",
       "   0.961,\n",
       "   0.956,\n",
       "   0.952,\n",
       "   0.948],\n",
       "  [0.999, 0.995, 0.99, 0.985, 0.98, 0.976, 0.971, 0.967, 0.963, 0.959, 0.955],\n",
       "  [0.997, 0.988, 0.98, 0.973, 0.967, 0.961, 0.956, 0.951, 0.946, 0.942, 0.937],\n",
       "  [1.0, 0.999, 0.996, 0.993, 0.99, 0.987, 0.984, 0.98, 0.977, 0.974, 0.97],\n",
       "  [0.992, 0.972, 0.958, 0.947, 0.937, 0.928, 0.92, 0.913, 0.906, 0.9, 0.894],\n",
       "  [1.0, 0.997, 0.994, 0.99, 0.986, 0.982, 0.978, 0.974, 0.97, 0.966, 0.962]],\n",
       " 'time_to_event': [[0.992,\n",
       "   0.908,\n",
       "   0.808,\n",
       "   0.725,\n",
       "   0.655,\n",
       "   0.596,\n",
       "   0.544,\n",
       "   0.498,\n",
       "   0.457,\n",
       "   0.42,\n",
       "   0.387],\n",
       "  [0.985, 0.853, 0.73, 0.635, 0.557, 0.491, 0.435, 0.389, 0.349, 0.315, 0.286],\n",
       "  [0.989, 0.913, 0.828, 0.753, 0.687, 0.629, 0.577, 0.531, 0.49, 0.453, 0.42],\n",
       "  [0.999,\n",
       "   0.968,\n",
       "   0.901,\n",
       "   0.823,\n",
       "   0.746,\n",
       "   0.676,\n",
       "   0.613,\n",
       "   0.557,\n",
       "   0.508,\n",
       "   0.464,\n",
       "   0.426],\n",
       "  [0.954, 0.799, 0.684, 0.601, 0.535, 0.482, 0.437, 0.4, 0.367, 0.339, 0.315],\n",
       "  [0.98, 0.895, 0.812, 0.736, 0.663, 0.593, 0.527, 0.468, 0.416, 0.37, 0.33],\n",
       "  [0.986, 0.91, 0.819, 0.733, 0.657, 0.59, 0.532, 0.482, 0.439, 0.402, 0.37],\n",
       "  [0.991, 0.9, 0.792, 0.701, 0.623, 0.558, 0.502, 0.453, 0.411, 0.375, 0.342],\n",
       "  [0.995, 0.935, 0.858, 0.788, 0.723, 0.664, 0.61, 0.561, 0.515, 0.474, 0.437],\n",
       "  [0.991, 0.909, 0.809, 0.717, 0.635, 0.563, 0.502, 0.449, 0.403, 0.364, 0.33],\n",
       "  [0.998,\n",
       "   0.947,\n",
       "   0.875,\n",
       "   0.807,\n",
       "   0.745,\n",
       "   0.686,\n",
       "   0.632,\n",
       "   0.583,\n",
       "   0.538,\n",
       "   0.496,\n",
       "   0.459],\n",
       "  [0.996, 0.94, 0.853, 0.772, 0.702, 0.641, 0.586, 0.538, 0.494, 0.454, 0.419],\n",
       "  [0.999, 0.967, 0.907, 0.836, 0.763, 0.693, 0.628, 0.569, 0.517, 0.47, 0.428],\n",
       "  [0.999, 0.963, 0.883, 0.798, 0.717, 0.642, 0.573, 0.51, 0.454, 0.405, 0.362],\n",
       "  [0.976,\n",
       "   0.881,\n",
       "   0.804,\n",
       "   0.731,\n",
       "   0.659,\n",
       "   0.591,\n",
       "   0.529,\n",
       "   0.475,\n",
       "   0.428,\n",
       "   0.388,\n",
       "   0.354],\n",
       "  [0.971,\n",
       "   0.859,\n",
       "   0.768,\n",
       "   0.692,\n",
       "   0.622,\n",
       "   0.559,\n",
       "   0.504,\n",
       "   0.458,\n",
       "   0.418,\n",
       "   0.385,\n",
       "   0.357],\n",
       "  [0.997, 0.941, 0.847, 0.755, 0.674, 0.604, 0.544, 0.493, 0.449, 0.41, 0.377],\n",
       "  [0.978, 0.875, 0.78, 0.703, 0.638, 0.581, 0.532, 0.488, 0.45, 0.415, 0.384],\n",
       "  [0.999, 0.968, 0.906, 0.835, 0.763, 0.694, 0.631, 0.573, 0.52, 0.474, 0.432],\n",
       "  [0.998, 0.946, 0.863, 0.782, 0.71, 0.647, 0.59, 0.538, 0.492, 0.45, 0.413]]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed\n",
    "def get_stuff_for_patient(patient_dict,data,tmodel1,tmodel2,outcomemodel,decisionmodel,survival_model,\n",
    "                          symptom_model=None,mdasi_data=None,\n",
    "                          override_outcome_model=True,\n",
    "                          state=0,\n",
    "                          model_type='optimal',\n",
    "                          timepoints = [1,6,12,18,24,30,36,42,48,54,60],\n",
    "                          fixed_decisions = [-1,-1,-1],\n",
    "                          **kwargs):\n",
    "    #this takes a patient dict and returns the results for a full treatment simulation\n",
    "    #currently if state > 0 it will check if prior transition states are all zero and if not, will input them\n",
    "    #currently works with categorical, might have to experiment with passing like -1 for fixed \"no\" with fixed no dlts\n",
    "    pdata = format_patient(data,patient_dict)\n",
    "    \n",
    "    baseline_inputs = dict_to_model_input(data,pdata,state=0,concat=False) \n",
    "    \n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    outcomemodel.eval()\n",
    "    decisionmodel.eval()\n",
    "    survival_model.eval()\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        device='cuda'\n",
    "    tmodel1.set_device(device)\n",
    "    tmodel2.set_device(device)\n",
    "    outcomemodel.set_device(device)\n",
    "    decisionmodel.set_device(device)\n",
    "    survival_model.set_device(device)\n",
    "    results = {}\n",
    "    embeddings = {}\n",
    "    #do a loop for imitation and a loop for optimal decision making, mod = 3 is imitation\n",
    "    format_transition = lambda x: x.view(1,-1).to(device)\n",
    "    #inputs are order baseline, dlt1, dlt2, pd, nd, cc type, dose modifications\n",
    "    #model output is nx6 -> optimal 1 , 2, 3, imitation 1, 2, 3\n",
    "    cat = lambda x: torch.cat([xx.to(device) for xx in x],axis=1).to(device)\n",
    "    \n",
    "    size_dict = decisionmodel.input_sizes\n",
    "    \n",
    "    #baseline, dlt1, dlt2, pd, nd, cc, mod\n",
    "    input_keys = get_inputkey_order(data)\n",
    "    \n",
    "    defaults = get_default_model_inputs(data)\n",
    "    defaults = [d.to(device) for d in defaults]\n",
    "    def get_attention(xx, position, offset):\n",
    "        attention = decisionmodel.get_attributions(xx,target=position+offset, position=position,base=defaults[position])[0].cpu().detach().numpy()\n",
    "        attention_dict = {\n",
    "            'step': position,\n",
    "            'model': 'optimal' if offset == 0 else 'imitation',\n",
    "            'range': [float(attention.min()),float(attention.max())],\n",
    "            'baseline': dictify(input_keys[0],attention[0:size_dict['baseline']]),\n",
    "        }\n",
    "        pos = size_dict['baseline']\n",
    "        attention_dict['dlt1'] = dictify(input_keys[1],attention[pos:pos+size_dict['dlt']])\n",
    "        pos += size_dict['dlt']\n",
    "        attention_dict['dlt2'] = dictify(input_keys[2], attention[pos:pos+size_dict['dlt']])\n",
    "        pos += size_dict['dlt']\n",
    "        attention_dict['pd'] = dictify(input_keys[3], attention[pos:pos+size_dict['pd']])\n",
    "        pos += size_dict['pd']\n",
    "        attention_dict['nd'] = dictify(input_keys[4], attention[pos:pos+size_dict['nd']])\n",
    "        pos += size_dict['nd']\n",
    "        attention_dict['cc'] = dictify(input_keys[5], attention[pos:pos+size_dict['cc']])\n",
    "        pos += size_dict['cc']\n",
    "        attention_dict['modifications'] = dictify(input_keys[6], attention[pos:])\n",
    "        return attention_dict\n",
    "        \n",
    "    memory = get_decision_input(data,state=2)\n",
    "    memory = cat([df_to_torch(f) for f in memory])\n",
    "    o1 = decisionmodel(cat(baseline_inputs),position=0)[0]\n",
    "    \n",
    "    thresh = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "    \n",
    "    modifiers = [3] if model_type == 'imitation' else [0]\n",
    "    if model_type == 'both':\n",
    "        modifiers = [0,3]\n",
    "        \n",
    "    def get_fixed_transitions():\n",
    "        \n",
    "        [base, dlt1,_,pd1,nd1,_,mod] =dict_to_model_input(data,pdata,state=1,\n",
    "                                                          concat=False,zero_transition_states=False)\n",
    "        [base, _,dlt2,pd2,nd2,cc,_] =dict_to_model_input(data,pdata,state=2,\n",
    "                                                          concat=False,zero_transition_states=False)\n",
    "        isfixed = lambda d: not (torch.sum(d) < .00001)\n",
    "        results = {\n",
    "            'dlt1': isfixed(dlt1),\n",
    "            'dlt2': isfixed(dlt2),\n",
    "            'pd1': isfixed(pd1),\n",
    "            'pd2': isfixed(pd2),\n",
    "            'nd1': isfixed(nd2),\n",
    "            'nd2': isfixed(nd2),\n",
    "            'cc': isfixed(cc),\n",
    "            'mod': isfixed(mod)\n",
    "        }\n",
    "        return results\n",
    "    fixed_transitions = get_fixed_transitions()\n",
    "\n",
    "    def run_simulation(modifier,decision1=None,decision2=None,decision3=None,is_alt=False):\n",
    "        #do this to track malahanobis distances?\n",
    "        is_default = (modifier == modifiers[0] and not is_alt)\n",
    "        if is_default:\n",
    "            embeddings[0] = decisionmodel.get_embedding(cat(baseline_inputs),position=0,\n",
    "                                                                  use_saved_memory=True)\n",
    "            \n",
    "        #transition 1 model uses usebaline + decision\n",
    "        if decision1 is not None:\n",
    "            d1 = torch.tensor([[decision1]]).type(torch.FloatTensor)\n",
    "            d1_attention=0\n",
    "        else:\n",
    "            d1 = o1[0+modifier].view(1,-1)\n",
    "            d1_attention = get_attention(cat(baseline_inputs),0,modifier)\n",
    "        propensity1 = o1[0+3].view(1,-1)\n",
    "        if is_alt and state == 0:\n",
    "            d1 = 1-d1    \n",
    "        \n",
    "            \n",
    "        tinput1 = cat([baseline_inputs[0],thresh(d1)])\n",
    "        \n",
    "        ytransition = tmodel1(tinput1)\n",
    "        [ypd1,ynd1,ymod,ydlt1] = ytransition['predictions']\n",
    "\n",
    "        [ypd1, ynd1, ymod] = [format_transition(i) for i in [ypd1,ynd1,ymod]]\n",
    "        \n",
    "        #I try to make this work in the model but it just thinks there's no outcome and softmaxes them all often\n",
    "        d1_thresh = torch.gt(d1,.5).view(-1,1).to(device)\n",
    "        ypd1[:,0:2] = ypd1[:,0:2]*d1_thresh\n",
    "        ynd1[:,0:2] = ynd1[:,0:2]*d1_thresh\n",
    "        \n",
    "        oinput2 = dict_to_model_input(data,pdata,state=1,concat=False,zero_transition_states=False)\n",
    "        #if the input stuff has a value for transition states and state passed is > 0, fix them\n",
    "        \n",
    "        #check if I should actually use the transition states\n",
    "        if state > 0 and fixed_transitions['dlt1']:\n",
    "            ydlt1 = torch.clone(oinput2[1])\n",
    "        else:\n",
    "            oinput2[1] = ydlt1.view(1,-1)\n",
    "        if state > 0 and fixed_transitions['pd1']:\n",
    "            ypd1 = torch.clone(oinput2[3])\n",
    "        else:\n",
    "            oinput2[3] = ypd1\n",
    "        if state > 0 and fixed_transitions['nd1']:\n",
    "            ynd1 = torch.clone(oinput2[4])\n",
    "        else:\n",
    "            oinput2[4] = ynd1\n",
    "        if state > 0 and fixed_transitions['mod']:\n",
    "            ymod = torch.clone(oinput2[6])\n",
    "        else:\n",
    "            oinput2[6] = torch.clone(ymod)\n",
    "            \n",
    "        d2_full = decisionmodel(cat(oinput2),position=1)\n",
    "        if decision2 is not None:\n",
    "            d2 = torch.tensor([[decision2]]).type(torch.FloatTensor)\n",
    "            d2_attention=0\n",
    "        else:\n",
    "            d2 = d2_full[0,1+modifier].view(1,-1)\n",
    "            d2_attention = get_attention(cat(oinput2),1,modifier)\n",
    "        propensity2 = d2_full[0,4].view(1,-1)\n",
    "        if is_alt and state == 1:\n",
    "            d2 = 1-d2\n",
    "            \n",
    "        if is_default:\n",
    "            embeddings[1] = decisionmodel.get_embedding(cat(oinput2),position=1,use_saved_memory=True)\n",
    "            \n",
    "        #transition 2 modle uses baseline + pd1 + nd1 + modification + dlt1 + decision 1 + deicsion 2\n",
    "        tinput2 = [baseline_inputs[0], ypd1, ynd1, ymod,ydlt1, thresh(d1),thresh(d2)]\n",
    "\n",
    "        tinput2 = cat(tinput2)\n",
    "        \n",
    "        ytransition2 = tmodel2(tinput2)\n",
    "        [ypd2, ynd2, ycc, ydlt2] = ytransition2['predictions']\n",
    "        [ypd2, ynd2, ycc] = [format_transition(i) for i in [ypd2,ynd2,ycc]]\n",
    "        \n",
    "        oinput3 = oinput2[:]\n",
    "        #check if I should use the transition states again\n",
    "        if state > 1 and fixed_transitions['dlt2']:\n",
    "            ydlt2 = torch.clone(oinput3[2])\n",
    "        else:\n",
    "            oinput3[2] = ydlt2.view(1,-1)\n",
    "        if state > 1 and fixed_transitions['pd2']:\n",
    "            ypd2 = torch.clone(oinput3[3])\n",
    "        else:\n",
    "            oinput3[3] = ypd2\n",
    "        if state > 1 and fixed_transitions['nd2']:\n",
    "            ynd2 = torch.clone(oinput3[4])\n",
    "        else:\n",
    "            oinput3[4] = ynd2\n",
    "        if state > 1 and fixed_transitions['cc']:\n",
    "            ycc = torch.clone(oinput3[5])\n",
    "        else:\n",
    "            oinput3[5] = torch.clone(ycc)\n",
    "\n",
    "        d3_full = decisionmodel(cat(oinput3),position = 2)\n",
    "        if decision3 is not None:\n",
    "            d3 = torch.tensor([[decision3]]).type(torch.FloatTensor)\n",
    "            d3_attention=0\n",
    "        else:\n",
    "            d3 = d3_full[0,2+modifier].view(1,-1)\n",
    "            d3_attention = get_attention(cat(oinput3),2,modifier)\n",
    "        propensity3= d3_full[0,4].view(1,-1)\n",
    "        if is_alt and state == 2:\n",
    "            d3 = 1-d3\n",
    "            \n",
    "        if is_default:\n",
    "            embeddings[2] = decisionmodel.get_embedding(cat(oinput3),position=2,use_saved_memory=True)\n",
    "        #outcomes uses baseline + pd2 + nd2 + cc type + dlt2 + decision 1,2,3\n",
    "        tinput3 = [baseline_inputs[0], ypd2, ynd2, ycc, ydlt2, thresh(d1), thresh(d2), thresh(d3)]\n",
    "        tinput3 = cat(tinput3)\n",
    "        outcomes = outcomemodel(tinput3)\n",
    "        \n",
    "        entry = {\n",
    "            'decision1': d1.cpu().detach().numpy()[0][0],\n",
    "            'decision2': d2.cpu().detach().numpy()[0][0],\n",
    "            'decision3': d3.cpu().detach().numpy()[0][0],\n",
    "            'decision1_attention': d1_attention,\n",
    "            'decision2_attention': d2_attention,\n",
    "            'decision3_attention': d3_attention,\n",
    "            'propensity1': propensity1.cpu().detach().numpy()[0][0],\n",
    "            'propensity2': propensity2.cpu().detach().numpy()[0][0],\n",
    "            'propensity3': propensity3.cpu().detach().numpy()[0][0],\n",
    "        }\n",
    "        \n",
    "        def add_to_entry(tmodel_output,names):\n",
    "            pred = tmodel_output['predictions']\n",
    "            lower = tmodel_output['5%']\n",
    "            upper = tmodel_output['95%']\n",
    "            for suffix,values in zip(['','_5%','_95%'],[pred,lower,upper]):\n",
    "                for name, v in zip(names,values):\n",
    "                    v = v.cpu().detach().numpy()\n",
    "                    if name != 'outcomes':\n",
    "                        v = v[0]\n",
    "                    #because of softmax the model will output 33% for pd and nd with no ic when it should be fixed to 0\n",
    "                    if entry['decision1'] < .5 and ('pd1' in name or 'nd1' in name):\n",
    "                        v = np.zeros(v.shape)\n",
    "                    entry[name+suffix] = v\n",
    "        add_to_entry(ytransition,['pd1','nd1','modifications','dlt1'])\n",
    "        add_to_entry(ytransition2,['pd2','nd2','cc_type','dlt2'])\n",
    "        add_to_entry(outcomes,['outcomes'])\n",
    "        \n",
    "        #add time to event  for each event, each is a seperate entry unlike the grouped outcomes\n",
    "        tte = survival_model.time_to_event(tinput3,n_samples=1)\n",
    "        tte_order = survival_model.outcome_names\n",
    "        for v, name in zip(tte,tte_order):\n",
    "            entry[name] = v.cpu().detach().numpy()[0]\n",
    "        #tte = survival_model.time_to_event(tinput3)\n",
    "        # add_to_entry(tte,tte_order)\n",
    "        \n",
    "        scurve_entry = {}\n",
    "        survival_curves = survival_model(tinput3,timepoints)\n",
    "        for name,scurve in zip(tte_order,survival_curves):\n",
    "            scurve = [np.round(v.cpu().detach().numpy()[0],3) for v in scurve]\n",
    "            scurve_entry[name] = scurve\n",
    "        scurve_entry['times'] = timepoints\n",
    "        entry['survival_curves'] = scurve_entry\n",
    "        \n",
    "        scurve_bootstrap_entries = {}\n",
    "        for i in range(20):\n",
    "            survival_model.enable_dropout()\n",
    "            survival_curves_sample = survival_model(tinput3,timepoints)\n",
    "            for name,scurve in zip(tte_order,survival_curves_sample):\n",
    "                e = scurve_bootstrap_entries.get(name,[])\n",
    "                scurve = [np.round(v.cpu().detach().numpy()[0],3) for v in scurve]\n",
    "                e.append(scurve)\n",
    "                scurve_bootstrap_entries[name] = e\n",
    "        survival_model.disable_dropout()\n",
    "        entry['survival_curves_bootstrapped'] = scurve_bootstrap_entries\n",
    "        #put the 4year probability for the timeseries input in case I want to override the other model\n",
    "        fouryear_probs = survival_model(tinput3,48)\n",
    "        for name, probs in zip(tte_order,fouryear_probs):\n",
    "            probs = probs[0].detach().cpu().numpy()[0]\n",
    "            entry[name+'(4yr)'] = np.round(probs,3)\n",
    "        key = 'optimal' if modifier < 1 else 'imitation'\n",
    "        if is_alt:\n",
    "            key = key + '_alt'\n",
    "#         if decision1 is not None:\n",
    "#             key += '_decision1-'+str(decision1)\n",
    "#         if decision2 is not None:\n",
    "#             key += '_decision2-'+str(decision2)\n",
    "#         if decision3 is not None:\n",
    "#             key += '_decision3-'+str(decision3)\n",
    "            \n",
    "        results[key] = entry\n",
    "\n",
    "    getfixed = lambda i: None if fixed_decisions[i] < 0 else fixed_decisions[i]\n",
    "    with torch.no_grad():\n",
    "        for modifier in modifiers:\n",
    "            for alt in [False,True]:\n",
    "                #is alt inverts the decisions for the current state and uses key + '_alt'\n",
    "                run_simulation(modifier,getfixed(0),getfixed(1),getfixed(2),is_alt=alt)\n",
    "#             for d1_fixed in [None,0,1]:\n",
    "#                 for d2_fixed in [None,0,1]:\n",
    "#                     for d3_fixed in [None,0,1]:\n",
    "#                         #we only need to do all fixed outcomes once\n",
    "#                         if d1_fixed is not None and d2_fixed is not None and d3_fixed is not None and modifier != modifiers[0]:\n",
    "#                             continue\n",
    "#                         run_simulation(modifier,d1_fixed,d2_fixed,d3_fixed)\n",
    "\n",
    "    for k,v in embeddings.items():\n",
    "        embeddings[k] = v.cpu().detach().numpy()\n",
    "    embedding_results = get_neighbors_and_embeddings_from_sim(embeddings,data,decisionmodel,**kwargs)\n",
    "    \n",
    "    res = {'simulation': results,'embeddings': embedding_results}\n",
    "    \n",
    "    symptoms = {}\n",
    "    if symptom_model is not None and mdasi_data is not None:\n",
    "        symptoms = get_knn_predictions(pdata,symptom_model,mdasi_data,decision_state=state+1)\n",
    "        res['symptoms'] = symptoms\n",
    "    return res\n",
    "\n",
    "from time import time\n",
    "t1 = time()\n",
    "test_patient= get_test_patient(data,7,False)\n",
    "test_results = get_stuff_for_patient(test_patient,data,\n",
    "                                     transition_model1,\n",
    "                                     transition_model2,\n",
    "                                     outcome_model,\n",
    "                                     decision_model,\n",
    "                                     survival_model,\n",
    "                                     symptom_model=sp,\n",
    "                                     mdasi_data=mdasi,\n",
    "                                     state=1,\n",
    "                                     max_neighbors=2,\n",
    "                                     model_type='imitation',\n",
    "#                                      model_type='both',\n",
    "                                     fixed_decisions=[-1,0,1]\n",
    "                                    )\n",
    "t2 = time()\n",
    "print(t2-t1)\n",
    "test_results['simulation']['imitation']['survival_curves_bootstrapped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6eba4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OS (Calculated)': [0.999,\n",
       "  0.993,\n",
       "  0.986,\n",
       "  0.979,\n",
       "  0.971,\n",
       "  0.964,\n",
       "  0.956,\n",
       "  0.948,\n",
       "  0.939,\n",
       "  0.93,\n",
       "  0.921],\n",
       " 'Locoregional control (Time)': [0.998,\n",
       "  0.986,\n",
       "  0.974,\n",
       "  0.964,\n",
       "  0.954,\n",
       "  0.945,\n",
       "  0.937,\n",
       "  0.929,\n",
       "  0.921,\n",
       "  0.914,\n",
       "  0.907],\n",
       " 'FDM (months)': [0.999,\n",
       "  0.994,\n",
       "  0.987,\n",
       "  0.982,\n",
       "  0.976,\n",
       "  0.971,\n",
       "  0.966,\n",
       "  0.961,\n",
       "  0.957,\n",
       "  0.952,\n",
       "  0.948],\n",
       " 'time_to_event': [0.993,\n",
       "  0.916,\n",
       "  0.82,\n",
       "  0.737,\n",
       "  0.664,\n",
       "  0.599,\n",
       "  0.542,\n",
       "  0.492,\n",
       "  0.448,\n",
       "  0.409,\n",
       "  0.374],\n",
       " 'times': [1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['simulation']['imitation']['survival_curves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2829a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "test_patient= get_test_patient(data,7,False)\n",
    "test_results = get_stuff_for_patient(test_patient,data,\n",
    "                                     transition_model1,\n",
    "                                     transition_model2,\n",
    "                                     outcome_model,\n",
    "                                     decision_model,\n",
    "                                     survival_model,\n",
    "                                     symptom_model=sp,\n",
    "                                     mdasi_data=mdasi,\n",
    "                                     state=1,\n",
    "                                     max_neighbors=2,\n",
    "                                     model_type='both',\n",
    "                                    )\n",
    "t2 = time()\n",
    "print(t2-t1)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['symptoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f29af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_default_predictions(dm):\n",
    "#     res  = []\n",
    "#     for state in [0,1,2]:\n",
    "#         if hasattr(dm,'memory'):\n",
    "#             mem = dm.memory[state]\n",
    "#             mem = torch.median(mem,dim=0)[0].type(torch.FloatTensor)\n",
    "#             val = dm(mem.reshape(1,-1),position=state)\n",
    "#         else:\n",
    "#         res.append(val.cpu().detach().numpy())\n",
    "#     return np.vstack(res)\n",
    "\n",
    "def get_default_predictions(dm,dataset):\n",
    "    res = []\n",
    "    for state in [0,1,2]:\n",
    "        xin = get_default_input(dataset,state)[0]\n",
    "        xin = dict_to_model_input(dataset,xin,state).to(dm.get_device())\n",
    "        val = dm(xin,position=state)\n",
    "        res.append(val.cpu().detach().numpy())\n",
    "    return np.vstack(res)\n",
    "\n",
    "def get_default_prediction_json(dm,dataset):\n",
    "    vals = get_default_predictions(dm,dataset)\n",
    "    res={}\n",
    "    for i,model in enumerate(['optimal','imitation']):\n",
    "        entry = {}\n",
    "        for state,decision in enumerate(Const.decisions):\n",
    "            val = vals[state, state + (3*i)]\n",
    "            entry[decision] = val\n",
    "        res[model] = entry\n",
    "    return res\n",
    "\n",
    "get_default_prediction_json(decision_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87995787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def np_converter(obj):\n",
    "    #converts stuff to vanilla python  for json since it gives an error with np.int64 and arrays\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return np.round(float(obj),3)\n",
    "    elif isinstance(obj, float):\n",
    "        return round(float(obj),3)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, datetime.datetime) or isinstance(obj, datetime.time):\n",
    "        return obj.__str__()\n",
    "    print('np_converter cant encode obj of type', obj,type(obj))\n",
    "    return obj\n",
    "\n",
    "import simplejson\n",
    "keys = ['outcomes','pd1','nd1','decision1','decision1_attention','decision2_attention']\n",
    "simplejson.dumps(test_results,default=np_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_results['optimal']['decision1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['optimal'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PseudoCode for treating the patient\n",
    "def getGroup(isTreated,candidates, new_patient_propensity, minimum_group_size,caliper_distance_base,scale_increment):\n",
    "    ##gets patients in the treated or untreated group that have a propensity similar to new_patient_propensity\n",
    "    group = []\n",
    "    caliper_distance_scale = scale_increment\n",
    "    #gradually increase caliper size until we have minimum_group_size patients or we run out of candidates\n",
    "    while len(group) < minimum_group_size and len(candidates) > 1:\n",
    "        #update caliper distance\n",
    "        caliper_distance = caliper_distance_base*caliper_distance_scale\n",
    "        for patient in candidates:\n",
    "            #check if the patient is in the treated group and has a close enough similarity score\n",
    "            if patient.treatment == isTreated and absolute_value(new_patient_propensity - patient.propensity) < caliper_distance:\n",
    "                #avoid repeating patients in subsequent loops\n",
    "                delete patient from candidates\n",
    "                #add patient to group if they are valid\n",
    "                group.push(patient)\n",
    "        #update caliper distance by scale_increment %\n",
    "        caliper_distance_scale = caliper_distance_scale*scale_increment\n",
    "    return group\n",
    "        \n",
    "def getNeighbors(cohort,new_patient_propensity, similiarity_filter_size, minimum_group_size, caliper_distance_scale, scale_increment):\n",
    "    #filter out the top patients by similarity\n",
    "    cohort = sort(cohort, key = lambda paient: patient.similarity_with_new_patient)\n",
    "    cohort = cohort[0:similarity_filter_size]\n",
    "    \n",
    "    #calculate the standard deviation of the logit of the propensity scores of the cohort\n",
    "    cohort_propensities = [patient.propensity for patient in cohort]\n",
    "    caliper_distance_base = standard_deviation(logit(cohort_propensities))\n",
    "    caliper_distance_scale = .1\n",
    "    \n",
    "    #calculate treated and untreated groups with scaling propensity independently\n",
    "    treated_group = getGroup(True, copy(cohort), *args)\n",
    "    untreated_group = getGroup(False, copy(cohort), *args)\n",
    "    return treated_group, untreated_group\n",
    "\n",
    "def localAverageTreatementEffect(outcome, *args):\n",
    "    treated_group, untreated_group = getNeighbors(*args)\n",
    "    treated_average = mean([patient[outcome] for patient in treated_group])\n",
    "    untreated_average = mean([patient[outcome] for patient in untreated_group])\n",
    "    return treated_average - untreated_average"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
