{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28cb8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from Constants import *\n",
    "import simplejson\n",
    "from Preprocessing import *\n",
    "from Models import *\n",
    "from DeepSurvivalModels import *\n",
    "from Utils import load_models\n",
    "from SymptomPrediction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b5afd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_model,transition_model1,transition_model2, outcome_model,survival_model = load_models()\n",
    "survival_model.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f42e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SymptomPredictor(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=27, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (batchnorm): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final_layer): Linear(in_features=100, out_features=112, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp, mdasi = load_mdasi_stuff()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15bd4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "decision_model.set_device(device)\n",
    "transition_model1.set_device(device)\n",
    "transition_model2.set_device(device)\n",
    "outcome_model.set_device(device)\n",
    "survival_model.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e6f5a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpv</th>\n",
       "      <th>age</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>Aspiration rate Pre-therapy</th>\n",
       "      <th>total_dose</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <th>FDM (months)</th>\n",
       "      <th>...</th>\n",
       "      <th>4_ipsi</th>\n",
       "      <th>4_contra</th>\n",
       "      <th>5A_ipsi</th>\n",
       "      <th>5A_contra</th>\n",
       "      <th>5B_ipsi</th>\n",
       "      <th>5B_contra</th>\n",
       "      <th>6_ipsi</th>\n",
       "      <th>6_contra</th>\n",
       "      <th>RPLN_ipsi</th>\n",
       "      <th>RPLN_contra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>55.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6.03</td>\n",
       "      <td>4.70</td>\n",
       "      <td>6.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20.95</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>69.93</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>72.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>59.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "      <td>2.20</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.07</td>\n",
       "      <td>8.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>1</td>\n",
       "      <td>49.57</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>143.20</td>\n",
       "      <td>143.20</td>\n",
       "      <td>143.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0</td>\n",
       "      <td>48.71</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>144.37</td>\n",
       "      <td>144.37</td>\n",
       "      <td>144.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>1</td>\n",
       "      <td>77.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>2.33</td>\n",
       "      <td>148.37</td>\n",
       "      <td>148.37</td>\n",
       "      <td>136.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0</td>\n",
       "      <td>45.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.12</td>\n",
       "      <td>152.60</td>\n",
       "      <td>152.60</td>\n",
       "      <td>152.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>1</td>\n",
       "      <td>49.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "      <td>2.12</td>\n",
       "      <td>155.53</td>\n",
       "      <td>155.53</td>\n",
       "      <td>155.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hpv    age  packs_per_year  gender  Aspiration rate Pre-therapy  \\\n",
       "id                                                                       \n",
       "3        1  55.97             0.0       1                            0   \n",
       "5        0  20.95            38.0       1                            0   \n",
       "6        1  69.93            35.0       0                            1   \n",
       "7        1  72.32             0.0       1                            0   \n",
       "8        1  59.73             0.0       1                            0   \n",
       "...    ...    ...             ...     ...                          ...   \n",
       "10201    1  49.57            30.0       1                            0   \n",
       "10202    0  48.71            30.0       1                            0   \n",
       "10203    1  77.12             0.0       1                            0   \n",
       "10204    0  45.95             5.0       1                            0   \n",
       "10205    1  49.73             0.0       1                            0   \n",
       "\n",
       "       total_dose  dose_fraction  OS (Calculated)  \\\n",
       "id                                                  \n",
       "3           66.00           2.20             6.03   \n",
       "5           72.00           1.80             7.33   \n",
       "6           70.00           2.12             7.47   \n",
       "7           70.00           2.12             7.80   \n",
       "8           66.00           2.20             8.07   \n",
       "...           ...            ...              ...   \n",
       "10201       70.00           2.12           143.20   \n",
       "10202       72.00           1.71           144.37   \n",
       "10203       70.00           2.33           148.37   \n",
       "10204       69.96           2.12           152.60   \n",
       "10205       69.96           2.12           155.53   \n",
       "\n",
       "       Locoregional control (Time)  FDM (months)  ...  4_ipsi  4_contra  \\\n",
       "id                                                ...                     \n",
       "3                             4.70          6.03  ...     0.0       0.0   \n",
       "5                             7.33          7.33  ...     0.0       0.0   \n",
       "6                             7.47          7.47  ...     0.0       0.0   \n",
       "7                             7.80          7.80  ...     0.0       0.0   \n",
       "8                             8.07          8.07  ...     0.0       0.0   \n",
       "...                            ...           ...  ...     ...       ...   \n",
       "10201                       143.20        143.20  ...     0.0       0.0   \n",
       "10202                       144.37        144.37  ...     0.0       0.0   \n",
       "10203                       148.37        136.03  ...     0.0       0.0   \n",
       "10204                       152.60        152.60  ...     0.0       0.0   \n",
       "10205                       155.53        155.53  ...     0.0       0.0   \n",
       "\n",
       "       5A_ipsi  5A_contra  5B_ipsi  5B_contra  6_ipsi  6_contra  RPLN_ipsi  \\\n",
       "id                                                                           \n",
       "3          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "5          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "6          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "7          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "8          0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "...        ...        ...      ...        ...     ...       ...        ...   \n",
       "10201      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10202      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10203      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10204      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "10205      0.0        0.0      0.0        0.0     0.0       0.0        0.0   \n",
       "\n",
       "       RPLN_contra  \n",
       "id                  \n",
       "3              0.0  \n",
       "5              0.0  \n",
       "6              0.0  \n",
       "7              0.0  \n",
       "8              0.0  \n",
       "...            ...  \n",
       "10201          0.0  \n",
       "10202          0.0  \n",
       "10203          0.0  \n",
       "10204          0.0  \n",
       "10205          0.0  \n",
       "\n",
       "[536 rows x 109 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DTDataset()\n",
    "newdf = data.processed_df.copy()\n",
    "for c in newdf.columns:\n",
    "    if newdf[c].dtype == np.float64:\n",
    "        newdf[c] = newdf[c].astype(np.float32).apply(lambda x: np.round(x,2))\n",
    "data.processed_df = newdf\n",
    "data.processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6056f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1A_contra</th>\n",
       "      <th>1A_ipsi</th>\n",
       "      <th>1B_contra</th>\n",
       "      <th>1B_ipsi</th>\n",
       "      <th>2A_contra</th>\n",
       "      <th>2A_ipsi</th>\n",
       "      <th>2B_contra</th>\n",
       "      <th>2B_ipsi</th>\n",
       "      <th>3_contra</th>\n",
       "      <th>3_ipsi</th>\n",
       "      <th>...</th>\n",
       "      <th>dose_fraction</th>\n",
       "      <th>gender</th>\n",
       "      <th>hpv</th>\n",
       "      <th>packs_per_year</th>\n",
       "      <th>subsite_BOT</th>\n",
       "      <th>subsite_GPS</th>\n",
       "      <th>subsite_NOS</th>\n",
       "      <th>subsite_Soft palate</th>\n",
       "      <th>subsite_Tonsil</th>\n",
       "      <th>total_dose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1A_contra  1A_ipsi  1B_contra  1B_ipsi  2A_contra  2A_ipsi  2B_contra  \\\n",
       "id                                                                             \n",
       "3            0.0      0.0        0.0      0.0        1.0      0.0        1.0   \n",
       "5            0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "6            0.0      0.0        0.0      0.0        1.0      1.0        1.0   \n",
       "7            0.0      0.0        1.0      0.0        0.0      0.0        0.0   \n",
       "8            0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "...          ...      ...        ...      ...        ...      ...        ...   \n",
       "10201        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10202        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10203        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10204        0.0      0.0        0.0      0.0        0.0      1.0        0.0   \n",
       "10205        0.0      0.0        0.0      0.0        0.0      0.0        0.0   \n",
       "\n",
       "       2B_ipsi  3_contra  3_ipsi  ...  dose_fraction  gender  hpv  \\\n",
       "id                                ...                               \n",
       "3          0.0       0.0     0.0  ...           2.20       1    1   \n",
       "5          1.0       0.0     0.0  ...           1.80       1    0   \n",
       "6          1.0       1.0     1.0  ...           2.12       0    1   \n",
       "7          0.0       0.0     0.0  ...           2.12       1    1   \n",
       "8          1.0       0.0     0.0  ...           2.20       1    1   \n",
       "...        ...       ...     ...  ...            ...     ...  ...   \n",
       "10201      1.0       0.0     0.0  ...           2.12       1    1   \n",
       "10202      1.0       0.0     0.0  ...           1.71       1    0   \n",
       "10203      1.0       0.0     1.0  ...           2.33       1    1   \n",
       "10204      1.0       0.0     1.0  ...           2.12       1    0   \n",
       "10205      0.0       0.0     1.0  ...           2.12       1    1   \n",
       "\n",
       "       packs_per_year  subsite_BOT  subsite_GPS  subsite_NOS  \\\n",
       "id                                                             \n",
       "3                 0.0            1            0            0   \n",
       "5                38.0            1            0            0   \n",
       "6                35.0            1            0            0   \n",
       "7                 0.0            0            0            1   \n",
       "8                 0.0            0            0            0   \n",
       "...               ...          ...          ...          ...   \n",
       "10201            30.0            1            0            0   \n",
       "10202            30.0            0            0            1   \n",
       "10203             0.0            0            0            0   \n",
       "10204             5.0            0            0            0   \n",
       "10205             0.0            1            0            0   \n",
       "\n",
       "       subsite_Soft palate  subsite_Tonsil  total_dose  \n",
       "id                                                      \n",
       "3                        0               0       66.00  \n",
       "5                        0               0       72.00  \n",
       "6                        0               0       70.00  \n",
       "7                        0               0       70.00  \n",
       "8                        0               1       66.00  \n",
       "...                    ...             ...         ...  \n",
       "10201                    0               0       70.00  \n",
       "10202                    0               0       72.00  \n",
       "10203                    0               1       70.00  \n",
       "10204                    0               1       69.96  \n",
       "10205                    0               0       69.96  \n",
       "\n",
       "[536 rows x 60 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_to_torch(df,ttype  = torch.FloatTensor):\n",
    "    values = df.values.astype(float)\n",
    "    values = torch.from_numpy(values)\n",
    "    return values.type(ttype)\n",
    "\n",
    "def get_decision_input(dataset,state=0,ids=None):\n",
    "    baseline = dataset.get_state('baseline')\n",
    "    dlt1 = dataset.get_state('dlt1')\n",
    "    dlt2 = dataset.get_state('dlt2')\n",
    "    pd1 = dataset.get_state('pd_states1')\n",
    "    pd2 = dataset.get_state('pd_states2')\n",
    "    nd1 = dataset.get_state('nd_states1')\n",
    "    nd2 = dataset.get_state('nd_states2')\n",
    "    modifications = dataset.get_state('modifications')\n",
    "    ccs = dataset.get_state('ccs')\n",
    "    if state < 2:\n",
    "        pd = pd1.copy()\n",
    "        nd = nd1.copy()\n",
    "        dlt2.values[:,:] = np.zeros(dlt2.shape)\n",
    "        ccs.values[:,:] = np.zeros(ccs.shape)\n",
    "        if state < 1:\n",
    "            dlt1.values[:,:] = np.zeros(dlt1.shape)\n",
    "            modifications.values[:,:] = np.zeros(modifications.shape)\n",
    "            pd.values[:,:] = np.zeros(pd.shape)\n",
    "            nd.values[:,:] = np.zeros(nd.shape)\n",
    "    else:\n",
    "        pd = pd2.copy()\n",
    "        nd = nd2.copy()\n",
    "        \n",
    "    output = [baseline, dlt1, dlt2, pd, nd,ccs,modifications]\n",
    "    if ids is not None:\n",
    "        output = [o.loc[ids] for o in output]\n",
    "    return output\n",
    "test_patient_id=7\n",
    "get_decision_input(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d795eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1A_contra',\n",
       "  '1A_ipsi',\n",
       "  '1B_contra',\n",
       "  '1B_ipsi',\n",
       "  '2A_contra',\n",
       "  '2A_ipsi',\n",
       "  '2B_contra',\n",
       "  '2B_ipsi',\n",
       "  '3_contra',\n",
       "  '3_ipsi',\n",
       "  '4_contra',\n",
       "  '4_ipsi',\n",
       "  '5A_contra',\n",
       "  '5A_ipsi',\n",
       "  '5B_contra',\n",
       "  '5B_ipsi',\n",
       "  '6_contra',\n",
       "  '6_ipsi',\n",
       "  'AJCC_1',\n",
       "  'AJCC_2',\n",
       "  'AJCC_3',\n",
       "  'AJCC_4',\n",
       "  'African American/Black',\n",
       "  'Asian',\n",
       "  'Aspiration rate Pre-therapy',\n",
       "  'DLT_Infection (Pneumonia)',\n",
       "  'DLT_Infection (Pneumonia) 2',\n",
       "  'DLT_Nephrological',\n",
       "  'DLT_Nephrological 2',\n",
       "  'DLT_Vascular',\n",
       "  'DLT_Vascular 2',\n",
       "  'Hispanic/Latino',\n",
       "  'N-category_0',\n",
       "  'N-category_1',\n",
       "  'N-category_2',\n",
       "  'N-category_3',\n",
       "  'Pathological Grade_0',\n",
       "  'Pathological Grade_1',\n",
       "  'Pathological Grade_2',\n",
       "  'Pathological Grade_3',\n",
       "  'Pathological Grade_4',\n",
       "  'RPLN_contra',\n",
       "  'RPLN_ipsi',\n",
       "  'T-category_1',\n",
       "  'T-category_2',\n",
       "  'T-category_3',\n",
       "  'T-category_4',\n",
       "  'White/Caucasion',\n",
       "  'age',\n",
       "  'bilateral',\n",
       "  'dose_fraction',\n",
       "  'gender',\n",
       "  'hpv',\n",
       "  'packs_per_year',\n",
       "  'subsite_BOT',\n",
       "  'subsite_GPS',\n",
       "  'subsite_NOS',\n",
       "  'subsite_Soft palate',\n",
       "  'subsite_Tonsil',\n",
       "  'total_dose'],\n",
       " ['DLT_Dermatological',\n",
       "  'DLT_Gastrointestinal',\n",
       "  'DLT_Hematological',\n",
       "  'DLT_Neurological',\n",
       "  'DLT_Other'],\n",
       " ['DLT_Dermatological 2',\n",
       "  'DLT_Gastrointestinal 2',\n",
       "  'DLT_Hematological 2',\n",
       "  'DLT_Neurological 2',\n",
       "  'DLT_Other 2'],\n",
       " ['CR Primary', 'PR Primary', 'SD Primary'],\n",
       " ['CR Nodal', 'PR Nodal', 'SD Nodal'],\n",
       " ['cc_none', 'cc_platinum', 'cc_cetuximab', 'cc_others'],\n",
       " ['no_dose_adjustment',\n",
       "  'dose_modified',\n",
       "  'dose_delayed',\n",
       "  'dose_cancelled',\n",
       "  'dose_delayed_&_modified',\n",
       "  'regiment_modification']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_inputkey_order(dataset,state=0):\n",
    "    return [list(f.columns) for f in get_decision_input(dataset,state=state)]\n",
    "\n",
    "get_inputkey_order(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a507552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpv': 1,\n",
       " 'age': 72.32,\n",
       " 'packs_per_year': 0.0,\n",
       " 'gender': 1,\n",
       " 'Aspiration rate Pre-therapy': 0,\n",
       " 'total_dose': 70.0,\n",
       " 'dose_fraction': 2.12,\n",
       " 'OS (Calculated)': 7.8,\n",
       " 'Locoregional control (Time)': 7.8,\n",
       " 'FDM (months)': 7.8,\n",
       " 'time_to_event': 6.0,\n",
       " 'Overall Survival (1=alive, 0=dead)': 0,\n",
       " 'LRC': 1,\n",
       " 'DC': 1,\n",
       " 'bilateral': False,\n",
       " 'White/Caucasion': True,\n",
       " 'Hispanic/Latino': False,\n",
       " 'African American/Black': False,\n",
       " 'Asian': False,\n",
       " 'cc_none': 1,\n",
       " 'cc_platinum': 0,\n",
       " 'cc_cetuximab': 0,\n",
       " 'cc_others': 0,\n",
       " 'no_dose_adjustment': 1,\n",
       " 'dose_modified': 0,\n",
       " 'dose_delayed': 0,\n",
       " 'dose_cancelled': 0,\n",
       " 'dose_delayed_&_modified': 0,\n",
       " 'regiment_modification': 0,\n",
       " 'T-category_1': 1,\n",
       " 'T-category_2': 0,\n",
       " 'T-category_3': 0,\n",
       " 'T-category_4': 0,\n",
       " 'N-category_0': 0,\n",
       " 'N-category_1': 0,\n",
       " 'N-category_2': 1,\n",
       " 'N-category_3': 0,\n",
       " 'AJCC_1': 0,\n",
       " 'AJCC_2': 1,\n",
       " 'AJCC_3': 0,\n",
       " 'AJCC_4': 0,\n",
       " 'Pathological Grade_0': 1,\n",
       " 'Pathological Grade_1': 0,\n",
       " 'Pathological Grade_2': 0,\n",
       " 'Pathological Grade_3': 0,\n",
       " 'Pathological Grade_4': 0,\n",
       " 'subsite_BOT': 0,\n",
       " 'subsite_GPS': 0,\n",
       " 'subsite_NOS': 1,\n",
       " 'subsite_Soft palate': 0,\n",
       " 'subsite_Tonsil': 0,\n",
       " 'treatment_CC': 0,\n",
       " 'treatment_IC+CC': 0,\n",
       " 'treatment_IC+Radiation alone': 0,\n",
       " 'treatment_Radiation alone': 1,\n",
       " 'DLT_Dermatological': 0.0,\n",
       " 'DLT_Neurological': 0.0,\n",
       " 'DLT_Gastrointestinal': 0.0,\n",
       " 'DLT_Hematological': 0.0,\n",
       " 'DLT_Nephrological': 0,\n",
       " 'DLT_Vascular': 0,\n",
       " 'DLT_Infection (Pneumonia)': 0,\n",
       " 'DLT_Other': 0.0,\n",
       " 'DLT_Dermatological 2': 0.0,\n",
       " 'DLT_Neurological 2': 0.0,\n",
       " 'DLT_Gastrointestinal 2': 0.0,\n",
       " 'DLT_Hematological 2': 0.0,\n",
       " 'DLT_Nephrological 2': 0,\n",
       " 'DLT_Vascular 2': 0,\n",
       " 'DLT_Infection (Pneumonia) 2': 0,\n",
       " 'DLT_Other 2': 0.0,\n",
       " 'CR Primary': 0,\n",
       " 'PR Primary': 0,\n",
       " 'SD Primary': 0,\n",
       " 'CR Nodal': 0,\n",
       " 'PR Nodal': 0,\n",
       " 'SD Nodal': 0,\n",
       " 'CR Primary 2': 0,\n",
       " 'PR Primary 2': 0,\n",
       " 'SD Primary 2': 0,\n",
       " 'CR Nodal 2': 0,\n",
       " 'PR Nodal 2': 0,\n",
       " 'SD Nodal 2': 0,\n",
       " 'Decision 1 (Induction Chemo) Y/N': 0,\n",
       " 'Decision 2 (CC / RT alone)': 0,\n",
       " 'Decision 3 Neck Dissection (Y/N)': 0,\n",
       " 'Overall Survival (4 Years)': 0,\n",
       " 'FT': 1,\n",
       " 'Aspiration rate Post-therapy': 0,\n",
       " '1A_ipsi': 0.0,\n",
       " '1A_contra': 0.0,\n",
       " '1B_ipsi': 0.0,\n",
       " '1B_contra': 1.0,\n",
       " '2A_ipsi': 0.0,\n",
       " '2A_contra': 0.0,\n",
       " '2B_ipsi': 0.0,\n",
       " '2B_contra': 0.0,\n",
       " '3_ipsi': 0.0,\n",
       " '3_contra': 0.0,\n",
       " '4_ipsi': 0.0,\n",
       " '4_contra': 0.0,\n",
       " '5A_ipsi': 0.0,\n",
       " '5A_contra': 0.0,\n",
       " '5B_ipsi': 0.0,\n",
       " '5B_contra': 0.0,\n",
       " '6_ipsi': 0.0,\n",
       " '6_contra': 0.0,\n",
       " 'RPLN_ipsi': 0.0,\n",
       " 'RPLN_contra': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_patient(d,pid=7,clear_transitions=True):\n",
    "    tp = d.processed_df.loc[pid].to_dict()\n",
    "    if clear_transitions:\n",
    "        for v in Const.primary_disease_states + Const.nodal_disease_states:\n",
    "            tp[v] = 0\n",
    "            tp[v + ' 2'] = 0\n",
    "    return tp \n",
    "test_patient = get_test_patient(data)\n",
    "test_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca3cb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [1237, 418, 1313, 1673, 361, 277, 298, 1483],\n",
       " 'dists': [47.4503453343392,\n",
       "  48.925031296142905,\n",
       "  49.16342763346124,\n",
       "  49.2733456894991,\n",
       "  49.29173611348111,\n",
       "  49.47347895424199,\n",
       "  49.47525944749981,\n",
       "  49.489565203565945],\n",
       " 'symptoms': {'choke': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "    [0.0, -1.0, 1.0, 2.0],\n",
       "    [3.0, 0.0, 0.0, -1.0],\n",
       "    [-1.0, 1.0, -1.0, -1.0],\n",
       "    [0.0, -1.0, -1.0, 0.0],\n",
       "    [0.0, -1.0, 0.0, 0.0],\n",
       "    [0.0, 1.0, 1.0, 4.0],\n",
       "    [-1.0, 0.0, -1.0, 3.0]],\n",
       "   'means': [0.5, 0.4, 0.4, 1.8]},\n",
       "  'drymouth': {'ratings': [[0.0, 5.0, 2.0, -1.0],\n",
       "    [0.0, -1.0, 6.0, 3.0],\n",
       "    [3.0, 5.0, 3.0, -1.0],\n",
       "    [-1.0, 1.0, -1.0, -1.0],\n",
       "    [0.0, -1.0, -1.0, 0.0],\n",
       "    [0.0, -1.0, 5.0, 3.0],\n",
       "    [0.0, 8.0, 7.0, 6.0],\n",
       "    [-1.0, 1.0, -1.0, 2.0]],\n",
       "   'means': [0.5, 4.0, 4.6, 2.8]}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from ClusterPredictions.py\n",
    "test_patient = get_test_patient(data,7)\n",
    "get_knn_predictions(test_patient,sp,mdasi,symptom_subset=['choke','drymouth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bef88125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(536, 1000), (536, 1000), (536, 1000)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings(dataset,dm,states=[0,1,2],use_saved_memory=True,decimals=2):\n",
    "    embeddings = []\n",
    "    inputs = []\n",
    "    decisions_optimal = [[] for i in states]\n",
    "    decisions_imitation = [[] for i in states]\n",
    "    for i,state in enumerate(states):\n",
    "        x = get_decision_input(dataset,state=state)\n",
    "        x = torch.cat([df_to_torch(f) for f in x],axis=1).to(dm.get_device())\n",
    "        print(x.shape)\n",
    "        embedding = dm.get_embedding(x,position = state,use_saved_memory=True)\n",
    "        inputs.append(x.cpu().detach().numpy())\n",
    "        decision = dm(x,position=state).cpu().detach().numpy()\n",
    "        decisions_optimal[i].append(decision[:,state])\n",
    "        decisions_imitation[i].append(decision[:,state+3])\n",
    "        embedding = embedding.cpu().detach().numpy()\n",
    "        if decimals is not None:\n",
    "            embedding = np.round(embedding,decimals)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings,np.array(decisions_optimal).reshape(len(states),-1).T, np.array(decisions_imitation).reshape(len(states),-1).T, inputs\n",
    "embeddings, decisions_optimal, decisions_imitation, testinputs = get_embeddings(data,decision_model)\n",
    "[e.shape for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1789c54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OS (Calculated)</th>\n",
       "      <th>Locoregional control (Time)</th>\n",
       "      <th>FDM (months)</th>\n",
       "      <th>time_to_event</th>\n",
       "      <th>OS (Calculated)_5%</th>\n",
       "      <th>Locoregional control (Time)_5%</th>\n",
       "      <th>FDM (months)_5%</th>\n",
       "      <th>time_to_event_5%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.478271</td>\n",
       "      <td>1060.589966</td>\n",
       "      <td>2004.874512</td>\n",
       "      <td>49.507156</td>\n",
       "      <td>254.452026</td>\n",
       "      <td>1014.422913</td>\n",
       "      <td>1684.298340</td>\n",
       "      <td>44.068024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>245.843048</td>\n",
       "      <td>911.368835</td>\n",
       "      <td>1745.499512</td>\n",
       "      <td>34.479568</td>\n",
       "      <td>230.089935</td>\n",
       "      <td>801.499817</td>\n",
       "      <td>1568.682617</td>\n",
       "      <td>27.238298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>329.097778</td>\n",
       "      <td>1238.492188</td>\n",
       "      <td>2055.133057</td>\n",
       "      <td>48.247662</td>\n",
       "      <td>303.553589</td>\n",
       "      <td>1084.653320</td>\n",
       "      <td>1965.405884</td>\n",
       "      <td>42.210831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    OS (Calculated)  Locoregional control (Time)  FDM (months)  time_to_event  \\\n",
       "id                                                                              \n",
       "3        276.478271                  1060.589966   2004.874512      49.507156   \n",
       "5        245.843048                   911.368835   1745.499512      34.479568   \n",
       "7        329.097778                  1238.492188   2055.133057      48.247662   \n",
       "\n",
       "    OS (Calculated)_5%  Locoregional control (Time)_5%  FDM (months)_5%  \\\n",
       "id                                                                        \n",
       "3           254.452026                     1014.422913      1684.298340   \n",
       "5           230.089935                      801.499817      1568.682617   \n",
       "7           303.553589                     1084.653320      1965.405884   \n",
       "\n",
       "    time_to_event_5%  \n",
       "id                    \n",
       "3          44.068024  \n",
       "5          27.238298  \n",
       "7          42.210831  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed\n",
    "def get_predictions(dataset,m1,m2,m3,sm3,states=[0,1,2],ids=None):\n",
    "    outcomes = {}\n",
    "    def add_outcomes(names, array,suffix=''):\n",
    "        for i,name in enumerate(names):\n",
    "            outcomes[name+suffix] = array[:,i]\n",
    "    for model,state in zip([m1,m2,m3],states):\n",
    "        x = dataset.get_input_state(step=state+1,ids=ids)\n",
    "        x = df_to_torch(x).to(model.get_device())\n",
    "        yout = model(x)\n",
    "        y = yout['predictions']\n",
    "        y_lower = yout['5%']\n",
    "        y_upper = yout['95%']\n",
    "        if state < 2:\n",
    "            y = [yy.cpu().detach().numpy() for yy in y]\n",
    "            y_lower = [yy.cpu().detach().numpy() for yy in y_lower]\n",
    "            y_upper = [yy.cpu().detach().numpy() for yy in y_upper]\n",
    "        else:\n",
    "            y = y.cpu().detach().numpy()\n",
    "            y_lower = y_lower.cpu().detach().numpy()\n",
    "            y_upper = y_upper.cpu().detach().numpy()\n",
    "        if state == 0:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                [pds, nd, mod, dlts] = values\n",
    "                add_outcomes(Const.primary_disease_states,pds,suffixes)\n",
    "                add_outcomes(Const.nodal_disease_states,nd,suffixes)\n",
    "                add_outcomes(Const.modifications,mod,suffixes)\n",
    "                add_outcomes(Const.dlt1,dlts,suffixes)\n",
    "        elif state == 1:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                [pd2, nd2, cc, dlts2] = values\n",
    "                add_outcomes(Const.primary_disease_states2,pd2,suffixes)\n",
    "                add_outcomes(Const.nodal_disease_states2,nd2,suffixes)\n",
    "                add_outcomes(Const.dlt2,dlts2,suffixes)\n",
    "        else:\n",
    "            for suffixes, values in zip(['','_5%','_95%'],[y,y_lower,y_upper]):\n",
    "                add_outcomes(Const.outcomes,values,suffixes)\n",
    "        if state == 2: #timeseries outcomes\n",
    "            survival = sm3.time_to_event(x,n_samples=20)\n",
    "            s = survival['predictions']\n",
    "            s_lower = survival['5%']\n",
    "            s_upper= survival['95%']\n",
    "            names = survival['order']\n",
    "            for suffixes,values in zip(['','_5%','_95%'],[s,s_lower,s_upper]):\n",
    "                values = torch.stack(values,axis=1).cpu().detach().numpy()\n",
    "                add_outcomes(names,values,suffixes)\n",
    "    if ids is None:\n",
    "        ids = dataset.processed_df.index.values\n",
    "    outcomes = pd.DataFrame(outcomes,ids)\n",
    "    outcomes.index.name = 'id'\n",
    "    return outcomes\n",
    "prediction_df = get_predictions(data,transition_model1,transition_model2,outcome_model,survival_model,ids=[3,5,7])\n",
    "prediction_df[Const.timeseries_outcomes + [c+'_5%' for c in Const.timeseries_outcomes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce07c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings_state0</th>\n",
       "      <th>embeddings_state1</th>\n",
       "      <th>embeddings_state2</th>\n",
       "      <th>decision0_optimal</th>\n",
       "      <th>decision0_imitation</th>\n",
       "      <th>inputs0</th>\n",
       "      <th>decision1_optimal</th>\n",
       "      <th>decision1_imitation</th>\n",
       "      <th>inputs1</th>\n",
       "      <th>decision2_optimal</th>\n",
       "      <th>decision2_imitation</th>\n",
       "      <th>inputs2</th>\n",
       "      <th>pca_state0</th>\n",
       "      <th>pca_state1</th>\n",
       "      <th>pca_state2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.316692</td>\n",
       "      <td>0.975234</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.014232</td>\n",
       "      <td>0.046543</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.238878</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.48599857, -0.506752]</td>\n",
       "      <td>[-0.45917124, -0.4639411]</td>\n",
       "      <td>[0.49081385, -0.4692875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.206143</td>\n",
       "      <td>0.431012</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.740672</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.286323</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[1.2279854, -0.26386157]</td>\n",
       "      <td>[1.0977091, -0.046363775]</td>\n",
       "      <td>[-1.0250679, 0.3060964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.152556</td>\n",
       "      <td>0.780169</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.552226</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.817031</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.6808392, -0.6142941]</td>\n",
       "      <td>[1.5127486, -0.60941494]</td>\n",
       "      <td>[-1.4664419, -0.11814983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.382589</td>\n",
       "      <td>0.974404</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.167392</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.22417444, -0.59941596]</td>\n",
       "      <td>[0.31850857, -0.85750437]</td>\n",
       "      <td>[-0.6068724, -0.6818945]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0...</td>\n",
       "      <td>[0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0...</td>\n",
       "      <td>[0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0...</td>\n",
       "      <td>0.646277</td>\n",
       "      <td>0.926530</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.268609</td>\n",
       "      <td>0.013533</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.827465</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-1.7481053, 0.70407444]</td>\n",
       "      <td>[-1.7431976, 0.8784005]</td>\n",
       "      <td>[2.068149, 0.6000858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>[0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.343991</td>\n",
       "      <td>0.961293</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.040797</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.028383</td>\n",
       "      <td>0.076898</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.1314283, -0.6250571]</td>\n",
       "      <td>[0.24043086, -0.6651105]</td>\n",
       "      <td>[-0.37348026, -0.41426834]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>[0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.231363</td>\n",
       "      <td>0.662527</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.582402</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.6399169, -0.50798887]</td>\n",
       "      <td>[0.61837995, -0.21105418]</td>\n",
       "      <td>[-0.59265363, 0.016543038]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>[0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.597669</td>\n",
       "      <td>0.947900</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.080935</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.05236329, 0.14106381]</td>\n",
       "      <td>[0.053728197, 0.05760461]</td>\n",
       "      <td>[-0.108006194, 0.17732997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>[0.51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78, 0.0...</td>\n",
       "      <td>[0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72, 0.0...</td>\n",
       "      <td>[0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, ...</td>\n",
       "      <td>0.869228</td>\n",
       "      <td>0.968241</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.021384</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>0.097314</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[-0.09948434, 0.94213074]</td>\n",
       "      <td>[0.039646197, 0.9279005]</td>\n",
       "      <td>[-0.33775666, 0.8870283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>[0.57, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.670887</td>\n",
       "      <td>0.923345</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.155170</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.040294</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.1605965, 0.573429]</td>\n",
       "      <td>[0.23535553, 0.6372578]</td>\n",
       "      <td>[-0.1023707, 0.53079444]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       embeddings_state0  \\\n",
       "3      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5      [0.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "6      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7      [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "8      [0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0...   \n",
       "...                                                  ...   \n",
       "10201  [0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10202  [0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10203  [0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10204  [0.51, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.78, 0.0...   \n",
       "10205  [0.57, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                       embeddings_state1  \\\n",
       "3      [0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "5      [0.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "6      [0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "7      [0.52, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "8      [0.41, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.0...   \n",
       "...                                                  ...   \n",
       "10201  [0.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10202  [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10203  [0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10204  [0.55, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72, 0.0...   \n",
       "10205  [0.62, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                       embeddings_state2  decision0_optimal  \\\n",
       "3      [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.316692   \n",
       "5      [0.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.206143   \n",
       "6      [0.17, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.152556   \n",
       "7      [0.47, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.382589   \n",
       "8      [0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42, 0.0...           0.646277   \n",
       "...                                                  ...                ...   \n",
       "10201  [0.39, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.343991   \n",
       "10202  [0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.231363   \n",
       "10203  [0.19, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.597669   \n",
       "10204  [0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, ...           0.869228   \n",
       "10205  [0.65, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...           0.670887   \n",
       "\n",
       "       decision0_imitation                                            inputs0  \\\n",
       "3                 0.975234  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "5                 0.431012  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "6                 0.780169  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7                 0.974404  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8                 0.926530  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "...                    ...                                                ...   \n",
       "10201             0.961293  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10202             0.662527  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10203             0.947900  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10204             0.968241  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10205             0.923345  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "       decision1_optimal  decision1_imitation  \\\n",
       "3               0.014232             0.046543   \n",
       "5               0.002766             0.740672   \n",
       "6               0.001055             0.552226   \n",
       "7               0.005392             0.038135   \n",
       "8               0.268609             0.013533   \n",
       "...                  ...                  ...   \n",
       "10201           0.004282             0.040797   \n",
       "10202           0.006583             0.582402   \n",
       "10203           0.013465             0.080935   \n",
       "10204           0.020028             0.021384   \n",
       "10205           0.016278             0.155170   \n",
       "\n",
       "                                                 inputs1  decision2_optimal  \\\n",
       "3      [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...           0.238878   \n",
       "5      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.005224   \n",
       "6      [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...           0.001892   \n",
       "7      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0.007603   \n",
       "8      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.827465   \n",
       "...                                                  ...                ...   \n",
       "10201  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.028383   \n",
       "10202  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.019196   \n",
       "10203  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.036082   \n",
       "10204  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...           0.019952   \n",
       "10205  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0.082418   \n",
       "\n",
       "       decision2_imitation                                            inputs2  \\\n",
       "3                 0.009288  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "5                 0.286323  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "6                 0.817031  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "7                 0.167392  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8                 0.001125  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "...                    ...                                                ...   \n",
       "10201             0.076898  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10202             0.064902  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10203             0.026800  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10204             0.097314  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "10205             0.040294  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                      pca_state0                 pca_state1  \\\n",
       "3       [-0.48599857, -0.506752]  [-0.45917124, -0.4639411]   \n",
       "5       [1.2279854, -0.26386157]  [1.0977091, -0.046363775]   \n",
       "6        [1.6808392, -0.6142941]   [1.5127486, -0.60941494]   \n",
       "7      [0.22417444, -0.59941596]  [0.31850857, -0.85750437]   \n",
       "8       [-1.7481053, 0.70407444]    [-1.7431976, 0.8784005]   \n",
       "...                          ...                        ...   \n",
       "10201    [0.1314283, -0.6250571]   [0.24043086, -0.6651105]   \n",
       "10202   [0.6399169, -0.50798887]  [0.61837995, -0.21105418]   \n",
       "10203   [0.05236329, 0.14106381]  [0.053728197, 0.05760461]   \n",
       "10204  [-0.09948434, 0.94213074]   [0.039646197, 0.9279005]   \n",
       "10205      [0.1605965, 0.573429]    [0.23535553, 0.6372578]   \n",
       "\n",
       "                       pca_state2  \n",
       "3        [0.49081385, -0.4692875]  \n",
       "5         [-1.0250679, 0.3060964]  \n",
       "6       [-1.4664419, -0.11814983]  \n",
       "7        [-0.6068724, -0.6818945]  \n",
       "8           [2.068149, 0.6000858]  \n",
       "...                           ...  \n",
       "10201  [-0.37348026, -0.41426834]  \n",
       "10202  [-0.59265363, 0.016543038]  \n",
       "10203  [-0.108006194, 0.17732997]  \n",
       "10204    [-0.33775666, 0.8870283]  \n",
       "10205    [-0.1023707, 0.53079444]  \n",
       "\n",
       "[536 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def get_embedding_pcas(dataset,decision_model,embeddings=None,components=2):\n",
    "    if embeddings is None:\n",
    "        embeddings, _, _, _ = get_embeddings(dataset,decision_model,states=[0,1,2])\n",
    "    pcas = [PCA(components,whiten=True).fit(e) for e in embeddings]\n",
    "    return pcas\n",
    "\n",
    "def get_embedding_df(dataset,dm,states=[0,1,2],pcas=None,**kwargs):\n",
    "    embeddings, decisions_opt, decisions_im, embedding_inputs = get_embeddings(dataset,dm,\n",
    "                                                                                      states=states,**kwargs)\n",
    "    values = {'embeddings_state'+str(i): [np.array(ee) for ee in e] for i,e in zip(states,embeddings)}\n",
    "    newdf = pd.DataFrame(values,index=dataset.processed_df.index.values)\n",
    "    for ii in states:\n",
    "        opt = decisions_opt[:,ii]\n",
    "        im = decisions_im[:,ii]\n",
    "        newdf['decision'+str(ii)+\"_optimal\"] = opt\n",
    "        newdf['decision'+str(ii)+'_imitation'] = im\n",
    "        newdf['inputs'+str(ii)] = [np.array(ee) for ee in embedding_inputs[ii]]\n",
    "    \n",
    "    if pcas is None:\n",
    "        pcas = get_embedding_pcas(dataset,dm,embeddings=embeddings)\n",
    "    reductions = [ipca.fit_transform(e) for ipca,e in zip(pcas,embeddings)]\n",
    "    for state,r in enumerate(reductions):\n",
    "        newdf['pca_state'+str(state)] = [np.array(rr) for rr in r]\n",
    "    return newdf\n",
    "\n",
    "embedding_df = get_embedding_df(data,decision_model)\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77caefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7] ['hpv', 'age']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"3\": {\"hpv\": 1, \"age\": 55.97}, \"7\": {\"hpv\": 1, \"age\": 72.32}}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import simplejson\n",
    "import pickle\n",
    "def np_converter(obj):\n",
    "    #converts stuff to vanilla python  for json since it gives an error with np.int64 and arrays\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return np.round(float(obj),3)\n",
    "    elif isinstance(obj, float):\n",
    "        return round(float(obj),3)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, datetime.datetime) or isinstance(obj, datetime.time):\n",
    "        return obj.__str__()\n",
    "    print('np_converter cant encode obj of type', obj,type(obj))\n",
    "    return obj\n",
    "\n",
    "def jsonify_np_dict(d):\n",
    "    return simplejson.dumps(d,default=np_converter)\n",
    "\n",
    "\n",
    "def get_dataset_jsons(dataset,ids=None,fields=None):\n",
    "    df = dataset.processed_df.copy()\n",
    "    print(ids,fields)\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        df = df.loc[ids]\n",
    "    if fields is not None and len(fields) > 0:\n",
    "        df = df[fields]\n",
    "    pdict = df.to_dict(orient='index')\n",
    "    return jsonify_np_dict(pdict)\n",
    "\n",
    "\n",
    "get_dataset_jsons(data,fields=['hpv','age'],ids=[3,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "682381e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "decision0_optimal\n",
      "decision0_imitation\n",
      "inputs0\n",
      "decision1_optimal\n",
      "decision1_imitation\n",
      "inputs1\n",
      "decision2_optimal\n",
      "decision2_imitation\n",
      "inputs2\n",
      "pca_state0\n",
      "pca_state1\n",
      "pca_state2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings_state0', 'embeddings_state1', 'embeddings_state2', 'decision0_optimal', 'decision0_imitation', 'decision1_optimal', 'decision1_imitation', 'decision2_optimal', 'decision2_imitation', 'pca_state0', 'pca_state1', 'pca_state2'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding_json(dataset,decisionmodel,embed_df = None,precision=4,ids=None,fields=None):\n",
    "    if embed_df is None:\n",
    "        embed_df = get_embedding_df(dataset,decisionmodel)\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        embed_df = embed_df.loc[ids]\n",
    "        \n",
    "    for c in embed_df.columns:\n",
    "        if 'embed' in c:\n",
    "            embed_df[c] = embed_df[c].apply(lambda x: [round(float(xx),precision) for xx in x.astype(float)])\n",
    "    to_keep = [c for c in embed_df if 'input' not in c]\n",
    "    if fields is not None and len(fields) > 0:\n",
    "        to_keep = [k for k in to_keep if k in fields]\n",
    "    \n",
    "    edict = embed_df[to_keep].to_dict(orient='index')\n",
    "    return edict\n",
    "    return jsonify_np_dict(edict)\n",
    "\n",
    "get_embedding_json(data,decision_model,ids=[3,7])[3].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "846ee110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot_embedding(dataset,dmodel,decision=0,ax=None,use_optimal=False):\n",
    "#     if ax is None:\n",
    "#         fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "#     embeddings, decisions_optimal, decisions_imitation,inputs = get_embeddings(dataset,dmodel,states=[decision])\n",
    "#     pca = PCA(2)\n",
    "#     coords = pca.fit_transform(embeddings[0])\n",
    "#     marks = data.get_state('decision'+ str(decision+1))\n",
    "#     if use_optimal:\n",
    "#         predicted = (decisions_optimal > .5).ravel().astype(int)\n",
    "#     else:\n",
    "#         predicted = (decisions_imitation > .5).ravel().astype(int)\n",
    "#     size = [400 for i in marks]\n",
    "#     sns.scatterplot(data=coords,\n",
    "#                     x=coords[:,0],\n",
    "#                     y=coords[:,1],\n",
    "#                     style=marks,\n",
    "#                     hue=predicted,\n",
    "#                     ax=ax,\n",
    "#                     palette='colorblind',\n",
    "#                     sizes=size,\n",
    "#                    )\n",
    "# plot_embedding(data,decision_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcd3c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axes = plt.subplots(2,3,figsize=(30,20))\n",
    "# for ii,opt in enumerate([True,False]):\n",
    "#     for i in range(3):\n",
    "#         plot_embedding(data,decision_model,use_optimal=opt,decision=i,ax=axes[ii,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6baa4b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1A_contra': 0,\n",
       "  '1A_ipsi': 0,\n",
       "  '1B_contra': 0,\n",
       "  '1B_ipsi': 0,\n",
       "  '2A_contra': 0,\n",
       "  '2A_ipsi': 0,\n",
       "  '2B_contra': 0,\n",
       "  '2B_ipsi': 0,\n",
       "  '3_contra': 0,\n",
       "  '3_ipsi': 0,\n",
       "  '4_contra': 0,\n",
       "  '4_ipsi': 0,\n",
       "  '5A_contra': 0,\n",
       "  '5A_ipsi': 0,\n",
       "  '5B_contra': 0,\n",
       "  '5B_ipsi': 0,\n",
       "  '6_contra': 0,\n",
       "  '6_ipsi': 0,\n",
       "  'AJCC_1': 0.0,\n",
       "  'AJCC_2': 0.0,\n",
       "  'AJCC_3': 0.0,\n",
       "  'AJCC_4': 0.0,\n",
       "  'African American/Black': 0.0,\n",
       "  'Asian': 0.0,\n",
       "  'Aspiration rate Pre-therapy': 0.0,\n",
       "  'DLT_Infection (Pneumonia)': 0.0,\n",
       "  'DLT_Infection (Pneumonia) 2': 0.0,\n",
       "  'DLT_Nephrological': 0.0,\n",
       "  'DLT_Nephrological 2': 0.0,\n",
       "  'DLT_Vascular': 0.0,\n",
       "  'DLT_Vascular 2': 0.0,\n",
       "  'Hispanic/Latino': 0.0,\n",
       "  'N-category_0': 0.0,\n",
       "  'N-category_1': 0.0,\n",
       "  'N-category_2': 0.0,\n",
       "  'N-category_3': 0.0,\n",
       "  'Pathological Grade_0': 0.0,\n",
       "  'Pathological Grade_1': 0.0,\n",
       "  'Pathological Grade_2': 0.0,\n",
       "  'Pathological Grade_3': 1.0,\n",
       "  'Pathological Grade_4': 0.0,\n",
       "  'RPLN_contra': 0,\n",
       "  'RPLN_ipsi': 0,\n",
       "  'T-category_1': 0.0,\n",
       "  'T-category_2': 0.0,\n",
       "  'T-category_3': 0.0,\n",
       "  'T-category_4': 0.0,\n",
       "  'White/Caucasion': 1.0,\n",
       "  'age': 58.155,\n",
       "  'bilateral': 0.0,\n",
       "  'dose_fraction': 2.12,\n",
       "  'gender': 1.0,\n",
       "  'hpv': 1.0,\n",
       "  'packs_per_year': 3.0,\n",
       "  'subsite_BOT': 0.0,\n",
       "  'subsite_GPS': 0.0,\n",
       "  'subsite_NOS': 0.0,\n",
       "  'subsite_Soft palate': 0.0,\n",
       "  'subsite_Tonsil': 0.0,\n",
       "  'total_dose': 70.0}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_input(dataset,state=0,ids=None):\n",
    "    output = get_decision_input(dataset,state=state,ids=ids)\n",
    "    output = [o.median().to_dict() for o in output]\n",
    "    output = [{k: (0 if '_ipsi' in k or '_contra' in k else v) for k,v in output[0].items()}]\n",
    "    return output\n",
    "\n",
    "get_default_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00e1c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hpv': 1.0,\n",
       " 'age': 58.155,\n",
       " 'packs_per_year': 3.0,\n",
       " 'gender': 1.0,\n",
       " 'Aspiration rate Pre-therapy': 0.0,\n",
       " 'total_dose': 70.0,\n",
       " 'dose_fraction': 2.12,\n",
       " 'OS (Calculated)': 76.72,\n",
       " 'Locoregional control (Time)': 74.315,\n",
       " 'FDM (months)': 75.765,\n",
       " 'time_to_event': 57.22,\n",
       " 'Overall Survival (1=alive, 0=dead)': 1.0,\n",
       " 'LRC': 1.0,\n",
       " 'DC': 1.0,\n",
       " 'bilateral': 0.0,\n",
       " 'White/Caucasion': 1.0,\n",
       " 'Hispanic/Latino': 0.0,\n",
       " 'African American/Black': 0.0,\n",
       " 'Asian': 0.0,\n",
       " 'cc_none': 0,\n",
       " 'cc_platinum': 0,\n",
       " 'cc_cetuximab': 0,\n",
       " 'cc_others': 0,\n",
       " 'no_dose_adjustment': 0,\n",
       " 'dose_modified': 0,\n",
       " 'dose_delayed': 0,\n",
       " 'dose_cancelled': 0,\n",
       " 'dose_delayed_&_modified': 0,\n",
       " 'regiment_modification': 0,\n",
       " 'T-category_1': 0.0,\n",
       " 'T-category_2': 0.0,\n",
       " 'T-category_3': 0.0,\n",
       " 'T-category_4': 0.0,\n",
       " 'N-category_0': 0.0,\n",
       " 'N-category_1': 0.0,\n",
       " 'N-category_2': 0.0,\n",
       " 'N-category_3': 0.0,\n",
       " 'AJCC_1': 0.0,\n",
       " 'AJCC_2': 0.0,\n",
       " 'AJCC_3': 0.0,\n",
       " 'AJCC_4': 0.0,\n",
       " 'Pathological Grade_0': 0.0,\n",
       " 'Pathological Grade_1': 0.0,\n",
       " 'Pathological Grade_2': 0.0,\n",
       " 'Pathological Grade_3': 1.0,\n",
       " 'Pathological Grade_4': 0.0,\n",
       " 'subsite_BOT': 0.0,\n",
       " 'subsite_GPS': 0.0,\n",
       " 'subsite_NOS': 0.0,\n",
       " 'subsite_Soft palate': 0.0,\n",
       " 'subsite_Tonsil': 0.0,\n",
       " 'treatment_CC': 1.0,\n",
       " 'treatment_IC+CC': 0.0,\n",
       " 'treatment_IC+Radiation alone': 0.0,\n",
       " 'treatment_Radiation alone': 0.0,\n",
       " 'DLT_Dermatological': 0.0,\n",
       " 'DLT_Neurological': 1,\n",
       " 'DLT_Gastrointestinal': 0.0,\n",
       " 'DLT_Hematological': 0.0,\n",
       " 'DLT_Nephrological': 0.0,\n",
       " 'DLT_Vascular': 0.0,\n",
       " 'DLT_Infection (Pneumonia)': 0.0,\n",
       " 'DLT_Other': 0.0,\n",
       " 'DLT_Dermatological 2': 0.0,\n",
       " 'DLT_Neurological 2': 0.0,\n",
       " 'DLT_Gastrointestinal 2': 0.0,\n",
       " 'DLT_Hematological 2': 0.0,\n",
       " 'DLT_Nephrological 2': 0.0,\n",
       " 'DLT_Vascular 2': 0.0,\n",
       " 'DLT_Infection (Pneumonia) 2': 0.0,\n",
       " 'DLT_Other 2': 0.0,\n",
       " 'CR Primary': 0,\n",
       " 'PR Primary': 0,\n",
       " 'SD Primary': 0,\n",
       " 'CR Nodal': 0,\n",
       " 'PR Nodal': 0,\n",
       " 'SD Nodal': 0,\n",
       " 'CR Primary 2': 0,\n",
       " 'PR Primary 2': 0,\n",
       " 'SD Primary 2': 0,\n",
       " 'CR Nodal 2': 0,\n",
       " 'PR Nodal 2': 0,\n",
       " 'SD Nodal 2': 0,\n",
       " 'Decision 1 (Induction Chemo) Y/N': 0.0,\n",
       " 'Decision 2 (CC / RT alone)': 1.0,\n",
       " 'Decision 3 Neck Dissection (Y/N)': 0.0,\n",
       " 'Overall Survival (4 Years)': 1.0,\n",
       " 'FT': 0.0,\n",
       " 'Aspiration rate Post-therapy': 0.0,\n",
       " '1A_ipsi': 0.0,\n",
       " '1A_contra': 0.0,\n",
       " '1B_ipsi': 0.0,\n",
       " '1B_contra': 0.0,\n",
       " '2A_ipsi': 1.0,\n",
       " '2A_contra': 0.0,\n",
       " '2B_ipsi': 1.0,\n",
       " '2B_contra': 0.0,\n",
       " '3_ipsi': 0.0,\n",
       " '3_contra': 0.0,\n",
       " '4_ipsi': 0.0,\n",
       " '4_contra': 0.0,\n",
       " '5A_ipsi': 0.0,\n",
       " '5A_contra': 0.0,\n",
       " '5B_ipsi': 0.0,\n",
       " '5B_contra': 0.0,\n",
       " '6_ipsi': 0.0,\n",
       " '6_contra': 0.0,\n",
       " 'RPLN_ipsi': 0.0,\n",
       " 'RPLN_contra': 0.0,\n",
       " 'no_dose_adjustment 2': 0,\n",
       " 'dose_modified 2': 0,\n",
       " 'dose_delayed 2': 0,\n",
       " 'dose_cancelled 2': 0,\n",
       " 'dose_delayed_&_modified 2': 0,\n",
       " 'regiment_modification 2': 0,\n",
       " 'cc_none 2': 0,\n",
       " 'cc_platinum 2': 0,\n",
       " 'cc_cetuximab 2': 0,\n",
       " 'cc_others 2': 0,\n",
       " 'ln_cluster_3': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_patient(dataset,input_dict,zero_transitions=True):\n",
    "    #converts patient input features into data input type\n",
    "    baselines = dataset.processed_df.median().to_dict()\n",
    "    #set all basline transition states to 0 so my lazy way of checking for fixed values works\n",
    "    if zero_transitions:\n",
    "        to_zero = (Const.primary_disease_states \n",
    "            + Const.nodal_disease_states \n",
    "            + list(Const.modification_types.values()) \n",
    "            + list(Const.cc_types.values()))\n",
    "        for k in to_zero:\n",
    "            baselines[k] = 0\n",
    "            baselines[k+' 2'] = 0\n",
    "    for k,v in input_dict.items():\n",
    "        baselines[k] = v\n",
    "    return baselines\n",
    "\n",
    "format_patient(data,{'ln_cluster_3': 1,'DLT_Neurological': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f3859d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,\n",
       "         20.9500,  0.0000,  1.8000,  1.0000,  0.0000, 38.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, 72.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_model_input(dataset,fdict,state=0,ttype=torch.FloatTensor,concat=True,zero_transition_states=True):\n",
    "    fdict = format_patient(dataset,fdict)\n",
    "    order = get_inputkey_order(dataset,state=state)\n",
    "    inputs = [torch.tensor([fdict[k] for k in ordersubset]).type(ttype).view(1,-1) for ordersubset in order]\n",
    "    \n",
    "    #this is assuming the order is baseline, dlt1, dlt2, primary progression, nodal progression, cc type, dose modification\n",
    "    def zeroinput(position):\n",
    "        return torch.zeros(inputs[position].shape).type(ttype)\n",
    "    if zero_transition_states:\n",
    "        if state == 0 or state == 1:\n",
    "            inputs[2] = zeroinput(2)\n",
    "            inputs[5] = zeroinput(5)\n",
    "        if state < 1:\n",
    "            inputs[1] = zeroinput(1)\n",
    "            inputs[3] = zeroinput(3)\n",
    "            inputs[4] = zeroinput(4)\n",
    "            inputs[6] =zeroinput(6)\n",
    "    if concat:\n",
    "        inputs = torch.cat(inputs,axis=1)\n",
    "    #currently at this line its baseline, dlt1, dlt2, pd, nd, cc, modifications\n",
    "    return inputs\n",
    "# decision_model(*dict_to_model_input(data,data.processed_df.iloc[7].to_dict(),state=0),position=0)\n",
    "dict_to_model_input(data,data.processed_df.loc[5].to_dict(),state=1,concat=True,zero_transition_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "389fa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_df(dataset,state=0):\n",
    "#     df = dataset.processed_df.copy()\n",
    "#     order = get_inputkey_order(dataset,state=state)\n",
    "#     inputs = [df[o] for o in order]\n",
    "#     df = pd.concat(inputs,axis=1)\n",
    "# input_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9426800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,\n",
       "         20.9500,  0.0000,  1.8000,  1.0000,  0.0000, 38.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, 72.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_to_model_input(data,data.processed_df.loc[5].to_dict(),state=1,concat=True,zero_transition_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4683c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "4467690121.803214\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "25093981.87168319\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "22948642.370797876\n"
     ]
    }
   ],
   "source": [
    "def calculateMahalanobis(y=None, data=None, cov=None):\n",
    "  \n",
    "    y_mu = y - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.T)\n",
    "    inv_covmat = np.linalg.pinv(cov)\n",
    "    left = np.dot(y_mu, inv_covmat)\n",
    "    mahal = np.dot(left, y_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "def get_neighbors_and_embedding(pdata,dataset,decisionmodel,embedding_df=None,state=2,max_neighbors=10,pcas=None):\n",
    "    decisionmodel.eval()\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "        \n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    \n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    inputs = dict_to_model_input(dataset,pdata,state=state,zero_transition_states=False).to(decisionmodel.get_device())\n",
    "    \n",
    "    \n",
    "    embedding = decisionmodel.get_embedding(inputs,position=state,use_saved_memory=True)[0].view(1,-1).cpu().detach().numpy()\n",
    "\n",
    "    mDist = calculateMahalanobis(embedding,embeddings)\n",
    "    dists = cdist(embedding,embeddings).ravel()\n",
    "    \n",
    "    max_neighbors = min(len(dists),max_neighbors)\n",
    "    min_positions = np.argsort(dists)[:max_neighbors]\n",
    "    neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "    min_dists = dists[min_positions]\n",
    "    similarities = 1/(1+min_dists)\n",
    "    # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "    if pcas is not None:\n",
    "        pPca = pcas[state].transform(embedding)[0]\n",
    "        return neighbor_ids, similarities,embedding[0],pPca, mDist[0]\n",
    "    return neighbor_ids, similarities, embedding[0], mDist[0]\n",
    "\n",
    "for state in [0,1,2]:\n",
    "    print(get_neighbors_and_embedding(test_patient,data,decision_model,state=state)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(dataset,states=[0,1,2],decimals=2):\n",
    "    inputs = []\n",
    "    for i,state in enumerate(states):\n",
    "        x = get_decision_input(dataset,state=state)\n",
    "        inputs.append(np.concatenate([xx.values for xx in x],axis=1))\n",
    "    return inputs\n",
    "\n",
    "def get_neighbors_and_embedding(pdata,dataset,decisionmodel,embedding_df=None,state=2,max_neighbors=10,pcas=None):\n",
    "    decisionmodel.eval()\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "        \n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    \n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    inputs = dict_to_model_input(dataset,pdata,state=state,zero_transition_states=False).to(decisionmodel.get_device())\n",
    "    \n",
    "    \n",
    "    embedding = decisionmodel.get_embedding(inputs,position=state,use_saved_memory=True)[0].view(1,-1).cpu().detach().numpy()\n",
    "\n",
    "    mDist = calculateMahalanobis(embedding,embeddings)\n",
    "    dists = cdist(embedding,embeddings).ravel()\n",
    "    \n",
    "    max_neighbors = min(len(dists),max_neighbors)\n",
    "    min_positions = np.argsort(dists)[:max_neighbors]\n",
    "    neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "    min_dists = dists[min_positions]\n",
    "    similarities = 1/(1+min_dists)\n",
    "    # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "    if pcas is not None:\n",
    "        pPca = pcas[state].transform(embedding)[0]\n",
    "        return neighbor_ids, similarities,embedding[0],pPca, mDist[0]\n",
    "    return neighbor_ids, similarities, embedding[0], mDist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "238e68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4482766483.702977, 25554765.7824055, 22151186.210548468]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_mahalanobis_distances(dataset=None,decision_model=None,state=1,embedding_df=None):\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decision_model)\n",
    "    embeddings = np.stack(embedding_df['embeddings_state'+str(state)].values)\n",
    "    dists =calculateMahalanobis(embeddings,embeddings) \n",
    "    return np.array(dists)\n",
    "\n",
    "def get_mdist_outlier_threshold(dataset=None,decision_model=None,embedding_df=None):\n",
    "    return [m.mean() + 2*m.std() for m in [test_mahalanobis_distances(dataset,decision_model,s,embedding_df) for s in [0,1,2]]]\n",
    "\n",
    "get_mdist_outlier_threshold(data,decision_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61f3741d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.48251408e+09, 4.48242751e+09, 4.48251394e+09, 4.48251384e+09,\n",
       "        4.48247881e+09, 4.48300997e+09, 4.48239666e+09, 4.48249018e+09,\n",
       "        4.48254010e+09, 4.48253659e+09, 4.48259716e+09, 4.48249894e+09,\n",
       "        4.48247624e+09, 4.48231756e+09, 4.48249712e+09, 4.48245912e+09,\n",
       "        4.48255362e+09, 4.48245595e+09, 4.48247782e+09, 4.48251034e+09,\n",
       "        4.48190730e+09, 4.48249038e+09, 4.48249884e+09, 4.48248053e+09,\n",
       "        4.48248426e+09, 4.48252651e+09, 4.48257471e+09, 4.48283273e+09,\n",
       "        4.48250854e+09, 4.48249348e+09, 4.48249858e+09, 4.48249767e+09,\n",
       "        4.48251721e+09, 4.48245557e+09, 4.48249279e+09, 4.48245415e+09,\n",
       "        4.48243367e+09, 4.48250922e+09, 4.48249841e+09, 4.48250012e+09,\n",
       "        4.48249710e+09, 4.48249891e+09, 4.48250190e+09, 4.48248290e+09,\n",
       "        4.48249657e+09, 4.48240869e+09, 4.48240992e+09, 4.48252387e+09,\n",
       "        4.48251603e+09, 4.48253339e+09, 4.48249901e+09, 4.48240337e+09,\n",
       "        4.48240398e+09, 4.48249836e+09, 4.48243531e+09, 4.48242895e+09,\n",
       "        4.48240358e+09, 4.48246281e+09, 4.48246530e+09, 4.48254574e+09,\n",
       "        4.48250234e+09, 4.48250986e+09, 4.48245523e+09, 4.48257733e+09,\n",
       "        4.48239061e+09, 4.48251182e+09, 4.48253925e+09, 4.48248431e+09,\n",
       "        4.48248245e+09, 4.48254016e+09, 4.48251498e+09, 4.48251004e+09,\n",
       "        4.48251745e+09, 4.48241965e+09, 4.48240654e+09, 4.48247951e+09,\n",
       "        4.48316777e+09, 4.48262556e+09, 4.48250398e+09, 4.48257895e+09,\n",
       "        4.48253581e+09, 4.48260222e+09, 4.48241383e+09, 4.48256460e+09,\n",
       "        4.48230753e+09, 4.48238656e+09, 4.48254332e+09, 4.48253504e+09,\n",
       "        4.48252493e+09, 4.48261151e+09, 4.48245815e+09, 4.48258782e+09,\n",
       "        4.48249471e+09, 4.48221151e+09, 4.48254281e+09, 4.48243043e+09,\n",
       "        4.48256438e+09, 4.48252052e+09, 4.48321604e+09, 4.48236516e+09,\n",
       "        4.48252045e+09, 4.48251190e+09, 4.48250875e+09, 4.48250515e+09,\n",
       "        4.48247807e+09, 4.48249282e+09, 4.48242771e+09, 4.48189204e+09,\n",
       "        4.48248869e+09, 4.48249287e+09, 4.48264857e+09, 4.48247565e+09,\n",
       "        4.48257979e+09, 4.48250152e+09, 4.48230496e+09, 4.48254700e+09,\n",
       "        4.48252282e+09, 4.48255944e+09, 4.48243387e+09, 4.48230408e+09,\n",
       "        4.48270534e+09, 4.48295988e+09, 4.48253392e+09, 4.48254800e+09,\n",
       "        4.48248774e+09, 4.48245924e+09, 4.48255909e+09, 4.48244130e+09,\n",
       "        4.48231685e+09, 4.48232295e+09, 4.48261335e+09, 4.48245289e+09,\n",
       "        4.48251129e+09, 4.48243468e+09, 4.48260619e+09, 4.48244573e+09,\n",
       "        4.48256950e+09, 4.48251309e+09, 4.48247473e+09, 4.48247383e+09,\n",
       "        4.48250764e+09, 4.48268134e+09, 4.48256871e+09, 4.48254903e+09,\n",
       "        4.48244682e+09, 4.48250272e+09, 4.48246454e+09, 4.48246768e+09,\n",
       "        4.48253335e+09, 4.48278150e+09, 4.48249592e+09, 4.48250572e+09,\n",
       "        4.48245600e+09, 4.48257741e+09, 4.48258455e+09, 4.48237205e+09,\n",
       "        4.48245486e+09, 4.48255433e+09, 4.48249819e+09, 4.48245291e+09,\n",
       "        4.48247338e+09, 4.48223073e+09, 4.48255003e+09, 4.48255511e+09,\n",
       "        4.48251231e+09, 4.48251753e+09, 4.48205707e+09, 4.48248709e+09,\n",
       "        4.48251330e+09, 4.48250292e+09, 4.48253781e+09, 4.48245789e+09,\n",
       "        4.48243306e+09, 4.48265391e+09, 4.48268818e+09, 4.48252694e+09,\n",
       "        4.48224779e+09, 4.48247775e+09, 4.48262766e+09, 4.48252403e+09,\n",
       "        4.48251003e+09, 4.48244489e+09, 4.48251360e+09, 4.48260204e+09,\n",
       "        4.48239565e+09, 4.48244656e+09, 4.48218155e+09, 4.48243631e+09,\n",
       "        4.48254770e+09, 4.48262881e+09, 4.48260175e+09, 4.48244960e+09,\n",
       "        4.48251658e+09, 4.48245871e+09, 4.48259365e+09, 4.48259412e+09,\n",
       "        4.48256160e+09, 4.48230203e+09, 4.48263971e+09, 4.48246479e+09,\n",
       "        4.48239882e+09, 4.48254994e+09, 4.48207616e+09, 4.48248282e+09,\n",
       "        4.48245838e+09, 4.48252501e+09, 4.48226591e+09, 4.48251189e+09,\n",
       "        4.48259345e+09, 4.48248405e+09, 4.48219655e+09, 4.48203397e+09,\n",
       "        4.48232916e+09, 4.48253826e+09, 4.48248521e+09, 4.48253154e+09,\n",
       "        4.48252108e+09, 4.48246891e+09, 4.48246500e+09, 4.48243885e+09,\n",
       "        4.48253502e+09, 4.48248765e+09, 4.48249844e+09, 4.48250273e+09,\n",
       "        4.48264244e+09, 4.48241545e+09, 4.48243918e+09, 4.48249640e+09,\n",
       "        4.48246033e+09, 4.48256295e+09, 4.48181830e+09, 4.48249826e+09,\n",
       "        4.48263934e+09, 4.48249407e+09, 4.48261641e+09, 4.48244755e+09,\n",
       "        4.48243111e+09, 4.48261914e+09, 4.48251743e+09, 4.48244389e+09,\n",
       "        4.48241863e+09, 4.48254995e+09, 4.48265076e+09, 4.48251721e+09,\n",
       "        4.48250119e+09, 4.48247818e+09, 4.48236102e+09, 4.48254361e+09,\n",
       "        4.48241480e+09, 4.48238766e+09, 4.48232230e+09, 4.48244670e+09,\n",
       "        4.48235409e+09, 4.48247391e+09, 4.48240734e+09, 4.48243863e+09,\n",
       "        4.48257795e+09, 4.48268526e+09, 4.48250213e+09, 4.48254371e+09,\n",
       "        4.48239105e+09, 4.48226803e+09, 4.48248568e+09, 4.48255185e+09,\n",
       "        4.48269378e+09, 4.48244363e+09, 4.48251532e+09, 4.48249365e+09,\n",
       "        4.48252864e+09, 4.48246829e+09, 4.48246618e+09, 4.48247835e+09,\n",
       "        4.48278545e+09, 4.48280499e+09, 4.48254242e+09, 4.48240888e+09,\n",
       "        4.48222228e+09, 4.48250698e+09, 4.48250069e+09, 4.48246470e+09,\n",
       "        4.48248769e+09, 4.48248089e+09, 4.48244304e+09, 4.48263246e+09,\n",
       "        4.48250381e+09, 4.48252863e+09, 4.48257847e+09, 4.48253056e+09,\n",
       "        4.48240117e+09, 4.48249874e+09, 4.48223210e+09, 4.48244377e+09,\n",
       "        4.48261454e+09, 4.48252412e+09, 4.48235225e+09, 4.48260183e+09,\n",
       "        4.48224038e+09, 4.48248878e+09, 4.48231879e+09, 4.48245203e+09,\n",
       "        4.48245211e+09, 4.48262980e+09, 4.48256807e+09, 4.48251259e+09,\n",
       "        4.48255123e+09, 4.48254361e+09, 4.48249759e+09, 4.48246497e+09,\n",
       "        4.48249096e+09, 4.48242131e+09, 4.48229002e+09, 4.48244417e+09,\n",
       "        4.48252844e+09, 4.48265916e+09, 4.48251053e+09, 4.48261499e+09,\n",
       "        4.48262772e+09, 4.48284984e+09, 4.48248394e+09, 4.48251352e+09,\n",
       "        4.48244853e+09, 4.48241005e+09, 4.48241175e+09, 4.48275027e+09,\n",
       "        4.48239689e+09, 4.48250226e+09, 4.48249204e+09, 4.48251890e+09,\n",
       "        4.48244642e+09, 4.48249712e+09, 4.48264406e+09, 4.48247626e+09,\n",
       "        4.48253243e+09, 4.48243138e+09, 4.48260678e+09, 4.48250608e+09,\n",
       "        4.48259790e+09, 4.48252782e+09, 4.48243557e+09, 4.48259148e+09,\n",
       "        4.48251775e+09, 4.48246876e+09, 4.48251340e+09, 4.48253508e+09,\n",
       "        4.48229116e+09, 4.48250036e+09, 4.48251652e+09, 4.48247261e+09,\n",
       "        4.48251504e+09, 4.48242003e+09, 4.48255109e+09, 4.48249260e+09,\n",
       "        4.48241499e+09, 4.48253215e+09, 4.48249153e+09, 4.48249785e+09,\n",
       "        4.48241230e+09, 4.48245248e+09, 4.48250825e+09, 4.48255663e+09,\n",
       "        4.48294327e+09, 4.48244694e+09, 4.48243772e+09, 4.48247610e+09,\n",
       "        4.48246939e+09, 4.48229702e+09, 4.48249191e+09, 4.48250077e+09,\n",
       "        4.48249449e+09, 4.48260351e+09, 4.48248590e+09, 4.48251067e+09,\n",
       "        4.48243581e+09, 4.48251704e+09, 4.48222050e+09, 4.48235134e+09,\n",
       "        4.48242541e+09, 4.48288978e+09, 4.48245755e+09, 4.48251328e+09,\n",
       "        4.48247023e+09, 4.48245513e+09, 4.48250818e+09, 4.48249920e+09,\n",
       "        4.48240711e+09, 4.48247155e+09, 4.48259316e+09, 4.48257428e+09,\n",
       "        4.48250741e+09, 4.48260888e+09, 4.48252953e+09, 4.48250003e+09,\n",
       "        4.48232746e+09, 4.48240575e+09, 4.48264412e+09, 4.48246624e+09,\n",
       "        4.48243993e+09, 4.48264850e+09, 4.48250177e+09, 4.48223702e+09,\n",
       "        4.48248580e+09, 4.48267970e+09, 4.48251674e+09, 4.48257145e+09,\n",
       "        4.48241933e+09, 4.48253507e+09, 4.48249548e+09, 4.48252412e+09,\n",
       "        4.48247083e+09, 4.48245847e+09, 4.48248541e+09, 4.48315112e+09,\n",
       "        4.48245132e+09, 4.48234585e+09, 4.48244595e+09, 4.48236447e+09,\n",
       "        4.48254372e+09, 4.48249682e+09, 4.48250340e+09, 4.48259391e+09,\n",
       "        4.48245533e+09, 4.48270668e+09, 4.48237504e+09, 4.48253190e+09,\n",
       "        4.48251053e+09, 4.48252878e+09, 4.48253126e+09, 4.48250279e+09,\n",
       "        4.48231561e+09, 4.48272697e+09, 4.48249791e+09, 4.48251053e+09,\n",
       "        4.48261762e+09, 4.48259291e+09, 4.48273659e+09, 4.48256818e+09,\n",
       "        4.48257001e+09, 4.48251924e+09, 4.48262843e+09, 4.48225935e+09,\n",
       "        4.48253139e+09, 4.48236386e+09, 4.48278609e+09, 4.48222162e+09,\n",
       "        4.48251561e+09, 4.48254705e+09, 4.48267532e+09, 4.48294155e+09,\n",
       "        4.48246193e+09, 4.48250266e+09, 4.48277330e+09, 4.48231753e+09,\n",
       "        4.48256061e+09, 4.48256152e+09, 4.48246214e+09, 4.48249780e+09,\n",
       "        4.48229841e+09, 4.48252518e+09, 4.48249218e+09, 4.48240711e+09,\n",
       "        4.48247076e+09, 4.48248145e+09, 4.48250653e+09, 4.48243723e+09,\n",
       "        4.48243637e+09, 4.48250960e+09, 4.48240923e+09, 4.48255618e+09,\n",
       "        4.48247939e+09, 4.48250693e+09, 4.48242642e+09, 4.48253299e+09,\n",
       "        4.48253748e+09, 4.48256006e+09, 4.48244089e+09, 4.48253655e+09,\n",
       "        4.48255927e+09, 4.48247947e+09, 4.48220201e+09, 4.48245513e+09,\n",
       "        4.48259982e+09, 4.48243276e+09, 4.48256560e+09, 4.48259446e+09,\n",
       "        4.48269888e+09, 4.48267501e+09, 4.48251976e+09, 4.48267374e+09,\n",
       "        4.48247208e+09, 4.48249807e+09, 4.48228623e+09, 4.48267747e+09,\n",
       "        4.48250812e+09, 4.48258768e+09, 4.48273436e+09, 4.48250511e+09,\n",
       "        4.48255709e+09, 4.48254380e+09, 4.48240894e+09, 4.48253132e+09,\n",
       "        4.48268491e+09, 4.48264262e+09, 4.48229968e+09, 4.48255254e+09,\n",
       "        4.48257801e+09, 4.48227024e+09, 4.48244364e+09, 4.48244436e+09,\n",
       "        4.48248181e+09, 4.48277871e+09, 4.48256985e+09, 4.48246611e+09,\n",
       "        4.48256017e+09, 4.48234607e+09, 4.48248665e+09, 4.48244060e+09,\n",
       "        4.48260578e+09, 4.48263259e+09, 4.48246716e+09, 4.48259000e+09,\n",
       "        4.48193366e+09, 4.48257241e+09, 4.48238637e+09, 4.48250526e+09,\n",
       "        4.48244874e+09, 4.48271916e+09, 4.48254831e+09, 4.48238865e+09,\n",
       "        4.48250346e+09, 4.48253863e+09, 4.48259928e+09, 4.48249789e+09,\n",
       "        4.48244408e+09, 4.48263086e+09, 4.48246665e+09, 4.48244644e+09]),\n",
       " array([25530353.76298439, 25536472.58123145, 25537084.68506677,\n",
       "        25538395.69010069, 25530458.60720142, 25538150.77093805,\n",
       "        25531390.65630175, 25536108.80091579, 25537643.45835062,\n",
       "        25523574.54171579, 25524347.99327359, 25534611.29765147,\n",
       "        25540037.68539548, 25534824.45582694, 25528397.6920306 ,\n",
       "        25533223.30724204, 25540242.54261101, 25533446.40029135,\n",
       "        25522355.19531247, 25529263.15607158, 25509044.78246705,\n",
       "        25535670.57672882, 25534289.76515421, 25536399.35372871,\n",
       "        25520992.32414484, 25535760.14267203, 25549465.61344467,\n",
       "        25549088.91402547, 25532886.90978489, 25531190.2759686 ,\n",
       "        25533821.23307455, 25533789.38228335, 25532350.37317832,\n",
       "        25523452.69982263, 25532917.92063553, 25536690.54848014,\n",
       "        25540192.60947923, 25530890.16461368, 25534067.76794497,\n",
       "        25532792.10810624, 25533756.10570815, 25534704.58349017,\n",
       "        25529288.84684266, 25535080.67241971, 25540085.82415745,\n",
       "        25532367.56182291, 25514684.7512561 , 25535581.10169257,\n",
       "        25533899.18683537, 25529463.69012655, 25534299.26913578,\n",
       "        25530895.24516124, 25523253.88237337, 25534292.54887225,\n",
       "        25539302.39569302, 25528487.08298687, 25518087.98715249,\n",
       "        25540058.04775906, 25531825.59855352, 25531816.14621912,\n",
       "        25534538.63544226, 25528609.55993536, 25537633.21656811,\n",
       "        25538195.47942571, 25521769.00024846, 25538584.99213465,\n",
       "        25543528.13261367, 25538191.42548338, 25531344.79690897,\n",
       "        25530060.58900213, 25533851.22344795, 25533106.30953405,\n",
       "        25539199.82532394, 25537363.49905288, 25530835.55270594,\n",
       "        25539650.25444485, 25526605.59259509, 25543798.90874621,\n",
       "        25537405.60713767, 25525457.78038639, 25538223.95974022,\n",
       "        25523018.19715163, 25545602.0576867 , 25539556.87947485,\n",
       "        25545063.74565352, 25534564.63927928, 25538001.5126405 ,\n",
       "        25535998.85678406, 25539139.09262967, 25533932.33704931,\n",
       "        25531591.8186201 , 25546637.08942785, 25536213.04361203,\n",
       "        25559047.86690772, 25538877.62094468, 25541582.57462268,\n",
       "        25536763.49615434, 25531868.45477444, 25510855.64024626,\n",
       "        25529273.43005254, 25531651.73865737, 25536288.51098702,\n",
       "        25531305.38374272, 25535067.54740515, 25527480.93037611,\n",
       "        25529680.71656675, 25548188.91262993, 25547028.35871513,\n",
       "        25529717.4038389 , 25530877.92648686, 25520564.69043997,\n",
       "        25533856.73509413, 25543015.10105834, 25534288.43601802,\n",
       "        25531457.47091706, 25528868.61142271, 25534755.80390218,\n",
       "        25540096.72073754, 25534062.5799436 , 25546079.7078133 ,\n",
       "        25535259.63371693, 25538654.4363372 , 25531418.06876323,\n",
       "        25533161.56641696, 25536263.21714435, 25541081.74417075,\n",
       "        25535625.67392982, 25529426.88539938, 25532943.01966584,\n",
       "        25550564.11601348, 25536359.43850427, 25536080.04439019,\n",
       "        25538750.92794098, 25539162.89815659, 25524249.75139676,\n",
       "        25531152.90286512, 25535188.22129171, 25551919.59632188,\n",
       "        25530772.5543235 , 25535886.9568276 , 25534467.29387357,\n",
       "        25481696.41868979, 25535768.29468604, 25541274.39927138,\n",
       "        25553518.93750895, 25538853.11865338, 25530051.81794111,\n",
       "        25537792.51759905, 25535004.62432649, 25534936.71360016,\n",
       "        25526514.70615079, 25533398.06479344, 25538351.61573012,\n",
       "        25538265.09963851, 25543788.65537814, 25537137.84598171,\n",
       "        25528332.17766136, 25535992.97903308, 25530458.75478699,\n",
       "        25528821.40434567, 25538283.14138655, 25499038.93340188,\n",
       "        25520963.55771717, 25529313.05506456, 25533946.10462347,\n",
       "        25528913.98036508, 25532557.49643694, 25534216.7911591 ,\n",
       "        25534917.06788695, 25535801.1019358 , 25528827.56816731,\n",
       "        25536721.46425337, 25532299.13087798, 25573950.62540078,\n",
       "        25553009.36710135, 25536405.44198501, 25530500.58220776,\n",
       "        25528115.454651  , 25527006.10637983, 25513466.41672827,\n",
       "        25529905.35767984, 25530828.48757478, 25545234.71146534,\n",
       "        25534570.900774  , 25540004.06189406, 25542377.29962708,\n",
       "        25587124.40052774, 25545831.55428813, 25536389.87713395,\n",
       "        25541945.51352139, 25543973.19386113, 25524052.49813898,\n",
       "        25542576.25524181, 25533156.39971082, 25563375.94948664,\n",
       "        25542165.44298868, 25540458.12086318, 25516385.57787887,\n",
       "        25542473.51842309, 25544497.4567297 , 25537909.32288294,\n",
       "        25524249.08380707, 25588887.93559048, 25533690.6474501 ,\n",
       "        25538177.39572673, 25532706.72492424, 25536432.14594333,\n",
       "        25533321.97632829, 25568898.1596406 , 25534176.62739507,\n",
       "        25544064.38469607, 25544419.86242707, 25523327.10602288,\n",
       "        25546016.92939533, 25543218.50255291, 25543137.83804312,\n",
       "        25531227.8421882 , 25534262.91534728, 25529055.27549635,\n",
       "        25530647.6469925 , 25533236.01930241, 25533598.65900039,\n",
       "        25522538.50122473, 25539205.80171849, 25539801.87755416,\n",
       "        25540013.71410519, 25531767.86776414, 25537390.84722025,\n",
       "        25534793.57208531, 25536535.39558407, 25511943.73698737,\n",
       "        25533879.37317745, 25568931.82728481, 25533778.16477814,\n",
       "        25487962.77905632, 25536125.61285398, 25544832.4881721 ,\n",
       "        25528086.1697128 , 25527342.97531545, 25539925.23149582,\n",
       "        25533874.86368273, 25536442.74704073, 25512205.70382234,\n",
       "        25536634.4731223 , 25529209.33060417, 25537183.71110711,\n",
       "        25521998.08717258, 25533123.8905777 , 25545117.94331982,\n",
       "        25545137.90383634, 25542369.98722027, 25534285.96649731,\n",
       "        25526687.66492207, 25533180.88962009, 25533315.97887156,\n",
       "        25541374.48595875, 25539627.42437696, 25483407.94066976,\n",
       "        25535336.45513193, 25526694.15967966, 25542062.6507449 ,\n",
       "        25511575.00901314, 25528995.71881273, 25538884.28704513,\n",
       "        25545770.03969706, 25530103.89485293, 25519709.30166283,\n",
       "        25531530.94103334, 25537484.65554458, 25536131.46190702,\n",
       "        25532725.16230793, 25560627.25317299, 25538569.75888129,\n",
       "        25539080.08730946, 25541185.04416471, 25533289.34638975,\n",
       "        25524562.38729037, 25535014.12545738, 25537184.15598527,\n",
       "        25531489.47502187, 25531733.99048847, 25535064.70418099,\n",
       "        25480129.53569914, 25528789.43890806, 25538128.80651213,\n",
       "        25535557.3761711 , 25539876.72986071, 25533588.63986666,\n",
       "        25531772.88016744, 25515443.89831143, 25523798.73789913,\n",
       "        25539844.68036602, 25534946.35491352, 25533863.74475882,\n",
       "        25539299.61822633, 25530534.13834028, 25532605.68552096,\n",
       "        25532574.50925254, 25545574.44001323, 25532907.36415964,\n",
       "        25534935.13143748, 25534180.14913329, 25527186.88996072,\n",
       "        25536991.34160956, 25528270.46604184, 25531562.73057988,\n",
       "        25535428.54227147, 25530813.74121287, 25533034.02554571,\n",
       "        25528982.00577801, 25524564.27803152, 25537323.55741316,\n",
       "        25534864.44679236, 25526417.1143388 , 25537620.23008283,\n",
       "        25537580.14101259, 25510603.69198528, 25550327.14352248,\n",
       "        25533246.53751652, 25531097.15201397, 25536304.06721135,\n",
       "        25541307.491147  , 25532613.13389651, 25548013.85516846,\n",
       "        25531258.01790065, 25531129.23894778, 25535522.49842554,\n",
       "        25536555.4773613 , 25528268.09868623, 25542567.01371291,\n",
       "        25542017.25338521, 25530428.43140122, 25532543.58278304,\n",
       "        25546304.58180828, 25537156.25225938, 25534282.21636297,\n",
       "        25536609.94019507, 25540152.72616771, 25537593.48729748,\n",
       "        25533694.0133406 , 25533214.82736161, 25519846.07911338,\n",
       "        25537996.33939308, 25536600.20666291, 25548243.37981841,\n",
       "        25539395.61651657, 25533485.48551861, 25543160.89148404,\n",
       "        25533093.51129712, 25540414.86508616, 25543744.7415428 ,\n",
       "        25537263.0110699 , 25522739.78303966, 25520563.5341293 ,\n",
       "        25538068.76952948, 25536152.05127833, 25553142.90157583,\n",
       "        25536899.46416915, 25533993.85043344, 25531033.34726455,\n",
       "        25516619.92064765, 25537307.99649826, 25524181.29999887,\n",
       "        25530427.82400451, 25529631.50096205, 25556084.37567836,\n",
       "        25523017.46705503, 25531622.15940487, 25532444.61786608,\n",
       "        25527352.66127057, 25533584.10173366, 25536445.11225202,\n",
       "        25538431.64609855, 25540498.36945212, 25551229.26615903,\n",
       "        25538774.47436684, 25526413.11316143, 25522353.42569467,\n",
       "        25525083.55471006, 25539455.37364275, 25533163.93522199,\n",
       "        25543591.10796754, 25554944.42742293, 25537444.43077729,\n",
       "        25525760.87705588, 25539401.85351104, 25529491.60606579,\n",
       "        25541948.93051022, 25538244.46448151, 25518299.55554962,\n",
       "        25538033.72486445, 25532112.8400294 , 25541371.42980231,\n",
       "        25532489.63280033, 25541438.04885984, 25543447.03613006,\n",
       "        25540224.60788032, 25524567.22852653, 25536720.728084  ,\n",
       "        25556665.05686099, 25532812.79427969, 25530279.87552711,\n",
       "        25531324.29457276, 25521989.42494401, 25534597.41261355,\n",
       "        25532661.27932908, 25528435.46713676, 25527103.66498394,\n",
       "        25540032.06013589, 25530789.35373666, 25528648.89865877,\n",
       "        25529939.21128626, 25525633.88113451, 25524310.24901718,\n",
       "        25540511.31275587, 25537084.38644319, 25533797.72050663,\n",
       "        25531672.16845904, 25535196.38194041, 25540740.23172282,\n",
       "        25533431.13942159, 25537580.35879016, 25529673.25256133,\n",
       "        25532149.93752181, 25538761.48337139, 25550923.40770535,\n",
       "        25533695.50259444, 25542582.82025035, 25537483.59527561,\n",
       "        25546265.41266993, 25538805.89061565, 25541832.25574411,\n",
       "        25531784.9112888 , 25533580.30311826, 25530851.01105183,\n",
       "        25536816.3340968 , 25526141.13967283, 25531967.74195252,\n",
       "        25534986.44744055, 25524615.12469003, 25538670.57278745,\n",
       "        25554313.82215996, 25530320.28428299, 25563218.6050245 ,\n",
       "        25528957.54507245, 25533415.41243795, 25539927.43445017,\n",
       "        25557946.53861973, 25528940.98932637, 25538949.31507979,\n",
       "        25521624.04934373, 25547626.26510823, 25539598.19446723,\n",
       "        25537477.48252532, 25512576.66356069, 25533293.92393709,\n",
       "        25531844.13850725, 25535562.18585347, 25536580.89071582,\n",
       "        25530201.04256869, 25535265.97457212, 25523832.37136156,\n",
       "        25538304.2918872 , 25540775.09618102, 25543589.26310182,\n",
       "        25536536.75053854, 25522975.33772708, 25550484.23099931,\n",
       "        25536124.46938825, 25543345.58884878, 25525977.82162685,\n",
       "        25521858.12746803, 25530709.30769817, 25533999.02200146,\n",
       "        25550851.05111907, 25526818.20680216, 25547114.53224105,\n",
       "        25536701.97722002, 25547486.86597418, 25514973.57306185,\n",
       "        25531396.06910797, 25528016.81827346, 25526245.34423237,\n",
       "        25545112.01813087, 25533727.77452265, 25531543.10583218,\n",
       "        25525643.21519911, 25539818.24104372, 25535420.83682361,\n",
       "        25534709.80321709, 25523642.38835458, 25538144.22221521,\n",
       "        25534220.81593225, 25536270.0398984 , 25531457.82764285,\n",
       "        25542847.59488356, 25543186.5219275 , 25543526.06420736,\n",
       "        25533127.73945058, 25531318.18566097, 25526025.52213935,\n",
       "        25534477.65024909, 25517859.80963355, 25532995.83611639,\n",
       "        25532849.26647235, 25531855.68975699, 25529282.62094427,\n",
       "        25532051.32990247, 25535569.3464062 , 25536890.89101157,\n",
       "        25528862.46354812, 25532808.0790461 , 25523714.79712265,\n",
       "        25526975.63010982, 25535941.82481466, 25534320.41835232,\n",
       "        25534628.61012697, 25556311.1360216 , 25531720.55598249,\n",
       "        25532355.38072622, 25541746.38635263, 25536436.38348825,\n",
       "        25530371.10555813, 25530489.02605223, 25535408.16557495,\n",
       "        25544255.91928762, 25533611.95956359, 25524709.71304687,\n",
       "        25536070.45388529, 25522735.45752119, 25519741.41758182,\n",
       "        25557328.92194017, 25532610.19242816, 25535741.09993907,\n",
       "        25535653.5535655 , 25526742.67895172]),\n",
       " array([22140395.7254497 , 22130157.23409181, 22135533.3083374 ,\n",
       "        22130879.72607602, 22126673.31698579, 22128912.70003971,\n",
       "        22136732.47176265, 22132121.41674431, 22139252.88703094,\n",
       "        22141932.37830627, 22111249.3921249 , 22131644.17265022,\n",
       "        22132519.77630548, 22114808.66564198, 22133012.69023215,\n",
       "        22125804.87479096, 22131922.56508151, 22119924.63296735,\n",
       "        22116804.23808996, 22137664.34003441, 22099102.0869327 ,\n",
       "        22140771.95156949, 22132957.89945803, 22132082.4099373 ,\n",
       "        22128397.47776928, 22133974.96302086, 22130168.59836875,\n",
       "        22125230.5341994 , 22134427.91152186, 22132147.83825326,\n",
       "        22138543.43314786, 22132854.56905752, 22129567.32786648,\n",
       "        22125630.20651409, 22135566.62553531, 22130536.5853578 ,\n",
       "        22130833.50240536, 22140672.8271273 , 22132054.00511564,\n",
       "        22136955.41099808, 22131681.36979369, 22131873.1252827 ,\n",
       "        22143480.19427647, 22138171.42197383, 22133909.23127541,\n",
       "        22124111.40433783, 22126529.6572658 , 22129170.9690873 ,\n",
       "        22129899.18289945, 22133190.45608096, 22132465.78075624,\n",
       "        22127820.04905733, 22147095.6765379 , 22132025.71364672,\n",
       "        22127730.19694877, 22126565.79035265, 22115709.04259614,\n",
       "        22132186.46606572, 22138099.92450269, 22132031.91605079,\n",
       "        22136924.84834995, 22127538.0546345 , 22131735.00203183,\n",
       "        22133981.27915979, 22132404.68702224, 22134424.33644329,\n",
       "        22131403.48076987, 22135165.25377832, 22138792.81958652,\n",
       "        22125775.30536513, 22131773.51399662, 22133619.07329927,\n",
       "        22134008.05725215, 22141753.96393649, 22129068.1823307 ,\n",
       "        22130465.18875519, 22162250.36432135, 22119839.52059662,\n",
       "        22136854.76188948, 22137492.68394148, 22130747.90263601,\n",
       "        22145574.89438393, 22128948.98694349, 22135713.08329945,\n",
       "        22129853.43811784, 22126102.92844169, 22131843.13012648,\n",
       "        22131536.85315976, 22151682.52607641, 22140255.48817752,\n",
       "        22136171.52020916, 22130282.83744003, 22131208.93992219,\n",
       "        22134827.31908227, 22123279.22047459, 22144928.94514352,\n",
       "        22134685.41252863, 22134661.76147163, 22139237.60460377,\n",
       "        22135886.49056505, 22141651.916661  , 22135462.15263627,\n",
       "        22131565.50764375, 22128849.46387718, 22140737.00749967,\n",
       "        22135951.37667808, 22124159.84747705, 22129895.32762189,\n",
       "        22134050.52873665, 22123889.13048875, 22132885.18275666,\n",
       "        22133507.34114523, 22124012.5199723 , 22121709.51694422,\n",
       "        22115322.51773274, 22129987.4722094 , 22129986.44161976,\n",
       "        22138941.43916497, 22129739.38434251, 22126544.16366354,\n",
       "        22117833.00880513, 22122864.44055221, 22125612.51539511,\n",
       "        22131421.41510677, 22127894.99005348, 22130695.54868297,\n",
       "        22132096.38625333, 22142815.6135544 , 22138929.03716821,\n",
       "        22133365.18515147, 22128163.68139207, 22131428.31227123,\n",
       "        22130755.10736619, 22109874.37197601, 22133561.57398255,\n",
       "        22136693.79405008, 22144904.25837188, 22134668.84996199,\n",
       "        22125255.74876199, 22127040.13429215, 22138431.00011255,\n",
       "        22148375.65983926, 22136096.26551471, 22131872.53907658,\n",
       "        22135847.92241066, 22136577.26476138, 22140529.54740224,\n",
       "        22128671.58417299, 22112479.64292078, 22132366.34966724,\n",
       "        22124554.33358692, 22133168.20943149, 22132292.37919555,\n",
       "        22138654.88127409, 22127963.80672451, 22106877.83232876,\n",
       "        22135685.83015044, 22125423.67757151, 22127627.72407823,\n",
       "        22135281.96128557, 22132650.14539962, 22135967.5282591 ,\n",
       "        22135169.10852855, 22133638.12728365, 22142227.13730391,\n",
       "        22128813.49116037, 22123385.00414151, 22137808.00618869,\n",
       "        22131421.25850396, 22132677.91590952, 22136533.39737528,\n",
       "        22137219.08502743, 22117195.85094346, 22120056.94057802,\n",
       "        22122398.6169066 , 22134375.37099239, 22125452.57963971,\n",
       "        22134685.2032829 , 22134448.52114977, 22138570.50111467,\n",
       "        22131870.3217444 , 22128679.1531354 , 22136026.84250917,\n",
       "        22141444.35640895, 22136496.83931264, 22122792.04386216,\n",
       "        22131078.11691855, 22128203.62685846, 22127243.20025778,\n",
       "        22132533.81599234, 22124311.80680383, 22156187.38525805,\n",
       "        22138608.75811327, 22131698.83514692, 22119679.78017601,\n",
       "        22140079.96905823, 22127969.21569385, 22133891.45983027,\n",
       "        22137440.23885223, 22139389.78911012, 22121801.17079277,\n",
       "        22137622.74809152, 22141023.45803434, 22131539.31808962,\n",
       "        22132027.84670893, 22131860.29234076, 22084878.74512757,\n",
       "        22128399.27928356, 22108446.77052346, 22135385.34075334,\n",
       "        22145126.16039855, 22149050.06780042, 22128956.43462797,\n",
       "        22150602.02133429, 22134259.79384755, 22137254.10863498,\n",
       "        22124181.77312023, 22130432.02685713, 22133221.99961625,\n",
       "        22131908.93757258, 22130623.66267897, 22133392.68509982,\n",
       "        22127088.53088567, 22125836.55493469, 22137133.03862486,\n",
       "        22140549.03670092, 22148708.13443162, 22136531.65207027,\n",
       "        22134052.18527579, 22139298.81204609, 22120938.81705038,\n",
       "        22131796.53475111, 22152712.83707861, 22135507.64986696,\n",
       "        22131093.98363147, 22121448.00533954, 22130386.70198895,\n",
       "        22133220.96408216, 22130386.05158389, 22123048.76885491,\n",
       "        22117974.68186904, 22140165.04589976, 22137065.53739049,\n",
       "        22139013.25392773, 22139297.6546756 , 22130553.57639205,\n",
       "        22131889.76043335, 22141956.7584514 , 22123023.960993  ,\n",
       "        22139475.08484106, 22138869.98819505, 22128659.93431411,\n",
       "        22121780.28760656, 22125300.24208514, 22130960.06540764,\n",
       "        22142089.09498869, 22117666.38546365, 22137668.11106693,\n",
       "        22125728.96591049, 22121619.25494314, 22153056.61371925,\n",
       "        22135497.76380511, 22132080.3492395 , 22137201.83479343,\n",
       "        22128374.85917383, 22134496.03893295, 22143607.52278313,\n",
       "        22139997.64750529, 22125055.12265322, 22134399.74494638,\n",
       "        22123743.82750446, 22141996.59836172, 22134741.74316362,\n",
       "        22130553.07657605, 22125494.26640819, 22140955.6236306 ,\n",
       "        22128974.2688801 , 22144617.26867225, 22124361.04041351,\n",
       "        22128867.5503078 , 22153517.42924844, 22142529.27853908,\n",
       "        22120694.59224053, 22135554.92370385, 22134964.1676329 ,\n",
       "        22130559.57686748, 22141794.59214702, 22129223.49875825,\n",
       "        22127627.02047961, 22145022.17834701, 22116758.26318771,\n",
       "        22128359.41074492, 22156006.91804495, 22124056.17269048,\n",
       "        22130387.579561  , 22142466.3831424 , 22131342.30945612,\n",
       "        22132716.73146407, 22142444.70444942, 22134112.12243696,\n",
       "        22132186.2857627 , 22150241.998173  , 22145996.14291811,\n",
       "        22128370.55534054, 22122617.48946179, 22131548.34501801,\n",
       "        22141329.81869868, 22137986.31219783, 22133862.04653005,\n",
       "        22118773.04320599, 22138429.35014965, 22132911.20291484,\n",
       "        22127365.52562844, 22140399.20454529, 22130362.646276  ,\n",
       "        22162661.42246417, 22181495.53089418, 22177484.52782033,\n",
       "        22122376.62489605, 22131932.19198429, 22127388.84010002,\n",
       "        22130240.9275248 , 22134132.46662186, 22137986.84053435,\n",
       "        22142908.7743508 , 22133093.23968159, 22130177.6366644 ,\n",
       "        22128195.24948302, 22138664.71580676, 22130360.654814  ,\n",
       "        22135902.37280874, 22134599.11399751, 22132609.13808705,\n",
       "        22131717.31218543, 22126297.12277435, 22132412.88988934,\n",
       "        22135705.67320484, 22129488.43691377, 22125520.80419326,\n",
       "        22135821.57702621, 22133239.58973468, 22099740.10606282,\n",
       "        22131171.08707234, 22130268.10714143, 22137774.35128977,\n",
       "        22142711.21088057, 22135118.93546342, 22120873.18399307,\n",
       "        22143804.49798105, 22135449.52311859, 22120052.19081237,\n",
       "        22126410.29437717, 22129334.68240079, 22140119.9587861 ,\n",
       "        22143806.32160332, 22149147.29374193, 22147903.22309867,\n",
       "        22130278.66540669, 22137487.98633306, 22123217.5835952 ,\n",
       "        22150197.44088816, 22122120.73472179, 22145415.40723117,\n",
       "        22132667.59313008, 22130484.67751492, 22131597.95334658,\n",
       "        22131199.40782469, 22134714.91249391, 22130605.97433439,\n",
       "        22112330.16131635, 22137331.93997138, 22132415.9020955 ,\n",
       "        22137129.20651435, 22130030.84183948, 22119705.57986581,\n",
       "        22144049.38524356, 22128987.79274384, 22127263.69641044,\n",
       "        22124327.82525778, 22140610.14235385, 22132730.87785337,\n",
       "        22132162.48954624, 22145350.75524892, 22136536.51832529,\n",
       "        22121931.74236398, 22139254.63775739, 22131364.50127647,\n",
       "        22138957.32788559, 22128271.22376485, 22120796.84331   ,\n",
       "        22127875.947581  , 22136655.83126701, 22132853.98317276,\n",
       "        22122033.56605916, 22114828.09654344, 22111443.12658734,\n",
       "        22123532.12699201, 22133711.17424979, 22120395.91759444,\n",
       "        22139967.82714295, 22126463.53074376, 22130025.6468271 ,\n",
       "        22122336.88106772, 22129276.27066967, 22137288.22190865,\n",
       "        22135073.14535222, 22132934.34503876, 22138616.34245005,\n",
       "        22132057.32969771, 22128958.53531993, 22133911.32907767,\n",
       "        22153116.07470962, 22134320.12243114, 22131849.66075306,\n",
       "        22132796.22812791, 22130831.07674656, 22127058.03965854,\n",
       "        22131437.65232644, 22129664.73265141, 22121362.1969325 ,\n",
       "        22128257.28940933, 22147305.70465658, 22127642.09712217,\n",
       "        22129797.04500305, 22135449.92114556, 22135004.58296866,\n",
       "        22134935.10717353, 22134107.47961481, 22131986.27581853,\n",
       "        22127991.23187334, 22132464.76258934, 22136788.13699617,\n",
       "        22121751.52253319, 22133106.26943314, 22136000.9209169 ,\n",
       "        22128244.93554207, 22137010.17653747, 22119754.55878963,\n",
       "        22136308.14062948, 22129999.29767549, 22121244.58738254,\n",
       "        22116715.78070742, 22172528.2265988 , 22124872.41469767,\n",
       "        22122774.39112264, 22119935.72229293, 22145690.96798221,\n",
       "        22135944.63124947, 22127495.14844839, 22133755.91209172,\n",
       "        22141133.34964883, 22140030.95155943, 22120768.70759404,\n",
       "        22132876.55691732, 22129118.08576239, 22131781.52044674,\n",
       "        22116134.21491867, 22132697.70902259, 22135514.09428494,\n",
       "        22147217.28534346, 22130807.74777813, 22144000.80165657,\n",
       "        22128581.31991072, 22119581.36812549, 22125196.46847623,\n",
       "        22133243.09216412, 22131412.07021463, 22133925.7678833 ,\n",
       "        22136771.21543125, 22118575.51224272, 22095951.81835546,\n",
       "        22129166.71304372, 22137240.50505814, 22119799.39544714,\n",
       "        22119277.34845308, 22123050.62029841, 22119253.26261781,\n",
       "        22133800.12961775, 22135566.77993989, 22156038.13712613,\n",
       "        22134662.80331117, 22138608.48429907, 22129301.11318014,\n",
       "        22139208.61788918, 22162415.00126791, 22128563.67140882,\n",
       "        22140656.85512128, 22138188.48904601, 22130920.00365364,\n",
       "        22131076.19511837, 22139869.74631851, 22118227.85158369,\n",
       "        22133594.6627439 , 22122744.9646434 , 22125419.16891096,\n",
       "        22131905.31100968, 22132893.21202146, 22142196.85432883,\n",
       "        22139285.43561137, 22141835.8202275 , 22130751.67050513,\n",
       "        22130989.46274462, 22139066.26841741, 22119610.97179987,\n",
       "        22128698.56070865, 22131435.7720695 , 22132303.5265893 ,\n",
       "        22138003.44514167, 22124651.07401777, 22109780.75988103,\n",
       "        22133619.3533891 , 22132629.22939046, 22127874.28765159,\n",
       "        22140133.93032605, 22122107.3197548 , 22129782.75728653,\n",
       "        22125517.2856589 , 22158805.73683092, 22140522.80577888,\n",
       "        22153792.05435356, 22123913.1162499 , 22135293.60354848,\n",
       "        22136763.20834515, 22128214.4923086 , 22131968.38570482,\n",
       "        22124799.20509697, 22141546.9347874 , 22122071.57917849,\n",
       "        22137967.05523424, 22130249.45763325, 22128662.87375007,\n",
       "        22125181.29423117, 22135660.28120138, 22119452.14931757,\n",
       "        22131765.77715122, 22136249.38204499])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_mahalanobis_distances(data,decision_model,s,embedding_df) for s in [0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4dc0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          58.1550,  0.0000,  2.1200,  1.0000,  1.0000,  3.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000, 70.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dictify(keys,values):\n",
    "    return {k:v for k,v in zip(keys,values)}\n",
    "\n",
    "def get_neighbors_and_embeddings_from_sim(embeddings,dataset,decisionmodel,\n",
    "                                         embedding_df=None,max_neighbors=100,\n",
    "                                          pcas=None,\n",
    "                                          pca_components=2,\n",
    "                                         ):\n",
    "    #this is get_embeddings_and_neighbors, but uses the optimal model from get_stuff_For_patient embeddings\n",
    "    #instead of just kinda not simulation anyhting. adds 1 second on my UIC workstation to the simulation\n",
    "    if embedding_df is None:\n",
    "        embedding_df = get_embedding_df(dataset,decisionmodel)\n",
    "    cat = lambda x: torch.cat(x,axis=1)\n",
    "    \n",
    "    embed_arrays = [np.stack(embedding_df['embeddings_state'+str(s)].values) for s in embeddings.keys()]\n",
    "    if pcas is None:\n",
    "        pcas = [PCA(pca_components,whiten=True).fit(e) for e in embed_arrays]\n",
    "    i = 0\n",
    "    results = {}\n",
    "    for state, embedding in embeddings.items():\n",
    "        embedding_array = embed_arrays[i]\n",
    "        mdist = calculateMahalanobis(embedding.reshape(1,-1),embedding_array)\n",
    "        \n",
    "        dists = cdist(embedding,embedding_array).ravel()\n",
    "        max_neighbors = min(len(dists),max_neighbors)\n",
    "        min_positions = np.argsort(dists)[:max_neighbors]\n",
    "        neighbor_ids = dataset.processed_df.index.values[min_positions]\n",
    "        min_dists = dists[min_positions]\n",
    "        similarities = 1/(1+min_dists)\n",
    "        # similarities /= similarities.max() #adjust for rounding errors, self sim should be the max\n",
    "        pPca = pcas[i].transform(embedding)[0]\n",
    "        entry = {\n",
    "            'neighbors': neighbor_ids, \n",
    "            'similarities': similarities,\n",
    "            'embedding': embedding[0],\n",
    "            'pca': pPca, \n",
    "            'mahalanobisDistance': mdist[0]\n",
    "        }\n",
    "        results[state] = entry\n",
    "        i+=1\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_default_model_inputs(dataset):\n",
    "    res = []\n",
    "    for state in [0,1,2]:\n",
    "        xin = get_default_input(dataset,state)[0]\n",
    "        xin = dict_to_model_input(dataset,xin,state)\n",
    "        res.append(xin)\n",
    "    return res\n",
    "get_default_model_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab629d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "Decision 2 (CC / RT alone)\n",
      "1.8837194442749023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simulation': {'imitation': {'decision1': 0.995538,\n",
       "   'decision2': 0.0,\n",
       "   'decision3': 1.0,\n",
       "   'decision1_attention': {'step': 0,\n",
       "    'model': 'imitation',\n",
       "    'range': [-0.004109903455914532, 0.004785101147933047],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': 0.003485457556594306,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': -0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': -0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': 0.0,\n",
       "     '5A_ipsi': 0.0,\n",
       "     '5B_contra': 0.0,\n",
       "     '5B_ipsi': 0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': 0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': 0.004785101147933047,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': 0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': 0.0,\n",
       "     'Aspiration rate Pre-therapy': -0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': -0.0,\n",
       "     'DLT_Nephrological': -0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': -0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': 0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': -0.0,\n",
       "     'N-category_2': 0.001974120726357221,\n",
       "     'N-category_3': 0.0,\n",
       "     'Pathological Grade_0': -0.0012098212523551975,\n",
       "     'Pathological Grade_1': -0.0,\n",
       "     'Pathological Grade_2': 0.0,\n",
       "     'Pathological Grade_3': 0.0021990766763030586,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': -0.0,\n",
       "     'T-category_1': 0.00460148747072783,\n",
       "     'T-category_2': -0.0,\n",
       "     'T-category_3': 0.0,\n",
       "     'T-category_4': -0.0,\n",
       "     'White/Caucasion': 0.0,\n",
       "     'age': -0.004109903455914532,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': 0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': -0.0,\n",
       "     'packs_per_year': 0.00023354957346195666,\n",
       "     'subsite_BOT': -0.0,\n",
       "     'subsite_GPS': 0.0,\n",
       "     'subsite_NOS': 0.004622304961935888,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': 0.0,\n",
       "     'total_dose': -0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.0,\n",
       "     'DLT_Gastrointestinal': 0.0,\n",
       "     'DLT_Hematological': 0.0,\n",
       "     'DLT_Neurological': 0.0,\n",
       "     'DLT_Other': 0.0},\n",
       "    'dlt2': {'DLT_Dermatological 2': 0.0,\n",
       "     'DLT_Gastrointestinal 2': -0.0,\n",
       "     'DLT_Hematological 2': -0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': 0.0},\n",
       "    'pd': {'CR Primary': -0.0, 'PR Primary': 0.0, 'SD Primary': -0.0},\n",
       "    'nd': {'CR Nodal': 0.0, 'PR Nodal': 0.0, 'SD Nodal': -0.0},\n",
       "    'cc': {'cc_none': -0.0,\n",
       "     'cc_platinum': 0.0,\n",
       "     'cc_cetuximab': -0.0,\n",
       "     'cc_others': 0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0,\n",
       "     'dose_modified': 0.0,\n",
       "     'dose_delayed': -0.0,\n",
       "     'dose_cancelled': 0.0,\n",
       "     'dose_delayed_&_modified': 0.0,\n",
       "     'regiment_modification': 0.0}},\n",
       "   'decision2_attention': 0,\n",
       "   'decision3_attention': 0,\n",
       "   'propensity1': 0.995538,\n",
       "   'propensity2': 0.013968321,\n",
       "   'propensity3': 0.012806581,\n",
       "   'pd1': array([0.842369  , 0.1484497 , 0.00918121], dtype=float32),\n",
       "   'nd1': array([0.00371144, 0.9926466 , 0.00364201], dtype=float32),\n",
       "   'modifications': array([0.9502783 , 0.00953959, 0.00992931, 0.01008717, 0.00967079,\n",
       "          0.01049488], dtype=float32),\n",
       "   'dlt1': array([0.20015396, 0.1570275 , 0.21410224, 0.13205093, 0.1148096 ],\n",
       "         dtype=float32),\n",
       "   'pd1_5%': array([0.68645996, 0.059973  , 0.00405889], dtype=float32),\n",
       "   'nd1_5%': array([0.00121855, 0.987898  , 0.001205  ], dtype=float32),\n",
       "   'modifications_5%': array([0.92836416, 0.00510814, 0.0051714 , 0.00538481, 0.00512147,\n",
       "          0.00566626], dtype=float32),\n",
       "   'dlt1_5%': array([0.10633876, 0.06540795, 0.13496335, 0.06468767, 0.0522415 ],\n",
       "         dtype=float32),\n",
       "   'pd1_95%': array([0.9371605 , 0.29942864, 0.01530631], dtype=float32),\n",
       "   'nd1_95%': array([0.00622589, 0.9975765 , 0.00587608], dtype=float32),\n",
       "   'modifications_95%': array([0.9732486 , 0.01319695, 0.01424999, 0.01530969, 0.01340867,\n",
       "          0.01495016], dtype=float32),\n",
       "   'dlt1_95%': array([0.24572825, 0.20566796, 0.32805717, 0.19860935, 0.18277267],\n",
       "         dtype=float32),\n",
       "   'pd2': array([9.9924576e-01, 3.7523708e-04, 3.7905952e-04], dtype=float32),\n",
       "   'nd2': array([0.8058619 , 0.18891177, 0.00522636], dtype=float32),\n",
       "   'cc_type': array([0.06264507, 0.8473813 , 0.04667044, 0.04330324], dtype=float32),\n",
       "   'dlt2': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_5%': array([9.9831194e-01, 4.3372438e-05, 4.3050626e-05], dtype=float32),\n",
       "   'nd2_5%': array([0.6848647 , 0.07410389, 0.00114386], dtype=float32),\n",
       "   'cc_type_5%': array([0.02999449, 0.7513194 , 0.02352081, 0.02169781], dtype=float32),\n",
       "   'dlt2_5%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_95%': array([9.9991351e-01, 8.3055836e-04, 8.5751677e-04], dtype=float32),\n",
       "   'nd2_95%': array([0.9221365 , 0.31340414, 0.00957846], dtype=float32),\n",
       "   'cc_type_95%': array([0.10317383, 0.92295516, 0.08040078, 0.07310885], dtype=float32),\n",
       "   'dlt2_95%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'outcomes': array([0.8388556 , 0.09896418, 0.29854584, 0.8621767 ], dtype=float32),\n",
       "   'outcomes_5%': array([0.7894116 , 0.05257849, 0.19288877, 0.83001506], dtype=float32),\n",
       "   'outcomes_95%': array([0.9043345 , 0.11219834, 0.33625144, 0.90884525], dtype=float32),\n",
       "   'OS (Calculated)': 332.20575,\n",
       "   'Locoregional control (Time)': 997.673,\n",
       "   'FDM (months)': 1935.1217,\n",
       "   'time_to_event': 39.786263,\n",
       "   'survival_curves': {'OS (Calculated)': [0.999,\n",
       "     0.993,\n",
       "     0.986,\n",
       "     0.979,\n",
       "     0.971,\n",
       "     0.964,\n",
       "     0.956,\n",
       "     0.948,\n",
       "     0.939,\n",
       "     0.93,\n",
       "     0.921],\n",
       "    'Locoregional control (Time)': [0.998,\n",
       "     0.986,\n",
       "     0.974,\n",
       "     0.964,\n",
       "     0.954,\n",
       "     0.945,\n",
       "     0.937,\n",
       "     0.929,\n",
       "     0.921,\n",
       "     0.914,\n",
       "     0.907],\n",
       "    'FDM (months)': [0.999,\n",
       "     0.994,\n",
       "     0.987,\n",
       "     0.982,\n",
       "     0.976,\n",
       "     0.971,\n",
       "     0.966,\n",
       "     0.961,\n",
       "     0.957,\n",
       "     0.952,\n",
       "     0.948],\n",
       "    'time_to_event': [0.993,\n",
       "     0.916,\n",
       "     0.82,\n",
       "     0.737,\n",
       "     0.664,\n",
       "     0.599,\n",
       "     0.542,\n",
       "     0.492,\n",
       "     0.448,\n",
       "     0.409,\n",
       "     0.374],\n",
       "    'times': [1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60]},\n",
       "   'OS (Calculated)(4yr)': 0.939,\n",
       "   'Locoregional control (Time)(4yr)': 0.921,\n",
       "   'FDM (months)(4yr)': 0.957,\n",
       "   'time_to_event(4yr)': 0.448},\n",
       "  'imitation_alt': {'decision1': 0.995538,\n",
       "   'decision2': 1.0,\n",
       "   'decision3': 1.0,\n",
       "   'decision1_attention': {'step': 0,\n",
       "    'model': 'imitation',\n",
       "    'range': [-0.004109903455914532, 0.004785101147933047],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': 0.003485457556594306,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': -0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': -0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': 0.0,\n",
       "     '5A_ipsi': 0.0,\n",
       "     '5B_contra': 0.0,\n",
       "     '5B_ipsi': 0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': 0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': 0.004785101147933047,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': 0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': 0.0,\n",
       "     'Aspiration rate Pre-therapy': -0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': -0.0,\n",
       "     'DLT_Nephrological': -0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': -0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': 0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': -0.0,\n",
       "     'N-category_2': 0.001974120726357221,\n",
       "     'N-category_3': 0.0,\n",
       "     'Pathological Grade_0': -0.0012098212523551975,\n",
       "     'Pathological Grade_1': -0.0,\n",
       "     'Pathological Grade_2': 0.0,\n",
       "     'Pathological Grade_3': 0.0021990766763030586,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': -0.0,\n",
       "     'T-category_1': 0.00460148747072783,\n",
       "     'T-category_2': -0.0,\n",
       "     'T-category_3': 0.0,\n",
       "     'T-category_4': -0.0,\n",
       "     'White/Caucasion': 0.0,\n",
       "     'age': -0.004109903455914532,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': 0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': -0.0,\n",
       "     'packs_per_year': 0.00023354957346195666,\n",
       "     'subsite_BOT': -0.0,\n",
       "     'subsite_GPS': 0.0,\n",
       "     'subsite_NOS': 0.004622304961935888,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': 0.0,\n",
       "     'total_dose': -0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.0,\n",
       "     'DLT_Gastrointestinal': 0.0,\n",
       "     'DLT_Hematological': 0.0,\n",
       "     'DLT_Neurological': 0.0,\n",
       "     'DLT_Other': 0.0},\n",
       "    'dlt2': {'DLT_Dermatological 2': 0.0,\n",
       "     'DLT_Gastrointestinal 2': -0.0,\n",
       "     'DLT_Hematological 2': -0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': 0.0},\n",
       "    'pd': {'CR Primary': -0.0, 'PR Primary': 0.0, 'SD Primary': -0.0},\n",
       "    'nd': {'CR Nodal': 0.0, 'PR Nodal': 0.0, 'SD Nodal': -0.0},\n",
       "    'cc': {'cc_none': -0.0,\n",
       "     'cc_platinum': 0.0,\n",
       "     'cc_cetuximab': -0.0,\n",
       "     'cc_others': 0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0,\n",
       "     'dose_modified': 0.0,\n",
       "     'dose_delayed': -0.0,\n",
       "     'dose_cancelled': 0.0,\n",
       "     'dose_delayed_&_modified': 0.0,\n",
       "     'regiment_modification': 0.0}},\n",
       "   'decision2_attention': 0,\n",
       "   'decision3_attention': 0,\n",
       "   'propensity1': 0.995538,\n",
       "   'propensity2': 0.013968321,\n",
       "   'propensity3': 0.012629426,\n",
       "   'pd1': array([0.842369  , 0.1484497 , 0.00918121], dtype=float32),\n",
       "   'nd1': array([0.00371144, 0.9926466 , 0.00364201], dtype=float32),\n",
       "   'modifications': array([0.9502783 , 0.00953959, 0.00992931, 0.01008717, 0.00967079,\n",
       "          0.01049488], dtype=float32),\n",
       "   'dlt1': array([0.20015396, 0.1570275 , 0.21410224, 0.13205093, 0.1148096 ],\n",
       "         dtype=float32),\n",
       "   'pd1_5%': array([0.7801891 , 0.05229867, 0.00393656], dtype=float32),\n",
       "   'nd1_5%': array([0.00111776, 0.9914543 , 0.00111766], dtype=float32),\n",
       "   'modifications_5%': array([0.9356164 , 0.00321863, 0.0035221 , 0.00328428, 0.00336923,\n",
       "          0.00343364], dtype=float32),\n",
       "   'dlt1_5%': array([0.12533323, 0.10403339, 0.14104502, 0.0842972 , 0.05630191],\n",
       "         dtype=float32),\n",
       "   'pd1_95%': array([0.94310504, 0.2042496 , 0.01065668], dtype=float32),\n",
       "   'nd1_95%': array([0.00436762, 0.99772394, 0.00417809], dtype=float32),\n",
       "   'modifications_95%': array([0.9831722 , 0.01219426, 0.01332552, 0.01273624, 0.01232377,\n",
       "          0.01380374], dtype=float32),\n",
       "   'dlt1_95%': array([0.29328305, 0.23247741, 0.2806418 , 0.23693419, 0.14838833],\n",
       "         dtype=float32),\n",
       "   'pd2': array([9.9915004e-01, 4.2258223e-04, 4.2730078e-04], dtype=float32),\n",
       "   'nd2': array([0.789414  , 0.20501417, 0.00557186], dtype=float32),\n",
       "   'cc_type': array([0.06238883, 0.8463406 , 0.04743632, 0.04383434], dtype=float32),\n",
       "   'dlt2': array([0.02763021, 0.0173607 , 0.00867816, 0.02405145, 0.02138302],\n",
       "         dtype=float32),\n",
       "   'pd2_5%': array([9.9775481e-01, 1.5470589e-04, 1.5569213e-04], dtype=float32),\n",
       "   'nd2_5%': array([0.6714428 , 0.10556087, 0.00183125], dtype=float32),\n",
       "   'cc_type_5%': array([0.02843127, 0.68338865, 0.02329438, 0.02113749], dtype=float32),\n",
       "   'dlt2_5%': array([0.01309249, 0.00414696, 0.00388766, 0.01029559, 0.00680021],\n",
       "         dtype=float32),\n",
       "   'pd2_95%': array([0.9996897 , 0.00111479, 0.00113043], dtype=float32),\n",
       "   'nd2_95%': array([0.88848805, 0.32528752, 0.01200868], dtype=float32),\n",
       "   'cc_type_95%': array([0.12852864, 0.93030065, 0.1004574 , 0.08413067], dtype=float32),\n",
       "   'dlt2_95%': array([0.06313469, 0.02858242, 0.02482265, 0.04920977, 0.06659082],\n",
       "         dtype=float32),\n",
       "   'outcomes': array([0.8195501 , 0.13069719, 0.3458935 , 0.84532005], dtype=float32),\n",
       "   'outcomes_5%': array([0.7708445 , 0.08984716, 0.266221  , 0.7894948 ], dtype=float32),\n",
       "   'outcomes_95%': array([0.88328815, 0.15399937, 0.44951624, 0.8969151 ], dtype=float32),\n",
       "   'OS (Calculated)': 316.44104,\n",
       "   'Locoregional control (Time)': 869.31915,\n",
       "   'FDM (months)': 1874.2314,\n",
       "   'time_to_event': 32.8801,\n",
       "   'survival_curves': {'OS (Calculated)': [1.0,\n",
       "     0.995,\n",
       "     0.987,\n",
       "     0.979,\n",
       "     0.97,\n",
       "     0.96,\n",
       "     0.95,\n",
       "     0.94,\n",
       "     0.929,\n",
       "     0.918,\n",
       "     0.907],\n",
       "    'Locoregional control (Time)': [0.998,\n",
       "     0.988,\n",
       "     0.975,\n",
       "     0.964,\n",
       "     0.953,\n",
       "     0.942,\n",
       "     0.933,\n",
       "     0.924,\n",
       "     0.915,\n",
       "     0.907,\n",
       "     0.899],\n",
       "    'FDM (months)': [1.0,\n",
       "     0.996,\n",
       "     0.991,\n",
       "     0.985,\n",
       "     0.98,\n",
       "     0.974,\n",
       "     0.969,\n",
       "     0.964,\n",
       "     0.959,\n",
       "     0.955,\n",
       "     0.95],\n",
       "    'time_to_event': [0.988,\n",
       "     0.886,\n",
       "     0.773,\n",
       "     0.678,\n",
       "     0.598,\n",
       "     0.531,\n",
       "     0.475,\n",
       "     0.427,\n",
       "     0.387,\n",
       "     0.352,\n",
       "     0.322],\n",
       "    'times': [1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60]},\n",
       "   'OS (Calculated)(4yr)': 0.929,\n",
       "   'Locoregional control (Time)(4yr)': 0.915,\n",
       "   'FDM (months)(4yr)': 0.959,\n",
       "   'time_to_event(4yr)': 0.387}},\n",
       " 'embeddings': {},\n",
       " 'symptoms': {'treated': {'ids': [1091,\n",
       "    1114,\n",
       "    1445,\n",
       "    605,\n",
       "    1313,\n",
       "    1124,\n",
       "    361,\n",
       "    461,\n",
       "    277,\n",
       "    1309],\n",
       "   'dists': [48.317201610682666,\n",
       "    48.47657728650545,\n",
       "    48.87702204390621,\n",
       "    49.03169140688463,\n",
       "    49.16342763346124,\n",
       "    49.29129695172902,\n",
       "    49.29173611348111,\n",
       "    49.35440523970693,\n",
       "    49.47347895424199,\n",
       "    49.477092298684596],\n",
       "   'symptoms': {'choke': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [3.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.3333333333333333, 2.0, 0.0, 0.14285714285714285]},\n",
       "    'drymouth': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, 9.0, 5.0],\n",
       "      [0.0, 8.0, 4.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, 8.0],\n",
       "      [3.0, 5.0, 3.0, -1.0],\n",
       "      [1.0, 2.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, 5.0, 3.0],\n",
       "      [0.0, 1.0, 1.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 4.6, 4.4, 3.2857142857142856]},\n",
       "    'fatigue': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, 4.0, 3.0],\n",
       "      [0.0, 8.0, 2.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, 1.0],\n",
       "      [2.0, 6.0, 3.0, -1.0],\n",
       "      [0.0, 2.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 4.6, 1.8, 0.8571428571428571]},\n",
       "    'mucus': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 6.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 8.0],\n",
       "      [1.0, 4.0, 8.0, -1.0],\n",
       "      [0.0, 1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 4.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 5.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.1111111111111111, 4.2, 3.2, 2.142857142857143]},\n",
       "    'nausea': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 3.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 4.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.0, 1.4, 0.0, 0.14285714285714285]},\n",
       "    'skin': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 8.0, 2.0, -1.0],\n",
       "      [0.0, 3.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.0, 2.2, 0.4, 0.0]},\n",
       "    'swallow': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 3.0, 1.0],\n",
       "      [0.0, 8.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [3.0, 4.0, 8.0, -1.0],\n",
       "      [0.0, 2.0, -1.0, 1.0],\n",
       "      [10.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 3.0],\n",
       "      [0.0, -1.0, 2.0, 1.0],\n",
       "      [1.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [1.5555555555555556, 4.8, 2.6, 0.8571428571428571]},\n",
       "    'taste': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 7.0, 6.0],\n",
       "      [0.0, 9.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 2.0, -1.0],\n",
       "      [0.0, 9.0, -1.0, 4.0],\n",
       "      [0.0, -1.0, -1.0, 5.0],\n",
       "      [-1.0, -1.0, -1.0, 7.0],\n",
       "      [0.0, -1.0, 4.0, 7.0],\n",
       "      [0.0, 5.0, 2.0, 0.0]],\n",
       "     'means': [0.0, 8.25, 3.0, 4.285714285714286]},\n",
       "    'teeth': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 3.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [8.0, 8.0, 7.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.8888888888888888, 2.75, 1.4, 0.0]},\n",
       "    'mood': {'ratings': [[0.0, 5.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, 2.0, 0.0],\n",
       "      [3.0, 2.0, 2.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 5.0, 0.0, -1.0],\n",
       "      [1.0, 0.0, -1.0, 0.0],\n",
       "      [1.0, -1.0, -1.0, 2.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 2.4, 0.8, 0.2857142857142857]}}},\n",
       "  'untreated': {'ids': [1237,\n",
       "    1543,\n",
       "    1565,\n",
       "    1560,\n",
       "    1326,\n",
       "    496,\n",
       "    1563,\n",
       "    553,\n",
       "    840,\n",
       "    1261],\n",
       "   'dists': [47.4503453343392,\n",
       "    47.64292676522173,\n",
       "    47.6950861770574,\n",
       "    48.48788282406037,\n",
       "    48.905936485619705,\n",
       "    48.94186213926406,\n",
       "    48.99010610993625,\n",
       "    49.0184394363471,\n",
       "    49.14272153527371,\n",
       "    49.33538305999806],\n",
       "   'symptoms': {'choke': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 4.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, -1.0]],\n",
       "     'means': [0.0, 1.0, 0.25, 0.0]},\n",
       "    'drymouth': {'ratings': [[0.0, 5.0, 2.0, -1.0],\n",
       "      [-1.0, -1.0, 6.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, 7.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [7.0, -1.0, -1.0, -1.0],\n",
       "      [4.0, 10.0, 9.0, -1.0]],\n",
       "     'means': [1.625, 5.0, 4.25, 2.3333333333333335]},\n",
       "    'fatigue': {'ratings': [[0.0, 4.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 6.0, -1.0, -1.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [6.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [1.625, 4.75, 2.75, 1.6666666666666667]},\n",
       "    'mucus': {'ratings': [[0.0, 3.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 6.0, -1.0, -1.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [9.0, 10.0, 0.0, -1.0]],\n",
       "     'means': [1.625, 4.75, 0.25, 0.0]},\n",
       "    'nausea': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 2.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, -1.0]],\n",
       "     'means': [0.125, 0.5, 0.25, 0.0]},\n",
       "    'skin': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 2.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, 10.0, 9.0, -1.0]],\n",
       "     'means': [0.5, 4.25, 2.25, 0.0]},\n",
       "    'swallow': {'ratings': [[0.0, 1.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 1.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 2.0],\n",
       "      [1.0, -1.0, -1.0, 1.0],\n",
       "      [-1.0, 7.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, -1.0],\n",
       "      [8.0, 6.0, 5.0, -1.0]],\n",
       "     'means': [1.625, 3.75, 2.75, 1.0]},\n",
       "    'taste': {'ratings': [[0.0, 10.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 7.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 2.0, 2.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 8.0, -1.0, -1.0],\n",
       "      [9.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, 9.0, 8.0, -1.0]],\n",
       "     'means': [1.375, 7.25, 5.0, 2.3333333333333335]},\n",
       "    'teeth': {'ratings': [[0.0, 1.0, 1.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 2.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [0.0, 3.0, 1.75, 0.6666666666666666]},\n",
       "    'mood': {'ratings': [[0.0, 0.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, -1.0],\n",
       "      [8.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [1.875, 3.5, 2.75, 0.0]}}},\n",
       "  'dates': [0, 7, 12, 27]}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changed\n",
    "def get_stuff_for_patient(patient_dict,data,tmodel1,tmodel2,outcomemodel,decisionmodel,survival_model,\n",
    "                          symptom_model=None,mdasi_data=None,\n",
    "                          override_outcome_model=True,\n",
    "                          state=0,\n",
    "                          model_type='optimal',\n",
    "                          timepoints = [1,6,12,18,24,30,36,42,48,54,60],\n",
    "                          fixed_decisions = [-1,-1,-1],\n",
    "                          **kwargs):\n",
    "    #this takes a patient dict and returns the results for a full treatment simulation\n",
    "    #currently if state > 0 it will check if prior transition states are all zero and if not, will input them\n",
    "    #currently works with categorical, might have to experiment with passing like -1 for fixed \"no\" with fixed no dlts\n",
    "    pdata = format_patient(data,patient_dict)\n",
    "    \n",
    "    baseline_inputs = dict_to_model_input(data,pdata,state=0,concat=False) \n",
    "    \n",
    "    \n",
    "    tmodel1.eval()\n",
    "    tmodel2.eval()\n",
    "    outcomemodel.eval()\n",
    "    decisionmodel.eval()\n",
    "    survival_model.eval()\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        device='cuda'\n",
    "    tmodel1.set_device(device)\n",
    "    tmodel2.set_device(device)\n",
    "    outcomemodel.set_device(device)\n",
    "    decisionmodel.set_device(device)\n",
    "    survival_model.set_device(device)\n",
    "    results = {}\n",
    "    embeddings = {}\n",
    "    #do a loop for imitation and a loop for optimal decision making, mod = 3 is imitation\n",
    "    format_transition = lambda x: x.view(1,-1).to(device)\n",
    "    #inputs are order baseline, dlt1, dlt2, pd, nd, cc type, dose modifications\n",
    "    #model output is nx6 -> optimal 1 , 2, 3, imitation 1, 2, 3\n",
    "    cat = lambda x: torch.cat([xx.to(device) for xx in x],axis=1).to(device)\n",
    "    \n",
    "    size_dict = decisionmodel.input_sizes\n",
    "    \n",
    "    #baseline, dlt1, dlt2, pd, nd, cc, mod\n",
    "    input_keys = get_inputkey_order(data)\n",
    "    \n",
    "    defaults = get_default_model_inputs(data)\n",
    "    defaults = [d.to(device) for d in defaults]\n",
    "    def get_attention(xx, position, offset):\n",
    "        attention = decisionmodel.get_attributions(xx,target=position+offset, position=position,base=defaults[position])[0].cpu().detach().numpy()\n",
    "        attention_dict = {\n",
    "            'step': position,\n",
    "            'model': 'optimal' if offset == 0 else 'imitation',\n",
    "            'range': [float(attention.min()),float(attention.max())],\n",
    "            'baseline': dictify(input_keys[0],attention[0:size_dict['baseline']]),\n",
    "        }\n",
    "        pos = size_dict['baseline']\n",
    "        attention_dict['dlt1'] = dictify(input_keys[1],attention[pos:pos+size_dict['dlt']])\n",
    "        pos += size_dict['dlt']\n",
    "        attention_dict['dlt2'] = dictify(input_keys[2], attention[pos:pos+size_dict['dlt']])\n",
    "        pos += size_dict['dlt']\n",
    "        attention_dict['pd'] = dictify(input_keys[3], attention[pos:pos+size_dict['pd']])\n",
    "        pos += size_dict['pd']\n",
    "        attention_dict['nd'] = dictify(input_keys[4], attention[pos:pos+size_dict['nd']])\n",
    "        pos += size_dict['nd']\n",
    "        attention_dict['cc'] = dictify(input_keys[5], attention[pos:pos+size_dict['cc']])\n",
    "        pos += size_dict['cc']\n",
    "        attention_dict['modifications'] = dictify(input_keys[6], attention[pos:])\n",
    "        return attention_dict\n",
    "        \n",
    "    memory = get_decision_input(data,state=2)\n",
    "    memory = cat([df_to_torch(f) for f in memory])\n",
    "    o1 = decisionmodel(cat(baseline_inputs),position=0)[0]\n",
    "    \n",
    "    thresh = lambda x: torch.gt(x,.5).type(torch.FloatTensor)\n",
    "    \n",
    "    modifiers = [3] if model_type == 'imitation' else [0]\n",
    "    if model_type == 'both':\n",
    "        modifiers = [0,3]\n",
    "        \n",
    "    def get_fixed_transitions():\n",
    "        \n",
    "        [base, dlt1,_,pd1,nd1,_,mod] =dict_to_model_input(data,pdata,state=1,\n",
    "                                                          concat=False,zero_transition_states=False)\n",
    "        [base, _,dlt2,pd2,nd2,cc,_] =dict_to_model_input(data,pdata,state=2,\n",
    "                                                          concat=False,zero_transition_states=False)\n",
    "        isfixed = lambda d: not (torch.sum(d) < .00001)\n",
    "        results = {\n",
    "            'dlt1': isfixed(dlt1),\n",
    "            'dlt2': isfixed(dlt2),\n",
    "            'pd1': isfixed(pd1),\n",
    "            'pd2': isfixed(pd2),\n",
    "            'nd1': isfixed(nd2),\n",
    "            'nd2': isfixed(nd2),\n",
    "            'cc': isfixed(cc),\n",
    "            'mod': isfixed(mod)\n",
    "        }\n",
    "        return results\n",
    "    fixed_transitions = get_fixed_transitions()\n",
    "\n",
    "    def run_simulation(modifier,decision1=None,decision2=None,decision3=None,is_alt=False):\n",
    "        #do this to track malahanobis distances?\n",
    "        is_default = (modifier == modifiers[0] and not is_alt)\n",
    "        if is_default:\n",
    "            embeddings[0] = decisionmodel.get_embedding(cat(baseline_inputs),position=0,\n",
    "                                                                  use_saved_memory=True)\n",
    "            \n",
    "        #transition 1 model uses usebaline + decision\n",
    "        if decision1 is not None:\n",
    "            d1 = torch.tensor([[decision1]]).type(torch.FloatTensor)\n",
    "            d1_attention=0\n",
    "        else:\n",
    "            d1 = o1[0+modifier].view(1,-1)\n",
    "            d1_attention = get_attention(cat(baseline_inputs),0,modifier)\n",
    "        propensity1 = o1[0+3].view(1,-1)\n",
    "        if is_alt and state == 0:\n",
    "            d1 = 1-d1    \n",
    "        \n",
    "            \n",
    "        tinput1 = cat([baseline_inputs[0],thresh(d1)])\n",
    "        \n",
    "        ytransition = tmodel1(tinput1)\n",
    "        [ypd1,ynd1,ymod,ydlt1] = ytransition['predictions']\n",
    "\n",
    "        [ypd1, ynd1, ymod] = [format_transition(i) for i in [ypd1,ynd1,ymod]]\n",
    "        \n",
    "        #I try to make this work in the model but it just thinks there's no outcome and softmaxes them all often\n",
    "        d1_thresh = torch.gt(d1,.5).view(-1,1).to(device)\n",
    "        ypd1[:,0:2] = ypd1[:,0:2]*d1_thresh\n",
    "        ynd1[:,0:2] = ynd1[:,0:2]*d1_thresh\n",
    "        \n",
    "        oinput2 = dict_to_model_input(data,pdata,state=1,concat=False,zero_transition_states=False)\n",
    "        #if the input stuff has a value for transition states and state passed is > 0, fix them\n",
    "        \n",
    "        #check if I should actually use the transition states\n",
    "        if state > 0 and fixed_transitions['dlt1']:\n",
    "            ydlt1 = torch.clone(oinput2[1])\n",
    "        else:\n",
    "            oinput2[1] = ydlt1.view(1,-1)\n",
    "        if state > 0 and fixed_transitions['pd1']:\n",
    "            ypd1 = torch.clone(oinput2[3])\n",
    "        else:\n",
    "            oinput2[3] = ypd1\n",
    "        if state > 0 and fixed_transitions['nd1']:\n",
    "            ynd1 = torch.clone(oinput2[4])\n",
    "        else:\n",
    "            oinput2[4] = ynd1\n",
    "        if state > 0 and fixed_transitions['mod']:\n",
    "            ymod = torch.clone(oinput2[6])\n",
    "        else:\n",
    "            oinput2[6] = torch.clone(ymod)\n",
    "            \n",
    "        d2_full = decisionmodel(cat(oinput2),position=1)\n",
    "        if decision2 is not None:\n",
    "            d2 = torch.tensor([[decision2]]).type(torch.FloatTensor)\n",
    "            d2_attention=0\n",
    "        else:\n",
    "            d2 = d2_full[0,1+modifier].view(1,-1)\n",
    "            d2_attention = get_attention(cat(oinput2),1,modifier)\n",
    "        propensity2 = d2_full[0,4].view(1,-1)\n",
    "        if is_alt and state == 1:\n",
    "            d2 = 1-d2\n",
    "            \n",
    "        if is_default:\n",
    "            embeddings[1] = decisionmodel.get_embedding(cat(oinput2),position=1,use_saved_memory=True)\n",
    "            \n",
    "        #transition 2 modle uses baseline + pd1 + nd1 + modification + dlt1 + decision 1 + deicsion 2\n",
    "        tinput2 = [baseline_inputs[0], ypd1, ynd1, ymod,ydlt1, thresh(d1),thresh(d2)]\n",
    "\n",
    "        tinput2 = cat(tinput2)\n",
    "        \n",
    "        ytransition2 = tmodel2(tinput2)\n",
    "        [ypd2, ynd2, ycc, ydlt2] = ytransition2['predictions']\n",
    "        [ypd2, ynd2, ycc] = [format_transition(i) for i in [ypd2,ynd2,ycc]]\n",
    "        \n",
    "        oinput3 = oinput2[:]\n",
    "        #check if I should use the transition states again\n",
    "        if state > 1 and fixed_transitions['dlt2']:\n",
    "            ydlt2 = torch.clone(oinput3[2])\n",
    "        else:\n",
    "            oinput3[2] = ydlt2.view(1,-1)\n",
    "        if state > 1 and fixed_transitions['pd2']:\n",
    "            ypd2 = torch.clone(oinput3[3])\n",
    "        else:\n",
    "            oinput3[3] = ypd2\n",
    "        if state > 1 and fixed_transitions['nd2']:\n",
    "            ynd2 = torch.clone(oinput3[4])\n",
    "        else:\n",
    "            oinput3[4] = ynd2\n",
    "        if state > 1 and fixed_transitions['cc']:\n",
    "            ycc = torch.clone(oinput3[5])\n",
    "        else:\n",
    "            oinput3[5] = torch.clone(ycc)\n",
    "\n",
    "        d3_full = decisionmodel(cat(oinput3),position = 2)\n",
    "        if decision3 is not None:\n",
    "            d3 = torch.tensor([[decision3]]).type(torch.FloatTensor)\n",
    "            d3_attention=0\n",
    "        else:\n",
    "            d3 = d3_full[0,2+modifier].view(1,-1)\n",
    "            d3_attention = get_attention(cat(oinput3),2,modifier)\n",
    "        propensity3= d3_full[0,4].view(1,-1)\n",
    "        if is_alt and state == 2:\n",
    "            d3 = 1-d3\n",
    "            \n",
    "        if is_default:\n",
    "            embeddings[2] = decisionmodel.get_embedding(cat(oinput3),position=2,use_saved_memory=True)\n",
    "        #outcomes uses baseline + pd2 + nd2 + cc type + dlt2 + decision 1,2,3\n",
    "        tinput3 = [baseline_inputs[0], ypd2, ynd2, ycc, ydlt2, thresh(d1), thresh(d2), thresh(d3)]\n",
    "        tinput3 = cat(tinput3)\n",
    "        outcomes = outcomemodel(tinput3)\n",
    "        \n",
    "        entry = {\n",
    "            'decision1': d1.cpu().detach().numpy()[0][0],\n",
    "            'decision2': d2.cpu().detach().numpy()[0][0],\n",
    "            'decision3': d3.cpu().detach().numpy()[0][0],\n",
    "            'decision1_attention': d1_attention,\n",
    "            'decision2_attention': d2_attention,\n",
    "            'decision3_attention': d3_attention,\n",
    "            'propensity1': propensity1.cpu().detach().numpy()[0][0],\n",
    "            'propensity2': propensity2.cpu().detach().numpy()[0][0],\n",
    "            'propensity3': propensity3.cpu().detach().numpy()[0][0],\n",
    "        }\n",
    "        \n",
    "        def add_to_entry(tmodel_output,names):\n",
    "            pred = tmodel_output['predictions']\n",
    "            lower = tmodel_output['5%']\n",
    "            upper = tmodel_output['95%']\n",
    "            for suffix,values in zip(['','_5%','_95%'],[pred,lower,upper]):\n",
    "                for name, v in zip(names,values):\n",
    "                    v = v.cpu().detach().numpy()\n",
    "                    if name != 'outcomes':\n",
    "                        v = v[0]\n",
    "                    #because of softmax the model will output 33% for pd and nd with no ic when it should be fixed to 0\n",
    "                    if entry['decision1'] < .5 and ('pd1' in name or 'nd1' in name):\n",
    "                        v = np.zeros(v.shape)\n",
    "                    entry[name+suffix] = v\n",
    "        add_to_entry(ytransition,['pd1','nd1','modifications','dlt1'])\n",
    "        add_to_entry(ytransition2,['pd2','nd2','cc_type','dlt2'])\n",
    "        add_to_entry(outcomes,['outcomes'])\n",
    "        \n",
    "        #add time to event  for each event, each is a seperate entry unlike the grouped outcomes\n",
    "        tte = survival_model.time_to_event(tinput3,n_samples=1)\n",
    "        tte_order = survival_model.outcome_names\n",
    "        for v, name in zip(tte,tte_order):\n",
    "            entry[name] = v.cpu().detach().numpy()[0]\n",
    "        #tte = survival_model.time_to_event(tinput3)\n",
    "        # add_to_entry(tte,tte_order)\n",
    "        \n",
    "        scurve_entry = {}\n",
    "        survival_curves = survival_model(tinput3,timepoints)\n",
    "        for name,scurve in zip(tte_order,survival_curves):\n",
    "            scurve = [np.round(v.cpu().detach().numpy()[0],3) for v in scurve]\n",
    "            scurve_entry[name] = scurve\n",
    "        scurve_entry['times'] = timepoints\n",
    "        entry['survival_curves'] = scurve_entry\n",
    "        #put the 4year probability for the timeseries input in case I want to override the other model\n",
    "        fouryear_probs = survival_model(tinput3,48)\n",
    "        for name, probs in zip(tte_order,fouryear_probs):\n",
    "            probs = probs[0].detach().cpu().numpy()[0]\n",
    "            entry[name+'(4yr)'] = np.round(probs,3)\n",
    "        key = 'optimal' if modifier < 1 else 'imitation'\n",
    "        if is_alt:\n",
    "            key = key + '_alt'\n",
    "#         if decision1 is not None:\n",
    "#             key += '_decision1-'+str(decision1)\n",
    "#         if decision2 is not None:\n",
    "#             key += '_decision2-'+str(decision2)\n",
    "#         if decision3 is not None:\n",
    "#             key += '_decision3-'+str(decision3)\n",
    "            \n",
    "        results[key] = entry\n",
    "\n",
    "    getfixed = lambda i: None if fixed_decisions[i] < 0 else fixed_decisions[i]\n",
    "    with torch.no_grad():\n",
    "        for modifier in modifiers:\n",
    "            for alt in [False,True]:\n",
    "                #is alt inverts the decisions for the current state and uses key + '_alt'\n",
    "                run_simulation(modifier,getfixed(0),getfixed(1),getfixed(2),is_alt=alt)\n",
    "#             for d1_fixed in [None,0,1]:\n",
    "#                 for d2_fixed in [None,0,1]:\n",
    "#                     for d3_fixed in [None,0,1]:\n",
    "#                         #we only need to do all fixed outcomes once\n",
    "#                         if d1_fixed is not None and d2_fixed is not None and d3_fixed is not None and modifier != modifiers[0]:\n",
    "#                             continue\n",
    "#                         run_simulation(modifier,d1_fixed,d2_fixed,d3_fixed)\n",
    "\n",
    "    for k,v in embeddings.items():\n",
    "        embeddings[k] = v.cpu().detach().numpy()\n",
    "    embedding_results = get_neighbors_and_embeddings_from_sim(embeddings,data,decisionmodel,**kwargs)\n",
    "    \n",
    "    res = {'simulation': results,'embeddings': embedding_results}\n",
    "    \n",
    "    symptoms = {}\n",
    "    if symptom_model is not None and mdasi_data is not None:\n",
    "        symptoms = get_knn_predictions(pdata,symptom_model,mdasi_data,decision_state=state+1)\n",
    "        res['symptoms'] = symptoms\n",
    "    return res\n",
    "\n",
    "from time import time\n",
    "t1 = time()\n",
    "test_patient= get_test_patient(data,7,False)\n",
    "test_results = get_stuff_for_patient(test_patient,data,\n",
    "                                     transition_model1,\n",
    "                                     transition_model2,\n",
    "                                     outcome_model,\n",
    "                                     decision_model,\n",
    "                                     survival_model,\n",
    "                                     symptom_model=sp,\n",
    "                                     mdasi_data=mdasi,\n",
    "                                     state=1,\n",
    "                                     max_neighbors=2,\n",
    "                                     model_type='imitation',\n",
    "#                                      model_type='both',\n",
    "                                     fixed_decisions=[-1,0,1]\n",
    "                                    )\n",
    "t2 = time()\n",
    "print(t2-t1)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db62a50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e2829a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "torch.Size([536, 86])\n",
      "Decision 2 (CC / RT alone)\n",
      "3.4139957427978516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simulation': {'optimal': {'decision1': 0.6497613,\n",
       "   'decision2': 0.0006328274,\n",
       "   'decision3': 0.0012098483,\n",
       "   'decision1_attention': {'step': 0,\n",
       "    'model': 'optimal',\n",
       "    'range': [-0.2573280799101862, 0.4054046344653485],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': -0.2573280799101862,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': -0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': 0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': 0.0,\n",
       "     '5A_contra': 0.0,\n",
       "     '5A_ipsi': -0.0,\n",
       "     '5B_contra': -0.0,\n",
       "     '5B_ipsi': -0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': -0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': 0.029775489697642585,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': 0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': 0.0,\n",
       "     'Aspiration rate Pre-therapy': 0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': -0.0,\n",
       "     'DLT_Nephrological': -0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': -0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': -0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': 0.0,\n",
       "     'N-category_2': -0.1339541330172619,\n",
       "     'N-category_3': 0.0,\n",
       "     'Pathological Grade_0': 0.04929174324925156,\n",
       "     'Pathological Grade_1': 0.0,\n",
       "     'Pathological Grade_2': 0.0,\n",
       "     'Pathological Grade_3': 0.03145008798083092,\n",
       "     'Pathological Grade_4': -0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': 0.0,\n",
       "     'T-category_1': -0.0969755171342013,\n",
       "     'T-category_2': 0.0,\n",
       "     'T-category_3': 0.0,\n",
       "     'T-category_4': 0.0,\n",
       "     'White/Caucasion': 0.0,\n",
       "     'age': -0.05973457337061537,\n",
       "     'bilateral': 0.0,\n",
       "     'dose_fraction': -0.0,\n",
       "     'gender': 0.0,\n",
       "     'hpv': -0.0,\n",
       "     'packs_per_year': 0.002992475700285129,\n",
       "     'subsite_BOT': -0.0,\n",
       "     'subsite_GPS': 0.0,\n",
       "     'subsite_NOS': 0.4054046344653485,\n",
       "     'subsite_Soft palate': 0.0,\n",
       "     'subsite_Tonsil': 0.0,\n",
       "     'total_dose': 0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.0,\n",
       "     'DLT_Gastrointestinal': -0.0,\n",
       "     'DLT_Hematological': 0.0,\n",
       "     'DLT_Neurological': 0.0,\n",
       "     'DLT_Other': 0.0},\n",
       "    'dlt2': {'DLT_Dermatological 2': -0.0,\n",
       "     'DLT_Gastrointestinal 2': 0.0,\n",
       "     'DLT_Hematological 2': 0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': -0.0},\n",
       "    'pd': {'CR Primary': 0.0, 'PR Primary': 0.0, 'SD Primary': -0.0},\n",
       "    'nd': {'CR Nodal': 0.0, 'PR Nodal': 0.0, 'SD Nodal': -0.0},\n",
       "    'cc': {'cc_none': 0.0,\n",
       "     'cc_platinum': 0.0,\n",
       "     'cc_cetuximab': 0.0,\n",
       "     'cc_others': -0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0,\n",
       "     'dose_modified': -0.0,\n",
       "     'dose_delayed': 0.0,\n",
       "     'dose_cancelled': -0.0,\n",
       "     'dose_delayed_&_modified': -0.0,\n",
       "     'regiment_modification': -0.0}},\n",
       "   'decision2_attention': {'step': 1,\n",
       "    'model': 'optimal',\n",
       "    'range': [-0.010991278042263969, 0.00314240148176824],\n",
       "    'baseline': {'1A_contra': 0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': 0.00314240148176824,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': -0.0,\n",
       "     '2A_ipsi': 0.0,\n",
       "     '2B_contra': 0.0,\n",
       "     '2B_ipsi': -0.0,\n",
       "     '3_contra': -0.0,\n",
       "     '3_ipsi': -0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': -0.0,\n",
       "     '5A_ipsi': 0.0,\n",
       "     '5B_contra': -0.0,\n",
       "     '5B_ipsi': -0.0,\n",
       "     '6_contra': 0.0,\n",
       "     '6_ipsi': -0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': -0.0009344839576613391,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': 0.0,\n",
       "     'African American/Black': 0.0,\n",
       "     'Asian': -0.0,\n",
       "     'Aspiration rate Pre-therapy': -0.0,\n",
       "     'DLT_Infection (Pneumonia)': 0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': 0.0,\n",
       "     'DLT_Nephrological': 0.0,\n",
       "     'DLT_Nephrological 2': -0.0,\n",
       "     'DLT_Vascular': 0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': 0.0,\n",
       "     'N-category_0': -0.0,\n",
       "     'N-category_1': 0.0,\n",
       "     'N-category_2': 6.071709787031559e-05,\n",
       "     'N-category_3': -0.0,\n",
       "     'Pathological Grade_0': -0.0028693339625333342,\n",
       "     'Pathological Grade_1': -0.0,\n",
       "     'Pathological Grade_2': -0.0,\n",
       "     'Pathological Grade_3': -0.0027019390182226304,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': 0.0,\n",
       "     'T-category_1': -0.000677295898508207,\n",
       "     'T-category_2': -0.0,\n",
       "     'T-category_3': -0.0,\n",
       "     'T-category_4': -0.0,\n",
       "     'White/Caucasion': -0.0,\n",
       "     'age': -0.002060819239682877,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': 0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': 0.0,\n",
       "     'packs_per_year': 0.00019819854611216522,\n",
       "     'subsite_BOT': 0.0,\n",
       "     'subsite_GPS': -0.0,\n",
       "     'subsite_NOS': -0.010991278042263969,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': -0.0,\n",
       "     'total_dose': -0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.00016779298527913662,\n",
       "     'DLT_Gastrointestinal': 0.00011492580874652895,\n",
       "     'DLT_Hematological': 9.723304893791392e-05,\n",
       "     'DLT_Neurological': -1.3954371453880184e-06,\n",
       "     'DLT_Other': -9.74097991924144e-05},\n",
       "    'dlt2': {'DLT_Dermatological 2': 0.0,\n",
       "     'DLT_Gastrointestinal 2': -0.0,\n",
       "     'DLT_Hematological 2': -0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': 0.0},\n",
       "    'pd': {'CR Primary': -0.00016464793132686044,\n",
       "     'PR Primary': 2.7353023175024258e-05,\n",
       "     'SD Primary': 2.3113319031963194e-06},\n",
       "    'nd': {'CR Nodal': -0.0, 'PR Nodal': -0.0, 'SD Nodal': -0.0},\n",
       "    'cc': {'cc_none': 0.000917131957101397,\n",
       "     'cc_platinum': -0.0,\n",
       "     'cc_cetuximab': 0.0,\n",
       "     'cc_others': -0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0004853162253594766,\n",
       "     'dose_modified': 0.0,\n",
       "     'dose_delayed': -0.0,\n",
       "     'dose_cancelled': -0.0,\n",
       "     'dose_delayed_&_modified': 0.0,\n",
       "     'regiment_modification': 0.0}},\n",
       "   'decision3_attention': {'step': 2,\n",
       "    'model': 'optimal',\n",
       "    'range': [-0.04409378674363995, 0.0062501920159013435],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': -0.02805897881349228,\n",
       "     '1B_ipsi': 0.0,\n",
       "     '2A_contra': -0.0,\n",
       "     '2A_ipsi': -0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': -0.0,\n",
       "     '3_ipsi': -0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': -0.0,\n",
       "     '5A_ipsi': -0.0,\n",
       "     '5B_contra': 0.0,\n",
       "     '5B_ipsi': -0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': -0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': 0.0062501920159013435,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': -0.0,\n",
       "     'African American/Black': 0.0,\n",
       "     'Asian': 0.0,\n",
       "     'Aspiration rate Pre-therapy': -0.0,\n",
       "     'DLT_Infection (Pneumonia)': 0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': 0.0,\n",
       "     'DLT_Nephrological': 0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': -0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': -0.0,\n",
       "     'N-category_0': -0.0,\n",
       "     'N-category_1': 0.0,\n",
       "     'N-category_2': -0.00020670124524309173,\n",
       "     'N-category_3': -0.0,\n",
       "     'Pathological Grade_0': -0.04409378674363995,\n",
       "     'Pathological Grade_1': 0.0,\n",
       "     'Pathological Grade_2': 0.0,\n",
       "     'Pathological Grade_3': -0.0034450122303017446,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': -0.0,\n",
       "     'T-category_1': -0.009219685978413737,\n",
       "     'T-category_2': 0.0,\n",
       "     'T-category_3': 0.0,\n",
       "     'T-category_4': -0.0,\n",
       "     'White/Caucasion': -0.0,\n",
       "     'age': -0.005218083856172769,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': 0.0,\n",
       "     'gender': 0.0,\n",
       "     'hpv': 0.0,\n",
       "     'packs_per_year': 0.001419759196486126,\n",
       "     'subsite_BOT': 0.0,\n",
       "     'subsite_GPS': -0.0,\n",
       "     'subsite_NOS': -0.021947148656893012,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': -0.0,\n",
       "     'total_dose': -0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.0005125260888066749,\n",
       "     'DLT_Gastrointestinal': 0.0014215902684479812,\n",
       "     'DLT_Hematological': 0.0004902065326220132,\n",
       "     'DLT_Neurological': 0.0006756476396716024,\n",
       "     'DLT_Other': -0.00032781633263892073},\n",
       "    'dlt2': {'DLT_Dermatological 2': 0.0,\n",
       "     'DLT_Gastrointestinal 2': -0.0,\n",
       "     'DLT_Hematological 2': 0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': -0.0},\n",
       "    'pd': {'CR Primary': -0.0007049903536652396,\n",
       "     'PR Primary': 2.590846288034722e-06,\n",
       "     'SD Primary': -1.7322843031720485e-06},\n",
       "    'nd': {'CR Nodal': 0.00018998724697269023,\n",
       "     'PR Nodal': 0.00033200774925293557,\n",
       "     'SD Nodal': -1.2520166423286885e-05},\n",
       "    'cc': {'cc_none': -0.0002456386880266172,\n",
       "     'cc_platinum': 0.004481929102405137,\n",
       "     'cc_cetuximab': -0.00018413361609975645,\n",
       "     'cc_others': -0.00017383340413331012},\n",
       "    'modifications': {'no_dose_adjustment': 0.0006649945584624676,\n",
       "     'dose_modified': 0.0,\n",
       "     'dose_delayed': -0.0,\n",
       "     'dose_cancelled': -0.0,\n",
       "     'dose_delayed_&_modified': 0.0,\n",
       "     'regiment_modification': 0.0}},\n",
       "   'propensity1': 0.995538,\n",
       "   'propensity2': 0.013968321,\n",
       "   'propensity3': 0.012806581,\n",
       "   'pd1': array([0.842369  , 0.1484497 , 0.00918121], dtype=float32),\n",
       "   'nd1': array([0.00371144, 0.9926466 , 0.00364201], dtype=float32),\n",
       "   'modifications': array([0.9502783 , 0.00953959, 0.00992931, 0.01008717, 0.00967079,\n",
       "          0.01049488], dtype=float32),\n",
       "   'dlt1': array([0.20015396, 0.1570275 , 0.21410224, 0.13205093, 0.1148096 ],\n",
       "         dtype=float32),\n",
       "   'pd1_5%': array([0.6742733 , 0.06332176, 0.00459627], dtype=float32),\n",
       "   'nd1_5%': array([0.00155881, 0.9882997 , 0.00156897], dtype=float32),\n",
       "   'modifications_5%': array([0.9306855 , 0.00493921, 0.0051583 , 0.0051613 , 0.00500843,\n",
       "          0.00555377], dtype=float32),\n",
       "   'dlt1_5%': array([0.11711909, 0.09005927, 0.13396718, 0.06040456, 0.07100161],\n",
       "         dtype=float32),\n",
       "   'pd1_95%': array([0.93017894, 0.3118802 , 0.01222178], dtype=float32),\n",
       "   'nd1_95%': array([0.00575776, 0.9968722 , 0.00593009], dtype=float32),\n",
       "   'modifications_95%': array([0.97417897, 0.01354055, 0.01382087, 0.01409342, 0.01348116,\n",
       "          0.01469503], dtype=float32),\n",
       "   'dlt1_95%': array([0.23607704, 0.23151664, 0.31314525, 0.18384899, 0.20225583],\n",
       "         dtype=float32),\n",
       "   'pd2': array([9.9924576e-01, 3.7523708e-04, 3.7905952e-04], dtype=float32),\n",
       "   'nd2': array([0.8058619 , 0.18891177, 0.00522636], dtype=float32),\n",
       "   'cc_type': array([0.06264507, 0.8473813 , 0.04667044, 0.04330324], dtype=float32),\n",
       "   'dlt2': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_5%': array([9.9665064e-01, 7.2920993e-05, 7.3816482e-05], dtype=float32),\n",
       "   'nd2_5%': array([0.62753594, 0.05508677, 0.00214985], dtype=float32),\n",
       "   'cc_type_5%': array([0.02308815, 0.7264191 , 0.01421419, 0.0148008 ], dtype=float32),\n",
       "   'dlt2_5%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_95%': array([0.99985325, 0.00166358, 0.00168585], dtype=float32),\n",
       "   'nd2_95%': array([0.9414297 , 0.36752552, 0.01175368], dtype=float32),\n",
       "   'cc_type_95%': array([0.10905386, 0.94789684, 0.0890645 , 0.08081819], dtype=float32),\n",
       "   'dlt2_95%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'outcomes': array([0.8625792 , 0.07931385, 0.21166976, 0.889929  ], dtype=float32),\n",
       "   'outcomes_5%': array([0.84099334, 0.04354819, 0.11172354, 0.87789464], dtype=float32),\n",
       "   'outcomes_95%': array([0.9093651 , 0.09700789, 0.2518262 , 0.92816514], dtype=float32),\n",
       "   'OS (Calculated)': 334.78613,\n",
       "   'Locoregional control (Time)': 1126.4114,\n",
       "   'FDM (months)': 2116.9756,\n",
       "   'time_to_event': 43.88755,\n",
       "   'survival_curves': {'OS (Calculated)': [0.999,\n",
       "     0.994,\n",
       "     0.987,\n",
       "     0.98,\n",
       "     0.974,\n",
       "     0.966,\n",
       "     0.959,\n",
       "     0.951,\n",
       "     0.942,\n",
       "     0.934,\n",
       "     0.925],\n",
       "    'Locoregional control (Time)': [0.998,\n",
       "     0.991,\n",
       "     0.984,\n",
       "     0.976,\n",
       "     0.97,\n",
       "     0.963,\n",
       "     0.957,\n",
       "     0.951,\n",
       "     0.945,\n",
       "     0.94,\n",
       "     0.934],\n",
       "    'FDM (months)': [1.0,\n",
       "     0.997,\n",
       "     0.992,\n",
       "     0.987,\n",
       "     0.983,\n",
       "     0.978,\n",
       "     0.974,\n",
       "     0.97,\n",
       "     0.965,\n",
       "     0.961,\n",
       "     0.957],\n",
       "    'time_to_event': [0.996,\n",
       "     0.932,\n",
       "     0.844,\n",
       "     0.762,\n",
       "     0.689,\n",
       "     0.624,\n",
       "     0.567,\n",
       "     0.517,\n",
       "     0.473,\n",
       "     0.434,\n",
       "     0.4],\n",
       "    'times': [1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60]},\n",
       "   'OS (Calculated)(4yr)': 0.942,\n",
       "   'Locoregional control (Time)(4yr)': 0.945,\n",
       "   'FDM (months)(4yr)': 0.965,\n",
       "   'time_to_event(4yr)': 0.473},\n",
       "  'imitation': {'decision1': 0.995538,\n",
       "   'decision2': 0.013968321,\n",
       "   'decision3': 0.43196642,\n",
       "   'decision1_attention': {'step': 0,\n",
       "    'model': 'imitation',\n",
       "    'range': [-0.004109903455914532, 0.004785101147933047],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': 0.003485457556594306,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': -0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': -0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': -0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': 0.0,\n",
       "     '5A_ipsi': 0.0,\n",
       "     '5B_contra': 0.0,\n",
       "     '5B_ipsi': 0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': 0.0,\n",
       "     'AJCC_1': 0.0,\n",
       "     'AJCC_2': 0.004785101147933047,\n",
       "     'AJCC_3': -0.0,\n",
       "     'AJCC_4': 0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': 0.0,\n",
       "     'Aspiration rate Pre-therapy': -0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': -0.0,\n",
       "     'DLT_Nephrological': -0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': -0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': 0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': -0.0,\n",
       "     'N-category_2': 0.001974120726357221,\n",
       "     'N-category_3': 0.0,\n",
       "     'Pathological Grade_0': -0.0012098212523551975,\n",
       "     'Pathological Grade_1': -0.0,\n",
       "     'Pathological Grade_2': 0.0,\n",
       "     'Pathological Grade_3': 0.0021990766763030586,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': -0.0,\n",
       "     'T-category_1': 0.00460148747072783,\n",
       "     'T-category_2': -0.0,\n",
       "     'T-category_3': 0.0,\n",
       "     'T-category_4': -0.0,\n",
       "     'White/Caucasion': 0.0,\n",
       "     'age': -0.004109903455914532,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': 0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': -0.0,\n",
       "     'packs_per_year': 0.00023354957346195666,\n",
       "     'subsite_BOT': -0.0,\n",
       "     'subsite_GPS': 0.0,\n",
       "     'subsite_NOS': 0.004622304961935888,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': 0.0,\n",
       "     'total_dose': -0.0},\n",
       "    'dlt1': {'DLT_Dermatological': -0.0,\n",
       "     'DLT_Gastrointestinal': 0.0,\n",
       "     'DLT_Hematological': 0.0,\n",
       "     'DLT_Neurological': 0.0,\n",
       "     'DLT_Other': 0.0},\n",
       "    'dlt2': {'DLT_Dermatological 2': 0.0,\n",
       "     'DLT_Gastrointestinal 2': -0.0,\n",
       "     'DLT_Hematological 2': -0.0,\n",
       "     'DLT_Neurological 2': 0.0,\n",
       "     'DLT_Other 2': 0.0},\n",
       "    'pd': {'CR Primary': -0.0, 'PR Primary': 0.0, 'SD Primary': -0.0},\n",
       "    'nd': {'CR Nodal': 0.0, 'PR Nodal': 0.0, 'SD Nodal': -0.0},\n",
       "    'cc': {'cc_none': -0.0,\n",
       "     'cc_platinum': 0.0,\n",
       "     'cc_cetuximab': -0.0,\n",
       "     'cc_others': 0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0,\n",
       "     'dose_modified': 0.0,\n",
       "     'dose_delayed': -0.0,\n",
       "     'dose_cancelled': 0.0,\n",
       "     'dose_delayed_&_modified': 0.0,\n",
       "     'regiment_modification': 0.0}},\n",
       "   'decision2_attention': {'step': 1,\n",
       "    'model': 'imitation',\n",
       "    'range': [-0.024945910483907353, 0.02597606194090365],\n",
       "    'baseline': {'1A_contra': 0.0,\n",
       "     '1A_ipsi': 0.0,\n",
       "     '1B_contra': 0.0036370490765720055,\n",
       "     '1B_ipsi': 0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': 0.0,\n",
       "     '2B_contra': 0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': 0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': 0.0,\n",
       "     '4_ipsi': 0.0,\n",
       "     '5A_contra': -0.0,\n",
       "     '5A_ipsi': -0.0,\n",
       "     '5B_contra': -0.0,\n",
       "     '5B_ipsi': -0.0,\n",
       "     '6_contra': 0.0,\n",
       "     '6_ipsi': -0.0,\n",
       "     'AJCC_1': -0.0,\n",
       "     'AJCC_2': -0.013989939477224099,\n",
       "     'AJCC_3': 0.0,\n",
       "     'AJCC_4': -0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': -0.0,\n",
       "     'Aspiration rate Pre-therapy': 0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': 0.0,\n",
       "     'DLT_Nephrological': 0.0,\n",
       "     'DLT_Nephrological 2': -0.0,\n",
       "     'DLT_Vascular': 0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': -0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': 0.0,\n",
       "     'N-category_2': -0.004669142996609577,\n",
       "     'N-category_3': -0.0,\n",
       "     'Pathological Grade_0': 0.019147489785996858,\n",
       "     'Pathological Grade_1': 0.0,\n",
       "     'Pathological Grade_2': -0.0,\n",
       "     'Pathological Grade_3': 0.00197983266077653,\n",
       "     'Pathological Grade_4': 0.0,\n",
       "     'RPLN_contra': -0.0,\n",
       "     'RPLN_ipsi': 0.0,\n",
       "     'T-category_1': -0.014600147216053393,\n",
       "     'T-category_2': -0.0,\n",
       "     'T-category_3': -0.0,\n",
       "     'T-category_4': 0.0,\n",
       "     'White/Caucasion': -0.0,\n",
       "     'age': 0.02597606194090365,\n",
       "     'bilateral': -0.0,\n",
       "     'dose_fraction': -0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': 0.0,\n",
       "     'packs_per_year': -0.0015357492965945364,\n",
       "     'subsite_BOT': 0.0,\n",
       "     'subsite_GPS': -0.0,\n",
       "     'subsite_NOS': -0.024945910483907353,\n",
       "     'subsite_Soft palate': 0.0,\n",
       "     'subsite_Tonsil': -0.0,\n",
       "     'total_dose': 0.0},\n",
       "    'dlt1': {'DLT_Dermatological': 0.0003123969840314548,\n",
       "     'DLT_Gastrointestinal': -0.002130786102911419,\n",
       "     'DLT_Hematological': -0.00014736581043534608,\n",
       "     'DLT_Neurological': 0.00018576983384973662,\n",
       "     'DLT_Other': -0.0013232931339040195},\n",
       "    'dlt2': {'DLT_Dermatological 2': -0.0,\n",
       "     'DLT_Gastrointestinal 2': 0.0,\n",
       "     'DLT_Hematological 2': -0.0,\n",
       "     'DLT_Neurological 2': -0.0,\n",
       "     'DLT_Other 2': -0.0},\n",
       "    'pd': {'CR Primary': 0.004557181868663063,\n",
       "     'PR Primary': -4.7719315901836484e-05,\n",
       "     'SD Primary': 2.9811160223551274e-05},\n",
       "    'nd': {'CR Nodal': -0.0, 'PR Nodal': -0.0, 'SD Nodal': 0.0},\n",
       "    'cc': {'cc_none': 0.004336277595218634,\n",
       "     'cc_platinum': -0.0,\n",
       "     'cc_cetuximab': 0.0,\n",
       "     'cc_others': 0.0},\n",
       "    'modifications': {'no_dose_adjustment': 0.0003772209318808592,\n",
       "     'dose_modified': -0.0,\n",
       "     'dose_delayed': 0.0,\n",
       "     'dose_cancelled': 0.0,\n",
       "     'dose_delayed_&_modified': -0.0,\n",
       "     'regiment_modification': -0.0}},\n",
       "   'decision3_attention': {'step': 2,\n",
       "    'model': 'imitation',\n",
       "    'range': [-0.03159565189252503, 0.10831582967236422],\n",
       "    'baseline': {'1A_contra': -0.0,\n",
       "     '1A_ipsi': -0.0,\n",
       "     '1B_contra': 0.07566189637954263,\n",
       "     '1B_ipsi': -0.0,\n",
       "     '2A_contra': 0.0,\n",
       "     '2A_ipsi': 0.0,\n",
       "     '2B_contra': -0.0,\n",
       "     '2B_ipsi': 0.0,\n",
       "     '3_contra': 0.0,\n",
       "     '3_ipsi': 0.0,\n",
       "     '4_contra': 0.0,\n",
       "     '4_ipsi': -0.0,\n",
       "     '5A_contra': 0.0,\n",
       "     '5A_ipsi': 0.0,\n",
       "     '5B_contra': -0.0,\n",
       "     '5B_ipsi': 0.0,\n",
       "     '6_contra': -0.0,\n",
       "     '6_ipsi': -0.0,\n",
       "     'AJCC_1': -0.0,\n",
       "     'AJCC_2': 0.032997257332234686,\n",
       "     'AJCC_3': 0.0,\n",
       "     'AJCC_4': -0.0,\n",
       "     'African American/Black': -0.0,\n",
       "     'Asian': -0.0,\n",
       "     'Aspiration rate Pre-therapy': 0.0,\n",
       "     'DLT_Infection (Pneumonia)': -0.0,\n",
       "     'DLT_Infection (Pneumonia) 2': -0.0,\n",
       "     'DLT_Nephrological': -0.0,\n",
       "     'DLT_Nephrological 2': 0.0,\n",
       "     'DLT_Vascular': 0.0,\n",
       "     'DLT_Vascular 2': 0.0,\n",
       "     'Hispanic/Latino': -0.0,\n",
       "     'N-category_0': 0.0,\n",
       "     'N-category_1': -0.0,\n",
       "     'N-category_2': 0.043942255677128374,\n",
       "     'N-category_3': 0.0,\n",
       "     'Pathological Grade_0': 0.050046376227652324,\n",
       "     'Pathological Grade_1': -0.0,\n",
       "     'Pathological Grade_2': -0.0,\n",
       "     'Pathological Grade_3': 0.024573770064406694,\n",
       "     'Pathological Grade_4': -0.0,\n",
       "     'RPLN_contra': 0.0,\n",
       "     'RPLN_ipsi': 0.0,\n",
       "     'T-category_1': -0.03159565189252503,\n",
       "     'T-category_2': 0.0,\n",
       "     'T-category_3': -0.0,\n",
       "     'T-category_4': 0.0,\n",
       "     'White/Caucasion': 0.0,\n",
       "     'age': 0.05919173484027567,\n",
       "     'bilateral': 0.0,\n",
       "     'dose_fraction': -0.0,\n",
       "     'gender': -0.0,\n",
       "     'hpv': -0.0,\n",
       "     'packs_per_year': -0.0038011488292462384,\n",
       "     'subsite_BOT': -0.0,\n",
       "     'subsite_GPS': -0.0,\n",
       "     'subsite_NOS': 0.10831582967236422,\n",
       "     'subsite_Soft palate': -0.0,\n",
       "     'subsite_Tonsil': 0.0,\n",
       "     'total_dose': 0.0},\n",
       "    'dlt1': {'DLT_Dermatological': 0.0007194178439532358,\n",
       "     'DLT_Gastrointestinal': -0.004679710388756979,\n",
       "     'DLT_Hematological': 0.0029679210251807387,\n",
       "     'DLT_Neurological': -0.002422036474568903,\n",
       "     'DLT_Other': -0.0019237045423794218},\n",
       "    'dlt2': {'DLT_Dermatological 2': -0.0,\n",
       "     'DLT_Gastrointestinal 2': 0.0,\n",
       "     'DLT_Hematological 2': 0.0,\n",
       "     'DLT_Neurological 2': -0.0,\n",
       "     'DLT_Other 2': -0.0},\n",
       "    'pd': {'CR Primary': 0.024158463565097196,\n",
       "     'PR Primary': 1.3373123409246148e-06,\n",
       "     'SD Primary': 1.8298587933992195e-06},\n",
       "    'nd': {'CR Nodal': 0.022265842651858696,\n",
       "     'PR Nodal': -8.313901940058381e-06,\n",
       "     'SD Nodal': -1.1960012898513658e-05},\n",
       "    'cc': {'cc_none': 0.00011776018641583014,\n",
       "     'cc_platinum': 0.013667381839160428,\n",
       "     'cc_cetuximab': 0.00023843458300660107,\n",
       "     'cc_others': -0.00024033736222348553},\n",
       "    'modifications': {'no_dose_adjustment': 0.01156499301750675,\n",
       "     'dose_modified': -0.0,\n",
       "     'dose_delayed': 0.0,\n",
       "     'dose_cancelled': 0.0,\n",
       "     'dose_delayed_&_modified': -0.0,\n",
       "     'regiment_modification': -0.0}},\n",
       "   'propensity1': 0.995538,\n",
       "   'propensity2': 0.013968321,\n",
       "   'propensity3': 0.012806581,\n",
       "   'pd1': array([0.842369  , 0.1484497 , 0.00918121], dtype=float32),\n",
       "   'nd1': array([0.00371144, 0.9926466 , 0.00364201], dtype=float32),\n",
       "   'modifications': array([0.9502783 , 0.00953959, 0.00992931, 0.01008717, 0.00967079,\n",
       "          0.01049488], dtype=float32),\n",
       "   'dlt1': array([0.20015396, 0.1570275 , 0.21410224, 0.13205093, 0.1148096 ],\n",
       "         dtype=float32),\n",
       "   'pd1_5%': array([0.75168407, 0.0776378 , 0.00445998], dtype=float32),\n",
       "   'nd1_5%': array([0.0011605 , 0.98771363, 0.00115802], dtype=float32),\n",
       "   'modifications_5%': array([0.93952495, 0.00493329, 0.00513218, 0.00529594, 0.0050069 ,\n",
       "          0.0053319 ], dtype=float32),\n",
       "   'dlt1_5%': array([0.11249033, 0.07769656, 0.14323474, 0.05013303, 0.06383739],\n",
       "         dtype=float32),\n",
       "   'pd1_95%': array([0.917038  , 0.24052046, 0.01411503], dtype=float32),\n",
       "   'nd1_95%': array([0.00640472, 0.9976815 , 0.00588048], dtype=float32),\n",
       "   'modifications_95%': array([0.97413486, 0.0112853 , 0.01187262, 0.01262772, 0.01161858,\n",
       "          0.01353248], dtype=float32),\n",
       "   'dlt1_95%': array([0.26904267, 0.16850732, 0.28025618, 0.16835067, 0.15944275],\n",
       "         dtype=float32),\n",
       "   'pd2': array([9.9924576e-01, 3.7523708e-04, 3.7905952e-04], dtype=float32),\n",
       "   'nd2': array([0.8058619 , 0.18891177, 0.00522636], dtype=float32),\n",
       "   'cc_type': array([0.06264507, 0.8473813 , 0.04667044, 0.04330324], dtype=float32),\n",
       "   'dlt2': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_5%': array([9.9893814e-01, 1.2988959e-04, 1.3223891e-04], dtype=float32),\n",
       "   'nd2_5%': array([0.6734665 , 0.09457073, 0.00142944], dtype=float32),\n",
       "   'cc_type_5%': array([0.02443074, 0.71561986, 0.01699845, 0.01620847], dtype=float32),\n",
       "   'dlt2_5%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'pd2_95%': array([9.9973798e-01, 5.3237641e-04, 5.2939414e-04], dtype=float32),\n",
       "   'nd2_95%': array([0.90385485, 0.32168645, 0.00695306], dtype=float32),\n",
       "   'cc_type_95%': array([0.10638274, 0.9399119 , 0.08996756, 0.08527745], dtype=float32),\n",
       "   'dlt2_95%': array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "   'outcomes': array([0.8625792 , 0.07931385, 0.21166976, 0.889929  ], dtype=float32),\n",
       "   'outcomes_5%': array([0.8100013 , 0.04808347, 0.12273517, 0.83474404], dtype=float32),\n",
       "   'outcomes_95%': array([0.8972604 , 0.11414426, 0.2617458 , 0.93200326], dtype=float32),\n",
       "   'OS (Calculated)': 334.78613,\n",
       "   'Locoregional control (Time)': 1126.4114,\n",
       "   'FDM (months)': 2116.9756,\n",
       "   'time_to_event': 43.88755,\n",
       "   'survival_curves': {'OS (Calculated)': [0.999,\n",
       "     0.994,\n",
       "     0.987,\n",
       "     0.98,\n",
       "     0.974,\n",
       "     0.966,\n",
       "     0.959,\n",
       "     0.951,\n",
       "     0.942,\n",
       "     0.934,\n",
       "     0.925],\n",
       "    'Locoregional control (Time)': [0.998,\n",
       "     0.991,\n",
       "     0.984,\n",
       "     0.976,\n",
       "     0.97,\n",
       "     0.963,\n",
       "     0.957,\n",
       "     0.951,\n",
       "     0.945,\n",
       "     0.94,\n",
       "     0.934],\n",
       "    'FDM (months)': [1.0,\n",
       "     0.997,\n",
       "     0.992,\n",
       "     0.987,\n",
       "     0.983,\n",
       "     0.978,\n",
       "     0.974,\n",
       "     0.97,\n",
       "     0.965,\n",
       "     0.961,\n",
       "     0.957],\n",
       "    'time_to_event': [0.996,\n",
       "     0.932,\n",
       "     0.844,\n",
       "     0.762,\n",
       "     0.689,\n",
       "     0.624,\n",
       "     0.567,\n",
       "     0.517,\n",
       "     0.473,\n",
       "     0.434,\n",
       "     0.4],\n",
       "    'times': [1, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60]},\n",
       "   'OS (Calculated)(4yr)': 0.942,\n",
       "   'Locoregional control (Time)(4yr)': 0.945,\n",
       "   'FDM (months)(4yr)': 0.965,\n",
       "   'time_to_event(4yr)': 0.473}},\n",
       " 'embeddings': {0: {'neighbors': array([   7, 5031]),\n",
       "   'similarities': array([0.95356761, 0.24504416]),\n",
       "   'embedding': array([0.55325407, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.3157454 , 0.        , 0.17408147, 0.        ,\n",
       "          1.1797255 , 0.22433536, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.11817072,\n",
       "          0.5551307 , 0.07971043, 0.        , 0.07823416, 0.20531   ,\n",
       "          0.3928459 , 0.        , 0.20061368, 0.        , 0.        ,\n",
       "          0.7239652 , 0.        , 0.7141015 , 0.        , 0.        ,\n",
       "          0.        , 0.43246946, 0.        , 0.55042744, 0.6764833 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.9245374 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.9359817 ,\n",
       "          0.9088998 , 0.17342664, 0.10089345, 0.2788201 , 0.18940553,\n",
       "          0.        , 0.05579183, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.1845892 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.05170406, 0.38246566, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.78146034, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.45816308,\n",
       "          0.        , 0.05752914, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.2428394 , 0.13383815,\n",
       "          0.        , 0.        , 0.9161899 , 0.        , 0.10948328,\n",
       "          0.        , 0.11257773, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.622284  , 0.1719889 , 0.        , 0.3768899 , 1.1358116 ,\n",
       "          0.03854277, 0.        , 0.        , 0.56293327, 0.2889545 ,\n",
       "          0.30992192, 0.6898048 , 0.        , 0.        , 0.7395719 ,\n",
       "          0.        , 0.        , 0.74407524, 0.4503736 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.19658402, 0.        ,\n",
       "          0.        , 0.        , 0.60798764, 0.        , 0.        ,\n",
       "          1.2656218 , 0.78070873, 0.        , 0.37121972, 0.9526637 ,\n",
       "          0.        , 0.8799438 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.28230634,\n",
       "          0.        , 0.        , 0.        , 0.06946197, 0.        ,\n",
       "          1.2767639 , 0.80088806, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.81870294, 0.        , 0.        , 0.48251078,\n",
       "          0.5540918 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.54324484, 0.7029103 , 0.        , 0.18304099, 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.016866  , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.23766007, 0.        , 0.        ,\n",
       "          0.4233302 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.3696127 , 0.        , 0.        , 0.85010093, 0.        ,\n",
       "          0.        , 0.        , 0.00469098, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.29226688,\n",
       "          0.        , 1.1356924 , 0.        , 0.05543861, 0.        ,\n",
       "          1.127609  , 0.4895718 , 1.3036411 , 0.        , 0.09521607,\n",
       "          0.        , 0.        , 0.01600065, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.07089238, 0.45068672, 0.        , 0.14245495, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.51245147, 0.1756721 , 0.        , 0.        ,\n",
       "          0.00311339, 0.2738367 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.01406296,\n",
       "          0.        , 0.1656406 , 0.04442153, 0.        , 0.        ,\n",
       "          0.        , 1.2742603 , 0.        , 0.        , 0.8005475 ,\n",
       "          0.76058453, 0.        , 0.        , 0.        , 0.0987328 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.31058833, 0.40706405, 0.        , 1.0511878 ,\n",
       "          0.11853816, 0.46626693, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.87281924, 0.        , 0.34379163, 0.        ,\n",
       "          0.        , 0.        , 0.70936054, 0.        , 0.8529599 ,\n",
       "          0.        , 0.2948712 , 0.        , 0.14003015, 0.42919493,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.509087  , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.31764728, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.25919148, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.887616  , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.66724414, 0.        ,\n",
       "          0.        , 0.        , 0.63360214, 0.        , 0.03946324,\n",
       "          0.4874157 , 0.5148073 , 0.        , 0.5868694 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.3359855 , 0.        ,\n",
       "          1.1971967 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.63211256, 0.14059325, 0.        ,\n",
       "          0.8792395 , 0.34233412, 0.07274755, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.77040267, 0.        , 0.66956925,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.66299444, 0.        , 0.08815232, 0.        , 0.        ,\n",
       "          0.        , 0.45417565, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.07841773,\n",
       "          0.        , 0.96102697, 0.05567788, 0.        , 0.42269963,\n",
       "          0.65385634, 0.21425548, 0.        , 0.34279102, 0.8015578 ,\n",
       "          0.        , 0.        , 0.1370183 , 0.30477634, 0.        ,\n",
       "          0.63024616, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.7124784 , 0.        , 0.9344954 , 0.        , 0.        ,\n",
       "          0.        , 0.15029365, 0.        , 0.        , 0.526105  ,\n",
       "          0.2405406 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.0709898 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.12441551, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.4548655 ,\n",
       "          0.        , 0.5691438 , 0.93965507, 0.        , 0.        ,\n",
       "          0.8937075 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.73796546, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.8485669 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.2054453 , 0.        , 0.        ,\n",
       "          0.35230365, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.69406414, 0.87076104, 0.4342267 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.09782356, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.82419574, 0.        , 0.        , 0.        , 0.5714981 ,\n",
       "          0.01787343, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.06770786, 0.66723675, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.28782254, 0.        ,\n",
       "          0.        , 0.        , 0.14524236, 0.        , 0.        ,\n",
       "          0.13416222, 0.16813919, 0.        , 0.18855625, 0.7667756 ,\n",
       "          0.9364942 , 0.3508949 , 0.4334847 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.66778016, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.08679407, 0.35589564, 0.        , 0.        , 0.01084214,\n",
       "          0.        , 0.5658728 , 0.4846626 , 0.        , 0.84349424,\n",
       "          0.08068177, 0.15907553, 0.        , 0.        , 0.2721476 ,\n",
       "          0.        , 0.        , 0.66499627, 0.        , 0.47502226,\n",
       "          0.        , 0.        , 0.        , 0.06833939, 0.        ,\n",
       "          0.        , 0.2162569 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.42720723, 0.        , 0.        ,\n",
       "          0.05922335, 0.        , 0.        , 0.45188364, 0.        ,\n",
       "          0.11509684, 0.        , 0.48018456, 0.        , 0.41535407,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.2503126 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.12823494,\n",
       "          0.        , 0.        , 0.21508038, 0.59563386, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.22686377,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.5391673 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.76037914, 0.12399118,\n",
       "          0.        , 0.        , 0.20371544, 0.26683146, 0.9815746 ,\n",
       "          0.3456674 , 0.25730416, 0.11165349, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.59317887, 0.9914176 , 0.        ,\n",
       "          0.        , 0.7868648 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.87295103, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.8097177 , 0.84597445, 0.        ,\n",
       "          0.        , 0.66171026, 0.54298174, 0.19824299, 0.        ,\n",
       "          0.        , 0.        , 0.29518637, 0.        , 0.        ,\n",
       "          0.571768  , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.5466339 , 1.5161558 , 0.01114013,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.04629884, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.07787111, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.2715552 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.04762605, 0.        , 0.46286824, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.4267468 , 0.        , 0.        , 0.54574394, 0.42058164,\n",
       "          0.2729732 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.5505929 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.152205  , 0.4279403 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.6372547 , 0.        ,\n",
       "          0.        , 0.        , 1.0175774 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.90170527, 0.03504306,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.68247294,\n",
       "          0.        , 0.8202082 , 0.51268303, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.29010665,\n",
       "          0.        , 0.        , 0.23540172, 0.        , 0.        ,\n",
       "          1.267251  , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.1437031 , 0.        ,\n",
       "          0.        , 0.        , 0.15805192, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.34036928, 0.        , 0.14286003,\n",
       "          0.        , 0.5273643 , 0.        , 0.16144636, 0.        ,\n",
       "          0.29403332, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.50811404, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.69236624,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.28460592, 0.        , 0.1780029 , 0.5583871 , 0.6643434 ,\n",
       "          1.2191741 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.14758164, 0.        , 0.        , 0.        , 0.65857655,\n",
       "          0.14331621, 0.5584558 , 0.2449269 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.3752869 , 0.        , 0.        ,\n",
       "          0.        , 0.24549694, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.18598714,\n",
       "          0.23109454, 0.33853915, 0.33123568, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.62097555, 0.        ,\n",
       "          0.2236216 , 0.47131032, 0.        , 0.10146417, 0.        ,\n",
       "          0.        , 0.7630725 , 0.        , 0.        , 0.6780339 ,\n",
       "          0.5344776 , 0.4491956 , 0.8505412 , 0.9421258 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.7788251 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.47251713, 0.        ,\n",
       "          0.14038575, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.14799371, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.0898971 , 0.        ,\n",
       "          0.        , 0.47303373, 0.        , 0.7690594 , 0.        ,\n",
       "          1.0276308 , 0.        , 0.        , 0.        , 0.6409369 ,\n",
       "          0.        , 0.        , 0.20385714, 0.        , 0.        ,\n",
       "          0.21686733, 0.        , 0.        , 0.        , 0.        ],\n",
       "         dtype=float32),\n",
       "   'pca': array([ 0.22397435, -0.5989016 ], dtype=float32),\n",
       "   'mahalanobisDistance': 4482342760.849156},\n",
       "  1: {'neighbors': array([   7, 5031]),\n",
       "   'similarities': array([0.6941619 , 0.28216994]),\n",
       "   'embedding': array([0.5037832 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.30951428, 0.        , 0.12050188, 0.        ,\n",
       "          1.1873443 , 0.1815965 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.03090297,\n",
       "          0.48520654, 0.        , 0.        , 0.        , 0.23577447,\n",
       "          0.35537332, 0.        , 0.12028404, 0.        , 0.        ,\n",
       "          0.6441958 , 0.        , 0.69952273, 0.        , 0.        ,\n",
       "          0.        , 0.3960546 , 0.        , 0.51419014, 0.60945344,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.9589351 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.9534846 ,\n",
       "          0.84384996, 0.1717466 , 0.08620262, 0.28382644, 0.10613541,\n",
       "          0.        , 0.04247797, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.26565683, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.01761482, 0.38816407, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.7560682 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.44776458,\n",
       "          0.        , 0.06370553, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.11944693, 0.16718283,\n",
       "          0.        , 0.        , 0.9076791 , 0.        , 0.09883402,\n",
       "          0.        , 0.1039441 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.6360257 , 0.12276172, 0.        , 0.36234826, 1.1616815 ,\n",
       "          0.01981426, 0.        , 0.        , 0.64933836, 0.30459026,\n",
       "          0.3058586 , 0.6596654 , 0.        , 0.        , 0.66429853,\n",
       "          0.        , 0.        , 0.71227777, 0.4305799 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.18155357, 0.        ,\n",
       "          0.        , 0.        , 0.578701  , 0.        , 0.        ,\n",
       "          1.2869109 , 0.7465487 , 0.        , 0.3340248 , 0.94001365,\n",
       "          0.        , 0.8678712 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.32183135,\n",
       "          0.        , 0.        , 0.        , 0.09935722, 0.        ,\n",
       "          1.2624038 , 0.6998548 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.7647704 , 0.        , 0.        , 0.5004855 ,\n",
       "          0.5248417 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.5816818 , 0.6543003 , 0.        , 0.21410449, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.9610559 , 0.        ,\n",
       "          0.        , 0.03831384, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.27441558, 0.        , 0.        ,\n",
       "          0.4101345 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          1.3715433 , 0.        , 0.        , 0.87491083, 0.        ,\n",
       "          0.        , 0.        , 0.01688067, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.36725155,\n",
       "          0.        , 1.1091319 , 0.        , 0.14928259, 0.        ,\n",
       "          1.112274  , 0.47067517, 1.2951963 , 0.        , 0.04623086,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.08327216, 0.46917966, 0.        , 0.04982967, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.57787675, 0.1711884 , 0.        , 0.        ,\n",
       "          0.01934528, 0.21266674, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.15202294, 0.04119083, 0.        , 0.03088228,\n",
       "          0.        , 1.2486901 , 0.        , 0.        , 0.8033916 ,\n",
       "          0.7252158 , 0.        , 0.        , 0.        , 0.12618928,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.29467916, 0.32756805, 0.        , 0.9951453 ,\n",
       "          0.06541523, 0.48287922, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.8439445 , 0.        , 0.3438338 , 0.        ,\n",
       "          0.        , 0.        , 0.6487351 , 0.        , 0.8622724 ,\n",
       "          0.        , 0.25154728, 0.        , 0.08203458, 0.433522  ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.48661977, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.01474097, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.34299383, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.22213882, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.8952579 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.6135096 , 0.        ,\n",
       "          0.        , 0.        , 0.62415606, 0.        , 0.00218689,\n",
       "          0.47303453, 0.5269452 , 0.        , 0.52687174, 0.        ,\n",
       "          0.        , 0.03547707, 0.        , 1.3163359 , 0.        ,\n",
       "          1.1587064 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.57710546, 0.10837174, 0.        ,\n",
       "          0.84712195, 0.391537  , 0.1298357 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.75036085, 0.        , 0.7088293 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.6744501 , 0.        , 0.06951024, 0.        , 0.        ,\n",
       "          0.        , 0.36284253, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.13284367,\n",
       "          0.        , 0.931651  , 0.        , 0.        , 0.4217566 ,\n",
       "          0.6199917 , 0.23946872, 0.        , 0.4486735 , 0.73417395,\n",
       "          0.        , 0.        , 0.15653305, 0.37765792, 0.        ,\n",
       "          0.55851835, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.6675505 , 0.        , 0.9170702 , 0.07007946, 0.        ,\n",
       "          0.        , 0.14930752, 0.        , 0.        , 0.47309828,\n",
       "          0.15841699, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.10182256, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.22194812, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.4486823 ,\n",
       "          0.        , 0.4733725 , 0.9055457 , 0.        , 0.        ,\n",
       "          0.8904008 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.71759534, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.80534273, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.1857169 , 0.        , 0.        ,\n",
       "          0.2772229 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.6610322 , 0.83699036, 0.45116514, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.04116438, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.8128009 , 0.        , 0.        , 0.        , 0.6162545 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.11987021, 0.6568012 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.27072343, 0.        ,\n",
       "          0.        , 0.        , 0.1401071 , 0.        , 0.        ,\n",
       "          0.10914018, 0.03942445, 0.        , 0.18025875, 0.7635796 ,\n",
       "          0.9275226 , 0.28496066, 0.42502764, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.5728998 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.10207221, 0.35097304, 0.        , 0.        , 0.04008865,\n",
       "          0.        , 0.53029263, 0.50244445, 0.        , 0.82717204,\n",
       "          0.12904531, 0.12989378, 0.        , 0.        , 0.16375034,\n",
       "          0.        , 0.        , 0.66476774, 0.        , 0.48537174,\n",
       "          0.        , 0.        , 0.        , 0.00181824, 0.        ,\n",
       "          0.        , 0.21506493, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.39188117, 0.        , 0.        ,\n",
       "          0.0208516 , 0.        , 0.        , 0.46794635, 0.        ,\n",
       "          0.07756658, 0.        , 0.5330727 , 0.        , 0.4859076 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.2464701 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.08880779,\n",
       "          0.        , 0.        , 0.20879655, 0.5276687 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.16253155,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.45259473, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.75617415, 0.05502662,\n",
       "          0.        , 0.        , 0.25629067, 0.2615359 , 0.95539695,\n",
       "          0.39820105, 0.17472292, 0.0488999 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.6096726 , 0.9355397 , 0.        ,\n",
       "          0.        , 0.7772933 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.85933733, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.76644254, 0.84717935, 0.        ,\n",
       "          0.        , 0.69325066, 0.5290747 , 0.13909455, 0.        ,\n",
       "          0.        , 0.        , 0.27300566, 0.        , 0.        ,\n",
       "          0.6215275 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.47873825, 1.4873606 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.07918359, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.2898675 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.07188042, 0.        , 0.37504813, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.4751915 , 0.        , 0.        , 0.48543948, 0.3768197 ,\n",
       "          0.24686708, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.47827607, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.1573229 , 0.38221025, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.6243282 , 0.        ,\n",
       "          0.        , 0.        , 1.0604094 , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.9167217 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.65625733,\n",
       "          0.        , 0.8454753 , 0.52574414, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.27827704,\n",
       "          0.        , 0.        , 0.16136622, 0.        , 0.02075233,\n",
       "          1.2491474 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.0874208 , 0.        ,\n",
       "          0.        , 0.        , 0.15527968, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.29678944, 0.        , 0.10137197,\n",
       "          0.        , 0.5128064 , 0.        , 0.15079398, 0.        ,\n",
       "          0.26357633, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.4900997 , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.6729064 ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.24569143, 0.        , 0.10108614, 0.52978617, 0.67836815,\n",
       "          1.1840165 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.0858461 , 0.        , 0.        , 0.        , 0.6379785 ,\n",
       "          0.10018504, 0.56119555, 0.25968274, 0.        , 0.        ,\n",
       "          0.        , 0.        , 1.3774071 , 0.        , 0.        ,\n",
       "          0.        , 0.25163525, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.14273691,\n",
       "          0.17546424, 0.38373697, 0.32957512, 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.52527696, 0.        ,\n",
       "          0.24318346, 0.46673572, 0.        , 0.07233608, 0.        ,\n",
       "          0.        , 0.66960967, 0.        , 0.        , 0.68774897,\n",
       "          0.5357704 , 0.3808436 , 0.8406177 , 0.8639255 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.80281305, 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.41062975, 0.        ,\n",
       "          0.11667938, 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.17202464, 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.4680286 , 0.        , 0.7863468 , 0.        ,\n",
       "          1.065618  , 0.        , 0.        , 0.        , 0.6629753 ,\n",
       "          0.        , 0.        , 0.1840538 , 0.        , 0.        ,\n",
       "          0.15806101, 0.        , 0.        , 0.        , 0.        ],\n",
       "         dtype=float32),\n",
       "   'pca': array([ 0.35962078, -0.7819415 ], dtype=float32),\n",
       "   'mahalanobisDistance': 25270510.009303104},\n",
       "  2: {'neighbors': array([   7, 5031]),\n",
       "   'similarities': array([0.67973817, 0.26898146]),\n",
       "   'embedding': array([4.95101213e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.27539295e-01,\n",
       "          0.00000000e+00, 1.66606665e-01, 0.00000000e+00, 1.19384074e+00,\n",
       "          1.75076991e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.81210876e-01, 5.97826242e-01, 9.54648331e-02, 0.00000000e+00,\n",
       "          2.70307343e-02, 3.09567660e-01, 3.93621325e-01, 0.00000000e+00,\n",
       "          1.69771075e-01, 0.00000000e+00, 0.00000000e+00, 7.44531929e-01,\n",
       "          0.00000000e+00, 8.04150701e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.06541407e-01, 0.00000000e+00, 4.88499314e-01,\n",
       "          7.02815950e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 9.84166086e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 9.93791342e-01, 8.69621456e-01,\n",
       "          1.55929193e-01, 1.52184933e-01, 2.93384314e-01, 1.10414430e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.83073068e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          6.71392381e-02, 3.72317612e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.01835120e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          4.50823009e-01, 0.00000000e+00, 1.14564970e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.37427464e-01, 1.80244684e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 9.83406782e-01, 0.00000000e+00, 8.70237797e-02,\n",
       "          0.00000000e+00, 1.49559051e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.19283140e-01, 1.36761427e-01,\n",
       "          0.00000000e+00, 4.95315850e-01, 1.15681219e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.71614170e-01, 3.03016573e-01,\n",
       "          3.35657179e-01, 7.26109266e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          7.25879252e-01, 0.00000000e+00, 0.00000000e+00, 6.90471530e-01,\n",
       "          5.26672482e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 2.78785884e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 7.17421591e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.29037774e+00, 8.19283366e-01, 0.00000000e+00, 3.52002174e-01,\n",
       "          9.58096743e-01, 0.00000000e+00, 8.83016109e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.80896062e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.69159845e-01, 0.00000000e+00,\n",
       "          1.27772486e+00, 8.06861758e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.82824814e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.53182542e-01, 5.41231036e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.80881596e-01,\n",
       "          7.05491900e-01, 0.00000000e+00, 1.59471110e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.01698399e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.47092541e-02, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 3.64687443e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          4.76750433e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.42878544e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          9.33862865e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.49136502e-01,\n",
       "          0.00000000e+00, 1.08847606e+00, 0.00000000e+00, 8.62973258e-02,\n",
       "          0.00000000e+00, 1.11201560e+00, 3.92619371e-01, 1.34339786e+00,\n",
       "          0.00000000e+00, 1.65556818e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          4.51132655e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          9.49691832e-02, 5.47558069e-01, 0.00000000e+00, 1.70390576e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.61466014e-02, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.12838507e-01,\n",
       "          1.48438320e-01, 0.00000000e+00, 0.00000000e+00, 2.00844482e-02,\n",
       "          2.59676754e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.43099070e-01, 7.91417435e-02,\n",
       "          0.00000000e+00, 9.93061811e-03, 0.00000000e+00, 1.25667059e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.98368931e-01, 7.42676258e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.12606958e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.98282808e-01, 4.39020425e-01,\n",
       "          0.00000000e+00, 1.06412196e+00, 1.11534469e-01, 4.92932200e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          9.02213633e-01, 0.00000000e+00, 3.37531477e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.82732165e-01, 0.00000000e+00,\n",
       "          8.03208590e-01, 0.00000000e+00, 2.46434882e-01, 0.00000000e+00,\n",
       "          7.41334334e-02, 4.36289549e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.88487035e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 2.57358402e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.09472471e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.12596446e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          8.57430696e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.56666100e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 7.33834147e-01, 0.00000000e+00, 4.55186665e-02,\n",
       "          5.39020419e-01, 5.23189962e-01, 0.00000000e+00, 5.68674982e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.37699035e-02, 0.00000000e+00,\n",
       "          1.34138918e+00, 0.00000000e+00, 1.21509612e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.95983982e-01, 1.49924248e-01,\n",
       "          0.00000000e+00, 9.61053848e-01, 3.37585360e-01, 5.11485003e-02,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          7.49806702e-01, 0.00000000e+00, 6.95339441e-01, 4.41888347e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          6.90402687e-01, 0.00000000e+00, 1.18889034e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.49863106e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.57669917e-01, 0.00000000e+00,\n",
       "          9.60615873e-01, 3.27660441e-02, 0.00000000e+00, 4.73058045e-01,\n",
       "          6.36683941e-01, 2.67754018e-01, 0.00000000e+00, 4.12232637e-01,\n",
       "          8.52634788e-01, 0.00000000e+00, 0.00000000e+00, 1.51429921e-01,\n",
       "          3.25333953e-01, 0.00000000e+00, 5.91532648e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.65105426e-01,\n",
       "          0.00000000e+00, 9.63106096e-01, 2.22860724e-02, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.67822748e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          4.93229598e-01, 2.12817430e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.36062369e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.62247330e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.89694721e-01, 0.00000000e+00,\n",
       "          4.79051650e-01, 9.33926582e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          9.82301831e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.84822226e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          8.27549756e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.21303535e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 3.58914167e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.31658280e-01,\n",
       "          8.96138310e-01, 4.70804930e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.28203049e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.37167978e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.37105107e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.68631077e-01, 6.55664027e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.58956283e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 2.13296384e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.10566609e-01, 2.15972587e-02, 0.00000000e+00,\n",
       "          1.80911720e-01, 7.49764919e-01, 9.52875912e-01, 3.20972711e-01,\n",
       "          4.03352112e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.93867922e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.33141643e-02, 3.02829742e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.82845344e-02, 0.00000000e+00, 5.14710188e-01,\n",
       "          4.65285063e-01, 0.00000000e+00, 8.98604393e-01, 1.65443510e-01,\n",
       "          1.67683795e-01, 0.00000000e+00, 0.00000000e+00, 2.13208809e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.30295777e-01, 5.59274033e-02,\n",
       "          4.48718429e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          6.46299496e-02, 0.00000000e+00, 0.00000000e+00, 2.57248133e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.01489097e-02,\n",
       "          0.00000000e+00, 5.09461761e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          4.77193221e-02, 0.00000000e+00, 0.00000000e+00, 3.69444191e-01,\n",
       "          0.00000000e+00, 1.00916773e-01, 0.00000000e+00, 6.41692281e-01,\n",
       "          0.00000000e+00, 3.52169782e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.32621062e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.30571023e-01, 0.00000000e+00, 0.00000000e+00, 1.91277325e-01,\n",
       "          5.50130963e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.49999470e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.48398799e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          8.09351385e-01, 9.72408503e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "          2.51364291e-01, 2.84522176e-01, 9.76925552e-01, 3.23105156e-01,\n",
       "          2.16498271e-01, 1.24991089e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.73339725e-01,\n",
       "          9.45288897e-01, 0.00000000e+00, 0.00000000e+00, 7.92165339e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 8.67510021e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.89118111e-01, 8.98878813e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.46410823e-01, 5.94007909e-01,\n",
       "          2.07068160e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          3.43828350e-01, 0.00000000e+00, 0.00000000e+00, 5.70205986e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.05640268e-01, 1.49974418e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.81277227e-03,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.67921968e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.30374789e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.02165535e-01,\n",
       "          0.00000000e+00, 3.95707011e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 4.30398136e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          5.44968665e-01, 4.46684569e-01, 3.40545028e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.89576185e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.23132026e+00, 3.33780646e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.15183294e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.12213862e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.04467762e+00,\n",
       "          5.83261997e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.29508495e-01, 0.00000000e+00, 8.71041059e-01,\n",
       "          6.24664426e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.98953295e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.97399050e-01, 1.91373639e-02,\n",
       "          1.11899473e-01, 1.28945470e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.14172804e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 1.01253748e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.86443913e-01, 0.00000000e+00,\n",
       "          1.54861689e-01, 0.00000000e+00, 5.34021914e-01, 0.00000000e+00,\n",
       "          1.66077510e-01, 0.00000000e+00, 2.92775661e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          5.40449619e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          6.78576648e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.68456572e-01, 0.00000000e+00,\n",
       "          4.01719660e-03, 5.95792413e-01, 6.88651621e-01, 1.22351289e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.30844945e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.28626549e-01,\n",
       "          1.39021695e-01, 5.69207013e-01, 2.12940961e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.42611241e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.20633829e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          2.57226229e-01, 1.19196117e-01, 3.81604165e-01, 3.93406957e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.67278862e-01, 0.00000000e+00, 2.70179391e-01,\n",
       "          4.60182726e-01, 0.00000000e+00, 1.25300080e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.04929566e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          6.67284250e-01, 5.38968623e-01, 4.12701070e-01, 7.78842330e-01,\n",
       "          9.41720128e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 8.26805413e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.98998255e-01, 0.00000000e+00,\n",
       "          1.46856636e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.10215759e-04, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.94761798e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.35961330e-01, 0.00000000e+00, 8.10563684e-01,\n",
       "          0.00000000e+00, 1.07713366e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.86802268e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          2.22133160e-01, 0.00000000e+00, 0.00000000e+00, 2.22831219e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         dtype=float32),\n",
       "   'pca': array([-0.59288067, -0.758985  ], dtype=float32),\n",
       "   'mahalanobisDistance': 21777363.56394911}},\n",
       " 'symptoms': {'treated': {'ids': [1091,\n",
       "    1114,\n",
       "    1445,\n",
       "    605,\n",
       "    1313,\n",
       "    1124,\n",
       "    361,\n",
       "    461,\n",
       "    277,\n",
       "    1309],\n",
       "   'dists': [48.317201610682666,\n",
       "    48.47657728650545,\n",
       "    48.87702204390621,\n",
       "    49.03169140688463,\n",
       "    49.16342763346124,\n",
       "    49.29129695172902,\n",
       "    49.29173611348111,\n",
       "    49.35440523970693,\n",
       "    49.47347895424199,\n",
       "    49.477092298684596],\n",
       "   'symptoms': {'choke': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [3.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.3333333333333333, 2.0, 0.0, 0.14285714285714285]},\n",
       "    'drymouth': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, 9.0, 5.0],\n",
       "      [0.0, 8.0, 4.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, 8.0],\n",
       "      [3.0, 5.0, 3.0, -1.0],\n",
       "      [1.0, 2.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, 5.0, 3.0],\n",
       "      [0.0, 1.0, 1.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 4.6, 4.4, 3.2857142857142856]},\n",
       "    'fatigue': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, 4.0, 3.0],\n",
       "      [0.0, 8.0, 2.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, 1.0],\n",
       "      [2.0, 6.0, 3.0, -1.0],\n",
       "      [0.0, 2.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 4.6, 1.8, 0.8571428571428571]},\n",
       "    'mucus': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 6.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 8.0],\n",
       "      [1.0, 4.0, 8.0, -1.0],\n",
       "      [0.0, 1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 4.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 5.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.1111111111111111, 4.2, 3.2, 2.142857142857143]},\n",
       "    'nausea': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 3.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 4.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.0, 1.4, 0.0, 0.14285714285714285]},\n",
       "    'skin': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 8.0, 2.0, -1.0],\n",
       "      [0.0, 3.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.0, 2.2, 0.4, 0.0]},\n",
       "    'swallow': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 3.0, 1.0],\n",
       "      [0.0, 8.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [3.0, 4.0, 8.0, -1.0],\n",
       "      [0.0, 2.0, -1.0, 1.0],\n",
       "      [10.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 3.0],\n",
       "      [0.0, -1.0, 2.0, 1.0],\n",
       "      [1.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [1.5555555555555556, 4.8, 2.6, 0.8571428571428571]},\n",
       "    'taste': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 7.0, 6.0],\n",
       "      [0.0, 9.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 1.0],\n",
       "      [0.0, -1.0, 2.0, -1.0],\n",
       "      [0.0, 9.0, -1.0, 4.0],\n",
       "      [0.0, -1.0, -1.0, 5.0],\n",
       "      [-1.0, -1.0, -1.0, 7.0],\n",
       "      [0.0, -1.0, 4.0, 7.0],\n",
       "      [0.0, 5.0, 2.0, 0.0]],\n",
       "     'means': [0.0, 8.25, 3.0, 4.285714285714286]},\n",
       "    'teeth': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 3.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [8.0, 8.0, 7.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.8888888888888888, 2.75, 1.4, 0.0]},\n",
       "    'mood': {'ratings': [[0.0, 5.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, 2.0, 0.0],\n",
       "      [3.0, 2.0, 2.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, 5.0, 0.0, -1.0],\n",
       "      [1.0, 0.0, -1.0, 0.0],\n",
       "      [1.0, -1.0, -1.0, 2.0],\n",
       "      [-1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, 0.0, 0.0],\n",
       "      [0.0, 0.0, 0.0, 0.0]],\n",
       "     'means': [0.6666666666666666, 2.4, 0.8, 0.2857142857142857]}}},\n",
       "  'untreated': {'ids': [1237,\n",
       "    1543,\n",
       "    1565,\n",
       "    1560,\n",
       "    1326,\n",
       "    496,\n",
       "    1563,\n",
       "    553,\n",
       "    840,\n",
       "    1261],\n",
       "   'dists': [47.4503453343392,\n",
       "    47.64292676522173,\n",
       "    47.6950861770574,\n",
       "    48.48788282406037,\n",
       "    48.905936485619705,\n",
       "    48.94186213926406,\n",
       "    48.99010610993625,\n",
       "    49.0184394363471,\n",
       "    49.14272153527371,\n",
       "    49.33538305999806],\n",
       "   'symptoms': {'choke': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 4.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, -1.0]],\n",
       "     'means': [0.0, 1.0, 0.25, 0.0]},\n",
       "    'drymouth': {'ratings': [[0.0, 5.0, 2.0, -1.0],\n",
       "      [-1.0, -1.0, 6.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, 7.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [7.0, -1.0, -1.0, -1.0],\n",
       "      [4.0, 10.0, 9.0, -1.0]],\n",
       "     'means': [1.625, 5.0, 4.25, 2.3333333333333335]},\n",
       "    'fatigue': {'ratings': [[0.0, 4.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 6.0, -1.0, -1.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [6.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [1.625, 4.75, 2.75, 1.6666666666666667]},\n",
       "    'mucus': {'ratings': [[0.0, 3.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 6.0, -1.0, -1.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [9.0, 10.0, 0.0, -1.0]],\n",
       "     'means': [1.625, 4.75, 0.25, 0.0]},\n",
       "    'nausea': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 2.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, -1.0]],\n",
       "     'means': [0.125, 0.5, 0.25, 0.0]},\n",
       "    'skin': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "      [-1.0, -1.0, 0.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 2.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [2.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, 10.0, 9.0, -1.0]],\n",
       "     'means': [0.5, 4.25, 2.25, 0.0]},\n",
       "    'swallow': {'ratings': [[0.0, 1.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [1.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 1.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 2.0],\n",
       "      [1.0, -1.0, -1.0, 1.0],\n",
       "      [-1.0, 7.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, -1.0],\n",
       "      [8.0, 6.0, 5.0, -1.0]],\n",
       "     'means': [1.625, 3.75, 2.75, 1.0]},\n",
       "    'taste': {'ratings': [[0.0, 10.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 7.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 2.0, 2.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 5.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 8.0, -1.0, -1.0],\n",
       "      [9.0, -1.0, -1.0, -1.0],\n",
       "      [2.0, 9.0, 8.0, -1.0]],\n",
       "     'means': [1.375, 7.25, 5.0, 2.3333333333333335]},\n",
       "    'teeth': {'ratings': [[0.0, 1.0, 1.0, -1.0],\n",
       "      [-1.0, -1.0, 1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 2.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 2.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [0.0, 3.0, 1.75, 0.6666666666666666]},\n",
       "    'mood': {'ratings': [[0.0, 0.0, 3.0, -1.0],\n",
       "      [-1.0, -1.0, 3.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, 0.0, 0.0, 0.0],\n",
       "      [4.0, -1.0, -1.0, -1.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [0.0, -1.0, -1.0, 0.0],\n",
       "      [-1.0, 5.0, -1.0, -1.0],\n",
       "      [3.0, -1.0, -1.0, -1.0],\n",
       "      [8.0, 9.0, 5.0, -1.0]],\n",
       "     'means': [1.875, 3.5, 2.75, 0.0]}}},\n",
       "  'dates': [0, 7, 12, 27]}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time()\n",
    "test_patient= get_test_patient(data,7,False)\n",
    "test_results = get_stuff_for_patient(test_patient,data,\n",
    "                                     transition_model1,\n",
    "                                     transition_model2,\n",
    "                                     outcome_model,\n",
    "                                     decision_model,\n",
    "                                     survival_model,\n",
    "                                     symptom_model=sp,\n",
    "                                     mdasi_data=mdasi,\n",
    "                                     state=1,\n",
    "                                     max_neighbors=2,\n",
    "                                     model_type='both',\n",
    "                                    )\n",
    "t2 = time()\n",
    "print(t2-t1)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65adac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'treated': {'ids': [1091, 1114, 1445, 605, 1313, 1124, 361, 461, 277, 1309],\n",
       "  'dists': [48.317201610682666,\n",
       "   48.47657728650545,\n",
       "   48.87702204390621,\n",
       "   49.03169140688463,\n",
       "   49.16342763346124,\n",
       "   49.29129695172902,\n",
       "   49.29173611348111,\n",
       "   49.35440523970693,\n",
       "   49.47347895424199,\n",
       "   49.477092298684596],\n",
       "  'symptoms': {'choke': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [3.0, 0.0, 0.0, -1.0],\n",
       "     [0.0, 0.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.3333333333333333, 2.0, 0.0, 0.14285714285714285]},\n",
       "   'drymouth': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "     [1.0, -1.0, 9.0, 5.0],\n",
       "     [0.0, 8.0, 4.0, -1.0],\n",
       "     [1.0, -1.0, -1.0, 8.0],\n",
       "     [3.0, 5.0, 3.0, -1.0],\n",
       "     [1.0, 2.0, -1.0, 2.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 5.0],\n",
       "     [0.0, -1.0, 5.0, 3.0],\n",
       "     [0.0, 1.0, 1.0, 0.0]],\n",
       "    'means': [0.6666666666666666, 4.6, 4.4, 3.2857142857142856]},\n",
       "   'fatigue': {'ratings': [[0.0, 7.0, -1.0, -1.0],\n",
       "     [2.0, -1.0, 4.0, 3.0],\n",
       "     [0.0, 8.0, 2.0, -1.0],\n",
       "     [2.0, -1.0, -1.0, 1.0],\n",
       "     [2.0, 6.0, 3.0, -1.0],\n",
       "     [0.0, 2.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 2.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.6666666666666666, 4.6, 1.8, 0.8571428571428571]},\n",
       "   'mucus': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 6.0, 3.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 8.0],\n",
       "     [1.0, 4.0, 8.0, -1.0],\n",
       "     [0.0, 1.0, -1.0, 2.0],\n",
       "     [0.0, -1.0, -1.0, 4.0],\n",
       "     [-1.0, -1.0, -1.0, 1.0],\n",
       "     [0.0, -1.0, 5.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.1111111111111111, 4.2, 3.2, 2.142857142857143]},\n",
       "   'nausea': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 3.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, 4.0, 0.0, -1.0],\n",
       "     [0.0, 0.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.0, 1.4, 0.0, 0.14285714285714285]},\n",
       "   'skin': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, 8.0, 2.0, -1.0],\n",
       "     [0.0, 3.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, 0.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.0, 2.2, 0.4, 0.0]},\n",
       "   'swallow': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 3.0, 1.0],\n",
       "     [0.0, 8.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [3.0, 4.0, 8.0, -1.0],\n",
       "     [0.0, 2.0, -1.0, 1.0],\n",
       "     [10.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 3.0],\n",
       "     [0.0, -1.0, 2.0, 1.0],\n",
       "     [1.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [1.5555555555555556, 4.8, 2.6, 0.8571428571428571]},\n",
       "   'taste': {'ratings': [[0.0, 10.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 7.0, 6.0],\n",
       "     [0.0, 9.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 1.0],\n",
       "     [0.0, -1.0, 2.0, -1.0],\n",
       "     [0.0, 9.0, -1.0, 4.0],\n",
       "     [0.0, -1.0, -1.0, 5.0],\n",
       "     [-1.0, -1.0, -1.0, 7.0],\n",
       "     [0.0, -1.0, 4.0, 7.0],\n",
       "     [0.0, 5.0, 2.0, 0.0]],\n",
       "    'means': [0.0, 8.25, 3.0, 4.285714285714286]},\n",
       "   'teeth': {'ratings': [[0.0, 0.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 3.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [8.0, 8.0, 7.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.8888888888888888, 2.75, 1.4, 0.0]},\n",
       "   'mood': {'ratings': [[0.0, 5.0, -1.0, -1.0],\n",
       "     [1.0, -1.0, 2.0, 0.0],\n",
       "     [3.0, 2.0, 2.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, 5.0, 0.0, -1.0],\n",
       "     [1.0, 0.0, -1.0, 0.0],\n",
       "     [1.0, -1.0, -1.0, 2.0],\n",
       "     [-1.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, 0.0, 0.0],\n",
       "     [0.0, 0.0, 0.0, 0.0]],\n",
       "    'means': [0.6666666666666666, 2.4, 0.8, 0.2857142857142857]}}},\n",
       " 'untreated': {'ids': [1237,\n",
       "   1543,\n",
       "   1565,\n",
       "   1560,\n",
       "   1326,\n",
       "   496,\n",
       "   1563,\n",
       "   553,\n",
       "   840,\n",
       "   1261],\n",
       "  'dists': [47.4503453343392,\n",
       "   47.64292676522173,\n",
       "   47.6950861770574,\n",
       "   48.48788282406037,\n",
       "   48.905936485619705,\n",
       "   48.94186213926406,\n",
       "   48.99010610993625,\n",
       "   49.0184394363471,\n",
       "   49.14272153527371,\n",
       "   49.33538305999806],\n",
       "  'symptoms': {'choke': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "     [-1.0, -1.0, 1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 4.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, -1.0]],\n",
       "    'means': [0.0, 1.0, 0.25, 0.0]},\n",
       "   'drymouth': {'ratings': [[0.0, 5.0, 2.0, -1.0],\n",
       "     [-1.0, -1.0, 6.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [2.0, -1.0, -1.0, 7.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 5.0, -1.0, -1.0],\n",
       "     [7.0, -1.0, -1.0, -1.0],\n",
       "     [4.0, 10.0, 9.0, -1.0]],\n",
       "    'means': [1.625, 5.0, 4.25, 2.3333333333333335]},\n",
       "   'fatigue': {'ratings': [[0.0, 4.0, 3.0, -1.0],\n",
       "     [-1.0, -1.0, 3.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [3.0, -1.0, -1.0, 5.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 6.0, -1.0, -1.0],\n",
       "     [4.0, -1.0, -1.0, -1.0],\n",
       "     [6.0, 9.0, 5.0, -1.0]],\n",
       "    'means': [1.625, 4.75, 2.75, 1.6666666666666667]},\n",
       "   'mucus': {'ratings': [[0.0, 3.0, 0.0, -1.0],\n",
       "     [-1.0, -1.0, 1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 6.0, -1.0, -1.0],\n",
       "     [4.0, -1.0, -1.0, -1.0],\n",
       "     [9.0, 10.0, 0.0, -1.0]],\n",
       "    'means': [1.625, 4.75, 0.25, 0.0]},\n",
       "   'nausea': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "     [-1.0, -1.0, 1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [1.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 2.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, -1.0]],\n",
       "    'means': [0.125, 0.5, 0.25, 0.0]},\n",
       "   'skin': {'ratings': [[0.0, 0.0, 0.0, -1.0],\n",
       "     [-1.0, -1.0, 0.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 2.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 5.0, -1.0, -1.0],\n",
       "     [2.0, -1.0, -1.0, -1.0],\n",
       "     [2.0, 10.0, 9.0, -1.0]],\n",
       "    'means': [0.5, 4.25, 2.25, 0.0]},\n",
       "   'swallow': {'ratings': [[0.0, 1.0, 3.0, -1.0],\n",
       "     [-1.0, -1.0, 3.0, -1.0],\n",
       "     [1.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 1.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 2.0],\n",
       "     [1.0, -1.0, -1.0, 1.0],\n",
       "     [-1.0, 7.0, -1.0, -1.0],\n",
       "     [3.0, -1.0, -1.0, -1.0],\n",
       "     [8.0, 6.0, 5.0, -1.0]],\n",
       "    'means': [1.625, 3.75, 2.75, 1.0]},\n",
       "   'taste': {'ratings': [[0.0, 10.0, 3.0, -1.0],\n",
       "     [-1.0, -1.0, 7.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 2.0, 2.0, 2.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 5.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 8.0, -1.0, -1.0],\n",
       "     [9.0, -1.0, -1.0, -1.0],\n",
       "     [2.0, 9.0, 8.0, -1.0]],\n",
       "    'means': [1.375, 7.25, 5.0, 2.3333333333333335]},\n",
       "   'teeth': {'ratings': [[0.0, 1.0, 1.0, -1.0],\n",
       "     [-1.0, -1.0, 1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 2.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 2.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 9.0, 5.0, -1.0]],\n",
       "    'means': [0.0, 3.0, 1.75, 0.6666666666666666]},\n",
       "   'mood': {'ratings': [[0.0, 0.0, 3.0, -1.0],\n",
       "     [-1.0, -1.0, 3.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, 0.0, 0.0, 0.0],\n",
       "     [4.0, -1.0, -1.0, -1.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [0.0, -1.0, -1.0, 0.0],\n",
       "     [-1.0, 5.0, -1.0, -1.0],\n",
       "     [3.0, -1.0, -1.0, -1.0],\n",
       "     [8.0, 9.0, 5.0, -1.0]],\n",
       "    'means': [1.875, 3.5, 2.75, 0.0]}}},\n",
       " 'dates': [0, 7, 12, 27]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['symptoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4f29af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimal': {'Decision 1 (Induction Chemo) Y/N': 0.038047604,\n",
       "  'Decision 2 (CC / RT alone)': 0.046430662,\n",
       "  'Decision 3 Neck Dissection (Y/N)': 0.90782195},\n",
       " 'imitation': {'Decision 1 (Induction Chemo) Y/N': 0.77922934,\n",
       "  'Decision 2 (CC / RT alone)': 0.18129703,\n",
       "  'Decision 3 Neck Dissection (Y/N)': 0.23397787}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_default_predictions(dm):\n",
    "#     res  = []\n",
    "#     for state in [0,1,2]:\n",
    "#         if hasattr(dm,'memory'):\n",
    "#             mem = dm.memory[state]\n",
    "#             mem = torch.median(mem,dim=0)[0].type(torch.FloatTensor)\n",
    "#             val = dm(mem.reshape(1,-1),position=state)\n",
    "#         else:\n",
    "#         res.append(val.cpu().detach().numpy())\n",
    "#     return np.vstack(res)\n",
    "\n",
    "def get_default_predictions(dm,dataset):\n",
    "    res = []\n",
    "    for state in [0,1,2]:\n",
    "        xin = get_default_input(dataset,state)[0]\n",
    "        xin = dict_to_model_input(dataset,xin,state).to(dm.get_device())\n",
    "        val = dm(xin,position=state)\n",
    "        res.append(val.cpu().detach().numpy())\n",
    "    return np.vstack(res)\n",
    "\n",
    "def get_default_prediction_json(dm,dataset):\n",
    "    vals = get_default_predictions(dm,dataset)\n",
    "    res={}\n",
    "    for i,model in enumerate(['optimal','imitation']):\n",
    "        entry = {}\n",
    "        for state,decision in enumerate(Const.decisions):\n",
    "            val = vals[state, state + (3*i)]\n",
    "            entry[decision] = val\n",
    "        res[model] = entry\n",
    "    return res\n",
    "\n",
    "get_default_prediction_json(decision_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87995787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def np_converter(obj):\n",
    "    #converts stuff to vanilla python  for json since it gives an error with np.int64 and arrays\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.float32):\n",
    "        return np.round(float(obj),3)\n",
    "    elif isinstance(obj, float):\n",
    "        return round(float(obj),3)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, datetime.datetime) or isinstance(obj, datetime.time):\n",
    "        return obj.__str__()\n",
    "    print('np_converter cant encode obj of type', obj,type(obj))\n",
    "    return obj\n",
    "\n",
    "import simplejson\n",
    "keys = ['outcomes','pd1','nd1','decision1','decision1_attention','decision2_attention']\n",
    "simplejson.dumps(test_results,default=np_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_results['optimal']['decision1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['optimal'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PseudoCode for treating the patient\n",
    "def getGroup(isTreated,candidates, new_patient_propensity, minimum_group_size,caliper_distance_base,scale_increment):\n",
    "    ##gets patients in the treated or untreated group that have a propensity similar to new_patient_propensity\n",
    "    group = []\n",
    "    caliper_distance_scale = scale_increment\n",
    "    #gradually increase caliper size until we have minimum_group_size patients or we run out of candidates\n",
    "    while len(group) < minimum_group_size and len(candidates) > 1:\n",
    "        #update caliper distance\n",
    "        caliper_distance = caliper_distance_base*caliper_distance_scale\n",
    "        for patient in candidates:\n",
    "            #check if the patient is in the treated group and has a close enough similarity score\n",
    "            if patient.treatment == isTreated and absolute_value(new_patient_propensity - patient.propensity) < caliper_distance:\n",
    "                #avoid repeating patients in subsequent loops\n",
    "                delete patient from candidates\n",
    "                #add patient to group if they are valid\n",
    "                group.push(patient)\n",
    "        #update caliper distance by scale_increment %\n",
    "        caliper_distance_scale = caliper_distance_scale*scale_increment\n",
    "    return group\n",
    "        \n",
    "def getNeighbors(cohort,new_patient_propensity, similiarity_filter_size, minimum_group_size, caliper_distance_scale, scale_increment):\n",
    "    #filter out the top patients by similarity\n",
    "    cohort = sort(cohort, key = lambda paient: patient.similarity_with_new_patient)\n",
    "    cohort = cohort[0:similarity_filter_size]\n",
    "    \n",
    "    #calculate the standard deviation of the logit of the propensity scores of the cohort\n",
    "    cohort_propensities = [patient.propensity for patient in cohort]\n",
    "    caliper_distance_base = standard_deviation(logit(cohort_propensities))\n",
    "    caliper_distance_scale = .1\n",
    "    \n",
    "    #calculate treated and untreated groups with scaling propensity independently\n",
    "    treated_group = getGroup(True, copy(cohort), *args)\n",
    "    untreated_group = getGroup(False, copy(cohort), *args)\n",
    "    return treated_group, untreated_group\n",
    "\n",
    "def localAverageTreatementEffect(outcome, *args):\n",
    "    treated_group, untreated_group = getNeighbors(*args)\n",
    "    treated_average = mean([patient[outcome] for patient in treated_group])\n",
    "    untreated_average = mean([patient[outcome] for patient in untreated_group])\n",
    "    return treated_average - untreated_average"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
